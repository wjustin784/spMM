/* Generated by Cython 3.1.6 */

/* BEGIN: Cython Metadata
{
    "distutils": {
        "define_macros": [
            [
                "_FORCE_INLINES",
                "1"
            ],
            [
                "CYTHON_EXTERN_C",
                "extern \"C\""
            ],
            [
                "CUPY_CACHE_KEY",
                "844d2e751011a75cff941997e1c6e0c687f0ac87"
            ],
            [
                "CUPY_CUB_VERSION_CODE",
                200800
            ],
            [
                "CUPY_JITIFY_VERSION_CODE",
                "1a0ca0e"
            ]
        ],
        "depends": [
            "cupy/cuda/cupy_cufft.h",
            "cupy/cuda/cupy_cufftXt.h"
        ],
        "extra_link_args": [
            "-Wl,--disable-new-dtags,-rpath,/usr/local/cuda/lib64"
        ],
        "extra_objects": [
            "/usr/local/cuda/lib64/libcudart_static.a"
        ],
        "include_dirs": [
            "cupy/cuda",
            "/home/chenwei/spMM/modify_src/cupy-src/cupy/_core/include/cupy/_cccl/libcudacxx",
            "/home/chenwei/spMM/modify_src/cupy-src/cupy/_core/include/cupy/_cccl/thrust",
            "/home/chenwei/spMM/modify_src/cupy-src/cupy/_core/include/cupy/_cccl/cub",
            "/home/chenwei/spMM/modify_src/cupy-src/cupy/_core/include",
            "/usr/local/cuda/include"
        ],
        "language": "c++",
        "libraries": [
            "pthread",
            "rt",
            "dl",
            "cublas",
            "cufft",
            "curand",
            "cusparse"
        ],
        "library_dirs": [
            "/usr/local/cuda/lib64"
        ],
        "name": "cupy.cuda.cufft",
        "sources": [
            "cupy/cuda/cufft.pyx"
        ]
    },
    "module_name": "cupy.cuda.cufft"
}
END: Cython Metadata */

#ifndef PY_SSIZE_T_CLEAN
#define PY_SSIZE_T_CLEAN
#endif /* PY_SSIZE_T_CLEAN */
/* InitLimitedAPI */
#if defined(Py_LIMITED_API)
  #if !defined(CYTHON_LIMITED_API)
  #define CYTHON_LIMITED_API 1
  #endif
#elif defined(CYTHON_LIMITED_API)
  #ifdef _MSC_VER
  #pragma message ("Limited API usage is enabled with 'CYTHON_LIMITED_API' but 'Py_LIMITED_API' does not define a Python target version. Consider setting 'Py_LIMITED_API' instead.")
  #else
  #warning Limited API usage is enabled with 'CYTHON_LIMITED_API' but 'Py_LIMITED_API' does not define a Python target version. Consider setting 'Py_LIMITED_API' instead.
  #endif
#endif

#include "Python.h"
#ifndef Py_PYTHON_H
    #error Python headers needed to compile C extensions, please install development version of Python.
#elif PY_VERSION_HEX < 0x03080000
    #error Cython requires Python 3.8+.
#else
#define __PYX_ABI_VERSION "3_1_6"
#define CYTHON_HEX_VERSION 0x030106F0
#define CYTHON_FUTURE_DIVISION 1
/* CModulePreamble */
#include <stddef.h>
#ifndef offsetof
  #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
#endif
#if !defined(_WIN32) && !defined(WIN32) && !defined(MS_WINDOWS)
  #ifndef __stdcall
    #define __stdcall
  #endif
  #ifndef __cdecl
    #define __cdecl
  #endif
  #ifndef __fastcall
    #define __fastcall
  #endif
#endif
#ifndef DL_IMPORT
  #define DL_IMPORT(t) t
#endif
#ifndef DL_EXPORT
  #define DL_EXPORT(t) t
#endif
#define __PYX_COMMA ,
#ifndef HAVE_LONG_LONG
  #define HAVE_LONG_LONG
#endif
#ifndef PY_LONG_LONG
  #define PY_LONG_LONG LONG_LONG
#endif
#ifndef Py_HUGE_VAL
  #define Py_HUGE_VAL HUGE_VAL
#endif
#define __PYX_LIMITED_VERSION_HEX PY_VERSION_HEX
#if defined(GRAALVM_PYTHON)
  /* For very preliminary testing purposes. Most variables are set the same as PyPy.
     The existence of this section does not imply that anything works or is even tested */
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #define CYTHON_COMPILING_IN_LIMITED_API 0
  #define CYTHON_COMPILING_IN_GRAAL 1
  #define CYTHON_COMPILING_IN_CPYTHON_FREETHREADING 0
  #undef CYTHON_USE_TYPE_SLOTS
  #define CYTHON_USE_TYPE_SLOTS 0
  #undef CYTHON_USE_TYPE_SPECS
  #define CYTHON_USE_TYPE_SPECS 0
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #undef CYTHON_USE_UNICODE_INTERNALS
  #define CYTHON_USE_UNICODE_INTERNALS 0
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #undef CYTHON_AVOID_BORROWED_REFS
  #define CYTHON_AVOID_BORROWED_REFS 1
  #undef CYTHON_AVOID_THREAD_UNSAFE_BORROWED_REFS
  #define CYTHON_AVOID_THREAD_UNSAFE_BORROWED_REFS 1
  #undef CYTHON_ASSUME_SAFE_MACROS
  #define CYTHON_ASSUME_SAFE_MACROS 0
  #undef CYTHON_ASSUME_SAFE_SIZE
  #define CYTHON_ASSUME_SAFE_SIZE 0
  #undef CYTHON_UNPACK_METHODS
  #define CYTHON_UNPACK_METHODS 0
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_GIL
  #define CYTHON_FAST_GIL 0
  #undef CYTHON_METH_FASTCALL
  #define CYTHON_METH_FASTCALL 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #ifndef CYTHON_PEP487_INIT_SUBCLASS
    #define CYTHON_PEP487_INIT_SUBCLASS 1
  #endif
  #undef CYTHON_PEP489_MULTI_PHASE_INIT
  #define CYTHON_PEP489_MULTI_PHASE_INIT 1
  #undef CYTHON_USE_MODULE_STATE
  #define CYTHON_USE_MODULE_STATE 0
  #undef CYTHON_USE_SYS_MONITORING
  #define CYTHON_USE_SYS_MONITORING 0
  #undef CYTHON_USE_TP_FINALIZE
  #define CYTHON_USE_TP_FINALIZE 0
  #undef CYTHON_USE_AM_SEND
  #define CYTHON_USE_AM_SEND 0
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 1
  #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
    #define CYTHON_UPDATE_DESCRIPTOR_DOC 0
  #endif
  #undef CYTHON_USE_FREELISTS
  #define CYTHON_USE_FREELISTS 0
#elif defined(PYPY_VERSION)
  #define CYTHON_COMPILING_IN_PYPY 1
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #define CYTHON_COMPILING_IN_LIMITED_API 0
  #define CYTHON_COMPILING_IN_GRAAL 0
  #define CYTHON_COMPILING_IN_CPYTHON_FREETHREADING 0
  #undef CYTHON_USE_TYPE_SLOTS
  #define CYTHON_USE_TYPE_SLOTS 1
  #ifndef CYTHON_USE_TYPE_SPECS
    #define CYTHON_USE_TYPE_SPECS 0
  #endif
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #undef CYTHON_USE_UNICODE_INTERNALS
  #define CYTHON_USE_UNICODE_INTERNALS 0
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #undef CYTHON_AVOID_BORROWED_REFS
  #define CYTHON_AVOID_BORROWED_REFS 1
  #undef CYTHON_AVOID_THREAD_UNSAFE_BORROWED_REFS
  #define CYTHON_AVOID_THREAD_UNSAFE_BORROWED_REFS 1
  #undef CYTHON_ASSUME_SAFE_MACROS
  #define CYTHON_ASSUME_SAFE_MACROS 0
  #ifndef CYTHON_ASSUME_SAFE_SIZE
    #define CYTHON_ASSUME_SAFE_SIZE 1
  #endif
  #undef CYTHON_UNPACK_METHODS
  #define CYTHON_UNPACK_METHODS 0
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_GIL
  #define CYTHON_FAST_GIL 0
  #undef CYTHON_METH_FASTCALL
  #define CYTHON_METH_FASTCALL 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #ifndef CYTHON_PEP487_INIT_SUBCLASS
    #define CYTHON_PEP487_INIT_SUBCLASS 1
  #endif
  #if PY_VERSION_HEX < 0x03090000
    #undef CYTHON_PEP489_MULTI_PHASE_INIT
    #define CYTHON_PEP489_MULTI_PHASE_INIT 0
  #elif !defined(CYTHON_PEP489_MULTI_PHASE_INIT)
    #define CYTHON_PEP489_MULTI_PHASE_INIT 1
  #endif
  #undef CYTHON_USE_MODULE_STATE
  #define CYTHON_USE_MODULE_STATE 0
  #undef CYTHON_USE_SYS_MONITORING
  #define CYTHON_USE_SYS_MONITORING 0
  #ifndef CYTHON_USE_TP_FINALIZE
    #define CYTHON_USE_TP_FINALIZE (PYPY_VERSION_NUM >= 0x07030C00)
  #endif
  #undef CYTHON_USE_AM_SEND
  #define CYTHON_USE_AM_SEND 0
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
  #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
    #define CYTHON_UPDATE_DESCRIPTOR_DOC (PYPY_VERSION_NUM >= 0x07031100)
  #endif
  #undef CYTHON_USE_FREELISTS
  #define CYTHON_USE_FREELISTS 0
#elif defined(CYTHON_LIMITED_API)
  #ifdef Py_LIMITED_API
    #undef __PYX_LIMITED_VERSION_HEX
    #define __PYX_LIMITED_VERSION_HEX Py_LIMITED_API
  #endif
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #define CYTHON_COMPILING_IN_LIMITED_API 1
  #define CYTHON_COMPILING_IN_GRAAL 0
  #define CYTHON_COMPILING_IN_CPYTHON_FREETHREADING 0
  #undef CYTHON_CLINE_IN_TRACEBACK
  #define CYTHON_CLINE_IN_TRACEBACK 0
  #undef CYTHON_USE_TYPE_SLOTS
  #define CYTHON_USE_TYPE_SLOTS 0
  #undef CYTHON_USE_TYPE_SPECS
  #define CYTHON_USE_TYPE_SPECS 1
  #undef CYTHON_USE_PYTYPE_LOOKUP
  #define CYTHON_USE_PYTYPE_LOOKUP 0
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #undef CYTHON_USE_UNICODE_INTERNALS
  #define CYTHON_USE_UNICODE_INTERNALS 0
  #ifndef CYTHON_USE_UNICODE_WRITER
    #define CYTHON_USE_UNICODE_WRITER 0
  #endif
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_AVOID_THREAD_UNSAFE_BORROWED_REFS
    #define CYTHON_AVOID_THREAD_UNSAFE_BORROWED_REFS 0
  #endif
  #undef CYTHON_ASSUME_SAFE_MACROS
  #define CYTHON_ASSUME_SAFE_MACROS 0
  #undef CYTHON_ASSUME_SAFE_SIZE
  #define CYTHON_ASSUME_SAFE_SIZE 0
  #undef CYTHON_UNPACK_METHODS
  #define CYTHON_UNPACK_METHODS 0
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_GIL
  #define CYTHON_FAST_GIL 0
  #undef CYTHON_METH_FASTCALL
  #define CYTHON_METH_FASTCALL (__PYX_LIMITED_VERSION_HEX >= 0x030C0000)
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
  #ifndef CYTHON_PEP487_INIT_SUBCLASS
    #define CYTHON_PEP487_INIT_SUBCLASS 1
  #endif
  #ifndef CYTHON_PEP489_MULTI_PHASE_INIT
    #define CYTHON_PEP489_MULTI_PHASE_INIT 1
  #endif
  #ifndef CYTHON_USE_MODULE_STATE
    #define CYTHON_USE_MODULE_STATE 0
  #endif
  #undef CYTHON_USE_SYS_MONITORING
  #define CYTHON_USE_SYS_MONITORING 0
  #ifndef CYTHON_USE_TP_FINALIZE
    #define CYTHON_USE_TP_FINALIZE 0
  #endif
  #ifndef CYTHON_USE_AM_SEND
    #define CYTHON_USE_AM_SEND (__PYX_LIMITED_VERSION_HEX >= 0x030A0000)
  #endif
  #undef CYTHON_USE_DICT_VERSIONS
  #define CYTHON_USE_DICT_VERSIONS 0
  #undef CYTHON_USE_EXC_INFO_STACK
  #define CYTHON_USE_EXC_INFO_STACK 0
  #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
    #define CYTHON_UPDATE_DESCRIPTOR_DOC 0
  #endif
  #undef CYTHON_USE_FREELISTS
  #define CYTHON_USE_FREELISTS 0
#else
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_CPYTHON 1
  #define CYTHON_COMPILING_IN_LIMITED_API 0
  #define CYTHON_COMPILING_IN_GRAAL 0
  #ifdef Py_GIL_DISABLED
    #define CYTHON_COMPILING_IN_CPYTHON_FREETHREADING 1
  #else
    #define CYTHON_COMPILING_IN_CPYTHON_FREETHREADING 0
  #endif
  #if PY_VERSION_HEX < 0x030A0000
    #undef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #elif !defined(CYTHON_USE_TYPE_SLOTS)
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #ifndef CYTHON_USE_TYPE_SPECS
    #define CYTHON_USE_TYPE_SPECS 0
  #endif
  #ifndef CYTHON_USE_PYTYPE_LOOKUP
    #define CYTHON_USE_PYTYPE_LOOKUP 1
  #endif
  #ifndef CYTHON_USE_PYLONG_INTERNALS
    #define CYTHON_USE_PYLONG_INTERNALS 1
  #endif
  #if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
    #undef CYTHON_USE_PYLIST_INTERNALS
    #define CYTHON_USE_PYLIST_INTERNALS 0
  #elif !defined(CYTHON_USE_PYLIST_INTERNALS)
    #define CYTHON_USE_PYLIST_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING || PY_VERSION_HEX >= 0x030B00A2
    #undef CYTHON_USE_UNICODE_WRITER
    #define CYTHON_USE_UNICODE_WRITER 0
  #elif !defined(CYTHON_USE_UNICODE_WRITER)
    #define CYTHON_USE_UNICODE_WRITER 1
  #endif
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
    #undef CYTHON_AVOID_THREAD_UNSAFE_BORROWED_REFS
    #define CYTHON_AVOID_THREAD_UNSAFE_BORROWED_REFS 1
  #elif !defined(CYTHON_AVOID_THREAD_UNSAFE_BORROWED_REFS)
    #define CYTHON_AVOID_THREAD_UNSAFE_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_ASSUME_SAFE_SIZE
    #define CYTHON_ASSUME_SAFE_SIZE 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #ifndef CYTHON_FAST_THREAD_STATE
    #define CYTHON_FAST_THREAD_STATE 1
  #endif
  #if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
    #undef CYTHON_FAST_GIL
    #define CYTHON_FAST_GIL 0
  #elif !defined(CYTHON_FAST_GIL)
    #define CYTHON_FAST_GIL (PY_VERSION_HEX < 0x030C00A6)
  #endif
  #ifndef CYTHON_METH_FASTCALL
    #define CYTHON_METH_FASTCALL 1
  #endif
  #ifndef CYTHON_FAST_PYCALL
    #define CYTHON_FAST_PYCALL 1
  #endif
  #ifndef CYTHON_PEP487_INIT_SUBCLASS
    #define CYTHON_PEP487_INIT_SUBCLASS 1
  #endif
  #ifndef CYTHON_PEP489_MULTI_PHASE_INIT
    #define CYTHON_PEP489_MULTI_PHASE_INIT 1
  #endif
  #ifndef CYTHON_USE_MODULE_STATE
    #define CYTHON_USE_MODULE_STATE 0
  #endif
  #ifndef CYTHON_USE_SYS_MONITORING
    #define CYTHON_USE_SYS_MONITORING (PY_VERSION_HEX >= 0x030d00B1)
  #endif
  #ifndef CYTHON_USE_TP_FINALIZE
    #define CYTHON_USE_TP_FINALIZE 1
  #endif
  #ifndef CYTHON_USE_AM_SEND
    #define CYTHON_USE_AM_SEND 1
  #endif
  #if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
    #undef CYTHON_USE_DICT_VERSIONS
    #define CYTHON_USE_DICT_VERSIONS 0
  #elif !defined(CYTHON_USE_DICT_VERSIONS)
    #define CYTHON_USE_DICT_VERSIONS  (PY_VERSION_HEX < 0x030C00A5 && !CYTHON_USE_MODULE_STATE)
  #endif
  #ifndef CYTHON_USE_EXC_INFO_STACK
    #define CYTHON_USE_EXC_INFO_STACK 1
  #endif
  #ifndef CYTHON_UPDATE_DESCRIPTOR_DOC
    #define CYTHON_UPDATE_DESCRIPTOR_DOC 1
  #endif
  #ifndef CYTHON_USE_FREELISTS
    #define CYTHON_USE_FREELISTS (!CYTHON_COMPILING_IN_CPYTHON_FREETHREADING)
  #endif
#endif
#ifndef CYTHON_FAST_PYCCALL
#define CYTHON_FAST_PYCCALL  CYTHON_FAST_PYCALL
#endif
#ifndef CYTHON_VECTORCALL
#if CYTHON_COMPILING_IN_LIMITED_API
#define CYTHON_VECTORCALL  (__PYX_LIMITED_VERSION_HEX >= 0x030C0000)
#else
#define CYTHON_VECTORCALL  (CYTHON_FAST_PYCCALL && PY_VERSION_HEX >= 0x030800B1)
#endif
#endif
#define CYTHON_BACKPORT_VECTORCALL (CYTHON_METH_FASTCALL && PY_VERSION_HEX < 0x030800B1)
#if CYTHON_USE_PYLONG_INTERNALS
  #undef SHIFT
  #undef BASE
  #undef MASK
  #ifdef SIZEOF_VOID_P
    enum { __pyx_check_sizeof_voidp = 1 / (int)(SIZEOF_VOID_P == sizeof(void*)) };
  #endif
#endif
#ifndef CYTHON_LOCK_AND_GIL_DEADLOCK_AVOIDANCE_TIME
  #define CYTHON_LOCK_AND_GIL_DEADLOCK_AVOIDANCE_TIME 100
#endif
#ifndef __has_attribute
  #define __has_attribute(x) 0
#endif
#ifndef __has_cpp_attribute
  #define __has_cpp_attribute(x) 0
#endif
#ifndef CYTHON_RESTRICT
  #if defined(__GNUC__)
    #define CYTHON_RESTRICT __restrict__
  #elif defined(_MSC_VER) && _MSC_VER >= 1400
    #define CYTHON_RESTRICT __restrict
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_RESTRICT restrict
  #else
    #define CYTHON_RESTRICT
  #endif
#endif
#ifndef CYTHON_UNUSED
  #if defined(__cplusplus)
    /* for clang __has_cpp_attribute(maybe_unused) is true even before C++17
     * but leads to warnings with -pedantic, since it is a C++17 feature */
    #if ((defined(_MSVC_LANG) && _MSVC_LANG >= 201703L) || __cplusplus >= 201703L)
      #if __has_cpp_attribute(maybe_unused)
        #define CYTHON_UNUSED [[maybe_unused]]
      #endif
    #endif
  #endif
#endif
#ifndef CYTHON_UNUSED
# if defined(__GNUC__)
#   if !(defined(__cplusplus)) || (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))
#     define CYTHON_UNUSED __attribute__ ((__unused__))
#   else
#     define CYTHON_UNUSED
#   endif
# elif defined(__ICC) || (defined(__INTEL_COMPILER) && !defined(_MSC_VER))
#   define CYTHON_UNUSED __attribute__ ((__unused__))
# else
#   define CYTHON_UNUSED
# endif
#endif
#ifndef CYTHON_UNUSED_VAR
#  if defined(__cplusplus)
     template<class T> void CYTHON_UNUSED_VAR( const T& ) { }
#  else
#    define CYTHON_UNUSED_VAR(x) (void)(x)
#  endif
#endif
#ifndef CYTHON_MAYBE_UNUSED_VAR
  #define CYTHON_MAYBE_UNUSED_VAR(x) CYTHON_UNUSED_VAR(x)
#endif
#ifndef CYTHON_NCP_UNUSED
# if CYTHON_COMPILING_IN_CPYTHON && !CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
#  define CYTHON_NCP_UNUSED
# else
#  define CYTHON_NCP_UNUSED CYTHON_UNUSED
# endif
#endif
#ifndef CYTHON_USE_CPP_STD_MOVE
  #if defined(__cplusplus) && (\
    __cplusplus >= 201103L || (defined(_MSC_VER) && _MSC_VER >= 1600))
    #define CYTHON_USE_CPP_STD_MOVE 1
  #else
    #define CYTHON_USE_CPP_STD_MOVE 0
  #endif
#endif
#define __Pyx_void_to_None(void_result) ((void)(void_result), Py_INCREF(Py_None), Py_None)
#ifdef _MSC_VER
    #ifndef _MSC_STDINT_H_
        #if _MSC_VER < 1300
            typedef unsigned char     uint8_t;
            typedef unsigned short    uint16_t;
            typedef unsigned int      uint32_t;
        #else
            typedef unsigned __int8   uint8_t;
            typedef unsigned __int16  uint16_t;
            typedef unsigned __int32  uint32_t;
        #endif
    #endif
    #if _MSC_VER < 1300
        #ifdef _WIN64
            typedef unsigned long long  __pyx_uintptr_t;
        #else
            typedef unsigned int        __pyx_uintptr_t;
        #endif
    #else
        #ifdef _WIN64
            typedef unsigned __int64    __pyx_uintptr_t;
        #else
            typedef unsigned __int32    __pyx_uintptr_t;
        #endif
    #endif
#else
    #include <stdint.h>
    typedef uintptr_t  __pyx_uintptr_t;
#endif
#ifndef CYTHON_FALLTHROUGH
  #if defined(__cplusplus)
    /* for clang __has_cpp_attribute(fallthrough) is true even before C++17
     * but leads to warnings with -pedantic, since it is a C++17 feature */
    #if ((defined(_MSVC_LANG) && _MSVC_LANG >= 201703L) || __cplusplus >= 201703L)
      #if __has_cpp_attribute(fallthrough)
        #define CYTHON_FALLTHROUGH [[fallthrough]]
      #endif
    #endif
    #ifndef CYTHON_FALLTHROUGH
      #if __has_cpp_attribute(clang::fallthrough)
        #define CYTHON_FALLTHROUGH [[clang::fallthrough]]
      #elif __has_cpp_attribute(gnu::fallthrough)
        #define CYTHON_FALLTHROUGH [[gnu::fallthrough]]
      #endif
    #endif
  #endif
  #ifndef CYTHON_FALLTHROUGH
    #if __has_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))
    #else
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
  #if defined(__clang__) && defined(__apple_build_version__)
    #if __apple_build_version__ < 7000000
      #undef  CYTHON_FALLTHROUGH
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
#endif
#ifndef Py_UNREACHABLE
  #define Py_UNREACHABLE()  assert(0); abort()
#endif
#ifdef __cplusplus
  template <typename T>
  struct __PYX_IS_UNSIGNED_IMPL {static const bool value = T(0) < T(-1);};
  #define __PYX_IS_UNSIGNED(type) (__PYX_IS_UNSIGNED_IMPL<type>::value)
#else
  #define __PYX_IS_UNSIGNED(type) (((type)-1) > 0)
#endif
#if CYTHON_COMPILING_IN_PYPY == 1
  #define __PYX_NEED_TP_PRINT_SLOT  (PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x030A0000)
#else
  #define __PYX_NEED_TP_PRINT_SLOT  (PY_VERSION_HEX >= 0x030800b4 && PY_VERSION_HEX < 0x03090000)
#endif
#define __PYX_REINTERPRET_FUNCION(func_pointer, other_pointer) ((func_pointer)(void(*)(void))(other_pointer))

/* CppInitCode */
#ifndef __cplusplus
  #error "Cython files generated with the C++ option must be compiled with a C++ compiler."
#endif
#ifndef CYTHON_INLINE
  #if defined(__clang__)
    #define CYTHON_INLINE __inline__ __attribute__ ((__unused__))
  #else
    #define CYTHON_INLINE inline
  #endif
#endif
template<typename T>
void __Pyx_call_destructor(T& x) {
    x.~T();
}
template<typename T>
class __Pyx_FakeReference {
  public:
    __Pyx_FakeReference() : ptr(NULL) { }
    __Pyx_FakeReference(const T& ref) : ptr(const_cast<T*>(&ref)) { }
    T *operator->() { return ptr; }
    T *operator&() { return ptr; }
    operator T&() { return *ptr; }
    template<typename U> bool operator ==(const U& other) const { return *ptr == other; }
    template<typename U> bool operator !=(const U& other) const { return *ptr != other; }
    template<typename U> bool operator==(const __Pyx_FakeReference<U>& other) const { return *ptr == *other.ptr; }
    template<typename U> bool operator!=(const __Pyx_FakeReference<U>& other) const { return *ptr != *other.ptr; }
  private:
    T *ptr;
};

/* PythonCompatibility */
#define __PYX_BUILD_PY_SSIZE_T "n"
#define CYTHON_FORMAT_SSIZE_T "z"
#define __Pyx_BUILTIN_MODULE_NAME "builtins"
#define __Pyx_DefaultClassType PyType_Type
#if CYTHON_COMPILING_IN_LIMITED_API
    #ifndef CO_OPTIMIZED
    static int CO_OPTIMIZED;
    #endif
    #ifndef CO_NEWLOCALS
    static int CO_NEWLOCALS;
    #endif
    #ifndef CO_VARARGS
    static int CO_VARARGS;
    #endif
    #ifndef CO_VARKEYWORDS
    static int CO_VARKEYWORDS;
    #endif
    #ifndef CO_ASYNC_GENERATOR
    static int CO_ASYNC_GENERATOR;
    #endif
    #ifndef CO_GENERATOR
    static int CO_GENERATOR;
    #endif
    #ifndef CO_COROUTINE
    static int CO_COROUTINE;
    #endif
#else
    #ifndef CO_COROUTINE
      #define CO_COROUTINE 0x80
    #endif
    #ifndef CO_ASYNC_GENERATOR
      #define CO_ASYNC_GENERATOR 0x200
    #endif
#endif
static int __Pyx_init_co_variables(void);
#if PY_VERSION_HEX >= 0x030900A4 || defined(Py_IS_TYPE)
  #define __Pyx_IS_TYPE(ob, type) Py_IS_TYPE(ob, type)
#else
  #define __Pyx_IS_TYPE(ob, type) (((const PyObject*)ob)->ob_type == (type))
#endif
#if PY_VERSION_HEX >= 0x030A00B1 || defined(Py_Is)
  #define __Pyx_Py_Is(x, y)  Py_Is(x, y)
#else
  #define __Pyx_Py_Is(x, y) ((x) == (y))
#endif
#if PY_VERSION_HEX >= 0x030A00B1 || defined(Py_IsNone)
  #define __Pyx_Py_IsNone(ob) Py_IsNone(ob)
#else
  #define __Pyx_Py_IsNone(ob) __Pyx_Py_Is((ob), Py_None)
#endif
#if PY_VERSION_HEX >= 0x030A00B1 || defined(Py_IsTrue)
  #define __Pyx_Py_IsTrue(ob) Py_IsTrue(ob)
#else
  #define __Pyx_Py_IsTrue(ob) __Pyx_Py_Is((ob), Py_True)
#endif
#if PY_VERSION_HEX >= 0x030A00B1 || defined(Py_IsFalse)
  #define __Pyx_Py_IsFalse(ob) Py_IsFalse(ob)
#else
  #define __Pyx_Py_IsFalse(ob) __Pyx_Py_Is((ob), Py_False)
#endif
#define __Pyx_NoneAsNull(obj)  (__Pyx_Py_IsNone(obj) ? NULL : (obj))
#if PY_VERSION_HEX >= 0x030900F0 && !CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyObject_GC_IsFinalized(o) PyObject_GC_IsFinalized(o)
#else
  #define __Pyx_PyObject_GC_IsFinalized(o) _PyGC_FINALIZED(o)
#endif
#ifndef Py_TPFLAGS_CHECKTYPES
  #define Py_TPFLAGS_CHECKTYPES 0
#endif
#ifndef Py_TPFLAGS_HAVE_INDEX
  #define Py_TPFLAGS_HAVE_INDEX 0
#endif
#ifndef Py_TPFLAGS_HAVE_NEWBUFFER
  #define Py_TPFLAGS_HAVE_NEWBUFFER 0
#endif
#ifndef Py_TPFLAGS_HAVE_FINALIZE
  #define Py_TPFLAGS_HAVE_FINALIZE 0
#endif
#ifndef Py_TPFLAGS_SEQUENCE
  #define Py_TPFLAGS_SEQUENCE 0
#endif
#ifndef Py_TPFLAGS_MAPPING
  #define Py_TPFLAGS_MAPPING 0
#endif
#ifndef METH_STACKLESS
  #define METH_STACKLESS 0
#endif
#ifndef METH_FASTCALL
  #ifndef METH_FASTCALL
     #define METH_FASTCALL 0x80
  #endif
  typedef PyObject *(*__Pyx_PyCFunctionFast) (PyObject *self, PyObject *const *args, Py_ssize_t nargs);
  typedef PyObject *(*__Pyx_PyCFunctionFastWithKeywords) (PyObject *self, PyObject *const *args,
                                                          Py_ssize_t nargs, PyObject *kwnames);
#else
  #if PY_VERSION_HEX >= 0x030d00A4
  #  define __Pyx_PyCFunctionFast PyCFunctionFast
  #  define __Pyx_PyCFunctionFastWithKeywords PyCFunctionFastWithKeywords
  #else
  #  define __Pyx_PyCFunctionFast _PyCFunctionFast
  #  define __Pyx_PyCFunctionFastWithKeywords _PyCFunctionFastWithKeywords
  #endif
#endif
#if CYTHON_METH_FASTCALL
  #define __Pyx_METH_FASTCALL METH_FASTCALL
  #define __Pyx_PyCFunction_FastCall __Pyx_PyCFunctionFast
  #define __Pyx_PyCFunction_FastCallWithKeywords __Pyx_PyCFunctionFastWithKeywords
#else
  #define __Pyx_METH_FASTCALL METH_VARARGS
  #define __Pyx_PyCFunction_FastCall PyCFunction
  #define __Pyx_PyCFunction_FastCallWithKeywords PyCFunctionWithKeywords
#endif
#if CYTHON_VECTORCALL
  #define __pyx_vectorcallfunc vectorcallfunc
  #define __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET  PY_VECTORCALL_ARGUMENTS_OFFSET
  #define __Pyx_PyVectorcall_NARGS(n)  PyVectorcall_NARGS((size_t)(n))
#elif CYTHON_BACKPORT_VECTORCALL
  typedef PyObject *(*__pyx_vectorcallfunc)(PyObject *callable, PyObject *const *args,
                                            size_t nargsf, PyObject *kwnames);
  #define __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET  ((size_t)1 << (8 * sizeof(size_t) - 1))
  #define __Pyx_PyVectorcall_NARGS(n)  ((Py_ssize_t)(((size_t)(n)) & ~__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET))
#else
  #define __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET  0
  #define __Pyx_PyVectorcall_NARGS(n)  ((Py_ssize_t)(n))
#endif
#if PY_VERSION_HEX >= 0x030900B1
#define __Pyx_PyCFunction_CheckExact(func)  PyCFunction_CheckExact(func)
#else
#define __Pyx_PyCFunction_CheckExact(func)  PyCFunction_Check(func)
#endif
#define __Pyx_CyOrPyCFunction_Check(func)  PyCFunction_Check(func)
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_CyOrPyCFunction_GET_FUNCTION(func)  (((PyCFunctionObject*)(func))->m_ml->ml_meth)
#elif !CYTHON_COMPILING_IN_LIMITED_API
#define __Pyx_CyOrPyCFunction_GET_FUNCTION(func)  PyCFunction_GET_FUNCTION(func)
#endif
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_CyOrPyCFunction_GET_FLAGS(func)  (((PyCFunctionObject*)(func))->m_ml->ml_flags)
static CYTHON_INLINE PyObject* __Pyx_CyOrPyCFunction_GET_SELF(PyObject *func) {
    return (__Pyx_CyOrPyCFunction_GET_FLAGS(func) & METH_STATIC) ? NULL : ((PyCFunctionObject*)func)->m_self;
}
#endif
static CYTHON_INLINE int __Pyx__IsSameCFunction(PyObject *func, void (*cfunc)(void)) {
#if CYTHON_COMPILING_IN_LIMITED_API
    return PyCFunction_Check(func) && PyCFunction_GetFunction(func) == (PyCFunction) cfunc;
#else
    return PyCFunction_Check(func) && PyCFunction_GET_FUNCTION(func) == (PyCFunction) cfunc;
#endif
}
#define __Pyx_IsSameCFunction(func, cfunc)   __Pyx__IsSameCFunction(func, cfunc)
#if __PYX_LIMITED_VERSION_HEX < 0x03090000
  #define __Pyx_PyType_FromModuleAndSpec(m, s, b)  ((void)m, PyType_FromSpecWithBases(s, b))
  typedef PyObject *(*__Pyx_PyCMethod)(PyObject *, PyTypeObject *, PyObject *const *, size_t, PyObject *);
#else
  #define __Pyx_PyType_FromModuleAndSpec(m, s, b)  PyType_FromModuleAndSpec(m, s, b)
  #define __Pyx_PyCMethod  PyCMethod
#endif
#ifndef METH_METHOD
  #define METH_METHOD 0x200
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
  #define PyObject_Malloc(s)   PyMem_Malloc(s)
  #define PyObject_Free(p)     PyMem_Free(p)
  #define PyObject_Realloc(p)  PyMem_Realloc(p)
#endif
#if CYTHON_COMPILING_IN_LIMITED_API
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno)
#elif CYTHON_COMPILING_IN_GRAAL
  #define __Pyx_PyCode_HasFreeVars(co)  (PyCode_GetNumFree(co) > 0)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno) _PyFrame_SetLineNumber((frame), (lineno))
#else
  #define __Pyx_PyCode_HasFreeVars(co)  (PyCode_GetNumFree(co) > 0)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno)  (frame)->f_lineno = (lineno)
#endif
#if CYTHON_COMPILING_IN_LIMITED_API
  #define __Pyx_PyThreadState_Current PyThreadState_Get()
#elif !CYTHON_FAST_THREAD_STATE
  #define __Pyx_PyThreadState_Current PyThreadState_GET()
#elif PY_VERSION_HEX >= 0x030d00A1
  #define __Pyx_PyThreadState_Current PyThreadState_GetUnchecked()
#else
  #define __Pyx_PyThreadState_Current _PyThreadState_UncheckedGet()
#endif
#if CYTHON_USE_MODULE_STATE
static CYTHON_INLINE void *__Pyx__PyModule_GetState(PyObject *op)
{
    void *result;
    result = PyModule_GetState(op);
    if (!result)
        Py_FatalError("Couldn't find the module state");
    return result;
}
#define __Pyx_PyModule_GetState(o) (__pyx_mstatetype *)__Pyx__PyModule_GetState(o)
#else
#define __Pyx_PyModule_GetState(op) ((void)op,__pyx_mstate_global)
#endif
#define __Pyx_PyObject_GetSlot(obj, name, func_ctype)  __Pyx_PyType_GetSlot(Py_TYPE((PyObject *) obj), name, func_ctype)
#define __Pyx_PyObject_TryGetSlot(obj, name, func_ctype) __Pyx_PyType_TryGetSlot(Py_TYPE(obj), name, func_ctype)
#define __Pyx_PyObject_GetSubSlot(obj, sub, name, func_ctype) __Pyx_PyType_GetSubSlot(Py_TYPE(obj), sub, name, func_ctype)
#define __Pyx_PyObject_TryGetSubSlot(obj, sub, name, func_ctype) __Pyx_PyType_TryGetSubSlot(Py_TYPE(obj), sub, name, func_ctype)
#if CYTHON_USE_TYPE_SLOTS
  #define __Pyx_PyType_GetSlot(type, name, func_ctype)  ((type)->name)
  #define __Pyx_PyType_TryGetSlot(type, name, func_ctype) __Pyx_PyType_GetSlot(type, name, func_ctype)
  #define __Pyx_PyType_GetSubSlot(type, sub, name, func_ctype) (((type)->sub) ? ((type)->sub->name) : NULL)
  #define __Pyx_PyType_TryGetSubSlot(type, sub, name, func_ctype) __Pyx_PyType_GetSubSlot(type, sub, name, func_ctype)
#else
  #define __Pyx_PyType_GetSlot(type, name, func_ctype)  ((func_ctype) PyType_GetSlot((type), Py_##name))
  #define __Pyx_PyType_TryGetSlot(type, name, func_ctype)\
    ((__PYX_LIMITED_VERSION_HEX >= 0x030A0000 ||\
     (PyType_GetFlags(type) & Py_TPFLAGS_HEAPTYPE) || __Pyx_get_runtime_version() >= 0x030A0000) ?\
     __Pyx_PyType_GetSlot(type, name, func_ctype) : NULL)
  #define __Pyx_PyType_GetSubSlot(obj, sub, name, func_ctype) __Pyx_PyType_GetSlot(obj, name, func_ctype)
  #define __Pyx_PyType_TryGetSubSlot(obj, sub, name, func_ctype) __Pyx_PyType_TryGetSlot(obj, name, func_ctype)
#endif
#if CYTHON_COMPILING_IN_CPYTHON || defined(_PyDict_NewPresized)
#define __Pyx_PyDict_NewPresized(n)  ((n <= 8) ? PyDict_New() : _PyDict_NewPresized(n))
#else
#define __Pyx_PyDict_NewPresized(n)  PyDict_New()
#endif
#define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
#define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceTrueDivide(x,y)
#if CYTHON_COMPILING_IN_CPYTHON && CYTHON_USE_UNICODE_INTERNALS
#define __Pyx_PyDict_GetItemStrWithError(dict, name)  _PyDict_GetItem_KnownHash(dict, name, ((PyASCIIObject *) name)->hash)
static CYTHON_INLINE PyObject * __Pyx_PyDict_GetItemStr(PyObject *dict, PyObject *name) {
    PyObject *res = __Pyx_PyDict_GetItemStrWithError(dict, name);
    if (res == NULL) PyErr_Clear();
    return res;
}
#elif !CYTHON_COMPILING_IN_PYPY || PYPY_VERSION_NUM >= 0x07020000
#define __Pyx_PyDict_GetItemStrWithError  PyDict_GetItemWithError
#define __Pyx_PyDict_GetItemStr           PyDict_GetItem
#else
static CYTHON_INLINE PyObject * __Pyx_PyDict_GetItemStrWithError(PyObject *dict, PyObject *name) {
#if CYTHON_COMPILING_IN_PYPY
    return PyDict_GetItem(dict, name);
#else
    PyDictEntry *ep;
    PyDictObject *mp = (PyDictObject*) dict;
    long hash = ((PyStringObject *) name)->ob_shash;
    assert(hash != -1);
    ep = (mp->ma_lookup)(mp, name, hash);
    if (ep == NULL) {
        return NULL;
    }
    return ep->me_value;
#endif
}
#define __Pyx_PyDict_GetItemStr           PyDict_GetItem
#endif
#if CYTHON_USE_TYPE_SLOTS
  #define __Pyx_PyType_GetFlags(tp)   (((PyTypeObject *)tp)->tp_flags)
  #define __Pyx_PyType_HasFeature(type, feature)  ((__Pyx_PyType_GetFlags(type) & (feature)) != 0)
#else
  #define __Pyx_PyType_GetFlags(tp)   (PyType_GetFlags((PyTypeObject *)tp))
  #define __Pyx_PyType_HasFeature(type, feature)  PyType_HasFeature(type, feature)
#endif
#define __Pyx_PyObject_GetIterNextFunc(iterator)  __Pyx_PyObject_GetSlot(iterator, tp_iternext, iternextfunc)
#if CYTHON_USE_TYPE_SPECS && PY_VERSION_HEX >= 0x03080000
#define __Pyx_PyHeapTypeObject_GC_Del(obj)  {\
    PyTypeObject *type = Py_TYPE((PyObject*)obj);\
    assert(__Pyx_PyType_HasFeature(type, Py_TPFLAGS_HEAPTYPE));\
    PyObject_GC_Del(obj);\
    Py_DECREF(type);\
}
#else
#define __Pyx_PyHeapTypeObject_GC_Del(obj)  PyObject_GC_Del(obj)
#endif
#if CYTHON_COMPILING_IN_LIMITED_API
  #define __Pyx_PyUnicode_READY(op)       (0)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_ReadChar(u, i)
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   ((void)u, 1114111U)
  #define __Pyx_PyUnicode_KIND(u)         ((void)u, (0))
  #define __Pyx_PyUnicode_DATA(u)         ((void*)u)
  #define __Pyx_PyUnicode_READ(k, d, i)   ((void)k, PyUnicode_ReadChar((PyObject*)(d), i))
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GetLength(u))
#else
  #if PY_VERSION_HEX >= 0x030C0000
    #define __Pyx_PyUnicode_READY(op)       (0)
  #else
    #define __Pyx_PyUnicode_READY(op)       (likely(PyUnicode_IS_READY(op)) ?\
                                                0 : _PyUnicode_Ready((PyObject *)(op)))
  #endif
  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_READ_CHAR(u, i)
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   PyUnicode_MAX_CHAR_VALUE(u)
  #define __Pyx_PyUnicode_KIND(u)         ((int)PyUnicode_KIND(u))
  #define __Pyx_PyUnicode_DATA(u)         PyUnicode_DATA(u)
  #define __Pyx_PyUnicode_READ(k, d, i)   PyUnicode_READ(k, d, i)
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  PyUnicode_WRITE(k, d, i, (Py_UCS4) ch)
  #if PY_VERSION_HEX >= 0x030C0000
    #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_LENGTH(u))
  #else
    #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x03090000
    #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : ((PyCompactUnicodeObject *)(u))->wstr_length))
    #else
    #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : PyUnicode_GET_SIZE(u)))
    #endif
  #endif
#endif
#if CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyUnicode_Concat(a, b)      PyNumber_Add(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  PyNumber_Add(a, b)
#else
  #define __Pyx_PyUnicode_Concat(a, b)      PyUnicode_Concat(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  ((unlikely((a) == Py_None) || unlikely((b) == Py_None)) ?\
      PyNumber_Add(a, b) : __Pyx_PyUnicode_Concat(a, b))
#endif
#if CYTHON_COMPILING_IN_PYPY
  #if !defined(PyUnicode_DecodeUnicodeEscape)
    #define PyUnicode_DecodeUnicodeEscape(s, size, errors)  PyUnicode_Decode(s, size, "unicode_escape", errors)
  #endif
  #if !defined(PyUnicode_Contains)
    #define PyUnicode_Contains(u, s)  PySequence_Contains(u, s)
  #endif
  #if !defined(PyByteArray_Check)
    #define PyByteArray_Check(obj)  PyObject_TypeCheck(obj, &PyByteArray_Type)
  #endif
  #if !defined(PyObject_Format)
    #define PyObject_Format(obj, fmt)  PyObject_CallMethod(obj, "__format__", "O", fmt)
  #endif
#endif
#define __Pyx_PyUnicode_FormatSafe(a, b)  ((unlikely((a) == Py_None || (PyUnicode_Check(b) && !PyUnicode_CheckExact(b)))) ? PyNumber_Remainder(a, b) : PyUnicode_Format(a, b))
#if CYTHON_COMPILING_IN_CPYTHON
  #define __Pyx_PySequence_ListKeepNew(obj)\
    (likely(PyList_CheckExact(obj) && Py_REFCNT(obj) == 1) ? __Pyx_NewRef(obj) : PySequence_List(obj))
#else
  #define __Pyx_PySequence_ListKeepNew(obj)  PySequence_List(obj)
#endif
#ifndef PySet_CheckExact
  #define PySet_CheckExact(obj)        __Pyx_IS_TYPE(obj, &PySet_Type)
#endif
#if PY_VERSION_HEX >= 0x030900A4
  #define __Pyx_SET_REFCNT(obj, refcnt) Py_SET_REFCNT(obj, refcnt)
  #define __Pyx_SET_SIZE(obj, size) Py_SET_SIZE(obj, size)
#else
  #define __Pyx_SET_REFCNT(obj, refcnt) Py_REFCNT(obj) = (refcnt)
  #define __Pyx_SET_SIZE(obj, size) Py_SIZE(obj) = (size)
#endif
#if CYTHON_AVOID_BORROWED_REFS || CYTHON_AVOID_THREAD_UNSAFE_BORROWED_REFS
  #if __PYX_LIMITED_VERSION_HEX >= 0x030d0000
    #define __Pyx_PyList_GetItemRef(o, i) PyList_GetItemRef(o, i)
  #elif CYTHON_COMPILING_IN_LIMITED_API || !CYTHON_ASSUME_SAFE_MACROS
    #define __Pyx_PyList_GetItemRef(o, i) (likely((i) >= 0) ? PySequence_GetItem(o, i) : (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL))
  #else
    #define __Pyx_PyList_GetItemRef(o, i) PySequence_ITEM(o, i)
  #endif
#elif CYTHON_COMPILING_IN_LIMITED_API || !CYTHON_ASSUME_SAFE_MACROS
  #if __PYX_LIMITED_VERSION_HEX >= 0x030d0000
    #define __Pyx_PyList_GetItemRef(o, i) PyList_GetItemRef(o, i)
  #else
    #define __Pyx_PyList_GetItemRef(o, i) __Pyx_XNewRef(PyList_GetItem(o, i))
  #endif
#else
  #define __Pyx_PyList_GetItemRef(o, i) __Pyx_NewRef(PyList_GET_ITEM(o, i))
#endif
#if __PYX_LIMITED_VERSION_HEX >= 0x030d0000
#define __Pyx_PyDict_GetItemRef(dict, key, result) PyDict_GetItemRef(dict, key, result)
#elif CYTHON_AVOID_BORROWED_REFS || CYTHON_AVOID_THREAD_UNSAFE_BORROWED_REFS
static CYTHON_INLINE int __Pyx_PyDict_GetItemRef(PyObject *dict, PyObject *key, PyObject **result) {
  *result = PyObject_GetItem(dict, key);
  if (*result == NULL) {
    if (PyErr_ExceptionMatches(PyExc_KeyError)) {
      PyErr_Clear();
      return 0;
    }
    return -1;
  }
  return 1;
}
#else
static CYTHON_INLINE int __Pyx_PyDict_GetItemRef(PyObject *dict, PyObject *key, PyObject **result) {
  *result = PyDict_GetItemWithError(dict, key);
  if (*result == NULL) {
    return PyErr_Occurred() ? -1 : 0;
  }
  Py_INCREF(*result);
  return 1;
}
#endif
#if defined(CYTHON_DEBUG_VISIT_CONST) && CYTHON_DEBUG_VISIT_CONST
  #define __Pyx_VISIT_CONST(obj)  Py_VISIT(obj)
#else
  #define __Pyx_VISIT_CONST(obj)
#endif
#if CYTHON_ASSUME_SAFE_MACROS
  #define __Pyx_PySequence_ITEM(o, i) PySequence_ITEM(o, i)
  #define __Pyx_PySequence_SIZE(seq)  Py_SIZE(seq)
  #define __Pyx_PyTuple_SET_ITEM(o, i, v) (PyTuple_SET_ITEM(o, i, v), (0))
  #define __Pyx_PyTuple_GET_ITEM(o, i) PyTuple_GET_ITEM(o, i)
  #define __Pyx_PyList_SET_ITEM(o, i, v) (PyList_SET_ITEM(o, i, v), (0))
  #define __Pyx_PyList_GET_ITEM(o, i) PyList_GET_ITEM(o, i)
#else
  #define __Pyx_PySequence_ITEM(o, i) PySequence_GetItem(o, i)
  #define __Pyx_PySequence_SIZE(seq)  PySequence_Size(seq)
  #define __Pyx_PyTuple_SET_ITEM(o, i, v) PyTuple_SetItem(o, i, v)
  #define __Pyx_PyTuple_GET_ITEM(o, i) PyTuple_GetItem(o, i)
  #define __Pyx_PyList_SET_ITEM(o, i, v) PyList_SetItem(o, i, v)
  #define __Pyx_PyList_GET_ITEM(o, i) PyList_GetItem(o, i)
#endif
#if CYTHON_ASSUME_SAFE_SIZE
  #define __Pyx_PyTuple_GET_SIZE(o) PyTuple_GET_SIZE(o)
  #define __Pyx_PyList_GET_SIZE(o) PyList_GET_SIZE(o)
  #define __Pyx_PySet_GET_SIZE(o) PySet_GET_SIZE(o)
  #define __Pyx_PyBytes_GET_SIZE(o) PyBytes_GET_SIZE(o)
  #define __Pyx_PyByteArray_GET_SIZE(o) PyByteArray_GET_SIZE(o)
  #define __Pyx_PyUnicode_GET_LENGTH(o) PyUnicode_GET_LENGTH(o)
#else
  #define __Pyx_PyTuple_GET_SIZE(o) PyTuple_Size(o)
  #define __Pyx_PyList_GET_SIZE(o) PyList_Size(o)
  #define __Pyx_PySet_GET_SIZE(o) PySet_Size(o)
  #define __Pyx_PyBytes_GET_SIZE(o) PyBytes_Size(o)
  #define __Pyx_PyByteArray_GET_SIZE(o) PyByteArray_Size(o)
  #define __Pyx_PyUnicode_GET_LENGTH(o) PyUnicode_GetLength(o)
#endif
#if __PYX_LIMITED_VERSION_HEX >= 0x030d0000
  #define __Pyx_PyImport_AddModuleRef(name) PyImport_AddModuleRef(name)
#else
  static CYTHON_INLINE PyObject *__Pyx_PyImport_AddModuleRef(const char *name) {
      PyObject *module = PyImport_AddModule(name);
      Py_XINCREF(module);
      return module;
  }
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyUnicode_InternFromString)
  #define PyUnicode_InternFromString(s) PyUnicode_FromString(s)
#endif
#define __Pyx_PyLong_FromHash_t PyLong_FromSsize_t
#define __Pyx_PyLong_AsHash_t   __Pyx_PyIndex_AsSsize_t
#if __PYX_LIMITED_VERSION_HEX >= 0x030A0000
    #define __Pyx_PySendResult PySendResult
#else
    typedef enum {
        PYGEN_RETURN = 0,
        PYGEN_ERROR = -1,
        PYGEN_NEXT = 1,
    } __Pyx_PySendResult;
#endif
#if CYTHON_COMPILING_IN_LIMITED_API || PY_VERSION_HEX < 0x030A00A3
  typedef __Pyx_PySendResult (*__Pyx_pyiter_sendfunc)(PyObject *iter, PyObject *value, PyObject **result);
#else
  #define __Pyx_pyiter_sendfunc sendfunc
#endif
#if !CYTHON_USE_AM_SEND
#define __PYX_HAS_PY_AM_SEND 0
#elif __PYX_LIMITED_VERSION_HEX >= 0x030A0000
#define __PYX_HAS_PY_AM_SEND 1
#else
#define __PYX_HAS_PY_AM_SEND 2  // our own backported implementation
#endif
#if __PYX_HAS_PY_AM_SEND < 2
    #define __Pyx_PyAsyncMethodsStruct PyAsyncMethods
#else
    typedef struct {
        unaryfunc am_await;
        unaryfunc am_aiter;
        unaryfunc am_anext;
        __Pyx_pyiter_sendfunc am_send;
    } __Pyx_PyAsyncMethodsStruct;
    #define __Pyx_SlotTpAsAsync(s) ((PyAsyncMethods*)(s))
#endif
#if CYTHON_USE_AM_SEND && PY_VERSION_HEX < 0x030A00F0
    #define __Pyx_TPFLAGS_HAVE_AM_SEND (1UL << 21)
#else
    #define __Pyx_TPFLAGS_HAVE_AM_SEND (0)
#endif
#if PY_VERSION_HEX >= 0x03090000
#define __Pyx_PyInterpreterState_Get() PyInterpreterState_Get()
#else
#define __Pyx_PyInterpreterState_Get() PyThreadState_Get()->interp
#endif
#if CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x030A0000
#ifdef __cplusplus
extern "C"
#endif
PyAPI_FUNC(void *) PyMem_Calloc(size_t nelem, size_t elsize);
#endif
#if CYTHON_COMPILING_IN_LIMITED_API
static int __Pyx_init_co_variable(PyObject *inspect, const char* name, int *write_to) {
    int value;
    PyObject *py_value = PyObject_GetAttrString(inspect, name);
    if (!py_value) return 0;
    value = (int) PyLong_AsLong(py_value);
    Py_DECREF(py_value);
    *write_to = value;
    return value != -1 || !PyErr_Occurred();
}
static int __Pyx_init_co_variables(void) {
    PyObject *inspect;
    int result;
    inspect = PyImport_ImportModule("inspect");
    result =
#if !defined(CO_OPTIMIZED)
        __Pyx_init_co_variable(inspect, "CO_OPTIMIZED", &CO_OPTIMIZED) &&
#endif
#if !defined(CO_NEWLOCALS)
        __Pyx_init_co_variable(inspect, "CO_NEWLOCALS", &CO_NEWLOCALS) &&
#endif
#if !defined(CO_VARARGS)
        __Pyx_init_co_variable(inspect, "CO_VARARGS", &CO_VARARGS) &&
#endif
#if !defined(CO_VARKEYWORDS)
        __Pyx_init_co_variable(inspect, "CO_VARKEYWORDS", &CO_VARKEYWORDS) &&
#endif
#if !defined(CO_ASYNC_GENERATOR)
        __Pyx_init_co_variable(inspect, "CO_ASYNC_GENERATOR", &CO_ASYNC_GENERATOR) &&
#endif
#if !defined(CO_GENERATOR)
        __Pyx_init_co_variable(inspect, "CO_GENERATOR", &CO_GENERATOR) &&
#endif
#if !defined(CO_COROUTINE)
        __Pyx_init_co_variable(inspect, "CO_COROUTINE", &CO_COROUTINE) &&
#endif
        1;
    Py_DECREF(inspect);
    return result ? 0 : -1;
}
#else
static int __Pyx_init_co_variables(void) {
    return 0;  // It's a limited API-only feature
}
#endif

/* MathInitCode */
#if defined(_WIN32) || defined(WIN32) || defined(MS_WINDOWS)
  #ifndef _USE_MATH_DEFINES
    #define _USE_MATH_DEFINES
  #endif
#endif
#include <math.h>
#ifdef NAN
#define __PYX_NAN() ((float) NAN)
#else
static CYTHON_INLINE float __PYX_NAN() {
  float value;
  memset(&value, 0xFF, sizeof(value));
  return value;
}
#endif
#if defined(__CYGWIN__) && defined(_LDBL_EQ_DBL)
#define __Pyx_truncl trunc
#else
#define __Pyx_truncl truncl
#endif

#ifndef CYTHON_CLINE_IN_TRACEBACK_RUNTIME
#define CYTHON_CLINE_IN_TRACEBACK_RUNTIME 0
#endif
#ifndef CYTHON_CLINE_IN_TRACEBACK
#define CYTHON_CLINE_IN_TRACEBACK CYTHON_CLINE_IN_TRACEBACK_RUNTIME
#endif
#if CYTHON_CLINE_IN_TRACEBACK
#define __PYX_MARK_ERR_POS(f_index, lineno)  { __pyx_filename = __pyx_f[f_index]; (void) __pyx_filename; __pyx_lineno = lineno; (void) __pyx_lineno; __pyx_clineno = __LINE__; (void) __pyx_clineno; }
#else
#define __PYX_MARK_ERR_POS(f_index, lineno)  { __pyx_filename = __pyx_f[f_index]; (void) __pyx_filename; __pyx_lineno = lineno; (void) __pyx_lineno; (void) __pyx_clineno; }
#endif
#define __PYX_ERR(f_index, lineno, Ln_error) \
    { __PYX_MARK_ERR_POS(f_index, lineno) goto Ln_error; }

#ifdef CYTHON_EXTERN_C
    #undef __PYX_EXTERN_C
    #define __PYX_EXTERN_C CYTHON_EXTERN_C
#elif defined(__PYX_EXTERN_C)
    #ifdef _MSC_VER
    #pragma message ("Please do not define the '__PYX_EXTERN_C' macro externally. Use 'CYTHON_EXTERN_C' instead.")
    #else
    #warning Please do not define the '__PYX_EXTERN_C' macro externally. Use 'CYTHON_EXTERN_C' instead.
    #endif
#else
    #define __PYX_EXTERN_C extern "C++"
#endif

#define __PYX_HAVE__cupy__cuda__cufft
#define __PYX_HAVE_API__cupy__cuda__cufft
/* Early includes */
#include <stdint.h>
#include <string.h>
#include "ios"
#include "new"
#include "stdexcept"
#include "typeinfo"
#include <vector>
#include "cupy_cufft.h"
#ifdef _OPENMP
#include <omp.h>
#endif /* _OPENMP */

#if defined(PYREX_WITHOUT_ASSERTIONS) && !defined(CYTHON_WITHOUT_ASSERTIONS)
#define CYTHON_WITHOUT_ASSERTIONS
#endif

#define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_UTF8 0
#define __PYX_DEFAULT_STRING_ENCODING ""
#define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
#define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#define __Pyx_uchar_cast(c) ((unsigned char)c)
#define __Pyx_long_cast(x) ((long)x)
#define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
    (sizeof(type) < sizeof(Py_ssize_t))  ||\
    (sizeof(type) > sizeof(Py_ssize_t) &&\
          likely(v < (type)PY_SSIZE_T_MAX ||\
                 v == (type)PY_SSIZE_T_MAX)  &&\
          (!is_signed || likely(v > (type)PY_SSIZE_T_MIN ||\
                                v == (type)PY_SSIZE_T_MIN)))  ||\
    (sizeof(type) == sizeof(Py_ssize_t) &&\
          (is_signed || likely(v < (type)PY_SSIZE_T_MAX ||\
                               v == (type)PY_SSIZE_T_MAX)))  )
static CYTHON_INLINE int __Pyx_is_valid_index(Py_ssize_t i, Py_ssize_t limit) {
    return (size_t) i < (size_t) limit;
}
#if defined (__cplusplus) && __cplusplus >= 201103L
    #include <cstdlib>
    #define __Pyx_sst_abs(value) std::abs(value)
#elif SIZEOF_INT >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) abs(value)
#elif SIZEOF_LONG >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) labs(value)
#elif defined (_MSC_VER)
    #define __Pyx_sst_abs(value) ((Py_ssize_t)_abs64(value))
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define __Pyx_sst_abs(value) llabs(value)
#elif defined (__GNUC__)
    #define __Pyx_sst_abs(value) __builtin_llabs(value)
#else
    #define __Pyx_sst_abs(value) ((value<0) ? -value : value)
#endif
static CYTHON_INLINE Py_ssize_t __Pyx_ssize_strlen(const char *s);
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject*);
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject*, Py_ssize_t* length);
static CYTHON_INLINE PyObject* __Pyx_PyByteArray_FromString(const char*);
#define __Pyx_PyByteArray_FromStringAndSize(s, l) PyByteArray_FromStringAndSize((const char*)s, l)
#define __Pyx_PyBytes_FromString        PyBytes_FromString
#define __Pyx_PyBytes_FromStringAndSize PyBytes_FromStringAndSize
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char*);
#if CYTHON_ASSUME_SAFE_MACROS
    #define __Pyx_PyBytes_AsWritableString(s)     ((char*) PyBytes_AS_STRING(s))
    #define __Pyx_PyBytes_AsWritableSString(s)    ((signed char*) PyBytes_AS_STRING(s))
    #define __Pyx_PyBytes_AsWritableUString(s)    ((unsigned char*) PyBytes_AS_STRING(s))
    #define __Pyx_PyBytes_AsString(s)     ((const char*) PyBytes_AS_STRING(s))
    #define __Pyx_PyBytes_AsSString(s)    ((const signed char*) PyBytes_AS_STRING(s))
    #define __Pyx_PyBytes_AsUString(s)    ((const unsigned char*) PyBytes_AS_STRING(s))
    #define __Pyx_PyByteArray_AsString(s) PyByteArray_AS_STRING(s)
#else
    #define __Pyx_PyBytes_AsWritableString(s)     ((char*) PyBytes_AsString(s))
    #define __Pyx_PyBytes_AsWritableSString(s)    ((signed char*) PyBytes_AsString(s))
    #define __Pyx_PyBytes_AsWritableUString(s)    ((unsigned char*) PyBytes_AsString(s))
    #define __Pyx_PyBytes_AsString(s)     ((const char*) PyBytes_AsString(s))
    #define __Pyx_PyBytes_AsSString(s)    ((const signed char*) PyBytes_AsString(s))
    #define __Pyx_PyBytes_AsUString(s)    ((const unsigned char*) PyBytes_AsString(s))
    #define __Pyx_PyByteArray_AsString(s) PyByteArray_AsString(s)
#endif
#define __Pyx_PyObject_AsWritableString(s)    ((char*)(__pyx_uintptr_t) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableSString(s)    ((signed char*)(__pyx_uintptr_t) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableUString(s)    ((unsigned char*)(__pyx_uintptr_t) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsSString(s)    ((const signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsUString(s)    ((const unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_FromCString(s)  __Pyx_PyObject_FromString((const char*)s)
#define __Pyx_PyBytes_FromCString(s)   __Pyx_PyBytes_FromString((const char*)s)
#define __Pyx_PyByteArray_FromCString(s)   __Pyx_PyByteArray_FromString((const char*)s)
#define __Pyx_PyUnicode_FromCString(s) __Pyx_PyUnicode_FromString((const char*)s)
#define __Pyx_PyUnicode_FromOrdinal(o)       PyUnicode_FromOrdinal((int)o)
#define __Pyx_PyUnicode_AsUnicode            PyUnicode_AsUnicode
static CYTHON_INLINE PyObject *__Pyx_NewRef(PyObject *obj) {
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030a0000 || defined(Py_NewRef)
    return Py_NewRef(obj);
#else
    Py_INCREF(obj);
    return obj;
#endif
}
static CYTHON_INLINE PyObject *__Pyx_XNewRef(PyObject *obj) {
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030a0000 || defined(Py_XNewRef)
    return Py_XNewRef(obj);
#else
    Py_XINCREF(obj);
    return obj;
#endif
}
static CYTHON_INLINE PyObject *__Pyx_Owned_Py_None(int b);
static CYTHON_INLINE PyObject * __Pyx_PyBool_FromLong(long b);
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject*);
static CYTHON_INLINE int __Pyx_PyObject_IsTrueAndDecref(PyObject*);
static CYTHON_INLINE PyObject* __Pyx_PyNumber_Long(PyObject* x);
#define __Pyx_PySequence_Tuple(obj)\
    (likely(PyTuple_CheckExact(obj)) ? __Pyx_NewRef(obj) : PySequence_Tuple(obj))
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject*);
static CYTHON_INLINE PyObject * __Pyx_PyLong_FromSize_t(size_t);
static CYTHON_INLINE Py_hash_t __Pyx_PyIndex_AsHash_t(PyObject*);
#if CYTHON_ASSUME_SAFE_MACROS
#define __Pyx_PyFloat_AsDouble(x) (PyFloat_CheckExact(x) ? PyFloat_AS_DOUBLE(x) : PyFloat_AsDouble(x))
#define __Pyx_PyFloat_AS_DOUBLE(x) PyFloat_AS_DOUBLE(x)
#else
#define __Pyx_PyFloat_AsDouble(x) PyFloat_AsDouble(x)
#define __Pyx_PyFloat_AS_DOUBLE(x) PyFloat_AsDouble(x)
#endif
#define __Pyx_PyFloat_AsFloat(x) ((float) __Pyx_PyFloat_AsDouble(x))
#define __Pyx_PyNumber_Int(x) (PyLong_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Long(x))
#if CYTHON_USE_PYLONG_INTERNALS
  #if PY_VERSION_HEX >= 0x030C00A7
  #ifndef _PyLong_SIGN_MASK
    #define _PyLong_SIGN_MASK 3
  #endif
  #ifndef _PyLong_NON_SIZE_BITS
    #define _PyLong_NON_SIZE_BITS 3
  #endif
  #define __Pyx_PyLong_Sign(x)  (((PyLongObject*)x)->long_value.lv_tag & _PyLong_SIGN_MASK)
  #define __Pyx_PyLong_IsNeg(x)  ((__Pyx_PyLong_Sign(x) & 2) != 0)
  #define __Pyx_PyLong_IsNonNeg(x)  (!__Pyx_PyLong_IsNeg(x))
  #define __Pyx_PyLong_IsZero(x)  (__Pyx_PyLong_Sign(x) & 1)
  #define __Pyx_PyLong_IsPos(x)  (__Pyx_PyLong_Sign(x) == 0)
  #define __Pyx_PyLong_CompactValueUnsigned(x)  (__Pyx_PyLong_Digits(x)[0])
  #define __Pyx_PyLong_DigitCount(x)  ((Py_ssize_t) (((PyLongObject*)x)->long_value.lv_tag >> _PyLong_NON_SIZE_BITS))
  #define __Pyx_PyLong_SignedDigitCount(x)\
        ((1 - (Py_ssize_t) __Pyx_PyLong_Sign(x)) * __Pyx_PyLong_DigitCount(x))
  #if defined(PyUnstable_Long_IsCompact) && defined(PyUnstable_Long_CompactValue)
    #define __Pyx_PyLong_IsCompact(x)     PyUnstable_Long_IsCompact((PyLongObject*) x)
    #define __Pyx_PyLong_CompactValue(x)  PyUnstable_Long_CompactValue((PyLongObject*) x)
  #else
    #define __Pyx_PyLong_IsCompact(x)     (((PyLongObject*)x)->long_value.lv_tag < (2 << _PyLong_NON_SIZE_BITS))
    #define __Pyx_PyLong_CompactValue(x)  ((1 - (Py_ssize_t) __Pyx_PyLong_Sign(x)) * (Py_ssize_t) __Pyx_PyLong_Digits(x)[0])
  #endif
  typedef Py_ssize_t  __Pyx_compact_pylong;
  typedef size_t  __Pyx_compact_upylong;
  #else
  #define __Pyx_PyLong_IsNeg(x)  (Py_SIZE(x) < 0)
  #define __Pyx_PyLong_IsNonNeg(x)  (Py_SIZE(x) >= 0)
  #define __Pyx_PyLong_IsZero(x)  (Py_SIZE(x) == 0)
  #define __Pyx_PyLong_IsPos(x)  (Py_SIZE(x) > 0)
  #define __Pyx_PyLong_CompactValueUnsigned(x)  ((Py_SIZE(x) == 0) ? 0 : __Pyx_PyLong_Digits(x)[0])
  #define __Pyx_PyLong_DigitCount(x)  __Pyx_sst_abs(Py_SIZE(x))
  #define __Pyx_PyLong_SignedDigitCount(x)  Py_SIZE(x)
  #define __Pyx_PyLong_IsCompact(x)  (Py_SIZE(x) == 0 || Py_SIZE(x) == 1 || Py_SIZE(x) == -1)
  #define __Pyx_PyLong_CompactValue(x)\
        ((Py_SIZE(x) == 0) ? (sdigit) 0 : ((Py_SIZE(x) < 0) ? -(sdigit)__Pyx_PyLong_Digits(x)[0] : (sdigit)__Pyx_PyLong_Digits(x)[0]))
  typedef sdigit  __Pyx_compact_pylong;
  typedef digit  __Pyx_compact_upylong;
  #endif
  static CYTHON_INLINE int __Pyx_PyLong_CompactAsLong(PyObject *x, long *return_value);
  #if PY_VERSION_HEX >= 0x030C00A5
  #define __Pyx_PyLong_Digits(x)  (((PyLongObject*)x)->long_value.ob_digit)
  #else
  #define __Pyx_PyLong_Digits(x)  (((PyLongObject*)x)->ob_digit)
  #endif
#endif
#if __PYX_DEFAULT_STRING_ENCODING_IS_UTF8
  #define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_DecodeUTF8(c_str, size, NULL)
#elif __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
  #define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_DecodeASCII(c_str, size, NULL)
#else
  #define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_Decode(c_str, size, __PYX_DEFAULT_STRING_ENCODING, NULL)
#endif


/* Test for GCC > 2.95 */
#if defined(__GNUC__)     && (__GNUC__ > 2 || (__GNUC__ == 2 && (__GNUC_MINOR__ > 95)))
  #define likely(x)   __builtin_expect(!!(x), 1)
  #define unlikely(x) __builtin_expect(!!(x), 0)
#else /* !__GNUC__ or GCC < 2.95 */
  #define likely(x)   (x)
  #define unlikely(x) (x)
#endif /* __GNUC__ */
/* PretendToInitialize */
#ifdef __cplusplus
#if __cplusplus > 201103L
#include <type_traits>
#endif
template <typename T>
static void __Pyx_pretend_to_initialize(T* ptr) {
#if __cplusplus > 201103L
    if ((std::is_trivially_default_constructible<T>::value))
#endif
        *ptr = T();
    (void)ptr;
}
#else
static CYTHON_INLINE void __Pyx_pretend_to_initialize(void* ptr) { (void)ptr; }
#endif


#if !CYTHON_USE_MODULE_STATE
static PyObject *__pyx_m = NULL;
#endif
static int __pyx_lineno;
static int __pyx_clineno = 0;
static const char * const __pyx_cfilenm = __FILE__;
static const char *__pyx_filename;

/* #### Code section: filename_table ### */

static const char* const __pyx_f[] = {
  "cupy/cuda/cufft.pyx",
  "<stringsource>",
  "cupy/cuda/cufft.pxd",
  "cupy_backends/cuda/_softlink.pxd",
};
/* #### Code section: utility_code_proto_before_types ### */
/* Atomics.proto */
#include <pythread.h>
#ifndef CYTHON_ATOMICS
    #define CYTHON_ATOMICS 1
#endif
#define __PYX_CYTHON_ATOMICS_ENABLED() CYTHON_ATOMICS
#define __PYX_GET_CYTHON_COMPILING_IN_CPYTHON_FREETHREADING() CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
#define __pyx_atomic_int_type int
#define __pyx_nonatomic_int_type int
#if CYTHON_ATOMICS && (defined(__STDC_VERSION__) &&\
                        (__STDC_VERSION__ >= 201112L) &&\
                        !defined(__STDC_NO_ATOMICS__))
    #include <stdatomic.h>
#elif CYTHON_ATOMICS && (defined(__cplusplus) && (\
                    (__cplusplus >= 201103L) ||\
                    (defined(_MSC_VER) && _MSC_VER >= 1700)))
    #include <atomic>
#endif
#if CYTHON_ATOMICS && (defined(__STDC_VERSION__) &&\
                        (__STDC_VERSION__ >= 201112L) &&\
                        !defined(__STDC_NO_ATOMICS__) &&\
                       ATOMIC_INT_LOCK_FREE == 2)
    #undef __pyx_atomic_int_type
    #define __pyx_atomic_int_type atomic_int
    #define __pyx_atomic_ptr_type atomic_uintptr_t
    #define __pyx_nonatomic_ptr_type uintptr_t
    #define __pyx_atomic_incr_relaxed(value) atomic_fetch_add_explicit(value, 1, memory_order_relaxed)
    #define __pyx_atomic_incr_acq_rel(value) atomic_fetch_add_explicit(value, 1, memory_order_acq_rel)
    #define __pyx_atomic_decr_acq_rel(value) atomic_fetch_sub_explicit(value, 1, memory_order_acq_rel)
    #define __pyx_atomic_sub(value, arg) atomic_fetch_sub(value, arg)
    #define __pyx_atomic_int_cmp_exchange(value, expected, desired) atomic_compare_exchange_strong(value, expected, desired)
    #define __pyx_atomic_load(value) atomic_load(value)
    #define __pyx_atomic_store(value, new_value) atomic_store(value, new_value)
    #define __pyx_atomic_pointer_load_relaxed(value) atomic_load_explicit(value, memory_order_relaxed)
    #define __pyx_atomic_pointer_load_acquire(value) atomic_load_explicit(value, memory_order_acquire)
    #define __pyx_atomic_pointer_exchange(value, new_value) atomic_exchange(value, (__pyx_nonatomic_ptr_type)new_value)
    #if defined(__PYX_DEBUG_ATOMICS) && defined(_MSC_VER)
        #pragma message ("Using standard C atomics")
    #elif defined(__PYX_DEBUG_ATOMICS)
        #warning "Using standard C atomics"
    #endif
#elif CYTHON_ATOMICS && (defined(__cplusplus) && (\
                    (__cplusplus >= 201103L) ||\
\
                    (defined(_MSC_VER) && _MSC_VER >= 1700)) &&\
                    ATOMIC_INT_LOCK_FREE == 2)
    #undef __pyx_atomic_int_type
    #define __pyx_atomic_int_type std::atomic_int
    #define __pyx_atomic_ptr_type std::atomic_uintptr_t
    #define __pyx_nonatomic_ptr_type uintptr_t
    #define __pyx_atomic_incr_relaxed(value) std::atomic_fetch_add_explicit(value, 1, std::memory_order_relaxed)
    #define __pyx_atomic_incr_acq_rel(value) std::atomic_fetch_add_explicit(value, 1, std::memory_order_acq_rel)
    #define __pyx_atomic_decr_acq_rel(value) std::atomic_fetch_sub_explicit(value, 1, std::memory_order_acq_rel)
    #define __pyx_atomic_sub(value, arg) std::atomic_fetch_sub(value, arg)
    #define __pyx_atomic_int_cmp_exchange(value, expected, desired) std::atomic_compare_exchange_strong(value, expected, desired)
    #define __pyx_atomic_load(value) std::atomic_load(value)
    #define __pyx_atomic_store(value, new_value) std::atomic_store(value, new_value)
    #define __pyx_atomic_pointer_load_relaxed(value) std::atomic_load_explicit(value, std::memory_order_relaxed)
    #define __pyx_atomic_pointer_load_acquire(value) std::atomic_load_explicit(value, std::memory_order_acquire)
    #define __pyx_atomic_pointer_exchange(value, new_value) std::atomic_exchange(value, (__pyx_nonatomic_ptr_type)new_value)
    #if defined(__PYX_DEBUG_ATOMICS) && defined(_MSC_VER)
        #pragma message ("Using standard C++ atomics")
    #elif defined(__PYX_DEBUG_ATOMICS)
        #warning "Using standard C++ atomics"
    #endif
#elif CYTHON_ATOMICS && (__GNUC__ >= 5 || (__GNUC__ == 4 &&\
                    (__GNUC_MINOR__ > 1 ||\
                    (__GNUC_MINOR__ == 1 && __GNUC_PATCHLEVEL__ >= 2))))
    #define __pyx_atomic_ptr_type void*
    #define __pyx_atomic_incr_relaxed(value) __sync_fetch_and_add(value, 1)
    #define __pyx_atomic_incr_acq_rel(value) __sync_fetch_and_add(value, 1)
    #define __pyx_atomic_decr_acq_rel(value) __sync_fetch_and_sub(value, 1)
    #define __pyx_atomic_sub(value, arg) __sync_fetch_and_sub(value, arg)
    static CYTHON_INLINE int __pyx_atomic_int_cmp_exchange(__pyx_atomic_int_type* value, __pyx_nonatomic_int_type* expected, __pyx_nonatomic_int_type desired) {
        __pyx_nonatomic_int_type old = __sync_val_compare_and_swap(value, *expected, desired);
        int result = old == *expected;
        *expected = old;
        return result;
    }
    #define __pyx_atomic_load(value) __sync_fetch_and_add(value, 0)
    #define __pyx_atomic_store(value, new_value) __sync_lock_test_and_set(value, new_value)
    #define __pyx_atomic_pointer_load_relaxed(value) __sync_fetch_and_add(value, 0)
    #define __pyx_atomic_pointer_load_acquire(value) __sync_fetch_and_add(value, 0)
    #define __pyx_atomic_pointer_exchange(value, new_value) __sync_lock_test_and_set(value, (__pyx_atomic_ptr_type)new_value)
    #ifdef __PYX_DEBUG_ATOMICS
        #warning "Using GNU atomics"
    #endif
#elif CYTHON_ATOMICS && defined(_MSC_VER)
    #include <intrin.h>
    #undef __pyx_atomic_int_type
    #define __pyx_atomic_int_type long
    #define __pyx_atomic_ptr_type void*
    #undef __pyx_nonatomic_int_type
    #define __pyx_nonatomic_int_type long
    #pragma intrinsic (_InterlockedExchangeAdd, _InterlockedExchange, _InterlockedCompareExchange, _InterlockedCompareExchangePointer, _InterlockedExchangePointer)
    #define __pyx_atomic_incr_relaxed(value) _InterlockedExchangeAdd(value, 1)
    #define __pyx_atomic_incr_acq_rel(value) _InterlockedExchangeAdd(value, 1)
    #define __pyx_atomic_decr_acq_rel(value) _InterlockedExchangeAdd(value, -1)
    #define __pyx_atomic_sub(value, arg) _InterlockedExchangeAdd(value, -arg)
    static CYTHON_INLINE int __pyx_atomic_int_cmp_exchange(__pyx_atomic_int_type* value, __pyx_nonatomic_int_type* expected, __pyx_nonatomic_int_type desired) {
        __pyx_nonatomic_int_type old = _InterlockedCompareExchange(value, desired, *expected);
        int result = old == *expected;
        *expected = old;
        return result;
    }
    #define __pyx_atomic_load(value) _InterlockedExchangeAdd(value, 0)
    #define __pyx_atomic_store(value, new_value) _InterlockedExchange(value, new_value)
    #define __pyx_atomic_pointer_load_relaxed(value) *(void * volatile *)value
    #define __pyx_atomic_pointer_load_acquire(value) _InterlockedCompareExchangePointer(value, 0, 0)
    #define __pyx_atomic_pointer_exchange(value, new_value) _InterlockedExchangePointer(value, (__pyx_atomic_ptr_type)new_value)
    #ifdef __PYX_DEBUG_ATOMICS
        #pragma message ("Using MSVC atomics")
    #endif
#else
    #undef CYTHON_ATOMICS
    #define CYTHON_ATOMICS 0
    #ifdef __PYX_DEBUG_ATOMICS
        #warning "Not using atomics"
    #endif
#endif
#if CYTHON_ATOMICS
    #define __pyx_add_acquisition_count(memview)\
             __pyx_atomic_incr_relaxed(__pyx_get_slice_count_pointer(memview))
    #define __pyx_sub_acquisition_count(memview)\
            __pyx_atomic_decr_acq_rel(__pyx_get_slice_count_pointer(memview))
#else
    #define __pyx_add_acquisition_count(memview)\
            __pyx_add_acquisition_count_locked(__pyx_get_slice_count_pointer(memview), memview->lock)
    #define __pyx_sub_acquisition_count(memview)\
            __pyx_sub_acquisition_count_locked(__pyx_get_slice_count_pointer(memview), memview->lock)
#endif

/* NoFastGil.proto */
#define __Pyx_PyGILState_Ensure PyGILState_Ensure
#define __Pyx_PyGILState_Release PyGILState_Release
#define __Pyx_FastGIL_Remember()
#define __Pyx_FastGIL_Forget()
#define __Pyx_FastGilFuncInit()

/* IncludeStructmemberH.proto */
#include <structmember.h>

/* CriticalSections.proto */
#if !CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
#define __Pyx_PyCriticalSection void*
#define __Pyx_PyCriticalSection2 void*
#define __Pyx_PyCriticalSection_Begin1(cs, arg) (void)cs
#define __Pyx_PyCriticalSection_Begin2(cs, arg1, arg2) (void)cs
#define __Pyx_PyCriticalSection_End1(cs)
#define __Pyx_PyCriticalSection_End2(cs)
#else
#define __Pyx_PyCriticalSection PyCriticalSection
#define __Pyx_PyCriticalSection2 PyCriticalSection2
#define __Pyx_PyCriticalSection_Begin1 PyCriticalSection_Begin
#define __Pyx_PyCriticalSection_Begin2 PyCriticalSection2_Begin
#define __Pyx_PyCriticalSection_End1 PyCriticalSection_End
#define __Pyx_PyCriticalSection_End2 PyCriticalSection2_End
#endif
#if PY_VERSION_HEX < 0x030d0000 || CYTHON_COMPILING_IN_LIMITED_API
#define __Pyx_BEGIN_CRITICAL_SECTION(o) {
#define __Pyx_END_CRITICAL_SECTION() }
#else
#define __Pyx_BEGIN_CRITICAL_SECTION Py_BEGIN_CRITICAL_SECTION
#define __Pyx_END_CRITICAL_SECTION Py_END_CRITICAL_SECTION
#endif

/* ForceInitThreads.proto */
#ifndef __PYX_FORCE_INIT_THREADS
  #define __PYX_FORCE_INIT_THREADS 0
#endif

/* #### Code section: numeric_typedefs ### */
/* #### Code section: complex_type_declarations ### */
/* #### Code section: type_declarations ### */

/*--- Type declarations ---*/
struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink;
struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d;
struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd;
struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd;

/* "cupy_backends/cuda/_softlink.pxd":1
 * ctypedef int (*func_ptr)(...) nogil  # NOQA             # <<<<<<<<<<<<<<
 * 
 * cdef class SoftLink:
*/
typedef int (*__pyx_t_13cupy_backends_4cuda_9_softlink_func_ptr)(...);
struct __pyx_opt_args_4cupy_4cuda_5cufft_setCallback;

/* "cupy/cuda/cufft.pxd":27
 * 
 * 
 * cpdef enum:             # <<<<<<<<<<<<<<
 *     CUFFT_C2C = 0x29
 *     CUFFT_R2C = 0x2a
*/
enum  {
  __pyx_e_4cupy_4cuda_5cufft_CUFFT_C2C = 0x29,
  __pyx_e_4cupy_4cuda_5cufft_CUFFT_R2C = 0x2a,
  __pyx_e_4cupy_4cuda_5cufft_CUFFT_C2R = 0x2c,
  __pyx_e_4cupy_4cuda_5cufft_CUFFT_Z2Z = 0x69,
  __pyx_e_4cupy_4cuda_5cufft_CUFFT_D2Z = 0x6a,
  __pyx_e_4cupy_4cuda_5cufft_CUFFT_Z2D = 0x6c,
  __pyx_e_4cupy_4cuda_5cufft_CUFFT_FORWARD = -1L,
  __pyx_e_4cupy_4cuda_5cufft_CUFFT_INVERSE = 1,
  __pyx_e_4cupy_4cuda_5cufft_CUFFT_CB_LD_COMPLEX = 0x0,
  __pyx_e_4cupy_4cuda_5cufft_CUFFT_CB_LD_COMPLEX_DOUBLE = 0x1,
  __pyx_e_4cupy_4cuda_5cufft_CUFFT_CB_LD_REAL = 0x2,
  __pyx_e_4cupy_4cuda_5cufft_CUFFT_CB_LD_REAL_DOUBLE = 0x3,
  __pyx_e_4cupy_4cuda_5cufft_CUFFT_CB_ST_COMPLEX = 0x4,
  __pyx_e_4cupy_4cuda_5cufft_CUFFT_CB_ST_COMPLEX_DOUBLE = 0x5,
  __pyx_e_4cupy_4cuda_5cufft_CUFFT_CB_ST_REAL = 0x6,
  __pyx_e_4cupy_4cuda_5cufft_CUFFT_CB_ST_REAL_DOUBLE = 0x7
};

/* "cupy/cuda/cufft.pyx":95
 * 
 * 
 * cdef enum:             # <<<<<<<<<<<<<<
 *     # Actually, this is 64, but it's undocumented. For the sake
 *     # of safety, let us use 16, which agrees with the cuFFT doc.
*/
enum  {
  __pyx_e_4cupy_4cuda_5cufft_MAX_CUDA_DESCRIPTOR_GPUS = 16
};

/* "cupy/cuda/cufft.pyx":20
 * 
 * 
 * ctypedef Result (*F_cufftXtSetJITCallback)(             # <<<<<<<<<<<<<<
 *     Handle plan, const char* callback_name, const void* callback,
 *     size_t callback_size, callbackType callback_type, void **caller_info) nogil
*/
typedef cufftResult_t (*__pyx_t_4cupy_4cuda_5cufft_F_cufftXtSetJITCallback)(cufftHandle, char const *, void const *, size_t, cufftXtCallbackType, void **);

/* "cupy/cuda/cufft.pyx":1262
 * 
 * 
 * cpdef intptr_t setCallback(             # <<<<<<<<<<<<<<
 *         intptr_t plan, int cb_type, bint is_load,
 *         intptr_t aux_arr=0) except?-1:
*/
struct __pyx_opt_args_4cupy_4cuda_5cufft_setCallback {
  int __pyx_n;
  intptr_t aux_arr;
};

/* "cupy_backends/cuda/_softlink.pxd":3
 * ctypedef int (*func_ptr)(...) nogil  # NOQA
 * 
 * cdef class SoftLink:             # <<<<<<<<<<<<<<
 *     cdef:
 *         object error
*/
struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink {
  PyObject_HEAD
  struct __pyx_vtabstruct_13cupy_backends_4cuda_9_softlink_SoftLink *__pyx_vtab;
  PyObject *error;
  PyObject *prefix;
  PyObject *_libname;
  PyObject *_cdll;
};


/* "cupy/cuda/cufft.pxd":52
 * 
 * 
 * cdef class Plan1d:             # <<<<<<<<<<<<<<
 *     cdef:
 *         readonly intptr_t handle
*/
struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d {
  PyObject_HEAD
  struct __pyx_vtabstruct_4cupy_4cuda_5cufft_Plan1d *__pyx_vtab;
  intptr_t handle;
  PyObject *work_area;
  int nx;
  int batch;
  cufftType_t fft_type;
  PyObject *gpus;
  PyObject *batch_share;
  PyObject *gather_streams;
  PyObject *gather_events;
  PyObject *scatter_streams;
  PyObject *scatter_events;
  intptr_t xtArr;
  PyObject *xtArr_buffer;
};


/* "cupy/cuda/cufft.pxd":76
 * 
 * 
 * cdef class PlanNd:             # <<<<<<<<<<<<<<
 *     cdef:
 *         readonly intptr_t handle
*/
struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd {
  PyObject_HEAD
  intptr_t handle;
  PyObject *work_area;
  PyObject *shape;
  cufftType_t fft_type;
  PyObject *order;
  int last_axis;
  PyObject *last_size;
  PyObject *gpus;
};


/* "cupy/cuda/cufft.pxd":90
 * 
 * 
 * cdef class XtPlanNd:             # <<<<<<<<<<<<<<
 *     cdef:
 *         readonly intptr_t handle
*/
struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd {
  PyObject_HEAD
  intptr_t handle;
  PyObject *work_area;
  PyObject *shape;
  int itype;
  int otype;
  int etype;
  PyObject *order;
  int last_axis;
  PyObject *last_size;
  PyObject *gpus;
};



/* "cupy_backends/cuda/_softlink.pxd":3
 * ctypedef int (*func_ptr)(...) nogil  # NOQA
 * 
 * cdef class SoftLink:             # <<<<<<<<<<<<<<
 *     cdef:
 *         object error
*/

struct __pyx_vtabstruct_13cupy_backends_4cuda_9_softlink_SoftLink {
  __pyx_t_13cupy_backends_4cuda_9_softlink_func_ptr (*get)(struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink *, PyObject *);
};
static struct __pyx_vtabstruct_13cupy_backends_4cuda_9_softlink_SoftLink *__pyx_vtabptr_13cupy_backends_4cuda_9_softlink_SoftLink;


/* "cupy/cuda/cufft.pyx":338
 * 
 * 
 * cdef class Plan1d:             # <<<<<<<<<<<<<<
 *     def __init__(self, int nx, int fft_type, int batch, *,
 *                  devices=None, out=None, intptr_t prealloc_plan=0):
*/

struct __pyx_vtabstruct_4cupy_4cuda_5cufft_Plan1d {
  void (*_single_gpu_get_plan)(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *, cufftHandle, int, int, int);
  void (*_multi_gpu_get_plan)(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *, cufftHandle, int, int, int, PyObject *, PyObject *);
};
static struct __pyx_vtabstruct_4cupy_4cuda_5cufft_Plan1d *__pyx_vtabptr_4cupy_4cuda_5cufft_Plan1d;
/* #### Code section: utility_code_proto ### */

/* --- Runtime support code (head) --- */
/* Refnanny.proto */
#ifndef CYTHON_REFNANNY
  #define CYTHON_REFNANNY 0
#endif
#if CYTHON_REFNANNY
  typedef struct {
    void (*INCREF)(void*, PyObject*, Py_ssize_t);
    void (*DECREF)(void*, PyObject*, Py_ssize_t);
    void (*GOTREF)(void*, PyObject*, Py_ssize_t);
    void (*GIVEREF)(void*, PyObject*, Py_ssize_t);
    void* (*SetupContext)(const char*, Py_ssize_t, const char*);
    void (*FinishContext)(void**);
  } __Pyx_RefNannyAPIStruct;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNanny = NULL;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname);
  #define __Pyx_RefNannyDeclarations void *__pyx_refnanny = NULL;
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          if (acquire_gil) {\
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), (__LINE__), (__FILE__));\
              PyGILState_Release(__pyx_gilstate_save);\
          } else {\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), (__LINE__), (__FILE__));\
          }
  #define __Pyx_RefNannyFinishContextNogil() {\
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();\
              __Pyx_RefNannyFinishContext();\
              PyGILState_Release(__pyx_gilstate_save);\
          }
  #define __Pyx_RefNannyFinishContextNogil() {\
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();\
              __Pyx_RefNannyFinishContext();\
              PyGILState_Release(__pyx_gilstate_save);\
          }
  #define __Pyx_RefNannyFinishContext()\
          __Pyx_RefNanny->FinishContext(&__pyx_refnanny)
  #define __Pyx_INCREF(r)  __Pyx_RefNanny->INCREF(__pyx_refnanny, (PyObject *)(r), (__LINE__))
  #define __Pyx_DECREF(r)  __Pyx_RefNanny->DECREF(__pyx_refnanny, (PyObject *)(r), (__LINE__))
  #define __Pyx_GOTREF(r)  __Pyx_RefNanny->GOTREF(__pyx_refnanny, (PyObject *)(r), (__LINE__))
  #define __Pyx_GIVEREF(r) __Pyx_RefNanny->GIVEREF(__pyx_refnanny, (PyObject *)(r), (__LINE__))
  #define __Pyx_XINCREF(r)  do { if((r) == NULL); else {__Pyx_INCREF(r); }} while(0)
  #define __Pyx_XDECREF(r)  do { if((r) == NULL); else {__Pyx_DECREF(r); }} while(0)
  #define __Pyx_XGOTREF(r)  do { if((r) == NULL); else {__Pyx_GOTREF(r); }} while(0)
  #define __Pyx_XGIVEREF(r) do { if((r) == NULL); else {__Pyx_GIVEREF(r);}} while(0)
#else
  #define __Pyx_RefNannyDeclarations
  #define __Pyx_RefNannySetupContext(name, acquire_gil)
  #define __Pyx_RefNannyFinishContextNogil()
  #define __Pyx_RefNannyFinishContext()
  #define __Pyx_INCREF(r) Py_INCREF(r)
  #define __Pyx_DECREF(r) Py_DECREF(r)
  #define __Pyx_GOTREF(r)
  #define __Pyx_GIVEREF(r)
  #define __Pyx_XINCREF(r) Py_XINCREF(r)
  #define __Pyx_XDECREF(r) Py_XDECREF(r)
  #define __Pyx_XGOTREF(r)
  #define __Pyx_XGIVEREF(r)
#endif
#define __Pyx_Py_XDECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; Py_XDECREF(tmp);\
    } while (0)
#define __Pyx_XDECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_XDECREF(tmp);\
    } while (0)
#define __Pyx_DECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_DECREF(tmp);\
    } while (0)
#define __Pyx_CLEAR(r)    do { PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);} while(0)
#define __Pyx_XCLEAR(r)   do { if((r) != NULL) {PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);}} while(0)

/* PyErrExceptionMatches.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_ExceptionMatches(err) __Pyx_PyErr_ExceptionMatchesInState(__pyx_tstate, err)
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err);
#else
#define __Pyx_PyErr_ExceptionMatches(err)  PyErr_ExceptionMatches(err)
#endif

/* PyThreadStateGet.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyThreadState_declare  PyThreadState *__pyx_tstate;
#define __Pyx_PyThreadState_assign  __pyx_tstate = __Pyx_PyThreadState_Current;
#if PY_VERSION_HEX >= 0x030C00A6
#define __Pyx_PyErr_Occurred()  (__pyx_tstate->current_exception != NULL)
#define __Pyx_PyErr_CurrentExceptionType()  (__pyx_tstate->current_exception ? (PyObject*) Py_TYPE(__pyx_tstate->current_exception) : (PyObject*) NULL)
#else
#define __Pyx_PyErr_Occurred()  (__pyx_tstate->curexc_type != NULL)
#define __Pyx_PyErr_CurrentExceptionType()  (__pyx_tstate->curexc_type)
#endif
#else
#define __Pyx_PyThreadState_declare
#define __Pyx_PyThreadState_assign
#define __Pyx_PyErr_Occurred()  (PyErr_Occurred() != NULL)
#define __Pyx_PyErr_CurrentExceptionType()  PyErr_Occurred()
#endif

/* PyErrFetchRestore.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyErr_Clear() __Pyx_ErrRestore(NULL, NULL, NULL)
#define __Pyx_ErrRestoreWithState(type, value, tb)  __Pyx_ErrRestoreInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)    __Pyx_ErrFetchInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  __Pyx_ErrRestoreInState(__pyx_tstate, type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)    __Pyx_ErrFetchInState(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030C00A6
#define __Pyx_PyErr_SetNone(exc) (Py_INCREF(exc), __Pyx_ErrRestore((exc), NULL, NULL))
#else
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#endif
#else
#define __Pyx_PyErr_Clear() PyErr_Clear()
#define __Pyx_PyErr_SetNone(exc) PyErr_SetNone(exc)
#define __Pyx_ErrRestoreWithState(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestoreInState(tstate, type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchInState(tstate, type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)  PyErr_Fetch(type, value, tb)
#endif

/* PyObjectGetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name);
#else
#define __Pyx_PyObject_GetAttrStr(o,n) PyObject_GetAttr(o,n)
#endif

/* PyObjectGetAttrStrNoError.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStrNoError(PyObject* obj, PyObject* attr_name);

/* GetBuiltinName.proto */
static PyObject *__Pyx_GetBuiltinName(PyObject *name);

/* PyDictVersioning.proto */
#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
#define __PYX_DICT_VERSION_INIT  ((PY_UINT64_T) -1)
#define __PYX_GET_DICT_VERSION(dict)  (((PyDictObject*)(dict))->ma_version_tag)
#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)\
    (version_var) = __PYX_GET_DICT_VERSION(dict);\
    (cache_var) = (value);
#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP) {\
    static PY_UINT64_T __pyx_dict_version = 0;\
    static PyObject *__pyx_dict_cached_value = NULL;\
    if (likely(__PYX_GET_DICT_VERSION(DICT) == __pyx_dict_version)) {\
        (VAR) = __pyx_dict_cached_value;\
    } else {\
        (VAR) = __pyx_dict_cached_value = (LOOKUP);\
        __pyx_dict_version = __PYX_GET_DICT_VERSION(DICT);\
    }\
}
static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj);
static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj);
static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version);
#else
#define __PYX_GET_DICT_VERSION(dict)  (0)
#define __PYX_UPDATE_DICT_CACHE(dict, value, cache_var, version_var)
#define __PYX_PY_DICT_LOOKUP_IF_MODIFIED(VAR, DICT, LOOKUP)  (VAR) = (LOOKUP);
#endif

/* GetModuleGlobalName.proto */
#if CYTHON_USE_DICT_VERSIONS
#define __Pyx_GetModuleGlobalName(var, name)  do {\
    static PY_UINT64_T __pyx_dict_version = 0;\
    static PyObject *__pyx_dict_cached_value = NULL;\
    (var) = (likely(__pyx_dict_version == __PYX_GET_DICT_VERSION(__pyx_mstate_global->__pyx_d))) ?\
        (likely(__pyx_dict_cached_value) ? __Pyx_NewRef(__pyx_dict_cached_value) : __Pyx_GetBuiltinName(name)) :\
        __Pyx__GetModuleGlobalName(name, &__pyx_dict_version, &__pyx_dict_cached_value);\
} while(0)
#define __Pyx_GetModuleGlobalNameUncached(var, name)  do {\
    PY_UINT64_T __pyx_dict_version;\
    PyObject *__pyx_dict_cached_value;\
    (var) = __Pyx__GetModuleGlobalName(name, &__pyx_dict_version, &__pyx_dict_cached_value);\
} while(0)
static PyObject *__Pyx__GetModuleGlobalName(PyObject *name, PY_UINT64_T *dict_version, PyObject **dict_cached_value);
#else
#define __Pyx_GetModuleGlobalName(var, name)  (var) = __Pyx__GetModuleGlobalName(name)
#define __Pyx_GetModuleGlobalNameUncached(var, name)  (var) = __Pyx__GetModuleGlobalName(name)
static CYTHON_INLINE PyObject *__Pyx__GetModuleGlobalName(PyObject *name);
#endif

/* PyFunctionFastCall.proto */
#if CYTHON_FAST_PYCALL
#if !CYTHON_VECTORCALL
#define __Pyx_PyFunction_FastCall(func, args, nargs)\
    __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject *const *args, Py_ssize_t nargs, PyObject *kwargs);
#endif
#define __Pyx_BUILD_ASSERT_EXPR(cond)\
    (sizeof(char [1 - 2*!(cond)]) - 1)
#ifndef Py_MEMBER_SIZE
#define Py_MEMBER_SIZE(type, member) sizeof(((type *)0)->member)
#endif
#if !CYTHON_VECTORCALL
#if PY_VERSION_HEX >= 0x03080000
  #include "frameobject.h"
  #define __Pxy_PyFrame_Initialize_Offsets()
  #define __Pyx_PyFrame_GetLocalsplus(frame)  ((frame)->f_localsplus)
#else
  static size_t __pyx_pyframe_localsplus_offset = 0;
  #include "frameobject.h"
  #define __Pxy_PyFrame_Initialize_Offsets()\
    ((void)__Pyx_BUILD_ASSERT_EXPR(sizeof(PyFrameObject) == offsetof(PyFrameObject, f_localsplus) + Py_MEMBER_SIZE(PyFrameObject, f_localsplus)),\
     (void)(__pyx_pyframe_localsplus_offset = ((size_t)PyFrame_Type.tp_basicsize) - Py_MEMBER_SIZE(PyFrameObject, f_localsplus)))
  #define __Pyx_PyFrame_GetLocalsplus(frame)\
    (assert(__pyx_pyframe_localsplus_offset), (PyObject **)(((char *)(frame)) + __pyx_pyframe_localsplus_offset))
#endif
#endif
#endif

/* PyObjectCall.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw);
#else
#define __Pyx_PyObject_Call(func, arg, kw) PyObject_Call(func, arg, kw)
#endif

/* PyObjectCallMethO.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg);
#endif

/* PyObjectFastCall.proto */
#define __Pyx_PyObject_FastCall(func, args, nargs)  __Pyx_PyObject_FastCallDict(func, args, (size_t)(nargs), NULL)
static CYTHON_INLINE PyObject* __Pyx_PyObject_FastCallDict(PyObject *func, PyObject * const*args, size_t nargs, PyObject *kwargs);

/* IncludeStringH.proto */
#include <string.h>

/* BytesEquals.proto */
static CYTHON_INLINE int __Pyx_PyBytes_Equals(PyObject* s1, PyObject* s2, int equals);

/* UnicodeEquals.proto */
static CYTHON_INLINE int __Pyx_PyUnicode_Equals(PyObject* s1, PyObject* s2, int equals);

/* RaiseException.proto */
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause);

/* PyObjectVectorCallKwBuilder.proto */
CYTHON_UNUSED static int __Pyx_VectorcallBuilder_AddArg_Check(PyObject *key, PyObject *value, PyObject *builder, PyObject **args, int n);
#if CYTHON_VECTORCALL
#if PY_VERSION_HEX >= 0x03090000
#define __Pyx_Object_Vectorcall_CallFromBuilder PyObject_Vectorcall
#else
#define __Pyx_Object_Vectorcall_CallFromBuilder _PyObject_Vectorcall
#endif
#define __Pyx_MakeVectorcallBuilderKwds(n) PyTuple_New(n)
static int __Pyx_VectorcallBuilder_AddArg(PyObject *key, PyObject *value, PyObject *builder, PyObject **args, int n);
static int __Pyx_VectorcallBuilder_AddArgStr(const char *key, PyObject *value, PyObject *builder, PyObject **args, int n);
#else
#define __Pyx_Object_Vectorcall_CallFromBuilder __Pyx_PyObject_FastCallDict
#define __Pyx_MakeVectorcallBuilderKwds(n) __Pyx_PyDict_NewPresized(n)
#define __Pyx_VectorcallBuilder_AddArg(key, value, builder, args, n) PyDict_SetItem(builder, key, value)
#define __Pyx_VectorcallBuilder_AddArgStr(key, value, builder, args, n) PyDict_SetItemString(builder, key, value)
#endif

/* HasAttr.proto */
#if __PYX_LIMITED_VERSION_HEX >= 0x030d0000
#define __Pyx_HasAttr(o, n)  PyObject_HasAttrWithError(o, n)
#else
static CYTHON_INLINE int __Pyx_HasAttr(PyObject *, PyObject *);
#endif

/* PyObjectDelAttr.proto */
#if CYTHON_COMPILING_IN_LIMITED_API && __PYX_LIMITED_VERSION_HEX < 0x030d0000
#define __Pyx_PyObject_DelAttr(o, n) PyObject_SetAttr(o, n, NULL)
#else
#define __Pyx_PyObject_DelAttr(o, n) PyObject_DelAttr(o, n)
#endif

/* PyObjectSetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
#define __Pyx_PyObject_DelAttrStr(o,n) __Pyx_PyObject_SetAttrStr(o, n, NULL)
static CYTHON_INLINE int __Pyx_PyObject_SetAttrStr(PyObject* obj, PyObject* attr_name, PyObject* value);
#else
#define __Pyx_PyObject_DelAttrStr(o,n)   __Pyx_PyObject_DelAttr(o,n)
#define __Pyx_PyObject_SetAttrStr(o,n,v) PyObject_SetAttr(o,n,v)
#endif

/* TupleAndListFromArray.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyList_FromArray(PyObject *const *src, Py_ssize_t n);
#endif
#if CYTHON_COMPILING_IN_CPYTHON || CYTHON_METH_FASTCALL
static CYTHON_INLINE PyObject* __Pyx_PyTuple_FromArray(PyObject *const *src, Py_ssize_t n);
#endif

/* fastcall.proto */
#if CYTHON_AVOID_BORROWED_REFS
    #define __Pyx_ArgRef_VARARGS(args, i) __Pyx_PySequence_ITEM(args, i)
#elif CYTHON_ASSUME_SAFE_MACROS
    #define __Pyx_ArgRef_VARARGS(args, i) __Pyx_NewRef(__Pyx_PyTuple_GET_ITEM(args, i))
#else
    #define __Pyx_ArgRef_VARARGS(args, i) __Pyx_XNewRef(PyTuple_GetItem(args, i))
#endif
#define __Pyx_NumKwargs_VARARGS(kwds) PyDict_Size(kwds)
#define __Pyx_KwValues_VARARGS(args, nargs) NULL
#define __Pyx_GetKwValue_VARARGS(kw, kwvalues, s) __Pyx_PyDict_GetItemStrWithError(kw, s)
#define __Pyx_KwargsAsDict_VARARGS(kw, kwvalues) PyDict_Copy(kw)
#if CYTHON_METH_FASTCALL
    #define __Pyx_ArgRef_FASTCALL(args, i) __Pyx_NewRef(args[i])
    #define __Pyx_NumKwargs_FASTCALL(kwds) __Pyx_PyTuple_GET_SIZE(kwds)
    #define __Pyx_KwValues_FASTCALL(args, nargs) ((args) + (nargs))
    static CYTHON_INLINE PyObject * __Pyx_GetKwValue_FASTCALL(PyObject *kwnames, PyObject *const *kwvalues, PyObject *s);
  #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030d0000 || CYTHON_COMPILING_IN_LIMITED_API
    CYTHON_UNUSED static PyObject *__Pyx_KwargsAsDict_FASTCALL(PyObject *kwnames, PyObject *const *kwvalues);
  #else
    #define __Pyx_KwargsAsDict_FASTCALL(kw, kwvalues) _PyStack_AsDict(kwvalues, kw)
  #endif
#else
    #define __Pyx_ArgRef_FASTCALL __Pyx_ArgRef_VARARGS
    #define __Pyx_NumKwargs_FASTCALL __Pyx_NumKwargs_VARARGS
    #define __Pyx_KwValues_FASTCALL __Pyx_KwValues_VARARGS
    #define __Pyx_GetKwValue_FASTCALL __Pyx_GetKwValue_VARARGS
    #define __Pyx_KwargsAsDict_FASTCALL __Pyx_KwargsAsDict_VARARGS
#endif
#define __Pyx_ArgsSlice_VARARGS(args, start, stop) PyTuple_GetSlice(args, start, stop)
#if CYTHON_METH_FASTCALL || (CYTHON_COMPILING_IN_CPYTHON && CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS)
#define __Pyx_ArgsSlice_FASTCALL(args, start, stop) __Pyx_PyTuple_FromArray(args + start, stop - start)
#else
#define __Pyx_ArgsSlice_FASTCALL(args, start, stop) PyTuple_GetSlice(args, start, stop)
#endif

/* RaiseDoubleKeywords.proto */
static void __Pyx_RaiseDoubleKeywordsError(const char* func_name, PyObject* kw_name);

/* ParseKeywords.proto */
static CYTHON_INLINE int __Pyx_ParseKeywords(
    PyObject *kwds, PyObject *const *kwvalues, PyObject ** const argnames[],
    PyObject *kwds2, PyObject *values[],
    Py_ssize_t num_pos_args, Py_ssize_t num_kwargs,
    const char* function_name,
    int ignore_unknown_kwargs
);

/* CallCFunction.proto */
#define __Pyx_CallCFunction(cfunc, self, args)\
    ((PyCFunction)(void(*)(void))(cfunc)->func)(self, args)
#define __Pyx_CallCFunctionWithKeywords(cfunc, self, args, kwargs)\
    ((PyCFunctionWithKeywords)(void(*)(void))(cfunc)->func)(self, args, kwargs)
#define __Pyx_CallCFunctionFast(cfunc, self, args, nargs)\
    ((__Pyx_PyCFunctionFast)(void(*)(void))(PyCFunction)(cfunc)->func)(self, args, nargs)
#define __Pyx_CallCFunctionFastWithKeywords(cfunc, self, args, nargs, kwnames)\
    ((__Pyx_PyCFunctionFastWithKeywords)(void(*)(void))(PyCFunction)(cfunc)->func)(self, args, nargs, kwnames)

/* UnpackUnboundCMethod.proto */
typedef struct {
    PyObject *type;
    PyObject **method_name;
#if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING && CYTHON_ATOMICS
    __pyx_atomic_int_type initialized;
#endif
    PyCFunction func;
    PyObject *method;
    int flag;
} __Pyx_CachedCFunction;
#if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
static CYTHON_INLINE int __Pyx_CachedCFunction_GetAndSetInitializing(__Pyx_CachedCFunction *cfunc) {
#if !CYTHON_ATOMICS
    return 1;
#else
    __pyx_nonatomic_int_type expected = 0;
    if (__pyx_atomic_int_cmp_exchange(&cfunc->initialized, &expected, 1)) {
        return 0;
    }
    return expected;
#endif
}
static CYTHON_INLINE void __Pyx_CachedCFunction_SetFinishedInitializing(__Pyx_CachedCFunction *cfunc) {
#if CYTHON_ATOMICS
    __pyx_atomic_store(&cfunc->initialized, 2);
#endif
}
#else
#define __Pyx_CachedCFunction_GetAndSetInitializing(cfunc) 2
#define __Pyx_CachedCFunction_SetFinishedInitializing(cfunc)
#endif

/* CallUnboundCMethod2.proto */
CYTHON_UNUSED
static PyObject* __Pyx__CallUnboundCMethod2(__Pyx_CachedCFunction* cfunc, PyObject* self, PyObject* arg1, PyObject* arg2);
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject *__Pyx_CallUnboundCMethod2(__Pyx_CachedCFunction *cfunc, PyObject *self, PyObject *arg1, PyObject *arg2);
#else
#define __Pyx_CallUnboundCMethod2(cfunc, self, arg1, arg2)  __Pyx__CallUnboundCMethod2(cfunc, self, arg1, arg2)
#endif

/* RaiseArgTupleInvalid.proto */
static void __Pyx_RaiseArgtupleInvalid(const char* func_name, int exact,
    Py_ssize_t num_min, Py_ssize_t num_max, Py_ssize_t num_found);

/* DictGetItem.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject *__Pyx_PyDict_GetItem(PyObject *d, PyObject* key);
#define __Pyx_PyObject_Dict_GetItem(obj, name)\
    (likely(PyDict_CheckExact(obj)) ?\
     __Pyx_PyDict_GetItem(obj, name) : PyObject_GetItem(obj, name))
#else
#define __Pyx_PyDict_GetItem(d, key) PyObject_GetItem(d, key)
#define __Pyx_PyObject_Dict_GetItem(obj, name)  PyObject_GetItem(obj, name)
#endif

/* PyObjectFastCallMethod.proto */
#if CYTHON_VECTORCALL && PY_VERSION_HEX >= 0x03090000
#define __Pyx_PyObject_FastCallMethod(name, args, nargsf) PyObject_VectorcallMethod(name, args, nargsf, NULL)
#else
static PyObject *__Pyx_PyObject_FastCallMethod(PyObject *name, PyObject *const *args, size_t nargsf);
#endif

/* AssertionsEnabled.proto */
#if CYTHON_COMPILING_IN_LIMITED_API  ||  (CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030C0000)
  static int __pyx_assertions_enabled_flag;
  #define __pyx_assertions_enabled() (__pyx_assertions_enabled_flag)
  static int __Pyx_init_assertions_enabled(void) {
    PyObject *builtins, *debug, *debug_str;
    int flag;
    builtins = PyEval_GetBuiltins();
    if (!builtins) goto bad;
    debug_str = PyUnicode_FromStringAndSize("__debug__", 9);
    if (!debug_str) goto bad;
    debug = PyObject_GetItem(builtins, debug_str);
    Py_DECREF(debug_str);
    if (!debug) goto bad;
    flag = PyObject_IsTrue(debug);
    Py_DECREF(debug);
    if (flag == -1) goto bad;
    __pyx_assertions_enabled_flag = flag;
    return 0;
  bad:
    __pyx_assertions_enabled_flag = 1;
    return -1;
  }
#else
  #define __Pyx_init_assertions_enabled()  (0)
  #define __pyx_assertions_enabled()  (!Py_OptimizeFlag)
#endif

/* ListAppend.proto */
#if CYTHON_USE_PYLIST_INTERNALS && CYTHON_ASSUME_SAFE_MACROS
static CYTHON_INLINE int __Pyx_PyList_Append(PyObject* list, PyObject* x) {
    PyListObject* L = (PyListObject*) list;
    Py_ssize_t len = Py_SIZE(list);
    if (likely(L->allocated > len) & likely(len > (L->allocated >> 1))) {
        Py_INCREF(x);
        #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030d0000
        L->ob_item[len] = x;
        #else
        PyList_SET_ITEM(list, len, x);
        #endif
        __Pyx_SET_SIZE(list, len + 1);
        return 0;
    }
    return PyList_Append(list, x);
}
#else
#define __Pyx_PyList_Append(L,x) PyList_Append(L,x)
#endif

/* RaiseTooManyValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected);

/* RaiseNeedMoreValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index);

/* IterFinish.proto */
static CYTHON_INLINE int __Pyx_IterFinish(void);

/* UnpackItemEndCheck.proto */
static int __Pyx_IternextUnpackEndCheck(PyObject *retval, Py_ssize_t expected);

/* RaiseUnexpectedTypeError.proto */
static int __Pyx_RaiseUnexpectedTypeError(const char *expected, PyObject *obj);

/* GetItemInt.proto */
#define __Pyx_GetItemInt(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck, has_gil)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Fast(o, (Py_ssize_t)i, is_list, wraparound, boundscheck) :\
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL) :\
               __Pyx_GetItemInt_Generic(o, to_py_func(i))))
#define __Pyx_GetItemInt_List(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck, has_gil)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_List_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
#define __Pyx_GetItemInt_Tuple(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck, has_gil)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Tuple_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "tuple index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j);
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i,
                                                     int is_list, int wraparound, int boundscheck);

/* SetItemInt.proto */
#define __Pyx_SetItemInt(o, i, v, type, is_signed, to_py_func, is_list, wraparound, boundscheck, has_gil)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_SetItemInt_Fast(o, (Py_ssize_t)i, v, is_list, wraparound, boundscheck) :\
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list assignment index out of range"), -1) :\
               __Pyx_SetItemInt_Generic(o, to_py_func(i), v)))
static int __Pyx_SetItemInt_Generic(PyObject *o, PyObject *j, PyObject *v);
static CYTHON_INLINE int __Pyx_SetItemInt_Fast(PyObject *o, Py_ssize_t i, PyObject *v,
                                               int is_list, int wraparound, int boundscheck);

/* GetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_GetException(type, value, tb)  __Pyx__GetException(__pyx_tstate, type, value, tb)
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* SwapException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSwap(type, value, tb)  __Pyx__ExceptionSwap(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb);
#endif

/* GetTopmostException.proto */
#if CYTHON_USE_EXC_INFO_STACK && CYTHON_FAST_THREAD_STATE
static _PyErr_StackItem * __Pyx_PyErr_GetTopmostException(PyThreadState *tstate);
#endif

/* SaveResetException.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ExceptionSave(type, value, tb)  __Pyx__ExceptionSave(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#define __Pyx_ExceptionReset(type, value, tb)  __Pyx__ExceptionReset(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
#else
#define __Pyx_ExceptionSave(type, value, tb)   PyErr_GetExcInfo(type, value, tb)
#define __Pyx_ExceptionReset(type, value, tb)  PyErr_SetExcInfo(type, value, tb)
#endif

/* ListCompAppend.proto */
#if CYTHON_USE_PYLIST_INTERNALS && CYTHON_ASSUME_SAFE_MACROS
static CYTHON_INLINE int __Pyx_ListComp_Append(PyObject* list, PyObject* x) {
    PyListObject* L = (PyListObject*) list;
    Py_ssize_t len = Py_SIZE(list);
    if (likely(L->allocated > len)) {
        Py_INCREF(x);
        #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030d0000
        L->ob_item[len] = x;
        #else
        PyList_SET_ITEM(list, len, x);
        #endif
        __Pyx_SET_SIZE(list, len + 1);
        return 0;
    }
    return PyList_Append(list, x);
}
#else
#define __Pyx_ListComp_Append(L,x) PyList_Append(L,x)
#endif

/* PySequenceContains.proto */
static CYTHON_INLINE int __Pyx_PySequence_ContainsTF(PyObject* item, PyObject* seq, int eq) {
    int result = PySequence_Contains(seq, item);
    return unlikely(result < 0) ? result : (result == (eq == Py_EQ));
}

/* WriteUnraisableException.proto */
static void __Pyx_WriteUnraisable(const char *name, int clineno,
                                  int lineno, const char *filename,
                                  int full_traceback, int nogil);

/* RejectKeywords.proto */
static void __Pyx_RejectKeywords(const char* function_name, PyObject *kwds);

/* DivInt[int].proto */
static CYTHON_INLINE int __Pyx_div_int(int, int, int b_is_constant);

/* UnaryNegOverflows.proto */
#define __Pyx_UNARY_NEG_WOULD_OVERFLOW(x)\
        (((x) < 0) & ((unsigned long)(x) == 0-(unsigned long)(x)))

/* ModInt[int].proto */
static CYTHON_INLINE int __Pyx_mod_int(int, int, int b_is_constant);

/* PyLongBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static CYTHON_INLINE PyObject* __Pyx_PyLong_AddObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check);
#else
#define __Pyx_PyLong_AddObjC(op1, op2, intval, inplace, zerodivision_check)\
    (inplace ? PyNumber_InPlaceAdd(op1, op2) : PyNumber_Add(op1, op2))
#endif

/* ArgTypeTest.proto */
#define __Pyx_ArgTypeTest(obj, type, none_allowed, name, exact)\
    ((likely(__Pyx_IS_TYPE(obj, type) | (none_allowed && (obj == Py_None)))) ? 1 :\
        __Pyx__ArgTypeTest(obj, type, name, exact))
static int __Pyx__ArgTypeTest(PyObject *obj, PyTypeObject *type, const char *name, int exact);

/* PyDictContains.proto */
static CYTHON_INLINE int __Pyx_PyDict_ContainsTF(PyObject* item, PyObject* dict, int eq) {
    int result = PyDict_Contains(dict, item);
    return unlikely(result < 0) ? result : (result == (eq == Py_EQ));
}

/* SliceObject.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetSlice(
        PyObject* obj, Py_ssize_t cstart, Py_ssize_t cstop,
        PyObject** py_start, PyObject** py_stop, PyObject** py_slice,
        int has_cstart, int has_cstop, int wraparound);

/* PyObjectCallOneArg.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg);

/* ObjectGetItem.proto */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject *__Pyx_PyObject_GetItem(PyObject *obj, PyObject *key);
#else
#define __Pyx_PyObject_GetItem(obj, key)  PyObject_GetItem(obj, key)
#endif

/* PyLongCompare.proto */
static CYTHON_INLINE int __Pyx_PyLong_BoolNeObjC(PyObject *op1, PyObject *op2, long intval, long inplace);

/* PyLongBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static CYTHON_INLINE PyObject* __Pyx_PyLong_SubtractObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check);
#else
#define __Pyx_PyLong_SubtractObjC(op1, op2, intval, inplace, zerodivision_check)\
    (inplace ? PyNumber_InPlaceSubtract(op1, op2) : PyNumber_Subtract(op1, op2))
#endif

/* PyLongBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static CYTHON_INLINE PyObject* __Pyx_PyLong_FloorDivideObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check);
#else
#define __Pyx_PyLong_FloorDivideObjC(op1, op2, intval, inplace, zerodivision_check)\
    (inplace ? PyNumber_InPlaceFloorDivide(op1, op2) : PyNumber_FloorDivide(op1, op2))
#endif

/* GetAttr3.proto */
static CYTHON_INLINE PyObject *__Pyx_GetAttr3(PyObject *, PyObject *, PyObject *);

/* MoveIfSupported.proto */
#if CYTHON_USE_CPP_STD_MOVE
  #include <utility>
  #define __PYX_STD_MOVE_IF_SUPPORTED(x) std::move(x)
#else
  #define __PYX_STD_MOVE_IF_SUPPORTED(x) x
#endif

/* RaiseKeywordRequired.proto */
static void __Pyx_RaiseKeywordRequired(const char* func_name, PyObject* kw_name);

/* Import.proto */
static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level);

/* ImportFrom.proto */
static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name);

/* RaiseUnboundLocalError.proto */
static void __Pyx_RaiseUnboundLocalError(const char *varname);

/* CallTypeTraverse.proto */
#if !CYTHON_USE_TYPE_SPECS || (!CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x03090000)
#define __Pyx_call_type_traverse(o, always_call, visit, arg) 0
#else
static int __Pyx_call_type_traverse(PyObject *o, int always_call, visitproc visit, void *arg);
#endif

/* LimitedApiGetTypeDict.proto */
#if CYTHON_COMPILING_IN_LIMITED_API
static PyObject *__Pyx_GetTypeDict(PyTypeObject *tp);
#endif

/* SetItemOnTypeDict.proto */
static int __Pyx__SetItemOnTypeDict(PyTypeObject *tp, PyObject *k, PyObject *v);
#define __Pyx_SetItemOnTypeDict(tp, k, v) __Pyx__SetItemOnTypeDict((PyTypeObject*)tp, k, v)

/* FixUpExtensionType.proto */
static CYTHON_INLINE int __Pyx_fix_up_extension_type_from_spec(PyType_Spec *spec, PyTypeObject *type);

/* PyObjectCallNoArg.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func);

/* PyObjectGetMethod.proto */
static int __Pyx_PyObject_GetMethod(PyObject *obj, PyObject *name, PyObject **method);

/* PyObjectCallMethod0.proto */
static PyObject* __Pyx_PyObject_CallMethod0(PyObject* obj, PyObject* method_name);

/* ValidateBasesTuple.proto */
#if CYTHON_COMPILING_IN_CPYTHON || CYTHON_COMPILING_IN_LIMITED_API || CYTHON_USE_TYPE_SPECS
static int __Pyx_validate_bases_tuple(const char *type_name, Py_ssize_t dictoffset, PyObject *bases);
#endif

/* PyType_Ready.proto */
CYTHON_UNUSED static int __Pyx_PyType_Ready(PyTypeObject *t);

/* SetVTable.proto */
static int __Pyx_SetVtable(PyTypeObject* typeptr , void* vtable);

/* GetVTable.proto */
static void* __Pyx_GetVtable(PyTypeObject *type);

/* MergeVTables.proto */
static int __Pyx_MergeVtables(PyTypeObject *type);

/* DelItemOnTypeDict.proto */
static int __Pyx__DelItemOnTypeDict(PyTypeObject *tp, PyObject *k);
#define __Pyx_DelItemOnTypeDict(tp, k) __Pyx__DelItemOnTypeDict((PyTypeObject*)tp, k)

/* SetupReduce.proto */
static int __Pyx_setup_reduce(PyObject* type_obj);

/* TypeImport.proto */
#ifndef __PYX_HAVE_RT_ImportType_proto_3_1_6
#define __PYX_HAVE_RT_ImportType_proto_3_1_6
#if defined (__STDC_VERSION__) && __STDC_VERSION__ >= 201112L
#include <stdalign.h>
#endif
#if (defined (__STDC_VERSION__) && __STDC_VERSION__ >= 201112L) || __cplusplus >= 201103L
#define __PYX_GET_STRUCT_ALIGNMENT_3_1_6(s) alignof(s)
#else
#define __PYX_GET_STRUCT_ALIGNMENT_3_1_6(s) sizeof(void*)
#endif
enum __Pyx_ImportType_CheckSize_3_1_6 {
   __Pyx_ImportType_CheckSize_Error_3_1_6 = 0,
   __Pyx_ImportType_CheckSize_Warn_3_1_6 = 1,
   __Pyx_ImportType_CheckSize_Ignore_3_1_6 = 2
};
static PyTypeObject *__Pyx_ImportType_3_1_6(PyObject* module, const char *module_name, const char *class_name, size_t size, size_t alignment, enum __Pyx_ImportType_CheckSize_3_1_6 check_size);
#endif

/* ImportDottedModule.proto */
static PyObject *__Pyx_ImportDottedModule(PyObject *name, PyObject *parts_tuple);
static PyObject *__Pyx_ImportDottedModule_WalkParts(PyObject *module, PyObject *name, PyObject *parts_tuple);

/* ListPack.proto */
static PyObject *__Pyx_PyList_Pack(Py_ssize_t n, ...);

/* Py3UpdateBases.proto */
static PyObject* __Pyx_PEP560_update_bases(PyObject *bases);

/* CalculateMetaclass.proto */
static PyObject *__Pyx_CalculateMetaclass(PyTypeObject *metaclass, PyObject *bases);

/* FetchSharedCythonModule.proto */
static PyObject *__Pyx_FetchSharedCythonABIModule(void);

/* dict_setdefault.proto */
static CYTHON_INLINE PyObject *__Pyx_PyDict_SetDefault(PyObject *d, PyObject *key, PyObject *default_value, int is_safe_type);

/* FetchCommonType.proto */
static PyTypeObject* __Pyx_FetchCommonTypeFromSpec(PyTypeObject *metaclass, PyObject *module, PyType_Spec *spec, PyObject *bases);

/* CommonTypesMetaclass.proto */
static int __pyx_CommonTypesMetaclass_init(PyObject *module);
#define __Pyx_CommonTypesMetaclass_USED

/* PyMethodNew.proto */
static PyObject *__Pyx_PyMethod_New(PyObject *func, PyObject *self, PyObject *typ);

/* PyVectorcallFastCallDict.proto */
#if CYTHON_METH_FASTCALL && (CYTHON_VECTORCALL || CYTHON_BACKPORT_VECTORCALL)
static CYTHON_INLINE PyObject *__Pyx_PyVectorcall_FastCallDict(PyObject *func, __pyx_vectorcallfunc vc, PyObject *const *args, size_t nargs, PyObject *kw);
#endif

/* CythonFunctionShared.proto */
#define __Pyx_CyFunction_USED
#define __Pyx_CYFUNCTION_STATICMETHOD  0x01
#define __Pyx_CYFUNCTION_CLASSMETHOD   0x02
#define __Pyx_CYFUNCTION_CCLASS        0x04
#define __Pyx_CYFUNCTION_COROUTINE     0x08
#define __Pyx_CyFunction_GetClosure(f)\
    (((__pyx_CyFunctionObject *) (f))->func_closure)
#if PY_VERSION_HEX < 0x030900B1 || CYTHON_COMPILING_IN_LIMITED_API
  #define __Pyx_CyFunction_GetClassObj(f)\
      (((__pyx_CyFunctionObject *) (f))->func_classobj)
#else
  #define __Pyx_CyFunction_GetClassObj(f)\
      ((PyObject*) ((PyCMethodObject *) (f))->mm_class)
#endif
#define __Pyx_CyFunction_SetClassObj(f, classobj)\
    __Pyx__CyFunction_SetClassObj((__pyx_CyFunctionObject *) (f), (classobj))
#define __Pyx_CyFunction_Defaults(type, f)\
    ((type *)(((__pyx_CyFunctionObject *) (f))->defaults))
#define __Pyx_CyFunction_SetDefaultsGetter(f, g)\
    ((__pyx_CyFunctionObject *) (f))->defaults_getter = (g)
typedef struct {
#if CYTHON_COMPILING_IN_LIMITED_API
    PyObject_HEAD
    PyObject *func;
#elif PY_VERSION_HEX < 0x030900B1
    PyCFunctionObject func;
#else
    PyCMethodObject func;
#endif
#if CYTHON_BACKPORT_VECTORCALL ||\
        (CYTHON_COMPILING_IN_LIMITED_API && CYTHON_METH_FASTCALL)
    __pyx_vectorcallfunc func_vectorcall;
#endif
#if CYTHON_COMPILING_IN_LIMITED_API
    PyObject *func_weakreflist;
#endif
    PyObject *func_dict;
    PyObject *func_name;
    PyObject *func_qualname;
    PyObject *func_doc;
    PyObject *func_globals;
    PyObject *func_code;
    PyObject *func_closure;
#if PY_VERSION_HEX < 0x030900B1 || CYTHON_COMPILING_IN_LIMITED_API
    PyObject *func_classobj;
#endif
    PyObject *defaults;
    int flags;
    PyObject *defaults_tuple;
    PyObject *defaults_kwdict;
    PyObject *(*defaults_getter)(PyObject *);
    PyObject *func_annotations;
    PyObject *func_is_coroutine;
} __pyx_CyFunctionObject;
#undef __Pyx_CyOrPyCFunction_Check
#define __Pyx_CyFunction_Check(obj)  __Pyx_TypeCheck(obj, __pyx_mstate_global->__pyx_CyFunctionType)
#define __Pyx_CyOrPyCFunction_Check(obj)  __Pyx_TypeCheck2(obj, __pyx_mstate_global->__pyx_CyFunctionType, &PyCFunction_Type)
#define __Pyx_CyFunction_CheckExact(obj)  __Pyx_IS_TYPE(obj, __pyx_mstate_global->__pyx_CyFunctionType)
static CYTHON_INLINE int __Pyx__IsSameCyOrCFunction(PyObject *func, void (*cfunc)(void));
#undef __Pyx_IsSameCFunction
#define __Pyx_IsSameCFunction(func, cfunc)   __Pyx__IsSameCyOrCFunction(func, cfunc)
static PyObject *__Pyx_CyFunction_Init(__pyx_CyFunctionObject* op, PyMethodDef *ml,
                                      int flags, PyObject* qualname,
                                      PyObject *closure,
                                      PyObject *module, PyObject *globals,
                                      PyObject* code);
static CYTHON_INLINE void __Pyx__CyFunction_SetClassObj(__pyx_CyFunctionObject* f, PyObject* classobj);
static CYTHON_INLINE PyObject *__Pyx_CyFunction_InitDefaults(PyObject *func,
                                                         PyTypeObject *defaults_type);
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsTuple(PyObject *m,
                                                            PyObject *tuple);
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsKwDict(PyObject *m,
                                                             PyObject *dict);
static CYTHON_INLINE void __Pyx_CyFunction_SetAnnotationsDict(PyObject *m,
                                                              PyObject *dict);
static int __pyx_CyFunction_init(PyObject *module);
#if CYTHON_METH_FASTCALL
static PyObject * __Pyx_CyFunction_Vectorcall_NOARGS(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames);
static PyObject * __Pyx_CyFunction_Vectorcall_O(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames);
static PyObject * __Pyx_CyFunction_Vectorcall_FASTCALL_KEYWORDS(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames);
static PyObject * __Pyx_CyFunction_Vectorcall_FASTCALL_KEYWORDS_METHOD(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames);
#if CYTHON_BACKPORT_VECTORCALL || CYTHON_COMPILING_IN_LIMITED_API
#define __Pyx_CyFunction_func_vectorcall(f) (((__pyx_CyFunctionObject*)f)->func_vectorcall)
#else
#define __Pyx_CyFunction_func_vectorcall(f) (((PyCFunctionObject*)f)->vectorcall)
#endif
#endif

/* CythonFunction.proto */
static PyObject *__Pyx_CyFunction_New(PyMethodDef *ml,
                                      int flags, PyObject* qualname,
                                      PyObject *closure,
                                      PyObject *module, PyObject *globals,
                                      PyObject* code);

/* SetNameInClass.proto */
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030d0000
#define __Pyx_SetNameInClass(ns, name, value)\
    (likely(PyDict_CheckExact(ns)) ? _PyDict_SetItem_KnownHash(ns, name, value, ((PyASCIIObject *) name)->hash) : PyObject_SetItem(ns, name, value))
#elif CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_SetNameInClass(ns, name, value)\
    (likely(PyDict_CheckExact(ns)) ? PyDict_SetItem(ns, name, value) : PyObject_SetItem(ns, name, value))
#else
#define __Pyx_SetNameInClass(ns, name, value)  PyObject_SetItem(ns, name, value)
#endif

/* PyObjectCall2Args.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call2Args(PyObject* function, PyObject* arg1, PyObject* arg2);

/* PyObjectLookupSpecial.proto */
#if CYTHON_USE_PYTYPE_LOOKUP && CYTHON_USE_TYPE_SLOTS
#define __Pyx_PyObject_LookupSpecialNoError(obj, attr_name)  __Pyx__PyObject_LookupSpecial(obj, attr_name, 0)
#define __Pyx_PyObject_LookupSpecial(obj, attr_name)  __Pyx__PyObject_LookupSpecial(obj, attr_name, 1)
static CYTHON_INLINE PyObject* __Pyx__PyObject_LookupSpecial(PyObject* obj, PyObject* attr_name, int with_error);
#else
#define __Pyx_PyObject_LookupSpecialNoError(o,n) __Pyx_PyObject_GetAttrStrNoError(o,n)
#define __Pyx_PyObject_LookupSpecial(o,n) __Pyx_PyObject_GetAttrStr(o,n)
#endif

/* Py3ClassCreate.proto */
static PyObject *__Pyx_Py3MetaclassPrepare(PyObject *metaclass, PyObject *bases, PyObject *name, PyObject *qualname,
                                           PyObject *mkw, PyObject *modname, PyObject *doc);
static PyObject *__Pyx_Py3ClassCreate(PyObject *metaclass, PyObject *name, PyObject *bases, PyObject *dict,
                                      PyObject *mkw, int calculate_metaclass, int allow_py2_metaclass);

/* CLineInTraceback.proto */
#if CYTHON_CLINE_IN_TRACEBACK && CYTHON_CLINE_IN_TRACEBACK_RUNTIME
static int __Pyx_CLineForTraceback(PyThreadState *tstate, int c_line);
#else
#define __Pyx_CLineForTraceback(tstate, c_line)  (((CYTHON_CLINE_IN_TRACEBACK)) ? c_line : 0)
#endif

/* CodeObjectCache.proto */
#if CYTHON_COMPILING_IN_LIMITED_API
typedef PyObject __Pyx_CachedCodeObjectType;
#else
typedef PyCodeObject __Pyx_CachedCodeObjectType;
#endif
typedef struct {
    __Pyx_CachedCodeObjectType* code_object;
    int code_line;
} __Pyx_CodeObjectCacheEntry;
struct __Pyx_CodeObjectCache {
    int count;
    int max_count;
    __Pyx_CodeObjectCacheEntry* entries;
  #if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
    __pyx_atomic_int_type accessor_count;
  #endif
};
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line);
static __Pyx_CachedCodeObjectType *__pyx_find_code_object(int code_line);
static void __pyx_insert_code_object(int code_line, __Pyx_CachedCodeObjectType* code_object);

/* AddTraceback.proto */
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename);

/* GCCDiagnostics.proto */
#if !defined(__INTEL_COMPILER) && defined(__GNUC__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 6))
#define __Pyx_HAS_GCC_DIAGNOSTIC
#endif

/* CppExceptionConversion.proto */
#ifndef __Pyx_CppExn2PyErr
#include <new>
#include <typeinfo>
#include <stdexcept>
#include <ios>
static void __Pyx_CppExn2PyErr() {
  try {
    if (PyErr_Occurred())
      ; // let the latest Python exn pass through and ignore the current one
    else
      throw;
  } catch (const std::bad_alloc& exn) {
    PyErr_SetString(PyExc_MemoryError, exn.what());
  } catch (const std::bad_cast& exn) {
    PyErr_SetString(PyExc_TypeError, exn.what());
  } catch (const std::bad_typeid& exn) {
    PyErr_SetString(PyExc_TypeError, exn.what());
  } catch (const std::domain_error& exn) {
    PyErr_SetString(PyExc_ValueError, exn.what());
  } catch (const std::invalid_argument& exn) {
    PyErr_SetString(PyExc_ValueError, exn.what());
  } catch (const std::ios_base::failure& exn) {
    PyErr_SetString(PyExc_IOError, exn.what());
  } catch (const std::out_of_range& exn) {
    PyErr_SetString(PyExc_IndexError, exn.what());
  } catch (const std::overflow_error& exn) {
    PyErr_SetString(PyExc_OverflowError, exn.what());
  } catch (const std::range_error& exn) {
    PyErr_SetString(PyExc_ArithmeticError, exn.what());
  } catch (const std::underflow_error& exn) {
    PyErr_SetString(PyExc_ArithmeticError, exn.what());
  } catch (const std::exception& exn) {
    PyErr_SetString(PyExc_RuntimeError, exn.what());
  }
  catch (...)
  {
    PyErr_SetString(PyExc_RuntimeError, "Unknown exception");
  }
}
#endif

/* LengthHint.proto */
#if CYTHON_COMPILING_IN_LIMITED_API
#define __Pyx_PyObject_LengthHint(o, defaultval)  (defaultval)
#else
#define __Pyx_PyObject_LengthHint(o, defaultval)  PyObject_LengthHint(o, defaultval)
#endif

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyLong_From_int(int value);

/* CIntFromPy.proto */
static CYTHON_INLINE int __Pyx_PyLong_As_int(PyObject *);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyLong_From_cufftType_t(cufftType_t value);

/* CIntFromPy.proto */
static CYTHON_INLINE cufftType_t __Pyx_PyLong_As_cufftType_t(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE PY_LONG_LONG __Pyx_PyLong_As_PY_LONG_LONG(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE long __Pyx_PyLong_As_long(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE size_t __Pyx_PyLong_As_size_t(PyObject *);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyLong_From_long(long value);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyLong_From_PY_LONG_LONG(PY_LONG_LONG value);

/* FormatTypeName.proto */
#if CYTHON_COMPILING_IN_LIMITED_API
typedef PyObject *__Pyx_TypeName;
#define __Pyx_FMT_TYPENAME "%U"
#define __Pyx_DECREF_TypeName(obj) Py_XDECREF(obj)
#if __PYX_LIMITED_VERSION_HEX >= 0x030d0000
#define __Pyx_PyType_GetFullyQualifiedName PyType_GetFullyQualifiedName
#else
static __Pyx_TypeName __Pyx_PyType_GetFullyQualifiedName(PyTypeObject* tp);
#endif
#else  // !LIMITED_API
typedef const char *__Pyx_TypeName;
#define __Pyx_FMT_TYPENAME "%.200s"
#define __Pyx_PyType_GetFullyQualifiedName(tp) ((tp)->tp_name)
#define __Pyx_DECREF_TypeName(obj)
#endif

/* FastTypeChecks.proto */
#if CYTHON_COMPILING_IN_CPYTHON
#define __Pyx_TypeCheck(obj, type) __Pyx_IsSubtype(Py_TYPE(obj), (PyTypeObject *)type)
#define __Pyx_TypeCheck2(obj, type1, type2) __Pyx_IsAnySubtype2(Py_TYPE(obj), (PyTypeObject *)type1, (PyTypeObject *)type2)
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b);
static CYTHON_INLINE int __Pyx_IsAnySubtype2(PyTypeObject *cls, PyTypeObject *a, PyTypeObject *b);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject *type);
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *type1, PyObject *type2);
#else
#define __Pyx_TypeCheck(obj, type) PyObject_TypeCheck(obj, (PyTypeObject *)type)
#define __Pyx_TypeCheck2(obj, type1, type2) (PyObject_TypeCheck(obj, (PyTypeObject *)type1) || PyObject_TypeCheck(obj, (PyTypeObject *)type2))
#define __Pyx_PyErr_GivenExceptionMatches(err, type) PyErr_GivenExceptionMatches(err, type)
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *type1, PyObject *type2) {
    return PyErr_GivenExceptionMatches(err, type1) || PyErr_GivenExceptionMatches(err, type2);
}
#endif
#define __Pyx_PyErr_ExceptionMatches2(err1, err2)  __Pyx_PyErr_GivenExceptionMatches2(__Pyx_PyErr_CurrentExceptionType(), err1, err2)
#define __Pyx_PyException_Check(obj) __Pyx_TypeCheck(obj, PyExc_Exception)
#ifdef PyExceptionInstance_Check
  #define __Pyx_PyBaseException_Check(obj) PyExceptionInstance_Check(obj)
#else
  #define __Pyx_PyBaseException_Check(obj) __Pyx_TypeCheck(obj, PyExc_BaseException)
#endif

/* GetRuntimeVersion.proto */
static unsigned long __Pyx_get_runtime_version(void);

/* CheckBinaryVersion.proto */
static int __Pyx_check_binary_version(unsigned long ct_version, unsigned long rt_version, int allow_newer);

/* FunctionExport.proto */
static int __Pyx_ExportFunction(const char *name, void (*f)(void), const char *sig);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyLong_From___pyx_anon_enum(int value);

/* MultiPhaseInitModuleState.proto */
#if CYTHON_PEP489_MULTI_PHASE_INIT && CYTHON_USE_MODULE_STATE
static PyObject *__Pyx_State_FindModule(void*);
static int __Pyx_State_AddModule(PyObject* module, void*);
static int __Pyx_State_RemoveModule(void*);
#elif CYTHON_USE_MODULE_STATE
#define __Pyx_State_FindModule PyState_FindModule
#define __Pyx_State_AddModule PyState_AddModule
#define __Pyx_State_RemoveModule PyState_RemoveModule
#endif

/* #### Code section: module_declarations ### */
/* CythonABIVersion.proto */
#if CYTHON_COMPILING_IN_LIMITED_API
    #if CYTHON_METH_FASTCALL
        #define __PYX_FASTCALL_ABI_SUFFIX  "_fastcall"
    #else
        #define __PYX_FASTCALL_ABI_SUFFIX
    #endif
    #define __PYX_LIMITED_ABI_SUFFIX "limited" __PYX_FASTCALL_ABI_SUFFIX __PYX_AM_SEND_ABI_SUFFIX
#else
    #define __PYX_LIMITED_ABI_SUFFIX
#endif
#if __PYX_HAS_PY_AM_SEND == 1
    #define __PYX_AM_SEND_ABI_SUFFIX
#elif __PYX_HAS_PY_AM_SEND == 2
    #define __PYX_AM_SEND_ABI_SUFFIX "amsendbackport"
#else
    #define __PYX_AM_SEND_ABI_SUFFIX "noamsend"
#endif
#ifndef __PYX_MONITORING_ABI_SUFFIX
    #define __PYX_MONITORING_ABI_SUFFIX
#endif
#if CYTHON_USE_TP_FINALIZE
    #define __PYX_TP_FINALIZE_ABI_SUFFIX
#else
    #define __PYX_TP_FINALIZE_ABI_SUFFIX "nofinalize"
#endif
#if CYTHON_USE_FREELISTS || !defined(__Pyx_AsyncGen_USED)
    #define __PYX_FREELISTS_ABI_SUFFIX
#else
    #define __PYX_FREELISTS_ABI_SUFFIX "nofreelists"
#endif
#define CYTHON_ABI  __PYX_ABI_VERSION __PYX_LIMITED_ABI_SUFFIX __PYX_MONITORING_ABI_SUFFIX __PYX_TP_FINALIZE_ABI_SUFFIX __PYX_FREELISTS_ABI_SUFFIX __PYX_AM_SEND_ABI_SUFFIX
#define __PYX_ABI_MODULE_NAME "_cython_" CYTHON_ABI
#define __PYX_TYPE_MODULE_PREFIX __PYX_ABI_MODULE_NAME "."

static void __pyx_f_4cupy_4cuda_5cufft_6Plan1d__single_gpu_get_plan(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, cufftHandle __pyx_v_plan, int __pyx_v_nx, int __pyx_v_fft_type, int __pyx_v_batch); /* proto*/
static void __pyx_f_4cupy_4cuda_5cufft_6Plan1d__multi_gpu_get_plan(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, cufftHandle __pyx_v_plan, int __pyx_v_nx, int __pyx_v_fft_type, int __pyx_v_batch, PyObject *__pyx_v_devices, CYTHON_UNUSED PyObject *__pyx_v_out); /* proto*/

/* Module declarations from "libc.stdint" */

/* Module declarations from "cython" */

/* Module declarations from "cpython.mem" */

/* Module declarations from "libc.string" */

/* Module declarations from "libcpp" */

/* Module declarations from "libcpp.vector" */

/* Module declarations from "cupy_backends.cuda._softlink" */

/* Module declarations from "cupy.cuda.cufft" */
static __pyx_t_4cupy_4cuda_5cufft_F_cufftXtSetJITCallback __pyx_v_4cupy_4cuda_5cufft__cufftXtSetJITCallback;
static struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink *__pyx_v_4cupy_4cuda_5cufft__L = 0;
static PyObject *__pyx_v_4cupy_4cuda_5cufft__thread_local = 0;
static PyObject *__pyx_v_4cupy_4cuda_5cufft_RESULT = 0;
static PyObject *__pyx_f_4cupy_4cuda_5cufft_get_current_plan(int __pyx_skip_dispatch); /*proto*/
static int __pyx_f_4cupy_4cuda_5cufft_getVersion(int __pyx_skip_dispatch); /*proto*/
static CYTHON_INLINE void __pyx_f_4cupy_4cuda_5cufft_initialize(void); /*proto*/
static struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink *__pyx_f_4cupy_4cuda_5cufft__initialize(void); /*proto*/
static struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink *__pyx_f_4cupy_4cuda_5cufft__get_softlink(void); /*proto*/
static CYTHON_INLINE void __pyx_f_4cupy_4cuda_5cufft_check_result(int, int __pyx_skip_dispatch); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft__reorder_buffers(cufftHandle, intptr_t, PyObject *); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft__XtMalloc(PyObject *, PyObject *, cufftXtSubFormat); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft__XtFree(intptr_t); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_execC2C(intptr_t, intptr_t, intptr_t, int, int __pyx_skip_dispatch); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_execR2C(intptr_t, intptr_t, intptr_t, int __pyx_skip_dispatch); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_execC2R(intptr_t, intptr_t, intptr_t, int __pyx_skip_dispatch); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_execZ2Z(intptr_t, intptr_t, intptr_t, int, int __pyx_skip_dispatch); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_execD2Z(intptr_t, intptr_t, intptr_t, int __pyx_skip_dispatch); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_execZ2D(intptr_t, intptr_t, intptr_t, int __pyx_skip_dispatch); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_multi_gpu_execC2C(intptr_t, intptr_t, intptr_t, int, int __pyx_skip_dispatch); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_multi_gpu_execZ2Z(intptr_t, intptr_t, intptr_t, int, int __pyx_skip_dispatch); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_XtExec(intptr_t, intptr_t, intptr_t, int, int __pyx_skip_dispatch); /*proto*/
static intptr_t __pyx_f_4cupy_4cuda_5cufft_setCallback(intptr_t, int, int, int __pyx_skip_dispatch, struct __pyx_opt_args_4cupy_4cuda_5cufft_setCallback *__pyx_optional_args); /*proto*/
static intptr_t __pyx_f_4cupy_4cuda_5cufft_create(int __pyx_skip_dispatch); /*proto*/
static int __pyx_f_4cupy_4cuda_5cufft_setAutoAllocation(intptr_t, int, int __pyx_skip_dispatch); /*proto*/
static int __pyx_f_4cupy_4cuda_5cufft_setJITCallback(intptr_t, PyObject *, PyObject *, int, intptr_t, int __pyx_skip_dispatch); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft___pyx_unpickle_Plan1d__set_state(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *, PyObject *); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft___pyx_unpickle_PlanNd__set_state(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *, PyObject *); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft___pyx_unpickle_XtPlanNd__set_state(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *, PyObject *); /*proto*/
static PyObject *__pyx_convert_vector_to_py_int(std::vector<int>  const &); /*proto*/
static std::vector<int>  __pyx_convert_vector_from_py_int(PyObject *); /*proto*/
static std::vector<PY_LONG_LONG>  __pyx_convert_vector_from_py_PY_LONG_LONG(PyObject *); /*proto*/
/* #### Code section: typeinfo ### */
/* #### Code section: before_global_var ### */
#define __Pyx_MODULE_NAME "cupy.cuda.cufft"
extern int __pyx_module_is_main_cupy__cuda__cufft;
int __pyx_module_is_main_cupy__cuda__cufft = 0;

/* Implementation of "cupy.cuda.cufft" */
/* #### Code section: global_var ### */
static PyObject *__pyx_builtin_RuntimeError;
static PyObject *__pyx_builtin_NotImplementedError;
static PyObject *__pyx_builtin_super;
static PyObject *__pyx_builtin_AssertionError;
static PyObject *__pyx_builtin_range;
static PyObject *__pyx_builtin_enumerate;
static PyObject *__pyx_builtin_zip;
static PyObject *__pyx_builtin_ValueError;
static PyObject *__pyx_builtin_MemoryError;
/* #### Code section: string_decls ### */
static const char __pyx_k_[] = ".";
static const char __pyx_k_C[] = "C";
static const char __pyx_k_a[] = "a";
static const char __pyx_k_s[] = "%s";
static const char __pyx_k__2[] = "?";
static const char __pyx_k_gc[] = "gc";
static const char __pyx_k_nx[] = "nx";
static const char __pyx_k_doc[] = "__doc__";
static const char __pyx_k_new[] = "__new__";
static const char __pyx_k_out[] = "out";
static const char __pyx_k_pop[] = "pop";
static const char __pyx_k_ptr[] = "ptr";
static const char __pyx_k_sys[] = "_sys";
static const char __pyx_k_zip[] = "zip";
static const char __pyx_k_char[] = "char";
static const char __pyx_k_cupy[] = "cupy";
static const char __pyx_k_data[] = "data";
static const char __pyx_k_dict[] = "__dict__";
static const char __pyx_k_func[] = "__func__";
static const char __pyx_k_init[] = "__init__";
static const char __pyx_k_main[] = "__main__";
static const char __pyx_k_name[] = "__name__";
static const char __pyx_k_ndim[] = "ndim";
static const char __pyx_k_plan[] = "plan";
static const char __pyx_k_self[] = "self";
static const char __pyx_k_size[] = "size";
static const char __pyx_k_spec[] = "__spec__";
static const char __pyx_k_test[] = "__test__";
static const char __pyx_k_A_AXT[] = "\200A\330\010\020\220\004\220A\220X\230T\240\021";
static const char __pyx_k_Event[] = "Event";
static const char __pyx_k_alloc[] = "alloc";
static const char __pyx_k_batch[] = "batch";
static const char __pyx_k_cufft[] = "__cufft";
static const char __pyx_k_dtype[] = "dtype";
static const char __pyx_k_empty[] = "empty";
static const char __pyx_k_etype[] = "etype";
static const char __pyx_k_flags[] = "flags";
static const char __pyx_k_idata[] = "idata";
static const char __pyx_k_idist[] = "idist";
static const char __pyx_k_itype[] = "itype";
static const char __pyx_k_linux[] = "linux";
static const char __pyx_k_local[] = "local";
static const char __pyx_k_lower[] = "lower";
static const char __pyx_k_numpy[] = "numpy";
static const char __pyx_k_odata[] = "odata";
static const char __pyx_k_odist[] = "odist";
static const char __pyx_k_order[] = "order";
static const char __pyx_k_otype[] = "otype";
static const char __pyx_k_range[] = "range";
static const char __pyx_k_ravel[] = "ravel";
static const char __pyx_k_shape[] = "shape";
static const char __pyx_k_super[] = "super";
static const char __pyx_k_sys_2[] = "sys";
static const char __pyx_k_upper[] = "upper";
static const char __pyx_k_Plan1d[] = "Plan1d";
static const char __pyx_k_PlanNd[] = "PlanNd";
static const char __pyx_k_Stream[] = "Stream";
static const char __pyx_k_action[] = "action";
static const char __pyx_k_ctypes[] = "ctypes";
static const char __pyx_k_device[] = "device";
static const char __pyx_k_edtype[] = "edtype";
static const char __pyx_k_enable[] = "enable";
static const char __pyx_k_format[] = "format";
static const char __pyx_k_gather[] = "gather";
static const char __pyx_k_idtype[] = "idtype";
static const char __pyx_k_is_hip[] = "is_hip";
static const char __pyx_k_memory[] = "memory";
static const char __pyx_k_module[] = "__module__";
static const char __pyx_k_odtype[] = "odtype";
static const char __pyx_k_pickle[] = "pickle";
static const char __pyx_k_record[] = "record";
static const char __pyx_k_reduce[] = "__reduce__";
static const char __pyx_k_result[] = "result";
static const char __pyx_k_stream[] = "stream";
static const char __pyx_k_update[] = "update";
static const char __pyx_k_OWNDATA[] = "OWNDATA";
static const char __pyx_k_aux_arr[] = "aux_arr";
static const char __pyx_k_cb_type[] = "cb_type";
static const char __pyx_k_cufft_2[] = "cufft";
static const char __pyx_k_devices[] = "devices";
static const char __pyx_k_disable[] = "disable";
static const char __pyx_k_float16[] = "float16";
static const char __pyx_k_float32[] = "float32";
static const char __pyx_k_float64[] = "float64";
static const char __pyx_k_inembed[] = "inembed";
static const char __pyx_k_is_load[] = "is_load";
static const char __pyx_k_istride[] = "istride";
static const char __pyx_k_ndarray[] = "ndarray";
static const char __pyx_k_onembed[] = "onembed";
static const char __pyx_k_ostride[] = "ostride";
static const char __pyx_k_prepare[] = "__prepare__";
static const char __pyx_k_runtime[] = "runtime";
static const char __pyx_k_scatter[] = "scatter";
static const char __pyx_k_XtPlanNd[] = "XtPlanNd";
static const char __pyx_k_add_note[] = "add_note";
static const char __pyx_k_callback[] = "callback";
static const char __pyx_k_exc_type[] = "exc_type";
static const char __pyx_k_fft_type[] = "fft_type";
static const char __pyx_k_getstate[] = "__getstate__";
static const char __pyx_k_itemsize[] = "itemsize";
static const char __pyx_k_platform[] = "platform";
static const char __pyx_k_pyx_type[] = "__pyx_type";
static const char __pyx_k_qualname[] = "__qualname__";
static const char __pyx_k_set_name[] = "__set_name__";
static const char __pyx_k_setstate[] = "__setstate__";
static const char __pyx_k_complex64[] = "complex64";
static const char __pyx_k_cupy_cuda[] = "cupy.cuda";
static const char __pyx_k_device_id[] = "device_id";
static const char __pyx_k_direction[] = "direction";
static const char __pyx_k_enumerate[] = "enumerate";
static const char __pyx_k_exc_value[] = "exc_value";
static const char __pyx_k_full_size[] = "full_size";
static const char __pyx_k_getDevice[] = "getDevice";
static const char __pyx_k_isenabled[] = "isenabled";
static const char __pyx_k_last_axis[] = "last_axis";
static const char __pyx_k_last_size[] = "last_size";
static const char __pyx_k_mandatory[] = "mandatory";
static const char __pyx_k_metaclass[] = "__metaclass__";
static const char __pyx_k_pyx_state[] = "__pyx_state";
static const char __pyx_k_reduce_ex[] = "__reduce_ex__";
static const char __pyx_k_setDevice[] = "setDevice";
static const char __pyx_k_threading[] = "threading";
static const char __pyx_k_traceback[] = "traceback";
static const char __pyx_k_CUDA_C_16F[] = "CUDA_C_16F";
static const char __pyx_k_CUDA_C_32F[] = "CUDA_C_32F";
static const char __pyx_k_CUDA_C_64F[] = "CUDA_C_64F";
static const char __pyx_k_CUDA_R_16F[] = "CUDA_R_16F";
static const char __pyx_k_CUDA_R_32F[] = "CUDA_R_32F";
static const char __pyx_k_CUDA_R_64F[] = "CUDA_R_64F";
static const char __pyx_k_CuFFTError[] = "CuFFTError";
static const char __pyx_k_ValueError[] = "ValueError";
static const char __pyx_k_complex128[] = "complex128";
static const char __pyx_k_pyx_vtable[] = "__pyx_vtable__";
static const char __pyx_k_wait_event[] = "wait_event";
static const char __pyx_k_MemoryError[] = "MemoryError";
static const char __pyx_k_PickleError[] = "PickleError";
static const char __pyx_k_caller_info[] = "caller_info";
static const char __pyx_k_curr_device[] = "curr_device";
static const char __pyx_k_mro_entries[] = "__mro_entries__";
static const char __pyx_k_synchronize[] = "synchronize";
static const char __pyx_k_RuntimeError[] = "RuntimeError";
static const char __pyx_k_autoAllocate[] = "autoAllocate";
static const char __pyx_k_c_contiguous[] = "c_contiguous";
static const char __pyx_k_current_plan[] = "_current_plan";
static const char __pyx_k_f_contiguous[] = "f_contiguous";
static const char __pyx_k_initializing[] = "_initializing";
static const char __pyx_k_is_coroutine[] = "_is_coroutine";
static const char __pyx_k_pyx_checksum[] = "__pyx_checksum";
static const char __pyx_k_A_Ja_Ql_y_c_q[] = "\200A\330\010\014\210J\220a\330\010\r\210Q\210l\230%\230y\250\001\250\025\250c\260\026\260q\270\001";
static const char __pyx_k_CUFFT_SUCCESS[] = "CUFFT_SUCCESS";
static const char __pyx_k_callback_name[] = "callback_name";
static const char __pyx_k_callback_type[] = "callback_type";
static const char __pyx_k_class_getitem[] = "__class_getitem__";
static const char __pyx_k_multi_gpu_fft[] = "_multi_gpu_fft";
static const char __pyx_k_prealloc_plan[] = "prealloc_plan";
static const char __pyx_k_reduce_cython[] = "__reduce_cython__";
static const char __pyx_k_sanity_checks[] = "_sanity_checks";
static const char __pyx_k_to_cuda_dtype[] = "to_cuda_dtype";
static const char __pyx_k_AssertionError[] = "AssertionError";
static const char __pyx_k_cufft64_11_dll[] = "cufft64_11.dll";
static const char __pyx_k_cufft64_12_dll[] = "cufft64_12.dll";
static const char __pyx_k_libcufft_so_11[] = "libcufft.so.11";
static const char __pyx_k_libcufft_so_12[] = "libcufft.so.12";
static const char __pyx_k_single_gpu_fft[] = "_single_gpu_fft";
static const char __pyx_k_cupy_cuda_cufft[] = "cupy.cuda.cufft";
static const char __pyx_k_free_all_blocks[] = "free_all_blocks";
static const char __pyx_k_setstate_cython[] = "__setstate_cython__";
static const char __pyx_k_XtSetJITCallback[] = "XtSetJITCallback";
static const char __pyx_k_multi_gpu_memcpy[] = "_multi_gpu_memcpy";
static const char __pyx_k_CUFFT_EXEC_FAILED[] = "CUFFT_EXEC_FAILED";
static const char __pyx_k_CUFFT_PARSE_ERROR[] = "CUFFT_PARSE_ERROR";
static const char __pyx_k_CuFFTError___init[] = "CuFFTError.__init__";
static const char __pyx_k_cupy__core__dtype[] = "cupy._core._dtype";
static const char __pyx_k_runtimeGetVersion[] = "runtimeGetVersion";
static const char __pyx_k_CUFFT_ALLOC_FAILED[] = "CUFFT_ALLOC_FAILED";
static const char __pyx_k_CUFFT_INVALID_PLAN[] = "CUFFT_INVALID_PLAN";
static const char __pyx_k_CUFFT_INVALID_SIZE[] = "CUFFT_INVALID_SIZE";
static const char __pyx_k_CUFFT_INVALID_TYPE[] = "CUFFT_INVALID_TYPE";
static const char __pyx_k_CUFFT_NO_WORKSPACE[] = "CUFFT_NO_WORKSPACE";
static const char __pyx_k_CUFFT_SETUP_FAILED[] = "CUFFT_SETUP_FAILED";
static const char __pyx_k_asyncio_coroutines[] = "asyncio.coroutines";
static const char __pyx_k_cline_in_traceback[] = "cline_in_traceback";
static const char __pyx_k_get_current_stream[] = "get_current_stream";
static const char __pyx_k_CUFFT_INVALID_VALUE[] = "CUFFT_INVALID_VALUE";
static const char __pyx_k_CUFFT_LICENSE_ERROR[] = "CUFFT_LICENSE_ERROR";
static const char __pyx_k_CUFFT_NOT_SUPPORTED[] = "CUFFT_NOT_SUPPORTED";
static const char __pyx_k_CuFFTError___reduce[] = "CuFFTError.__reduce__";
static const char __pyx_k_Impossible_to_reach[] = "Impossible to reach.";
static const char __pyx_k_NotImplementedError[] = "NotImplementedError";
static const char __pyx_k_cupy_cuda_cufft_pyx[] = "cupy/cuda/cufft.pyx";
static const char __pyx_k_out_must_have_shape[] = "out must have shape {}.";
static const char __pyx_k_pyx_unpickle_Plan1d[] = "__pyx_unpickle_Plan1d";
static const char __pyx_k_pyx_unpickle_PlanNd[] = "__pyx_unpickle_PlanNd";
static const char __pyx_k_CUFFT_INTERNAL_ERROR[] = "CUFFT_INTERNAL_ERROR";
static const char __pyx_k_CUFFT_INVALID_DEVICE[] = "CUFFT_INVALID_DEVICE";
static const char __pyx_k_CUFFT_UNALIGNED_DATA[] = "CUFFT_UNALIGNED_DATA";
static const char __pyx_k_CUFFT_NOT_IMPLEMENTED[] = "CUFFT_NOT_IMPLEMENTED";
static const char __pyx_k_input_array_too_large[] = "input array too large";
static const char __pyx_k_output_dtype_mismatch[] = "output dtype mismatch";
static const char __pyx_k_output_shape_mismatch[] = "output shape mismatch";
static const char __pyx_k_pyx_unpickle_XtPlanNd[] = "__pyx_unpickle_XtPlanNd";
static const char __pyx_k_copy_from_device_async[] = "copy_from_device_async";
static const char __pyx_k_get_compute_capability[] = "get_compute_capability";
static const char __pyx_k_multi_gpu_setup_buffer[] = "_multi_gpu_setup_buffer";
static const char __pyx_k_output_dtype_and_shape[] = "_output_dtype_and_shape";
static const char __pyx_k_get_default_memory_pool[] = "get_default_memory_pool";
static const char __pyx_k_size_must_be_power_of_2[] = "size must be power of 2";
static const char __pyx_k_output_dimension_mismatch[] = "output dimension mismatch";
static const char __pyx_k_output_contiguity_mismatch[] = "output contiguity mismatch";
static const char __pyx_k_output_dtype_is_unexpected[] = "output dtype is unexpected";
static const char __pyx_k_output_shape_is_incorrecct[] = "output shape is incorrecct";
static const char __pyx_k_devices_should_be_an_int_or_an[] = "\"devices\" should be an int or an iterable of int.";
static const char __pyx_k_CUFFT_INCOMPLETE_PARAMETER_LIST[] = "CUFFT_INCOMPLETE_PARAMETER_LIST";
static const char __pyx_k_User_managed_buffer_area_is_not[] = "User-managed buffer area is not yet supported.";
static const char __pyx_k_cuFFT_is_dynamically_linked_and[] = "cuFFT is dynamically linked and thus does not support callback";
static const char __pyx_k_multi_gpu_get_scatter_streams_e[] = "_multi_gpu_get_scatter_streams_events";
static const char __pyx_k_Currently_for_multiple_GPUs_only[] = "Currently for multiple GPUs only C2C and Z2Z are supported.";
static const char __pyx_k_For_GPUs_the_array_length_must_b[] = "For {} GPUs, the array length must be at least {} (you have {}).";
static const char __pyx_k_For_multi_GPU_FFT_with_batch_1_t[] = "For multi-GPU FFT with batch = 1, the array size must be a power of 2.";
static const char __pyx_k_Incompatible_checksums_0x_x_vs_0[] = "Incompatible checksums (0x%x vs (0xbdeb9ba, 0x989b82b, 0xf5e4dcb) = (batch, batch_share, fft_type, gather_events, gather_streams, gpus, handle, nx, scatter_events, scatter_streams, work_area, xtArr, xtArr_buffer))";
static const char __pyx_k_Note_that_Cython_is_deliberately[] = "Note that Cython is deliberately stricter than PEP-484 and rejects subclasses of builtin types. If you need to pass subclasses then set the 'annotation_typing' directive to False.";
static const char __pyx_k_complex32_is_not_supported_yet_p[] = "complex32 is not supported yet, please allocate the output array manually";
static const char __pyx_k_hipFFT_rocFFT_does_not_support_m[] = "hipFFT/rocFFT does not support multi-GPU FFT";
static const char __pyx_k_input_output_execution_types_mis[] = "input/output/execution types mismatch";
static const char __pyx_k_out_dtype_mismatch_found_expecte[] = "out dtype mismatch: found {}, expected {}";
static const char __pyx_k_this_device_doesn_t_support_comp[] = "this device doesn't support complex32 FFT";
static const char __pyx_k_For_multi_GPU_FFT_with_batch_1_t_2[] = "For multi-GPU FFT with batch = 1, the number of devices must be 2, 4, 8, or 16.";
static const char __pyx_k_Incompatible_checksums_0x_x_vs_0_2[] = "Incompatible checksums (0x%x vs (0xc57f9e5, 0x9bf2b45, 0x12c7fc7) = (fft_type, gpus, handle, last_axis, last_size, order, shape, work_area))";
static const char __pyx_k_Incompatible_checksums_0x_x_vs_0_3[] = "Incompatible checksums (0x%x vs (0x19c6497, 0x054ffc9, 0x5c231b7) = (etype, gpus, handle, itype, last_axis, last_size, order, otype, shape, work_area))";
/* #### Code section: decls ### */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_get_current_plan(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_10CuFFTError___init__(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_self, int __pyx_v_result); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_10CuFFTError_2__reduce__(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_2check_result(CYTHON_UNUSED PyObject *__pyx_self, int __pyx_v_result); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_4getVersion(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static int __pyx_pf_4cupy_4cuda_5cufft_6Plan1d___init__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, int __pyx_v_nx, int __pyx_v_fft_type, int __pyx_v_batch, PyObject *__pyx_v_devices, PyObject *__pyx_v_out, intptr_t __pyx_v_prealloc_plan); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_2_multi_gpu_get_scatter_streams_events(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, int __pyx_v_curr_device); /* proto */
static void __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_4__dealloc__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_6__enter__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_8__exit__(CYTHON_UNUSED struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v_exc_type, CYTHON_UNUSED PyObject *__pyx_v_exc_value, CYTHON_UNUSED PyObject *__pyx_v_traceback); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_10fft(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_out, PyObject *__pyx_v_direction); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_12_single_gpu_fft(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_out, PyObject *__pyx_v_direction); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_14_multi_gpu_setup_buffer(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v_a); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_16_multi_gpu_memcpy(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_action); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_18_multi_gpu_fft(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_out, PyObject *__pyx_v_direction); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_20_output_dtype_and_shape(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v_a); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_22get_output_array(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v_a); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_24check_output_array(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_out); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_6handle___get__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_9work_area___get__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_2nx___get__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_5batch___get__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_8fft_type___get__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_4gpus___get__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_26__reduce_cython__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_28__setstate_cython__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v___pyx_state); /* proto */
static int __pyx_pf_4cupy_4cuda_5cufft_6PlanNd___init__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self, PyObject *__pyx_v_shape, PyObject *__pyx_v_inembed, int __pyx_v_istride, int __pyx_v_idist, PyObject *__pyx_v_onembed, int __pyx_v_ostride, int __pyx_v_odist, int __pyx_v_fft_type, int __pyx_v_batch, PyObject *__pyx_v_order, int __pyx_v_last_axis, PyObject *__pyx_v_last_size, intptr_t __pyx_v_prealloc_plan); /* proto */
static void __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_2__dealloc__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_4__enter__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_6__exit__(CYTHON_UNUSED struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v_exc_type, CYTHON_UNUSED PyObject *__pyx_v_exc_value, CYTHON_UNUSED PyObject *__pyx_v_traceback); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_8fft(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_out, PyObject *__pyx_v_direction); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_10_output_dtype_and_shape(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self, PyObject *__pyx_v_a); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_12get_output_array(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_order); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_14check_output_array(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_out); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_6handle___get__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_9work_area___get__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_5shape___get__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_8fft_type___get__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_5order___get__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_9last_axis___get__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_9last_size___get__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_4gpus___get__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_16__reduce_cython__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_18__setstate_cython__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self, PyObject *__pyx_v___pyx_state); /* proto */
static int __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd___init__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self, PyObject *__pyx_v_shape, PyObject *__pyx_v_inembed, PY_LONG_LONG __pyx_v_istride, PY_LONG_LONG __pyx_v_idist, PyObject *__pyx_v_idtype, PyObject *__pyx_v_onembed, PY_LONG_LONG __pyx_v_ostride, PY_LONG_LONG __pyx_v_odist, PyObject *__pyx_v_odtype, PY_LONG_LONG __pyx_v_batch, PyObject *__pyx_v_edtype, PyObject *__pyx_v_order, int __pyx_v_last_axis, PyObject *__pyx_v_last_size, intptr_t __pyx_v_prealloc_plan); /* proto */
static void __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_2__dealloc__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_4__enter__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_6__exit__(CYTHON_UNUSED struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v_exc_type, CYTHON_UNUSED PyObject *__pyx_v_exc_value, CYTHON_UNUSED PyObject *__pyx_v_traceback); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_8fft(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_out, PyObject *__pyx_v_direction); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_10_sanity_checks(CYTHON_UNUSED struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self, int __pyx_v_itype, int __pyx_v_otype, int __pyx_v_etype, PY_LONG_LONG __pyx_v_last_size, PY_LONG_LONG __pyx_v_full_size); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_12_output_dtype_and_shape(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self, PyObject *__pyx_v_a); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_14get_output_array(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_order); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_6handle___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_9work_area___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_5shape___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_5itype___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_5otype___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_5etype___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_5order___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_9last_axis___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_9last_size___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_4gpus___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_16__reduce_cython__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_18__setstate_cython__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self, PyObject *__pyx_v___pyx_state); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6execC2C(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, int __pyx_v_direction); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8execR2C(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_10execC2R(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_12execZ2Z(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, int __pyx_v_direction); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_14execD2Z(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_16execZ2D(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_18multi_gpu_execC2C(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, int __pyx_v_direction); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_20multi_gpu_execZ2Z(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, int __pyx_v_direction); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_22XtExec(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, int __pyx_v_direction); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_24setCallback(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, int __pyx_v_cb_type, int __pyx_v_is_load, intptr_t __pyx_v_aux_arr); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_26create(CYTHON_UNUSED PyObject *__pyx_self); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_28setAutoAllocation(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, int __pyx_v_autoAllocate); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_30setJITCallback(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, PyObject *__pyx_v_callback_name, PyObject *__pyx_v_callback, int __pyx_v_callback_type, intptr_t __pyx_v_caller_info); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_32__pyx_unpickle_Plan1d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v___pyx_type, long __pyx_v___pyx_checksum, PyObject *__pyx_v___pyx_state); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_34__pyx_unpickle_PlanNd(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v___pyx_type, long __pyx_v___pyx_checksum, PyObject *__pyx_v___pyx_state); /* proto */
static PyObject *__pyx_pf_4cupy_4cuda_5cufft_36__pyx_unpickle_XtPlanNd(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v___pyx_type, long __pyx_v___pyx_checksum, PyObject *__pyx_v___pyx_state); /* proto */
static PyObject *__pyx_tp_new_4cupy_4cuda_5cufft_Plan1d(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_4cupy_4cuda_5cufft_PlanNd(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
static PyObject *__pyx_tp_new_4cupy_4cuda_5cufft_XtPlanNd(PyTypeObject *t, PyObject *a, PyObject *k); /*proto*/
/* #### Code section: late_includes ### */
/* #### Code section: module_state ### */
/* SmallCodeConfig */
#ifndef CYTHON_SMALL_CODE
#if defined(__clang__)
    #define CYTHON_SMALL_CODE
#elif defined(__GNUC__) && (__GNUC__ > 4 || (__GNUC__ == 4 && __GNUC_MINOR__ >= 3))
    #define CYTHON_SMALL_CODE __attribute__((cold))
#else
    #define CYTHON_SMALL_CODE
#endif
#endif

typedef struct {
  PyObject *__pyx_d;
  PyObject *__pyx_b;
  PyObject *__pyx_cython_runtime;
  PyObject *__pyx_empty_tuple;
  PyObject *__pyx_empty_bytes;
  PyObject *__pyx_empty_unicode;
  #ifdef __Pyx_CyFunction_USED
  PyTypeObject *__pyx_CyFunctionType;
  #endif
  #ifdef __Pyx_FusedFunction_USED
  PyTypeObject *__pyx_FusedFunctionType;
  #endif
  #ifdef __Pyx_Generator_USED
  PyTypeObject *__pyx_GeneratorType;
  #endif
  #ifdef __Pyx_IterableCoroutine_USED
  PyTypeObject *__pyx_IterableCoroutineType;
  #endif
  #ifdef __Pyx_Coroutine_USED
  PyTypeObject *__pyx_CoroutineAwaitType;
  #endif
  #ifdef __Pyx_Coroutine_USED
  PyTypeObject *__pyx_CoroutineType;
  #endif
  PyTypeObject *__pyx_ptype_13cupy_backends_4cuda_9_softlink_SoftLink;
  PyObject *__pyx_type_4cupy_4cuda_5cufft_Plan1d;
  PyObject *__pyx_type_4cupy_4cuda_5cufft_PlanNd;
  PyObject *__pyx_type_4cupy_4cuda_5cufft_XtPlanNd;
  PyTypeObject *__pyx_ptype_4cupy_4cuda_5cufft_Plan1d;
  PyTypeObject *__pyx_ptype_4cupy_4cuda_5cufft_PlanNd;
  PyTypeObject *__pyx_ptype_4cupy_4cuda_5cufft_XtPlanNd;
  __Pyx_CachedCFunction __pyx_umethod_PyDict_Type_pop;
  PyObject *__pyx_tuple[5];
  PyObject *__pyx_codeobj_tab[2];
  PyObject *__pyx_string_tab[227];
  PyObject *__pyx_int_0;
  PyObject *__pyx_int_1;
  PyObject *__pyx_int_2;
  PyObject *__pyx_int_3;
  PyObject *__pyx_int_4;
  PyObject *__pyx_int_5;
  PyObject *__pyx_int_6;
  PyObject *__pyx_int_7;
  PyObject *__pyx_int_8;
  PyObject *__pyx_int_9;
  PyObject *__pyx_int_10;
  PyObject *__pyx_int_11;
  PyObject *__pyx_int_12;
  PyObject *__pyx_int_13;
  PyObject *__pyx_int_14;
  PyObject *__pyx_int_15;
  PyObject *__pyx_int_16;
  PyObject *__pyx_int_53;
  PyObject *__pyx_int_5570505;
  PyObject *__pyx_int_19693511;
  PyObject *__pyx_int_27026583;
  PyObject *__pyx_int_96612791;
  PyObject *__pyx_int_160020523;
  PyObject *__pyx_int_163523397;
  PyObject *__pyx_int_199145914;
  PyObject *__pyx_int_207092197;
  PyObject *__pyx_int_257838539;
  PyObject *__pyx_int_4000000000;
/* #### Code section: module_state_contents ### */
/* CommonTypesMetaclass.module_state_decls */
PyTypeObject *__pyx_CommonTypesMetaclassType;

/* CachedMethodType.module_state_decls */
#if CYTHON_COMPILING_IN_LIMITED_API
PyObject *__Pyx_CachedMethodType;
#endif

/* CodeObjectCache.module_state_decls */
struct __Pyx_CodeObjectCache __pyx_code_cache;

/* #### Code section: module_state_end ### */
} __pyx_mstatetype;

#if CYTHON_USE_MODULE_STATE
#ifdef __cplusplus
namespace {
extern struct PyModuleDef __pyx_moduledef;
} /* anonymous namespace */
#else
static struct PyModuleDef __pyx_moduledef;
#endif

#define __pyx_mstate_global (__Pyx_PyModule_GetState(__Pyx_State_FindModule(&__pyx_moduledef)))

#define __pyx_m (__Pyx_State_FindModule(&__pyx_moduledef))
#else
static __pyx_mstatetype __pyx_mstate_global_static =
#ifdef __cplusplus
    {};
#else
    {0};
#endif
static __pyx_mstatetype * const __pyx_mstate_global = &__pyx_mstate_global_static;
#endif
/* #### Code section: constant_name_defines ### */
#define __pyx_kp_u_ __pyx_string_tab[0]
#define __pyx_n_u_AssertionError __pyx_string_tab[1]
#define __pyx_n_u_C __pyx_string_tab[2]
#define __pyx_n_u_CUDA_C_16F __pyx_string_tab[3]
#define __pyx_n_u_CUDA_C_32F __pyx_string_tab[4]
#define __pyx_n_u_CUDA_C_64F __pyx_string_tab[5]
#define __pyx_n_u_CUDA_R_16F __pyx_string_tab[6]
#define __pyx_n_u_CUDA_R_32F __pyx_string_tab[7]
#define __pyx_n_u_CUDA_R_64F __pyx_string_tab[8]
#define __pyx_n_u_CUFFT_ALLOC_FAILED __pyx_string_tab[9]
#define __pyx_n_u_CUFFT_EXEC_FAILED __pyx_string_tab[10]
#define __pyx_n_u_CUFFT_INCOMPLETE_PARAMETER_LIST __pyx_string_tab[11]
#define __pyx_n_u_CUFFT_INTERNAL_ERROR __pyx_string_tab[12]
#define __pyx_n_u_CUFFT_INVALID_DEVICE __pyx_string_tab[13]
#define __pyx_n_u_CUFFT_INVALID_PLAN __pyx_string_tab[14]
#define __pyx_n_u_CUFFT_INVALID_SIZE __pyx_string_tab[15]
#define __pyx_n_u_CUFFT_INVALID_TYPE __pyx_string_tab[16]
#define __pyx_n_u_CUFFT_INVALID_VALUE __pyx_string_tab[17]
#define __pyx_n_u_CUFFT_LICENSE_ERROR __pyx_string_tab[18]
#define __pyx_n_u_CUFFT_NOT_IMPLEMENTED __pyx_string_tab[19]
#define __pyx_n_u_CUFFT_NOT_SUPPORTED __pyx_string_tab[20]
#define __pyx_n_u_CUFFT_NO_WORKSPACE __pyx_string_tab[21]
#define __pyx_n_u_CUFFT_PARSE_ERROR __pyx_string_tab[22]
#define __pyx_n_u_CUFFT_SETUP_FAILED __pyx_string_tab[23]
#define __pyx_n_u_CUFFT_SUCCESS __pyx_string_tab[24]
#define __pyx_n_u_CUFFT_UNALIGNED_DATA __pyx_string_tab[25]
#define __pyx_n_u_CuFFTError __pyx_string_tab[26]
#define __pyx_n_u_CuFFTError___init __pyx_string_tab[27]
#define __pyx_n_u_CuFFTError___reduce __pyx_string_tab[28]
#define __pyx_kp_u_Currently_for_multiple_GPUs_only __pyx_string_tab[29]
#define __pyx_n_u_Event __pyx_string_tab[30]
#define __pyx_kp_u_For_GPUs_the_array_length_must_b __pyx_string_tab[31]
#define __pyx_kp_u_For_multi_GPU_FFT_with_batch_1_t __pyx_string_tab[32]
#define __pyx_kp_u_For_multi_GPU_FFT_with_batch_1_t_2 __pyx_string_tab[33]
#define __pyx_kp_u_Impossible_to_reach __pyx_string_tab[34]
#define __pyx_kp_u_Incompatible_checksums_0x_x_vs_0 __pyx_string_tab[35]
#define __pyx_kp_u_Incompatible_checksums_0x_x_vs_0_2 __pyx_string_tab[36]
#define __pyx_kp_u_Incompatible_checksums_0x_x_vs_0_3 __pyx_string_tab[37]
#define __pyx_n_u_MemoryError __pyx_string_tab[38]
#define __pyx_n_u_NotImplementedError __pyx_string_tab[39]
#define __pyx_kp_u_Note_that_Cython_is_deliberately __pyx_string_tab[40]
#define __pyx_n_u_OWNDATA __pyx_string_tab[41]
#define __pyx_n_u_PickleError __pyx_string_tab[42]
#define __pyx_n_u_Plan1d __pyx_string_tab[43]
#define __pyx_n_u_PlanNd __pyx_string_tab[44]
#define __pyx_n_u_RuntimeError __pyx_string_tab[45]
#define __pyx_n_u_Stream __pyx_string_tab[46]
#define __pyx_kp_u_User_managed_buffer_area_is_not __pyx_string_tab[47]
#define __pyx_n_u_ValueError __pyx_string_tab[48]
#define __pyx_n_u_XtPlanNd __pyx_string_tab[49]
#define __pyx_n_u_XtSetJITCallback __pyx_string_tab[50]
#define __pyx_kp_u__2 __pyx_string_tab[51]
#define __pyx_n_u_a __pyx_string_tab[52]
#define __pyx_n_u_action __pyx_string_tab[53]
#define __pyx_kp_u_add_note __pyx_string_tab[54]
#define __pyx_n_u_alloc __pyx_string_tab[55]
#define __pyx_n_u_asyncio_coroutines __pyx_string_tab[56]
#define __pyx_n_u_autoAllocate __pyx_string_tab[57]
#define __pyx_n_u_aux_arr __pyx_string_tab[58]
#define __pyx_n_u_batch __pyx_string_tab[59]
#define __pyx_n_u_c_contiguous __pyx_string_tab[60]
#define __pyx_n_u_callback __pyx_string_tab[61]
#define __pyx_n_u_callback_name __pyx_string_tab[62]
#define __pyx_n_u_callback_type __pyx_string_tab[63]
#define __pyx_n_u_caller_info __pyx_string_tab[64]
#define __pyx_n_u_cb_type __pyx_string_tab[65]
#define __pyx_n_u_char __pyx_string_tab[66]
#define __pyx_n_u_class_getitem __pyx_string_tab[67]
#define __pyx_n_u_cline_in_traceback __pyx_string_tab[68]
#define __pyx_n_u_complex128 __pyx_string_tab[69]
#define __pyx_kp_u_complex32_is_not_supported_yet_p __pyx_string_tab[70]
#define __pyx_n_u_complex64 __pyx_string_tab[71]
#define __pyx_n_u_copy_from_device_async __pyx_string_tab[72]
#define __pyx_n_u_ctypes __pyx_string_tab[73]
#define __pyx_kp_u_cuFFT_is_dynamically_linked_and __pyx_string_tab[74]
#define __pyx_n_u_cufft __pyx_string_tab[75]
#define __pyx_kp_u_cufft64_11_dll __pyx_string_tab[76]
#define __pyx_kp_u_cufft64_12_dll __pyx_string_tab[77]
#define __pyx_n_u_cufft_2 __pyx_string_tab[78]
#define __pyx_n_u_cupy __pyx_string_tab[79]
#define __pyx_n_u_cupy__core__dtype __pyx_string_tab[80]
#define __pyx_n_u_cupy_cuda __pyx_string_tab[81]
#define __pyx_n_u_cupy_cuda_cufft __pyx_string_tab[82]
#define __pyx_kp_u_cupy_cuda_cufft_pyx __pyx_string_tab[83]
#define __pyx_n_u_curr_device __pyx_string_tab[84]
#define __pyx_n_u_current_plan __pyx_string_tab[85]
#define __pyx_n_u_data __pyx_string_tab[86]
#define __pyx_n_u_device __pyx_string_tab[87]
#define __pyx_n_u_device_id __pyx_string_tab[88]
#define __pyx_n_u_devices __pyx_string_tab[89]
#define __pyx_kp_u_devices_should_be_an_int_or_an __pyx_string_tab[90]
#define __pyx_n_u_dict __pyx_string_tab[91]
#define __pyx_n_u_direction __pyx_string_tab[92]
#define __pyx_kp_u_disable __pyx_string_tab[93]
#define __pyx_n_u_doc __pyx_string_tab[94]
#define __pyx_n_u_dtype __pyx_string_tab[95]
#define __pyx_n_u_edtype __pyx_string_tab[96]
#define __pyx_n_u_empty __pyx_string_tab[97]
#define __pyx_kp_u_enable __pyx_string_tab[98]
#define __pyx_n_u_enumerate __pyx_string_tab[99]
#define __pyx_n_u_etype __pyx_string_tab[100]
#define __pyx_n_u_exc_type __pyx_string_tab[101]
#define __pyx_n_u_exc_value __pyx_string_tab[102]
#define __pyx_n_u_f_contiguous __pyx_string_tab[103]
#define __pyx_n_u_fft_type __pyx_string_tab[104]
#define __pyx_n_u_flags __pyx_string_tab[105]
#define __pyx_n_u_float16 __pyx_string_tab[106]
#define __pyx_n_u_float32 __pyx_string_tab[107]
#define __pyx_n_u_float64 __pyx_string_tab[108]
#define __pyx_n_u_format __pyx_string_tab[109]
#define __pyx_n_u_free_all_blocks __pyx_string_tab[110]
#define __pyx_n_u_full_size __pyx_string_tab[111]
#define __pyx_n_u_func __pyx_string_tab[112]
#define __pyx_n_u_gather __pyx_string_tab[113]
#define __pyx_kp_u_gc __pyx_string_tab[114]
#define __pyx_n_u_getDevice __pyx_string_tab[115]
#define __pyx_n_u_get_compute_capability __pyx_string_tab[116]
#define __pyx_n_u_get_current_stream __pyx_string_tab[117]
#define __pyx_n_u_get_default_memory_pool __pyx_string_tab[118]
#define __pyx_n_u_getstate __pyx_string_tab[119]
#define __pyx_kp_u_hipFFT_rocFFT_does_not_support_m __pyx_string_tab[120]
#define __pyx_n_u_idata __pyx_string_tab[121]
#define __pyx_n_u_idist __pyx_string_tab[122]
#define __pyx_n_u_idtype __pyx_string_tab[123]
#define __pyx_n_u_inembed __pyx_string_tab[124]
#define __pyx_n_u_init __pyx_string_tab[125]
#define __pyx_n_u_initializing __pyx_string_tab[126]
#define __pyx_kp_u_input_array_too_large __pyx_string_tab[127]
#define __pyx_kp_u_input_output_execution_types_mis __pyx_string_tab[128]
#define __pyx_n_u_is_coroutine __pyx_string_tab[129]
#define __pyx_n_u_is_hip __pyx_string_tab[130]
#define __pyx_n_u_is_load __pyx_string_tab[131]
#define __pyx_kp_u_isenabled __pyx_string_tab[132]
#define __pyx_n_u_istride __pyx_string_tab[133]
#define __pyx_n_u_itemsize __pyx_string_tab[134]
#define __pyx_n_u_itype __pyx_string_tab[135]
#define __pyx_n_u_last_axis __pyx_string_tab[136]
#define __pyx_n_u_last_size __pyx_string_tab[137]
#define __pyx_kp_u_libcufft_so_11 __pyx_string_tab[138]
#define __pyx_kp_u_libcufft_so_12 __pyx_string_tab[139]
#define __pyx_n_u_linux __pyx_string_tab[140]
#define __pyx_n_u_local __pyx_string_tab[141]
#define __pyx_n_u_lower __pyx_string_tab[142]
#define __pyx_n_u_main __pyx_string_tab[143]
#define __pyx_n_u_mandatory __pyx_string_tab[144]
#define __pyx_n_u_memory __pyx_string_tab[145]
#define __pyx_n_u_metaclass __pyx_string_tab[146]
#define __pyx_n_u_module __pyx_string_tab[147]
#define __pyx_n_u_mro_entries __pyx_string_tab[148]
#define __pyx_n_u_multi_gpu_fft __pyx_string_tab[149]
#define __pyx_n_u_multi_gpu_get_scatter_streams_e __pyx_string_tab[150]
#define __pyx_n_u_multi_gpu_memcpy __pyx_string_tab[151]
#define __pyx_n_u_multi_gpu_setup_buffer __pyx_string_tab[152]
#define __pyx_n_u_name __pyx_string_tab[153]
#define __pyx_n_u_ndarray __pyx_string_tab[154]
#define __pyx_n_u_ndim __pyx_string_tab[155]
#define __pyx_n_u_new __pyx_string_tab[156]
#define __pyx_n_u_numpy __pyx_string_tab[157]
#define __pyx_n_u_nx __pyx_string_tab[158]
#define __pyx_n_u_odata __pyx_string_tab[159]
#define __pyx_n_u_odist __pyx_string_tab[160]
#define __pyx_n_u_odtype __pyx_string_tab[161]
#define __pyx_n_u_onembed __pyx_string_tab[162]
#define __pyx_n_u_order __pyx_string_tab[163]
#define __pyx_n_u_ostride __pyx_string_tab[164]
#define __pyx_n_u_otype __pyx_string_tab[165]
#define __pyx_n_u_out __pyx_string_tab[166]
#define __pyx_kp_u_out_dtype_mismatch_found_expecte __pyx_string_tab[167]
#define __pyx_kp_u_out_must_have_shape __pyx_string_tab[168]
#define __pyx_kp_u_output_contiguity_mismatch __pyx_string_tab[169]
#define __pyx_kp_u_output_dimension_mismatch __pyx_string_tab[170]
#define __pyx_n_u_output_dtype_and_shape __pyx_string_tab[171]
#define __pyx_kp_u_output_dtype_is_unexpected __pyx_string_tab[172]
#define __pyx_kp_u_output_dtype_mismatch __pyx_string_tab[173]
#define __pyx_kp_u_output_shape_is_incorrecct __pyx_string_tab[174]
#define __pyx_kp_u_output_shape_mismatch __pyx_string_tab[175]
#define __pyx_n_u_pickle __pyx_string_tab[176]
#define __pyx_n_u_plan __pyx_string_tab[177]
#define __pyx_n_u_platform __pyx_string_tab[178]
#define __pyx_n_u_pop __pyx_string_tab[179]
#define __pyx_n_u_prealloc_plan __pyx_string_tab[180]
#define __pyx_n_u_prepare __pyx_string_tab[181]
#define __pyx_n_u_ptr __pyx_string_tab[182]
#define __pyx_n_u_pyx_checksum __pyx_string_tab[183]
#define __pyx_n_u_pyx_state __pyx_string_tab[184]
#define __pyx_n_u_pyx_type __pyx_string_tab[185]
#define __pyx_n_u_pyx_unpickle_Plan1d __pyx_string_tab[186]
#define __pyx_n_u_pyx_unpickle_PlanNd __pyx_string_tab[187]
#define __pyx_n_u_pyx_unpickle_XtPlanNd __pyx_string_tab[188]
#define __pyx_n_u_pyx_vtable __pyx_string_tab[189]
#define __pyx_n_u_qualname __pyx_string_tab[190]
#define __pyx_n_u_range __pyx_string_tab[191]
#define __pyx_n_u_ravel __pyx_string_tab[192]
#define __pyx_n_u_record __pyx_string_tab[193]
#define __pyx_n_u_reduce __pyx_string_tab[194]
#define __pyx_n_u_reduce_cython __pyx_string_tab[195]
#define __pyx_n_u_reduce_ex __pyx_string_tab[196]
#define __pyx_n_u_result __pyx_string_tab[197]
#define __pyx_n_u_runtime __pyx_string_tab[198]
#define __pyx_n_u_runtimeGetVersion __pyx_string_tab[199]
#define __pyx_kp_u_s __pyx_string_tab[200]
#define __pyx_n_u_sanity_checks __pyx_string_tab[201]
#define __pyx_n_u_scatter __pyx_string_tab[202]
#define __pyx_n_u_self __pyx_string_tab[203]
#define __pyx_n_u_setDevice __pyx_string_tab[204]
#define __pyx_n_u_set_name __pyx_string_tab[205]
#define __pyx_n_u_setstate __pyx_string_tab[206]
#define __pyx_n_u_setstate_cython __pyx_string_tab[207]
#define __pyx_n_u_shape __pyx_string_tab[208]
#define __pyx_n_u_single_gpu_fft __pyx_string_tab[209]
#define __pyx_n_u_size __pyx_string_tab[210]
#define __pyx_kp_u_size_must_be_power_of_2 __pyx_string_tab[211]
#define __pyx_n_u_spec __pyx_string_tab[212]
#define __pyx_n_u_stream __pyx_string_tab[213]
#define __pyx_n_u_super __pyx_string_tab[214]
#define __pyx_n_u_synchronize __pyx_string_tab[215]
#define __pyx_n_u_sys __pyx_string_tab[216]
#define __pyx_n_u_sys_2 __pyx_string_tab[217]
#define __pyx_n_u_test __pyx_string_tab[218]
#define __pyx_kp_u_this_device_doesn_t_support_comp __pyx_string_tab[219]
#define __pyx_n_u_threading __pyx_string_tab[220]
#define __pyx_n_u_to_cuda_dtype __pyx_string_tab[221]
#define __pyx_n_u_traceback __pyx_string_tab[222]
#define __pyx_n_u_update __pyx_string_tab[223]
#define __pyx_n_u_upper __pyx_string_tab[224]
#define __pyx_n_u_wait_event __pyx_string_tab[225]
#define __pyx_n_u_zip __pyx_string_tab[226]
/* #### Code section: module_state_clear ### */
#if CYTHON_USE_MODULE_STATE
static CYTHON_SMALL_CODE int __pyx_m_clear(PyObject *m) {
  __pyx_mstatetype *clear_module_state = __Pyx_PyModule_GetState(m);
  if (!clear_module_state) return 0;
  Py_CLEAR(clear_module_state->__pyx_d);
  Py_CLEAR(clear_module_state->__pyx_b);
  Py_CLEAR(clear_module_state->__pyx_cython_runtime);
  Py_CLEAR(clear_module_state->__pyx_empty_tuple);
  Py_CLEAR(clear_module_state->__pyx_empty_bytes);
  Py_CLEAR(clear_module_state->__pyx_empty_unicode);
  #ifdef __Pyx_CyFunction_USED
  Py_CLEAR(clear_module_state->__pyx_CyFunctionType);
  #endif
  #ifdef __Pyx_FusedFunction_USED
  Py_CLEAR(clear_module_state->__pyx_FusedFunctionType);
  #endif
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  __Pyx_State_RemoveModule(NULL);
  #endif
  Py_CLEAR(clear_module_state->__pyx_ptype_13cupy_backends_4cuda_9_softlink_SoftLink);
  Py_CLEAR(clear_module_state->__pyx_ptype_4cupy_4cuda_5cufft_Plan1d);
  Py_CLEAR(clear_module_state->__pyx_type_4cupy_4cuda_5cufft_Plan1d);
  Py_CLEAR(clear_module_state->__pyx_ptype_4cupy_4cuda_5cufft_PlanNd);
  Py_CLEAR(clear_module_state->__pyx_type_4cupy_4cuda_5cufft_PlanNd);
  Py_CLEAR(clear_module_state->__pyx_ptype_4cupy_4cuda_5cufft_XtPlanNd);
  Py_CLEAR(clear_module_state->__pyx_type_4cupy_4cuda_5cufft_XtPlanNd);
  for (int i=0; i<5; ++i) { Py_CLEAR(clear_module_state->__pyx_tuple[i]); }
  for (int i=0; i<2; ++i) { Py_CLEAR(clear_module_state->__pyx_codeobj_tab[i]); }
  for (int i=0; i<227; ++i) { Py_CLEAR(clear_module_state->__pyx_string_tab[i]); }
  Py_CLEAR(clear_module_state->__pyx_int_0);
  Py_CLEAR(clear_module_state->__pyx_int_1);
  Py_CLEAR(clear_module_state->__pyx_int_2);
  Py_CLEAR(clear_module_state->__pyx_int_3);
  Py_CLEAR(clear_module_state->__pyx_int_4);
  Py_CLEAR(clear_module_state->__pyx_int_5);
  Py_CLEAR(clear_module_state->__pyx_int_6);
  Py_CLEAR(clear_module_state->__pyx_int_7);
  Py_CLEAR(clear_module_state->__pyx_int_8);
  Py_CLEAR(clear_module_state->__pyx_int_9);
  Py_CLEAR(clear_module_state->__pyx_int_10);
  Py_CLEAR(clear_module_state->__pyx_int_11);
  Py_CLEAR(clear_module_state->__pyx_int_12);
  Py_CLEAR(clear_module_state->__pyx_int_13);
  Py_CLEAR(clear_module_state->__pyx_int_14);
  Py_CLEAR(clear_module_state->__pyx_int_15);
  Py_CLEAR(clear_module_state->__pyx_int_16);
  Py_CLEAR(clear_module_state->__pyx_int_53);
  Py_CLEAR(clear_module_state->__pyx_int_5570505);
  Py_CLEAR(clear_module_state->__pyx_int_19693511);
  Py_CLEAR(clear_module_state->__pyx_int_27026583);
  Py_CLEAR(clear_module_state->__pyx_int_96612791);
  Py_CLEAR(clear_module_state->__pyx_int_160020523);
  Py_CLEAR(clear_module_state->__pyx_int_163523397);
  Py_CLEAR(clear_module_state->__pyx_int_199145914);
  Py_CLEAR(clear_module_state->__pyx_int_207092197);
  Py_CLEAR(clear_module_state->__pyx_int_257838539);
  Py_CLEAR(clear_module_state->__pyx_int_4000000000);
  return 0;
}
#endif
/* #### Code section: module_state_traverse ### */
#if CYTHON_USE_MODULE_STATE
static CYTHON_SMALL_CODE int __pyx_m_traverse(PyObject *m, visitproc visit, void *arg) {
  __pyx_mstatetype *traverse_module_state = __Pyx_PyModule_GetState(m);
  if (!traverse_module_state) return 0;
  Py_VISIT(traverse_module_state->__pyx_d);
  Py_VISIT(traverse_module_state->__pyx_b);
  Py_VISIT(traverse_module_state->__pyx_cython_runtime);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_empty_tuple);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_empty_bytes);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_empty_unicode);
  #ifdef __Pyx_CyFunction_USED
  Py_VISIT(traverse_module_state->__pyx_CyFunctionType);
  #endif
  #ifdef __Pyx_FusedFunction_USED
  Py_VISIT(traverse_module_state->__pyx_FusedFunctionType);
  #endif
  Py_VISIT(traverse_module_state->__pyx_ptype_13cupy_backends_4cuda_9_softlink_SoftLink);
  Py_VISIT(traverse_module_state->__pyx_ptype_4cupy_4cuda_5cufft_Plan1d);
  Py_VISIT(traverse_module_state->__pyx_type_4cupy_4cuda_5cufft_Plan1d);
  Py_VISIT(traverse_module_state->__pyx_ptype_4cupy_4cuda_5cufft_PlanNd);
  Py_VISIT(traverse_module_state->__pyx_type_4cupy_4cuda_5cufft_PlanNd);
  Py_VISIT(traverse_module_state->__pyx_ptype_4cupy_4cuda_5cufft_XtPlanNd);
  Py_VISIT(traverse_module_state->__pyx_type_4cupy_4cuda_5cufft_XtPlanNd);
  for (int i=0; i<5; ++i) { __Pyx_VISIT_CONST(traverse_module_state->__pyx_tuple[i]); }
  for (int i=0; i<2; ++i) { __Pyx_VISIT_CONST(traverse_module_state->__pyx_codeobj_tab[i]); }
  for (int i=0; i<227; ++i) { __Pyx_VISIT_CONST(traverse_module_state->__pyx_string_tab[i]); }
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_0);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_1);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_2);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_3);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_4);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_5);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_6);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_7);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_8);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_9);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_10);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_11);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_12);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_13);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_14);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_15);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_16);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_53);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_5570505);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_19693511);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_27026583);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_96612791);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_160020523);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_163523397);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_199145914);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_207092197);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_257838539);
  __Pyx_VISIT_CONST(traverse_module_state->__pyx_int_4000000000);
  return 0;
}
#endif
/* #### Code section: module_code ### */

/* "vector.to_py":79
 *     const Py_ssize_t PY_SSIZE_T_MAX
 * 
 * @cname("__pyx_convert_vector_to_py_int")             # <<<<<<<<<<<<<<
 * cdef object __pyx_convert_vector_to_py_int(const vector[X]& v):
 *     if v.size() > <size_t> PY_SSIZE_T_MAX:
*/

static PyObject *__pyx_convert_vector_to_py_int(std::vector<int>  const &__pyx_v_v) {
  Py_ssize_t __pyx_v_v_size_signed;
  PyObject *__pyx_v_o = NULL;
  Py_ssize_t __pyx_v_i;
  PyObject *__pyx_v_item = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  Py_ssize_t __pyx_t_3;
  Py_ssize_t __pyx_t_4;
  Py_ssize_t __pyx_t_5;
  int __pyx_t_6;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__pyx_convert_vector_to_py_int", 0);

  /* "vector.to_py":81
 * @cname("__pyx_convert_vector_to_py_int")
 * cdef object __pyx_convert_vector_to_py_int(const vector[X]& v):
 *     if v.size() > <size_t> PY_SSIZE_T_MAX:             # <<<<<<<<<<<<<<
 *         raise MemoryError()
 *     v_size_signed = <Py_ssize_t> v.size()
*/
  __pyx_t_1 = (__pyx_v_v.size() > ((size_t)PY_SSIZE_T_MAX));
  if (unlikely(__pyx_t_1)) {

    /* "vector.to_py":82
 * cdef object __pyx_convert_vector_to_py_int(const vector[X]& v):
 *     if v.size() > <size_t> PY_SSIZE_T_MAX:
 *         raise MemoryError()             # <<<<<<<<<<<<<<
 *     v_size_signed = <Py_ssize_t> v.size()
 * 
*/
    PyErr_NoMemory(); __PYX_ERR(1, 82, __pyx_L1_error)

    /* "vector.to_py":81
 * @cname("__pyx_convert_vector_to_py_int")
 * cdef object __pyx_convert_vector_to_py_int(const vector[X]& v):
 *     if v.size() > <size_t> PY_SSIZE_T_MAX:             # <<<<<<<<<<<<<<
 *         raise MemoryError()
 *     v_size_signed = <Py_ssize_t> v.size()
*/
  }

  /* "vector.to_py":83
 *     if v.size() > <size_t> PY_SSIZE_T_MAX:
 *         raise MemoryError()
 *     v_size_signed = <Py_ssize_t> v.size()             # <<<<<<<<<<<<<<
 * 
 *     o = PyList_New(v_size_signed)
*/
  __pyx_v_v_size_signed = ((Py_ssize_t)__pyx_v_v.size());

  /* "vector.to_py":85
 *     v_size_signed = <Py_ssize_t> v.size()
 * 
 *     o = PyList_New(v_size_signed)             # <<<<<<<<<<<<<<
 * 
 *     cdef Py_ssize_t i
*/
  __pyx_t_2 = PyList_New(__pyx_v_v_size_signed); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 85, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_v_o = ((PyObject*)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "vector.to_py":90
 *     cdef object item
 * 
 *     for i in range(v_size_signed):             # <<<<<<<<<<<<<<
 *         item = v[i]
 *         Py_INCREF(item)
*/
  __pyx_t_3 = __pyx_v_v_size_signed;
  __pyx_t_4 = __pyx_t_3;
  for (__pyx_t_5 = 0; __pyx_t_5 < __pyx_t_4; __pyx_t_5+=1) {
    __pyx_v_i = __pyx_t_5;

    /* "vector.to_py":91
 * 
 *     for i in range(v_size_signed):
 *         item = v[i]             # <<<<<<<<<<<<<<
 *         Py_INCREF(item)
 *         __Pyx_PyList_SET_ITEM(o, i, item)
*/
    __pyx_t_2 = __Pyx_PyLong_From_int((__pyx_v_v[__pyx_v_i])); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 91, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_XDECREF_SET(__pyx_v_item, __pyx_t_2);
    __pyx_t_2 = 0;

    /* "vector.to_py":92
 *     for i in range(v_size_signed):
 *         item = v[i]
 *         Py_INCREF(item)             # <<<<<<<<<<<<<<
 *         __Pyx_PyList_SET_ITEM(o, i, item)
 * 
*/
    Py_INCREF(__pyx_v_item);

    /* "vector.to_py":93
 *         item = v[i]
 *         Py_INCREF(item)
 *         __Pyx_PyList_SET_ITEM(o, i, item)             # <<<<<<<<<<<<<<
 * 
 *     return o
*/
    __pyx_t_6 = __Pyx_PyList_SET_ITEM(__pyx_v_o, __pyx_v_i, __pyx_v_item); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(1, 93, __pyx_L1_error)
  }

  /* "vector.to_py":95
 *         __Pyx_PyList_SET_ITEM(o, i, item)
 * 
 *     return o             # <<<<<<<<<<<<<<
 * 
*/
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_o);
  __pyx_r = __pyx_v_o;
  goto __pyx_L0;

  /* "vector.to_py":79
 *     const Py_ssize_t PY_SSIZE_T_MAX
 * 
 * @cname("__pyx_convert_vector_to_py_int")             # <<<<<<<<<<<<<<
 * cdef object __pyx_convert_vector_to_py_int(const vector[X]& v):
 *     if v.size() > <size_t> PY_SSIZE_T_MAX:
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("vector.to_py.__pyx_convert_vector_to_py_int", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_o);
  __Pyx_XDECREF(__pyx_v_item);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "vector.from_py":51
 *     cdef Py_ssize_t __Pyx_PyObject_LengthHint(object o, Py_ssize_t defaultval) except -1
 * 
 * @cname("__pyx_convert_vector_from_py_int")             # <<<<<<<<<<<<<<
 * cdef vector[X] __pyx_convert_vector_from_py_int(object o) except *:
 * 
*/

static std::vector<int>  __pyx_convert_vector_from_py_int(PyObject *__pyx_v_o) {
  std::vector<int>  __pyx_v_v;
  Py_ssize_t __pyx_v_s;
  PyObject *__pyx_v_item = NULL;
  std::vector<int>  __pyx_r;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *(*__pyx_t_4)(PyObject *);
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__pyx_convert_vector_from_py_int", 0);

  /* "vector.from_py":55
 * 
 *     cdef vector[X] v
 *     cdef Py_ssize_t s = __Pyx_PyObject_LengthHint(o, 0)             # <<<<<<<<<<<<<<
 * 
 *     if s > 0:
*/
  __pyx_t_1 = __Pyx_PyObject_LengthHint(__pyx_v_o, 0); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(1, 55, __pyx_L1_error)
  __pyx_v_s = __pyx_t_1;

  /* "vector.from_py":57
 *     cdef Py_ssize_t s = __Pyx_PyObject_LengthHint(o, 0)
 * 
 *     if s > 0:             # <<<<<<<<<<<<<<
 *         v.reserve(<size_t> s)
 * 
*/
  __pyx_t_2 = (__pyx_v_s > 0);
  if (__pyx_t_2) {

    /* "vector.from_py":58
 * 
 *     if s > 0:
 *         v.reserve(<size_t> s)             # <<<<<<<<<<<<<<
 * 
 *     for item in o:
*/
    try {
      __pyx_v_v.reserve(((size_t)__pyx_v_s));
    } catch(...) {
      __Pyx_CppExn2PyErr();
      __PYX_ERR(1, 58, __pyx_L1_error)
    }

    /* "vector.from_py":57
 *     cdef Py_ssize_t s = __Pyx_PyObject_LengthHint(o, 0)
 * 
 *     if s > 0:             # <<<<<<<<<<<<<<
 *         v.reserve(<size_t> s)
 * 
*/
  }

  /* "vector.from_py":60
 *         v.reserve(<size_t> s)
 * 
 *     for item in o:             # <<<<<<<<<<<<<<
 *         v.push_back(<X>item)
 * 
*/
  if (likely(PyList_CheckExact(__pyx_v_o)) || PyTuple_CheckExact(__pyx_v_o)) {
    __pyx_t_3 = __pyx_v_o; __Pyx_INCREF(__pyx_t_3);
    __pyx_t_1 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_1 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_v_o); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 60, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = (CYTHON_COMPILING_IN_LIMITED_API) ? PyIter_Next : __Pyx_PyObject_GetIterNextFunc(__pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 60, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_3))) {
        {
          Py_ssize_t __pyx_temp = __Pyx_PyList_GET_SIZE(__pyx_t_3);
          #if !CYTHON_ASSUME_SAFE_SIZE
          if (unlikely((__pyx_temp < 0))) __PYX_ERR(1, 60, __pyx_L1_error)
          #endif
          if (__pyx_t_1 >= __pyx_temp) break;
        }
        __pyx_t_5 = __Pyx_PyList_GetItemRef(__pyx_t_3, __pyx_t_1);
        ++__pyx_t_1;
      } else {
        {
          Py_ssize_t __pyx_temp = __Pyx_PyTuple_GET_SIZE(__pyx_t_3);
          #if !CYTHON_ASSUME_SAFE_SIZE
          if (unlikely((__pyx_temp < 0))) __PYX_ERR(1, 60, __pyx_L1_error)
          #endif
          if (__pyx_t_1 >= __pyx_temp) break;
        }
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = __Pyx_NewRef(PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_1));
        #else
        __pyx_t_5 = __Pyx_PySequence_ITEM(__pyx_t_3, __pyx_t_1);
        #endif
        ++__pyx_t_1;
      }
      if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 60, __pyx_L1_error)
    } else {
      __pyx_t_5 = __pyx_t_4(__pyx_t_3);
      if (unlikely(!__pyx_t_5)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (unlikely(!__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) __PYX_ERR(1, 60, __pyx_L1_error)
          PyErr_Clear();
        }
        break;
      }
    }
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_XDECREF_SET(__pyx_v_item, __pyx_t_5);
    __pyx_t_5 = 0;

    /* "vector.from_py":61
 * 
 *     for item in o:
 *         v.push_back(<X>item)             # <<<<<<<<<<<<<<
 * 
 *     return v
*/
    __pyx_t_6 = __Pyx_PyLong_As_int(__pyx_v_item); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 61, __pyx_L1_error)
    try {
      __pyx_v_v.push_back(((int)__pyx_t_6));
    } catch(...) {
      __Pyx_CppExn2PyErr();
      __PYX_ERR(1, 61, __pyx_L1_error)
    }

    /* "vector.from_py":60
 *         v.reserve(<size_t> s)
 * 
 *     for item in o:             # <<<<<<<<<<<<<<
 *         v.push_back(<X>item)
 * 
*/
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "vector.from_py":63
 *         v.push_back(<X>item)
 * 
 *     return v             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_r = __pyx_v_v;
  goto __pyx_L0;

  /* "vector.from_py":51
 *     cdef Py_ssize_t __Pyx_PyObject_LengthHint(object o, Py_ssize_t defaultval) except -1
 * 
 * @cname("__pyx_convert_vector_from_py_int")             # <<<<<<<<<<<<<<
 * cdef vector[X] __pyx_convert_vector_from_py_int(object o) except *:
 * 
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("vector.from_py.__pyx_convert_vector_from_py_int", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_pretend_to_initialize(&__pyx_r);
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_item);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static std::vector<PY_LONG_LONG>  __pyx_convert_vector_from_py_PY_LONG_LONG(PyObject *__pyx_v_o) {
  std::vector<PY_LONG_LONG>  __pyx_v_v;
  Py_ssize_t __pyx_v_s;
  PyObject *__pyx_v_item = NULL;
  std::vector<PY_LONG_LONG>  __pyx_r;
  __Pyx_RefNannyDeclarations
  Py_ssize_t __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *(*__pyx_t_4)(PyObject *);
  PyObject *__pyx_t_5 = NULL;
  PY_LONG_LONG __pyx_t_6;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__pyx_convert_vector_from_py_PY_LONG_LONG", 0);

  /* "vector.from_py":55
 * 
 *     cdef vector[X] v
 *     cdef Py_ssize_t s = __Pyx_PyObject_LengthHint(o, 0)             # <<<<<<<<<<<<<<
 * 
 *     if s > 0:
*/
  __pyx_t_1 = __Pyx_PyObject_LengthHint(__pyx_v_o, 0); if (unlikely(__pyx_t_1 == ((Py_ssize_t)-1))) __PYX_ERR(1, 55, __pyx_L1_error)
  __pyx_v_s = __pyx_t_1;

  /* "vector.from_py":57
 *     cdef Py_ssize_t s = __Pyx_PyObject_LengthHint(o, 0)
 * 
 *     if s > 0:             # <<<<<<<<<<<<<<
 *         v.reserve(<size_t> s)
 * 
*/
  __pyx_t_2 = (__pyx_v_s > 0);
  if (__pyx_t_2) {

    /* "vector.from_py":58
 * 
 *     if s > 0:
 *         v.reserve(<size_t> s)             # <<<<<<<<<<<<<<
 * 
 *     for item in o:
*/
    try {
      __pyx_v_v.reserve(((size_t)__pyx_v_s));
    } catch(...) {
      __Pyx_CppExn2PyErr();
      __PYX_ERR(1, 58, __pyx_L1_error)
    }

    /* "vector.from_py":57
 *     cdef Py_ssize_t s = __Pyx_PyObject_LengthHint(o, 0)
 * 
 *     if s > 0:             # <<<<<<<<<<<<<<
 *         v.reserve(<size_t> s)
 * 
*/
  }

  /* "vector.from_py":60
 *         v.reserve(<size_t> s)
 * 
 *     for item in o:             # <<<<<<<<<<<<<<
 *         v.push_back(<X>item)
 * 
*/
  if (likely(PyList_CheckExact(__pyx_v_o)) || PyTuple_CheckExact(__pyx_v_o)) {
    __pyx_t_3 = __pyx_v_o; __Pyx_INCREF(__pyx_t_3);
    __pyx_t_1 = 0;
    __pyx_t_4 = NULL;
  } else {
    __pyx_t_1 = -1; __pyx_t_3 = PyObject_GetIter(__pyx_v_o); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 60, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = (CYTHON_COMPILING_IN_LIMITED_API) ? PyIter_Next : __Pyx_PyObject_GetIterNextFunc(__pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 60, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_4)) {
      if (likely(PyList_CheckExact(__pyx_t_3))) {
        {
          Py_ssize_t __pyx_temp = __Pyx_PyList_GET_SIZE(__pyx_t_3);
          #if !CYTHON_ASSUME_SAFE_SIZE
          if (unlikely((__pyx_temp < 0))) __PYX_ERR(1, 60, __pyx_L1_error)
          #endif
          if (__pyx_t_1 >= __pyx_temp) break;
        }
        __pyx_t_5 = __Pyx_PyList_GetItemRef(__pyx_t_3, __pyx_t_1);
        ++__pyx_t_1;
      } else {
        {
          Py_ssize_t __pyx_temp = __Pyx_PyTuple_GET_SIZE(__pyx_t_3);
          #if !CYTHON_ASSUME_SAFE_SIZE
          if (unlikely((__pyx_temp < 0))) __PYX_ERR(1, 60, __pyx_L1_error)
          #endif
          if (__pyx_t_1 >= __pyx_temp) break;
        }
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_5 = __Pyx_NewRef(PyTuple_GET_ITEM(__pyx_t_3, __pyx_t_1));
        #else
        __pyx_t_5 = __Pyx_PySequence_ITEM(__pyx_t_3, __pyx_t_1);
        #endif
        ++__pyx_t_1;
      }
      if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 60, __pyx_L1_error)
    } else {
      __pyx_t_5 = __pyx_t_4(__pyx_t_3);
      if (unlikely(!__pyx_t_5)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (unlikely(!__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) __PYX_ERR(1, 60, __pyx_L1_error)
          PyErr_Clear();
        }
        break;
      }
    }
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_XDECREF_SET(__pyx_v_item, __pyx_t_5);
    __pyx_t_5 = 0;

    /* "vector.from_py":61
 * 
 *     for item in o:
 *         v.push_back(<X>item)             # <<<<<<<<<<<<<<
 * 
 *     return v
*/
    __pyx_t_6 = __Pyx_PyLong_As_PY_LONG_LONG(__pyx_v_item); if (unlikely((__pyx_t_6 == (PY_LONG_LONG)-1) && PyErr_Occurred())) __PYX_ERR(1, 61, __pyx_L1_error)
    try {
      __pyx_v_v.push_back(((PY_LONG_LONG)__pyx_t_6));
    } catch(...) {
      __Pyx_CppExn2PyErr();
      __PYX_ERR(1, 61, __pyx_L1_error)
    }

    /* "vector.from_py":60
 *         v.reserve(<size_t> s)
 * 
 *     for item in o:             # <<<<<<<<<<<<<<
 *         v.push_back(<X>item)
 * 
*/
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "vector.from_py":63
 *         v.push_back(<X>item)
 * 
 *     return v             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_r = __pyx_v_v;
  goto __pyx_L0;

  /* "vector.from_py":51
 *     cdef Py_ssize_t __Pyx_PyObject_LengthHint(object o, Py_ssize_t defaultval) except -1
 * 
 * @cname("__pyx_convert_vector_from_py_PY_LONG_LONG")             # <<<<<<<<<<<<<<
 * cdef vector[X] __pyx_convert_vector_from_py_PY_LONG_LONG(object o) except *:
 * 
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("vector.from_py.__pyx_convert_vector_from_py_PY_LONG_LONG", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_pretend_to_initialize(&__pyx_r);
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_item);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":30
 * cdef SoftLink _L = None
 * 
 * cdef inline void initialize() except *:             # <<<<<<<<<<<<<<
 *     global _L
 *     if _L is not None:
*/

static CYTHON_INLINE void __pyx_f_4cupy_4cuda_5cufft_initialize(void) {
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("initialize", 0);

  /* "cupy/cuda/cufft.pyx":32
 * cdef inline void initialize() except *:
 *     global _L
 *     if _L is not None:             # <<<<<<<<<<<<<<
 *         return
 *     _L = _initialize()
*/
  __pyx_t_1 = (((PyObject *)__pyx_v_4cupy_4cuda_5cufft__L) != Py_None);
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":33
 *     global _L
 *     if _L is not None:
 *         return             # <<<<<<<<<<<<<<
 *     _L = _initialize()
 * 
*/
    goto __pyx_L0;

    /* "cupy/cuda/cufft.pyx":32
 * cdef inline void initialize() except *:
 *     global _L
 *     if _L is not None:             # <<<<<<<<<<<<<<
 *         return
 *     _L = _initialize()
*/
  }

  /* "cupy/cuda/cufft.pyx":34
 *     if _L is not None:
 *         return
 *     _L = _initialize()             # <<<<<<<<<<<<<<
 * 
 * cdef SoftLink _initialize() except *:
*/
  __pyx_t_2 = ((PyObject *)__pyx_f_4cupy_4cuda_5cufft__initialize()); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 34, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_XGOTREF((PyObject *)__pyx_v_4cupy_4cuda_5cufft__L);
  __Pyx_DECREF_SET(__pyx_v_4cupy_4cuda_5cufft__L, ((struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink *)__pyx_t_2));
  __Pyx_GIVEREF(__pyx_t_2);
  __pyx_t_2 = 0;

  /* "cupy/cuda/cufft.pyx":30
 * cdef SoftLink _L = None
 * 
 * cdef inline void initialize() except *:             # <<<<<<<<<<<<<<
 *     global _L
 *     if _L is not None:
*/

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("cupy.cuda.cufft.initialize", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
}

/* "cupy/cuda/cufft.pyx":36
 *     _L = _initialize()
 * 
 * cdef SoftLink _initialize() except *:             # <<<<<<<<<<<<<<
 *     _L = _get_softlink()
 * 
*/

static struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink *__pyx_f_4cupy_4cuda_5cufft__initialize(void) {
  struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink *__pyx_v__L = NULL;
  struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_initialize", 0);

  /* "cupy/cuda/cufft.pyx":37
 * 
 * cdef SoftLink _initialize() except *:
 *     _L = _get_softlink()             # <<<<<<<<<<<<<<
 * 
 *     global _cufftXtSetJITCallback
*/
  __pyx_t_1 = ((PyObject *)__pyx_f_4cupy_4cuda_5cufft__get_softlink()); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 37, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v__L = ((struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink *)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":45
 *             'XtSetJITCallback_12_7')
 *     else:
 *         _cufftXtSetJITCallback = <F_cufftXtSetJITCallback>_L.get(             # <<<<<<<<<<<<<<
 *             'XtSetJITCallback')
 * 
*/
  __pyx_v_4cupy_4cuda_5cufft__cufftXtSetJITCallback = ((__pyx_t_4cupy_4cuda_5cufft_F_cufftXtSetJITCallback)((struct __pyx_vtabstruct_13cupy_backends_4cuda_9_softlink_SoftLink *)__pyx_v__L->__pyx_vtab)->get(__pyx_v__L, __pyx_mstate_global->__pyx_n_u_XtSetJITCallback));

  /* "cupy/cuda/cufft.pyx":48
 *             'XtSetJITCallback')
 * 
 *     return _L             # <<<<<<<<<<<<<<
 * 
 * cdef SoftLink _get_softlink():
*/
  __Pyx_XDECREF((PyObject *)__pyx_r);
  __Pyx_INCREF((PyObject *)__pyx_v__L);
  __pyx_r = __pyx_v__L;
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":36
 *     _L = _initialize()
 * 
 * cdef SoftLink _initialize() except *:             # <<<<<<<<<<<<<<
 *     _L = _get_softlink()
 * 
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft._initialize", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_v__L);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":50
 *     return _L
 * 
 * cdef SoftLink _get_softlink():             # <<<<<<<<<<<<<<
 *     cdef int runtime_version
 *     cdef str prefix = None
*/

static struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink *__pyx_f_4cupy_4cuda_5cufft__get_softlink(void) {
  int __pyx_v_runtime_version;
  PyObject *__pyx_v_prefix = 0;
  PyObject *__pyx_v_libname = 0;
  struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  size_t __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_get_softlink", 0);

  /* "cupy/cuda/cufft.pyx":52
 * cdef SoftLink _get_softlink():
 *     cdef int runtime_version
 *     cdef str prefix = None             # <<<<<<<<<<<<<<
 *     cdef str libname = None
 * 
*/
  __Pyx_INCREF(Py_None);
  __pyx_v_prefix = ((PyObject*)Py_None);

  /* "cupy/cuda/cufft.pyx":53
 *     cdef int runtime_version
 *     cdef str prefix = None
 *     cdef str libname = None             # <<<<<<<<<<<<<<
 * 
 *     if CUPY_CUDA_VERSION != 0:
*/
  __Pyx_INCREF(Py_None);
  __pyx_v_libname = ((PyObject*)Py_None);

  /* "cupy/cuda/cufft.pyx":56
 * 
 *     if CUPY_CUDA_VERSION != 0:
 *         runtime_version = runtime.runtimeGetVersion()             # <<<<<<<<<<<<<<
 *         if 12080 <= runtime_version < 13000:
 *             # CUDA 12.8+
*/
  __pyx_t_2 = NULL;
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 56, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_runtimeGetVersion); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 56, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_5 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_4);
    assert(__pyx_t_2);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_4);
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_4, __pyx__function);
    __pyx_t_5 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, NULL};
    __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_4, __pyx_callargs+__pyx_t_5, (1-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 56, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  __pyx_t_6 = __Pyx_PyLong_As_int(__pyx_t_1); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 56, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_runtime_version = __pyx_t_6;

  /* "cupy/cuda/cufft.pyx":57
 *     if CUPY_CUDA_VERSION != 0:
 *         runtime_version = runtime.runtimeGetVersion()
 *         if 12080 <= runtime_version < 13000:             # <<<<<<<<<<<<<<
 *             # CUDA 12.8+
 *             prefix = '__cufft'
*/
  __pyx_t_7 = (0x2F30 <= __pyx_v_runtime_version);
  if (__pyx_t_7) {
    __pyx_t_7 = (__pyx_v_runtime_version < 0x32C8);
  }
  if (__pyx_t_7) {

    /* "cupy/cuda/cufft.pyx":59
 *         if 12080 <= runtime_version < 13000:
 *             # CUDA 12.8+
 *             prefix = '__cufft'             # <<<<<<<<<<<<<<
 *             if _sys.platform == 'linux':
 *                 libname = 'libcufft.so.11'
*/
    __Pyx_INCREF(__pyx_mstate_global->__pyx_n_u_cufft);
    __Pyx_DECREF_SET(__pyx_v_prefix, __pyx_mstate_global->__pyx_n_u_cufft);

    /* "cupy/cuda/cufft.pyx":60
 *             # CUDA 12.8+
 *             prefix = '__cufft'
 *             if _sys.platform == 'linux':             # <<<<<<<<<<<<<<
 *                 libname = 'libcufft.so.11'
 *             else:  # win
*/
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_sys); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 60, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_platform); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 60, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_linux, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(0, 60, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (__pyx_t_7) {

      /* "cupy/cuda/cufft.pyx":61
 *             prefix = '__cufft'
 *             if _sys.platform == 'linux':
 *                 libname = 'libcufft.so.11'             # <<<<<<<<<<<<<<
 *             else:  # win
 *                 libname = 'cufft64_11.dll'
*/
      __Pyx_INCREF(__pyx_mstate_global->__pyx_kp_u_libcufft_so_11);
      __Pyx_DECREF_SET(__pyx_v_libname, __pyx_mstate_global->__pyx_kp_u_libcufft_so_11);

      /* "cupy/cuda/cufft.pyx":60
 *             # CUDA 12.8+
 *             prefix = '__cufft'
 *             if _sys.platform == 'linux':             # <<<<<<<<<<<<<<
 *                 libname = 'libcufft.so.11'
 *             else:  # win
*/
      goto __pyx_L4;
    }

    /* "cupy/cuda/cufft.pyx":63
 *                 libname = 'libcufft.so.11'
 *             else:  # win
 *                 libname = 'cufft64_11.dll'             # <<<<<<<<<<<<<<
 *         # TODO(leofang): we don't actually know the upper bound!
 *         elif 13000 <= runtime_version < 14000:
*/
    /*else*/ {
      __Pyx_INCREF(__pyx_mstate_global->__pyx_kp_u_cufft64_11_dll);
      __Pyx_DECREF_SET(__pyx_v_libname, __pyx_mstate_global->__pyx_kp_u_cufft64_11_dll);
    }
    __pyx_L4:;

    /* "cupy/cuda/cufft.pyx":57
 *     if CUPY_CUDA_VERSION != 0:
 *         runtime_version = runtime.runtimeGetVersion()
 *         if 12080 <= runtime_version < 13000:             # <<<<<<<<<<<<<<
 *             # CUDA 12.8+
 *             prefix = '__cufft'
*/
    goto __pyx_L3;
  }

  /* "cupy/cuda/cufft.pyx":65
 *                 libname = 'cufft64_11.dll'
 *         # TODO(leofang): we don't actually know the upper bound!
 *         elif 13000 <= runtime_version < 14000:             # <<<<<<<<<<<<<<
 *             # CUDA 13.0+
 *             prefix = 'cufft'
*/
  __pyx_t_7 = (0x32C8 <= __pyx_v_runtime_version);
  if (__pyx_t_7) {
    __pyx_t_7 = (__pyx_v_runtime_version < 0x36B0);
  }
  if (__pyx_t_7) {

    /* "cupy/cuda/cufft.pyx":67
 *         elif 13000 <= runtime_version < 14000:
 *             # CUDA 13.0+
 *             prefix = 'cufft'             # <<<<<<<<<<<<<<
 *             if _sys.platform == 'linux':
 *                 libname = 'libcufft.so.12'
*/
    __Pyx_INCREF(__pyx_mstate_global->__pyx_n_u_cufft_2);
    __Pyx_DECREF_SET(__pyx_v_prefix, __pyx_mstate_global->__pyx_n_u_cufft_2);

    /* "cupy/cuda/cufft.pyx":68
 *             # CUDA 13.0+
 *             prefix = 'cufft'
 *             if _sys.platform == 'linux':             # <<<<<<<<<<<<<<
 *                 libname = 'libcufft.so.12'
 *             else:  # win
*/
    __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_sys); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 68, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_platform); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 68, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_7 = (__Pyx_PyUnicode_Equals(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_linux, Py_EQ)); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(0, 68, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (__pyx_t_7) {

      /* "cupy/cuda/cufft.pyx":69
 *             prefix = 'cufft'
 *             if _sys.platform == 'linux':
 *                 libname = 'libcufft.so.12'             # <<<<<<<<<<<<<<
 *             else:  # win
 *                 libname = 'cufft64_12.dll'
*/
      __Pyx_INCREF(__pyx_mstate_global->__pyx_kp_u_libcufft_so_12);
      __Pyx_DECREF_SET(__pyx_v_libname, __pyx_mstate_global->__pyx_kp_u_libcufft_so_12);

      /* "cupy/cuda/cufft.pyx":68
 *             # CUDA 13.0+
 *             prefix = 'cufft'
 *             if _sys.platform == 'linux':             # <<<<<<<<<<<<<<
 *                 libname = 'libcufft.so.12'
 *             else:  # win
*/
      goto __pyx_L5;
    }

    /* "cupy/cuda/cufft.pyx":71
 *                 libname = 'libcufft.so.12'
 *             else:  # win
 *                 libname = 'cufft64_12.dll'             # <<<<<<<<<<<<<<
 * 
 *     if libname is None:
*/
    /*else*/ {
      __Pyx_INCREF(__pyx_mstate_global->__pyx_kp_u_cufft64_12_dll);
      __Pyx_DECREF_SET(__pyx_v_libname, __pyx_mstate_global->__pyx_kp_u_cufft64_12_dll);
    }
    __pyx_L5:;

    /* "cupy/cuda/cufft.pyx":65
 *                 libname = 'cufft64_11.dll'
 *         # TODO(leofang): we don't actually know the upper bound!
 *         elif 13000 <= runtime_version < 14000:             # <<<<<<<<<<<<<<
 *             # CUDA 13.0+
 *             prefix = 'cufft'
*/
  }
  __pyx_L3:;

  /* "cupy/cuda/cufft.pyx":73
 *                 libname = 'cufft64_12.dll'
 * 
 *     if libname is None:             # <<<<<<<<<<<<<<
 *         raise NotImplementedError
 * 
*/
  __pyx_t_7 = (__pyx_v_libname == ((PyObject*)Py_None));
  if (unlikely(__pyx_t_7)) {

    /* "cupy/cuda/cufft.pyx":74
 * 
 *     if libname is None:
 *         raise NotImplementedError             # <<<<<<<<<<<<<<
 * 
 *     return SoftLink(libname, prefix, mandatory=True)
*/
    __Pyx_Raise(__pyx_builtin_NotImplementedError, 0, 0, 0);
    __PYX_ERR(0, 74, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":73
 *                 libname = 'cufft64_12.dll'
 * 
 *     if libname is None:             # <<<<<<<<<<<<<<
 *         raise NotImplementedError
 * 
*/
  }

  /* "cupy/cuda/cufft.pyx":76
 *         raise NotImplementedError
 * 
 *     return SoftLink(libname, prefix, mandatory=True)             # <<<<<<<<<<<<<<
 * 
 * ####################################################
*/
  __Pyx_XDECREF((PyObject *)__pyx_r);
  __pyx_t_4 = NULL;
  __Pyx_INCREF((PyObject *)__pyx_mstate_global->__pyx_ptype_13cupy_backends_4cuda_9_softlink_SoftLink);
  __pyx_t_2 = ((PyObject *)__pyx_mstate_global->__pyx_ptype_13cupy_backends_4cuda_9_softlink_SoftLink); 
  __pyx_t_5 = 1;
  {
    PyObject *__pyx_callargs[3 + ((CYTHON_VECTORCALL) ? 1 : 0)] = {__pyx_t_4, __pyx_v_libname, __pyx_v_prefix};
    __pyx_t_3 = __Pyx_MakeVectorcallBuilderKwds(1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 76, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    if (__Pyx_VectorcallBuilder_AddArg(__pyx_mstate_global->__pyx_n_u_mandatory, Py_True, __pyx_t_3, __pyx_callargs+3, 0) < (0)) __PYX_ERR(0, 76, __pyx_L1_error)
    __pyx_t_1 = __Pyx_Object_Vectorcall_CallFromBuilder(__pyx_t_2, __pyx_callargs+__pyx_t_5, (3-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET), __pyx_t_3);
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 76, __pyx_L1_error)
    __Pyx_GOTREF((PyObject *)__pyx_t_1);
  }
  __pyx_r = ((struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink *)__pyx_t_1);
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":50
 *     return _L
 * 
 * cdef SoftLink _get_softlink():             # <<<<<<<<<<<<<<
 *     cdef int runtime_version
 *     cdef str prefix = None
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("cupy.cuda.cufft._get_softlink", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_prefix);
  __Pyx_XDECREF(__pyx_v_libname);
  __Pyx_XGIVEREF((PyObject *)__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":84
 * 
 * 
 * cpdef get_current_plan():             # <<<<<<<<<<<<<<
 *     """Get current cuFFT plan.
 * 
*/

static PyObject *__pyx_pw_4cupy_4cuda_5cufft_1get_current_plan(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_get_current_plan(CYTHON_UNUSED int __pyx_skip_dispatch) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  int __pyx_t_3;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get_current_plan", 0);

  /* "cupy/cuda/cufft.pyx":90
 *         None or cupy.cuda.cufft.Plan1d or cupy.cuda.cufft.PlanNd
 *     """
 *     if not hasattr(_thread_local, '_current_plan'):             # <<<<<<<<<<<<<<
 *         _thread_local._current_plan = None
 *     return _thread_local._current_plan
*/
  __pyx_t_1 = __pyx_v_4cupy_4cuda_5cufft__thread_local;
  __Pyx_INCREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_HasAttr(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_current_plan); if (unlikely(__pyx_t_2 == ((int)-1))) __PYX_ERR(0, 90, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = (!__pyx_t_2);
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":91
 *     """
 *     if not hasattr(_thread_local, '_current_plan'):
 *         _thread_local._current_plan = None             # <<<<<<<<<<<<<<
 *     return _thread_local._current_plan
 * 
*/
    if (__Pyx_PyObject_SetAttrStr(__pyx_v_4cupy_4cuda_5cufft__thread_local, __pyx_mstate_global->__pyx_n_u_current_plan, Py_None) < (0)) __PYX_ERR(0, 91, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":90
 *         None or cupy.cuda.cufft.Plan1d or cupy.cuda.cufft.PlanNd
 *     """
 *     if not hasattr(_thread_local, '_current_plan'):             # <<<<<<<<<<<<<<
 *         _thread_local._current_plan = None
 *     return _thread_local._current_plan
*/
  }

  /* "cupy/cuda/cufft.pyx":92
 *     if not hasattr(_thread_local, '_current_plan'):
 *         _thread_local._current_plan = None
 *     return _thread_local._current_plan             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_4cupy_4cuda_5cufft__thread_local, __pyx_mstate_global->__pyx_n_u_current_plan); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 92, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":84
 * 
 * 
 * cpdef get_current_plan():             # <<<<<<<<<<<<<<
 *     """Get current cuFFT plan.
 * 
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.get_current_plan", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_1get_current_plan(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_get_current_plan, "get_current_plan()\n\nGet current cuFFT plan.\n\nReturns:\n    None or cupy.cuda.cufft.Plan1d or cupy.cuda.cufft.PlanNd");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_1get_current_plan(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_current_plan (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_get_current_plan(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_get_current_plan(CYTHON_UNUSED PyObject *__pyx_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get_current_plan", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_get_current_plan(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 84, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.get_current_plan", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":221
 * class CuFFTError(RuntimeError):
 * 
 *     def __init__(self, int result):             # <<<<<<<<<<<<<<
 *         self.result = result
 *         super(CuFFTError, self).__init__('%s' % (RESULT[result]))
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_10CuFFTError_1__init__(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_10CuFFTError___init__, "CuFFTError.__init__(self, int result)");
static PyMethodDef __pyx_mdef_4cupy_4cuda_5cufft_10CuFFTError_1__init__ = {"__init__", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_10CuFFTError_1__init__, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_10CuFFTError___init__};
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_10CuFFTError_1__init__(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_self = 0;
  int __pyx_v_result;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[2] = {0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_self,&__pyx_mstate_global->__pyx_n_u_result,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 221, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 221, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 221, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "__init__", 0) < (0)) __PYX_ERR(0, 221, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 2; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("__init__", 1, 2, 2, i); __PYX_ERR(0, 221, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 2)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 221, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 221, __pyx_L3_error)
    }
    __pyx_v_self = values[0];
    __pyx_v_result = __Pyx_PyLong_As_int(values[1]); if (unlikely((__pyx_v_result == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 221, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 1, 2, 2, __pyx_nargs); __PYX_ERR(0, 221, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.CuFFTError.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_10CuFFTError___init__(__pyx_self, __pyx_v_self, __pyx_v_result);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_10CuFFTError___init__(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_self, int __pyx_v_result) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  size_t __pyx_t_7;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "cupy/cuda/cufft.pyx":222
 * 
 *     def __init__(self, int result):
 *         self.result = result             # <<<<<<<<<<<<<<
 *         super(CuFFTError, self).__init__('%s' % (RESULT[result]))
 * 
*/
  __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_result); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 222, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (__Pyx_PyObject_SetAttrStr(__pyx_v_self, __pyx_mstate_global->__pyx_n_u_result, __pyx_t_1) < (0)) __PYX_ERR(0, 222, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":223
 *     def __init__(self, int result):
 *         self.result = result
 *         super(CuFFTError, self).__init__('%s' % (RESULT[result]))             # <<<<<<<<<<<<<<
 * 
 *     def __reduce__(self):
*/
  __pyx_t_4 = NULL;
  __Pyx_INCREF(__pyx_builtin_super);
  __pyx_t_5 = __pyx_builtin_super; 
  __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_mstate_global->__pyx_n_u_CuFFTError); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 223, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_7 = 1;
  {
    PyObject *__pyx_callargs[3] = {__pyx_t_4, __pyx_t_6, __pyx_v_self};
    __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_5, __pyx_callargs+__pyx_t_7, (3-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 223, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
  }
  __pyx_t_2 = __pyx_t_3;
  __Pyx_INCREF(__pyx_t_2);
  if (unlikely(__pyx_v_4cupy_4cuda_5cufft_RESULT == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(0, 223, __pyx_L1_error)
  }
  __pyx_t_5 = __Pyx_PyLong_From_int(__pyx_v_result); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 223, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyDict_GetItem(__pyx_v_4cupy_4cuda_5cufft_RESULT, __pyx_t_5); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 223, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyUnicode_FormatSafe(__pyx_mstate_global->__pyx_kp_u_s, __pyx_t_6); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 223, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __pyx_t_7 = 0;
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_t_5};
    __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_init, __pyx_callargs+__pyx_t_7, (2-__pyx_t_7) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 223, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":221
 * class CuFFTError(RuntimeError):
 * 
 *     def __init__(self, int result):             # <<<<<<<<<<<<<<
 *         self.result = result
 *         super(CuFFTError, self).__init__('%s' % (RESULT[result]))
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("cupy.cuda.cufft.CuFFTError.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":225
 *         super(CuFFTError, self).__init__('%s' % (RESULT[result]))
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         return (type(self), (self.result,))
 * 
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_10CuFFTError_3__reduce__(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_10CuFFTError_2__reduce__, "CuFFTError.__reduce__(self)");
static PyMethodDef __pyx_mdef_4cupy_4cuda_5cufft_10CuFFTError_3__reduce__ = {"__reduce__", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_10CuFFTError_3__reduce__, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_10CuFFTError_2__reduce__};
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_10CuFFTError_3__reduce__(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_self = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[1] = {0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce__ (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_self,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 225, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 225, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "__reduce__", 0) < (0)) __PYX_ERR(0, 225, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 1; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("__reduce__", 1, 1, 1, i); __PYX_ERR(0, 225, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 1)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 225, __pyx_L3_error)
    }
    __pyx_v_self = values[0];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__reduce__", 1, 1, 1, __pyx_nargs); __PYX_ERR(0, 225, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.CuFFTError.__reduce__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_10CuFFTError_2__reduce__(__pyx_self, __pyx_v_self);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_10CuFFTError_2__reduce__(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__reduce__", 0);

  /* "cupy/cuda/cufft.pyx":226
 * 
 *     def __reduce__(self):
 *         return (type(self), (self.result,))             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_self, __pyx_mstate_global->__pyx_n_u_result); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 226, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyTuple_New(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 226, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_1);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_1) != (0)) __PYX_ERR(0, 226, __pyx_L1_error);
  __pyx_t_1 = 0;
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 226, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_INCREF(((PyObject *)Py_TYPE(__pyx_v_self)));
  __Pyx_GIVEREF(((PyObject *)Py_TYPE(__pyx_v_self)));
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 0, ((PyObject *)Py_TYPE(__pyx_v_self))) != (0)) __PYX_ERR(0, 226, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_2);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_t_2) != (0)) __PYX_ERR(0, 226, __pyx_L1_error);
  __pyx_t_2 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":225
 *         super(CuFFTError, self).__init__('%s' % (RESULT[result]))
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         return (type(self), (self.result,))
 * 
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("cupy.cuda.cufft.CuFFTError.__reduce__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":229
 * 
 * 
 * @cython.profile(False)             # <<<<<<<<<<<<<<
 * cpdef inline void check_result(int result) except *:
 *     if result != 0:
*/

static PyObject *__pyx_pw_4cupy_4cuda_5cufft_3check_result(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
static CYTHON_INLINE void __pyx_f_4cupy_4cuda_5cufft_check_result(int __pyx_v_result, CYTHON_UNUSED int __pyx_skip_dispatch) {
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  size_t __pyx_t_6;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("check_result", 0);

  /* "cupy/cuda/cufft.pyx":231
 * @cython.profile(False)
 * cpdef inline void check_result(int result) except *:
 *     if result != 0:             # <<<<<<<<<<<<<<
 *         raise CuFFTError(result)
 * 
*/
  __pyx_t_1 = (__pyx_v_result != 0);
  if (unlikely(__pyx_t_1)) {

    /* "cupy/cuda/cufft.pyx":232
 * cpdef inline void check_result(int result) except *:
 *     if result != 0:
 *         raise CuFFTError(result)             # <<<<<<<<<<<<<<
 * 
 * 
*/
    __pyx_t_3 = NULL;
    __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_CuFFTError); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 232, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_5 = __Pyx_PyLong_From_int(__pyx_v_result); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 232, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = 1;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_4))) {
      __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_4);
      assert(__pyx_t_3);
      PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_4);
      __Pyx_INCREF(__pyx_t_3);
      __Pyx_INCREF(__pyx__function);
      __Pyx_DECREF_SET(__pyx_t_4, __pyx__function);
      __pyx_t_6 = 0;
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_3, __pyx_t_5};
      __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_4, __pyx_callargs+__pyx_t_6, (2-__pyx_t_6) | (__pyx_t_6*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 232, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 232, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":231
 * @cython.profile(False)
 * cpdef inline void check_result(int result) except *:
 *     if result != 0:             # <<<<<<<<<<<<<<
 *         raise CuFFTError(result)
 * 
*/
  }

  /* "cupy/cuda/cufft.pyx":229
 * 
 * 
 * @cython.profile(False)             # <<<<<<<<<<<<<<
 * cpdef inline void check_result(int result) except *:
 *     if result != 0:
*/

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("cupy.cuda.cufft.check_result", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
}

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_3check_result(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_2check_result, "check_result(int result) -> void");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_3check_result(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  int __pyx_v_result;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[1] = {0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("check_result (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_result,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 229, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 229, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "check_result", 0) < (0)) __PYX_ERR(0, 229, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 1; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("check_result", 1, 1, 1, i); __PYX_ERR(0, 229, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 1)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 229, __pyx_L3_error)
    }
    __pyx_v_result = __Pyx_PyLong_As_int(values[0]); if (unlikely((__pyx_v_result == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 230, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("check_result", 1, 1, 1, __pyx_nargs); __PYX_ERR(0, 229, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.check_result", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_2check_result(__pyx_self, __pyx_v_result);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_2check_result(CYTHON_UNUSED PyObject *__pyx_self, int __pyx_v_result) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("check_result", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 1); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 229, __pyx_L1_error)
  __pyx_t_1 = __Pyx_void_to_None(NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 229, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.check_result", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":235
 * 
 * 
 * cpdef int getVersion() except? -1:             # <<<<<<<<<<<<<<
 *     cdef int version, result
 *     result = cufftGetVersion(&version)
*/

static PyObject *__pyx_pw_4cupy_4cuda_5cufft_5getVersion(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static int __pyx_f_4cupy_4cuda_5cufft_getVersion(CYTHON_UNUSED int __pyx_skip_dispatch) {
  int __pyx_v_version;
  int __pyx_v_result;
  int __pyx_r;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;

  /* "cupy/cuda/cufft.pyx":237
 * cpdef int getVersion() except? -1:
 *     cdef int version, result
 *     result = cufftGetVersion(&version)             # <<<<<<<<<<<<<<
 *     check_result(result)
 *     return version
*/
  __pyx_v_result = cufftGetVersion((&__pyx_v_version));

  /* "cupy/cuda/cufft.pyx":238
 *     cdef int version, result
 *     result = cufftGetVersion(&version)
 *     check_result(result)             # <<<<<<<<<<<<<<
 *     return version
 * 
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 238, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":239
 *     result = cufftGetVersion(&version)
 *     check_result(result)
 *     return version             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_r = __pyx_v_version;
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":235
 * 
 * 
 * cpdef int getVersion() except? -1:             # <<<<<<<<<<<<<<
 *     cdef int version, result
 *     result = cufftGetVersion(&version)
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.getVersion", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_5getVersion(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_4getVersion, "getVersion() -> int");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_5getVersion(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("getVersion (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_4getVersion(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_4getVersion(CYTHON_UNUSED PyObject *__pyx_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("getVersion", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_getVersion(1); if (unlikely(__pyx_t_1 == ((int)-1) && PyErr_Occurred())) __PYX_ERR(0, 235, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 235, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("cupy.cuda.cufft.getVersion", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":245
 * # left in the GPU memory in a permutation of the natural output", see
 * # https://docs.nvidia.com/cuda/cufft/index.html#multiple-GPU-cufft-intermediate-helper  # NOQA
 * cdef _reorder_buffers(Handle plan, intptr_t xtArr, list xtArr_buffer):             # <<<<<<<<<<<<<<
 *     cdef int i, result, nGPUs
 *     cdef intptr_t temp_xtArr
*/

static PyObject *__pyx_f_4cupy_4cuda_5cufft__reorder_buffers(cufftHandle __pyx_v_plan, intptr_t __pyx_v_xtArr, PyObject *__pyx_v_xtArr_buffer) {
  int __pyx_v_i;
  int __pyx_v_result;
  int __pyx_v_nGPUs;
  intptr_t __pyx_v_temp_xtArr;
  cudaLibXtDesc *__pyx_v_temp_arr;
  cudaLibXtDesc *__pyx_v_arr;
  PyObject *__pyx_v_gpus = 0;
  PyObject *__pyx_v_sizes = 0;
  PyObject *__pyx_v_temp_xtArr_buffer = 0;
  PyObject *__pyx_v_temp = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *(*__pyx_t_11)(PyObject *);
  intptr_t __pyx_t_12;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_reorder_buffers", 0);

  /* "cupy/cuda/cufft.pyx":250
 *     cdef XtArray* temp_arr
 *     cdef XtArray* arr
 *     cdef list gpus = []             # <<<<<<<<<<<<<<
 *     cdef list sizes = []
 *     cdef list temp_xtArr_buffer
*/
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 250, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_gpus = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":251
 *     cdef XtArray* arr
 *     cdef list gpus = []
 *     cdef list sizes = []             # <<<<<<<<<<<<<<
 *     cdef list temp_xtArr_buffer
 * 
*/
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 251, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_sizes = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":254
 *     cdef list temp_xtArr_buffer
 * 
 *     arr = <XtArray*>xtArr             # <<<<<<<<<<<<<<
 *     nGPUs = len(xtArr_buffer)
 *     assert nGPUs == arr.descriptor.nGPUs
*/
  __pyx_v_arr = ((cudaLibXtDesc *)__pyx_v_xtArr);

  /* "cupy/cuda/cufft.pyx":255
 * 
 *     arr = <XtArray*>xtArr
 *     nGPUs = len(xtArr_buffer)             # <<<<<<<<<<<<<<
 *     assert nGPUs == arr.descriptor.nGPUs
 * 
*/
  if (unlikely(__pyx_v_xtArr_buffer == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(0, 255, __pyx_L1_error)
  }
  __pyx_t_2 = __Pyx_PyList_GET_SIZE(__pyx_v_xtArr_buffer); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 255, __pyx_L1_error)
  __pyx_v_nGPUs = __pyx_t_2;

  /* "cupy/cuda/cufft.pyx":256
 *     arr = <XtArray*>xtArr
 *     nGPUs = len(xtArr_buffer)
 *     assert nGPUs == arr.descriptor.nGPUs             # <<<<<<<<<<<<<<
 * 
 *     # allocate another buffer to prepare for order conversion
*/
  #ifndef CYTHON_WITHOUT_ASSERTIONS
  if (unlikely(__pyx_assertions_enabled())) {
    __pyx_t_3 = (__pyx_v_nGPUs == __pyx_v_arr->descriptor->nGPUs);
    if (unlikely(!__pyx_t_3)) {
      __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
      __PYX_ERR(0, 256, __pyx_L1_error)
    }
  }
  #else
  if ((1)); else __PYX_ERR(0, 256, __pyx_L1_error)
  #endif

  /* "cupy/cuda/cufft.pyx":259
 * 
 *     # allocate another buffer to prepare for order conversion
 *     for i in range(nGPUs):             # <<<<<<<<<<<<<<
 *         gpus.append(arr.descriptor.GPUs[i])
 *         sizes.append(arr.descriptor.size[i])
*/
  __pyx_t_4 = __pyx_v_nGPUs;
  __pyx_t_5 = __pyx_t_4;
  for (__pyx_t_6 = 0; __pyx_t_6 < __pyx_t_5; __pyx_t_6+=1) {
    __pyx_v_i = __pyx_t_6;

    /* "cupy/cuda/cufft.pyx":260
 *     # allocate another buffer to prepare for order conversion
 *     for i in range(nGPUs):
 *         gpus.append(arr.descriptor.GPUs[i])             # <<<<<<<<<<<<<<
 *         sizes.append(arr.descriptor.size[i])
 *     temp_xtArr, temp_xtArr_buffer = _XtMalloc(gpus, sizes,
*/
    __pyx_t_1 = __Pyx_PyLong_From_int((__pyx_v_arr->descriptor->GPUs[__pyx_v_i])); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 260, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_7 = __Pyx_PyList_Append(__pyx_v_gpus, __pyx_t_1); if (unlikely(__pyx_t_7 == ((int)-1))) __PYX_ERR(0, 260, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":261
 *     for i in range(nGPUs):
 *         gpus.append(arr.descriptor.GPUs[i])
 *         sizes.append(arr.descriptor.size[i])             # <<<<<<<<<<<<<<
 *     temp_xtArr, temp_xtArr_buffer = _XtMalloc(gpus, sizes,
 *                                               CUFFT_XT_FORMAT_INPLACE)
*/
    __pyx_t_1 = __Pyx_PyLong_FromSize_t((__pyx_v_arr->descriptor->size[__pyx_v_i])); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 261, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_7 = __Pyx_PyList_Append(__pyx_v_sizes, __pyx_t_1); if (unlikely(__pyx_t_7 == ((int)-1))) __PYX_ERR(0, 261, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "cupy/cuda/cufft.pyx":262
 *         gpus.append(arr.descriptor.GPUs[i])
 *         sizes.append(arr.descriptor.size[i])
 *     temp_xtArr, temp_xtArr_buffer = _XtMalloc(gpus, sizes,             # <<<<<<<<<<<<<<
 *                                               CUFFT_XT_FORMAT_INPLACE)
 *     temp_arr = <XtArray*>temp_xtArr
*/
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft__XtMalloc(__pyx_v_gpus, __pyx_v_sizes, CUFFT_XT_FORMAT_INPLACE); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 262, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 262, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_8 = PyTuple_GET_ITEM(sequence, 0);
      __Pyx_INCREF(__pyx_t_8);
      __pyx_t_9 = PyTuple_GET_ITEM(sequence, 1);
      __Pyx_INCREF(__pyx_t_9);
    } else {
      __pyx_t_8 = __Pyx_PyList_GetItemRef(sequence, 0);
      if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 262, __pyx_L1_error)
      __Pyx_XGOTREF(__pyx_t_8);
      __pyx_t_9 = __Pyx_PyList_GetItemRef(sequence, 1);
      if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 262, __pyx_L1_error)
      __Pyx_XGOTREF(__pyx_t_9);
    }
    #else
    __pyx_t_8 = __Pyx_PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 262, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_9 = __Pyx_PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 262, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_10 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 262, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_11 = (CYTHON_COMPILING_IN_LIMITED_API) ? PyIter_Next : __Pyx_PyObject_GetIterNextFunc(__pyx_t_10);
    index = 0; __pyx_t_8 = __pyx_t_11(__pyx_t_10); if (unlikely(!__pyx_t_8)) goto __pyx_L5_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_8);
    index = 1; __pyx_t_9 = __pyx_t_11(__pyx_t_10); if (unlikely(!__pyx_t_9)) goto __pyx_L5_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_9);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_11(__pyx_t_10), 2) < (0)) __PYX_ERR(0, 262, __pyx_L1_error)
    __pyx_t_11 = NULL;
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    goto __pyx_L6_unpacking_done;
    __pyx_L5_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __pyx_t_11 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 262, __pyx_L1_error)
    __pyx_L6_unpacking_done:;
  }
  __pyx_t_12 = PyLong_AsSsize_t(__pyx_t_8); if (unlikely((__pyx_t_12 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 262, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  if (!(likely(PyList_CheckExact(__pyx_t_9))||((__pyx_t_9) == Py_None) || __Pyx_RaiseUnexpectedTypeError("list", __pyx_t_9))) __PYX_ERR(0, 262, __pyx_L1_error)
  __pyx_v_temp_xtArr = __pyx_t_12;
  __pyx_v_temp_xtArr_buffer = ((PyObject*)__pyx_t_9);
  __pyx_t_9 = 0;

  /* "cupy/cuda/cufft.pyx":264
 *     temp_xtArr, temp_xtArr_buffer = _XtMalloc(gpus, sizes,
 *                                               CUFFT_XT_FORMAT_INPLACE)
 *     temp_arr = <XtArray*>temp_xtArr             # <<<<<<<<<<<<<<
 * 
 *     # Make a device copy to bring the data from the permuted order back to
*/
  __pyx_v_temp_arr = ((cudaLibXtDesc *)__pyx_v_temp_xtArr);

  /* "cupy/cuda/cufft.pyx":269
 *     # the natural order. Note that this works because after FFT
 *     # arr.subFormat is silently changed to CUFFT_XT_FORMAT_INPLACE_SHUFFLED
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftXtMemcpy(plan, <void*>temp_arr, <void*>arr,
 *                                CUFFT_COPY_DEVICE_TO_DEVICE)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":270
 *     # arr.subFormat is silently changed to CUFFT_XT_FORMAT_INPLACE_SHUFFLED
 *     with nogil:
 *         result = cufftXtMemcpy(plan, <void*>temp_arr, <void*>arr,             # <<<<<<<<<<<<<<
 *                                CUFFT_COPY_DEVICE_TO_DEVICE)
 *     check_result(result)
*/
        __pyx_v_result = cufftXtMemcpy(__pyx_v_plan, ((void *)__pyx_v_temp_arr), ((void *)__pyx_v_arr), CUFFT_COPY_DEVICE_TO_DEVICE);
      }

      /* "cupy/cuda/cufft.pyx":269
 *     # the natural order. Note that this works because after FFT
 *     # arr.subFormat is silently changed to CUFFT_XT_FORMAT_INPLACE_SHUFFLED
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftXtMemcpy(plan, <void*>temp_arr, <void*>arr,
 *                                CUFFT_COPY_DEVICE_TO_DEVICE)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L9;
        }
        __pyx_L9:;
      }
  }

  /* "cupy/cuda/cufft.pyx":272
 *         result = cufftXtMemcpy(plan, <void*>temp_arr, <void*>arr,
 *                                CUFFT_COPY_DEVICE_TO_DEVICE)
 *     check_result(result)             # <<<<<<<<<<<<<<
 * 
 *     for i in range(nGPUs):
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 272, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":274
 *     check_result(result)
 * 
 *     for i in range(nGPUs):             # <<<<<<<<<<<<<<
 *         # swap MemoryPointer in xtArr_buffer
 *         temp = temp_xtArr_buffer[i]
*/
  __pyx_t_4 = __pyx_v_nGPUs;
  __pyx_t_5 = __pyx_t_4;
  for (__pyx_t_6 = 0; __pyx_t_6 < __pyx_t_5; __pyx_t_6+=1) {
    __pyx_v_i = __pyx_t_6;

    /* "cupy/cuda/cufft.pyx":276
 *     for i in range(nGPUs):
 *         # swap MemoryPointer in xtArr_buffer
 *         temp = temp_xtArr_buffer[i]             # <<<<<<<<<<<<<<
 *         temp_xtArr_buffer[i] = xtArr_buffer[i]
 *         xtArr_buffer[i] = temp
*/
    if (unlikely(__pyx_v_temp_xtArr_buffer == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
      __PYX_ERR(0, 276, __pyx_L1_error)
    }
    __pyx_t_1 = __Pyx_GetItemInt_List(__pyx_v_temp_xtArr_buffer, __pyx_v_i, int, 1, __Pyx_PyLong_From_int, 1, 1, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 276, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_XDECREF_SET(__pyx_v_temp, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":277
 *         # swap MemoryPointer in xtArr_buffer
 *         temp = temp_xtArr_buffer[i]
 *         temp_xtArr_buffer[i] = xtArr_buffer[i]             # <<<<<<<<<<<<<<
 *         xtArr_buffer[i] = temp
 * 
*/
    if (unlikely(__pyx_v_xtArr_buffer == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
      __PYX_ERR(0, 277, __pyx_L1_error)
    }
    __pyx_t_1 = __Pyx_GetItemInt_List(__pyx_v_xtArr_buffer, __pyx_v_i, int, 1, __Pyx_PyLong_From_int, 1, 1, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 277, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (unlikely(__pyx_v_temp_xtArr_buffer == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
      __PYX_ERR(0, 277, __pyx_L1_error)
    }
    if (unlikely((__Pyx_SetItemInt(__pyx_v_temp_xtArr_buffer, __pyx_v_i, __pyx_t_1, int, 1, __Pyx_PyLong_From_int, 1, 1, 1, 1) < 0))) __PYX_ERR(0, 277, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":278
 *         temp = temp_xtArr_buffer[i]
 *         temp_xtArr_buffer[i] = xtArr_buffer[i]
 *         xtArr_buffer[i] = temp             # <<<<<<<<<<<<<<
 * 
 *         # swap pointer in xtArr
*/
    if (unlikely(__pyx_v_xtArr_buffer == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
      __PYX_ERR(0, 278, __pyx_L1_error)
    }
    if (unlikely((__Pyx_SetItemInt(__pyx_v_xtArr_buffer, __pyx_v_i, __pyx_v_temp, int, 1, __Pyx_PyLong_From_int, 1, 1, 1, 1) < 0))) __PYX_ERR(0, 278, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":281
 * 
 *         # swap pointer in xtArr
 *         arr.descriptor.data[i] = temp_arr.descriptor.data[i]             # <<<<<<<<<<<<<<
 *         assert arr.descriptor.size[i] == temp_arr.descriptor.size[i]
 *         temp_arr.descriptor.data[i] = NULL
*/
    (__pyx_v_arr->descriptor->data[__pyx_v_i]) = (__pyx_v_temp_arr->descriptor->data[__pyx_v_i]);

    /* "cupy/cuda/cufft.pyx":282
 *         # swap pointer in xtArr
 *         arr.descriptor.data[i] = temp_arr.descriptor.data[i]
 *         assert arr.descriptor.size[i] == temp_arr.descriptor.size[i]             # <<<<<<<<<<<<<<
 *         temp_arr.descriptor.data[i] = NULL
 *         temp_arr.descriptor.size[i] = 0
*/
    #ifndef CYTHON_WITHOUT_ASSERTIONS
    if (unlikely(__pyx_assertions_enabled())) {
      __pyx_t_3 = ((__pyx_v_arr->descriptor->size[__pyx_v_i]) == (__pyx_v_temp_arr->descriptor->size[__pyx_v_i]));
      if (unlikely(!__pyx_t_3)) {
        __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
        __PYX_ERR(0, 282, __pyx_L1_error)
      }
    }
    #else
    if ((1)); else __PYX_ERR(0, 282, __pyx_L1_error)
    #endif

    /* "cupy/cuda/cufft.pyx":283
 *         arr.descriptor.data[i] = temp_arr.descriptor.data[i]
 *         assert arr.descriptor.size[i] == temp_arr.descriptor.size[i]
 *         temp_arr.descriptor.data[i] = NULL             # <<<<<<<<<<<<<<
 *         temp_arr.descriptor.size[i] = 0
 * 
*/
    (__pyx_v_temp_arr->descriptor->data[__pyx_v_i]) = NULL;

    /* "cupy/cuda/cufft.pyx":284
 *         assert arr.descriptor.size[i] == temp_arr.descriptor.size[i]
 *         temp_arr.descriptor.data[i] = NULL
 *         temp_arr.descriptor.size[i] = 0             # <<<<<<<<<<<<<<
 * 
 *     # temp_xtArr now points to the old data, which is now in temp_xtArr_buffer
*/
    (__pyx_v_temp_arr->descriptor->size[__pyx_v_i]) = 0;
  }

  /* "cupy/cuda/cufft.pyx":288
 *     # temp_xtArr now points to the old data, which is now in temp_xtArr_buffer
 *     # and will be deallocated after this line (out of scope)
 *     _XtFree(temp_xtArr)             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft__XtFree(__pyx_v_temp_xtArr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 288, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":245
 * # left in the GPU memory in a permutation of the natural output", see
 * # https://docs.nvidia.com/cuda/cufft/index.html#multiple-GPU-cufft-intermediate-helper  # NOQA
 * cdef _reorder_buffers(Handle plan, intptr_t xtArr, list xtArr_buffer):             # <<<<<<<<<<<<<<
 *     cdef int i, result, nGPUs
 *     cdef intptr_t temp_xtArr
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("cupy.cuda.cufft._reorder_buffers", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_gpus);
  __Pyx_XDECREF(__pyx_v_sizes);
  __Pyx_XDECREF(__pyx_v_temp_xtArr_buffer);
  __Pyx_XDECREF(__pyx_v_temp);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":294
 * # We need to manage the buffers ourselves in order to 1. avoid excessive,
 * # unnecessary memory usage, and 2. use CuPy's memory pool.
 * cdef _XtMalloc(list gpus, list sizes, XtSubFormat fmt):             # <<<<<<<<<<<<<<
 *     cdef XtArrayDesc* xtArr_desc
 *     cdef XtArray* xtArr
*/

static PyObject *__pyx_f_4cupy_4cuda_5cufft__XtMalloc(PyObject *__pyx_v_gpus, PyObject *__pyx_v_sizes, cufftXtSubFormat __pyx_v_fmt) {
  cudaXtDesc *__pyx_v_xtArr_desc;
  cudaLibXtDesc *__pyx_v_xtArr;
  PyObject *__pyx_v_xtArr_buffer = 0;
  int __pyx_v_i;
  int __pyx_v_nGPUs;
  size_t __pyx_v_size;
  PyObject *__pyx_v_gpu = NULL;
  PyObject *__pyx_v_prev_device = NULL;
  PyObject *__pyx_v_buf = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  Py_ssize_t __pyx_t_2;
  int __pyx_t_3;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  size_t __pyx_t_7;
  PyObject *(*__pyx_t_8)(PyObject *);
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  PyObject *(*__pyx_t_11)(PyObject *);
  int __pyx_t_12;
  int __pyx_t_13;
  char const *__pyx_t_14;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  PyObject *__pyx_t_17 = NULL;
  PyObject *__pyx_t_18 = NULL;
  PyObject *__pyx_t_19 = NULL;
  PyObject *__pyx_t_20 = NULL;
  int __pyx_t_21;
  intptr_t __pyx_t_22;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_XtMalloc", 0);

  /* "cupy/cuda/cufft.pyx":297
 *     cdef XtArrayDesc* xtArr_desc
 *     cdef XtArray* xtArr
 *     cdef list xtArr_buffer = []             # <<<<<<<<<<<<<<
 *     cdef int i, nGPUs
 *     cdef size_t size
*/
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 297, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_xtArr_buffer = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":301
 *     cdef size_t size
 * 
 *     nGPUs = len(gpus)             # <<<<<<<<<<<<<<
 *     assert nGPUs == len(sizes)
 *     xtArr_desc = <XtArrayDesc*>PyMem_Malloc(sizeof(XtArrayDesc))
*/
  if (unlikely(__pyx_v_gpus == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(0, 301, __pyx_L1_error)
  }
  __pyx_t_2 = __Pyx_PyList_GET_SIZE(__pyx_v_gpus); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 301, __pyx_L1_error)
  __pyx_v_nGPUs = __pyx_t_2;

  /* "cupy/cuda/cufft.pyx":302
 * 
 *     nGPUs = len(gpus)
 *     assert nGPUs == len(sizes)             # <<<<<<<<<<<<<<
 *     xtArr_desc = <XtArrayDesc*>PyMem_Malloc(sizeof(XtArrayDesc))
 *     xtArr = <XtArray*>PyMem_Malloc(sizeof(XtArray))
*/
  #ifndef CYTHON_WITHOUT_ASSERTIONS
  if (unlikely(__pyx_assertions_enabled())) {
    if (unlikely(__pyx_v_sizes == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
      __PYX_ERR(0, 302, __pyx_L1_error)
    }
    __pyx_t_2 = __Pyx_PyList_GET_SIZE(__pyx_v_sizes); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 302, __pyx_L1_error)
    __pyx_t_3 = (__pyx_v_nGPUs == __pyx_t_2);
    if (unlikely(!__pyx_t_3)) {
      __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
      __PYX_ERR(0, 302, __pyx_L1_error)
    }
  }
  #else
  if ((1)); else __PYX_ERR(0, 302, __pyx_L1_error)
  #endif

  /* "cupy/cuda/cufft.pyx":303
 *     nGPUs = len(gpus)
 *     assert nGPUs == len(sizes)
 *     xtArr_desc = <XtArrayDesc*>PyMem_Malloc(sizeof(XtArrayDesc))             # <<<<<<<<<<<<<<
 *     xtArr = <XtArray*>PyMem_Malloc(sizeof(XtArray))
 *     c_memset(xtArr_desc, 0, sizeof(XtArrayDesc))
*/
  __pyx_v_xtArr_desc = ((cudaXtDesc *)PyMem_Malloc((sizeof(cudaXtDesc))));

  /* "cupy/cuda/cufft.pyx":304
 *     assert nGPUs == len(sizes)
 *     xtArr_desc = <XtArrayDesc*>PyMem_Malloc(sizeof(XtArrayDesc))
 *     xtArr = <XtArray*>PyMem_Malloc(sizeof(XtArray))             # <<<<<<<<<<<<<<
 *     c_memset(xtArr_desc, 0, sizeof(XtArrayDesc))
 *     c_memset(xtArr, 0, sizeof(XtArray))
*/
  __pyx_v_xtArr = ((cudaLibXtDesc *)PyMem_Malloc((sizeof(cudaLibXtDesc))));

  /* "cupy/cuda/cufft.pyx":305
 *     xtArr_desc = <XtArrayDesc*>PyMem_Malloc(sizeof(XtArrayDesc))
 *     xtArr = <XtArray*>PyMem_Malloc(sizeof(XtArray))
 *     c_memset(xtArr_desc, 0, sizeof(XtArrayDesc))             # <<<<<<<<<<<<<<
 *     c_memset(xtArr, 0, sizeof(XtArray))
 * 
*/
  (void)(memset(__pyx_v_xtArr_desc, 0, (sizeof(cudaXtDesc))));

  /* "cupy/cuda/cufft.pyx":306
 *     xtArr = <XtArray*>PyMem_Malloc(sizeof(XtArray))
 *     c_memset(xtArr_desc, 0, sizeof(XtArrayDesc))
 *     c_memset(xtArr, 0, sizeof(XtArray))             # <<<<<<<<<<<<<<
 * 
 *     xtArr_desc.nGPUs = nGPUs
*/
  (void)(memset(__pyx_v_xtArr, 0, (sizeof(cudaLibXtDesc))));

  /* "cupy/cuda/cufft.pyx":308
 *     c_memset(xtArr, 0, sizeof(XtArray))
 * 
 *     xtArr_desc.nGPUs = nGPUs             # <<<<<<<<<<<<<<
 *     for i, (gpu, size) in enumerate(zip(gpus, sizes)):
 *         prev_device = runtime.getDevice()
*/
  __pyx_v_xtArr_desc->nGPUs = __pyx_v_nGPUs;

  /* "cupy/cuda/cufft.pyx":309
 * 
 *     xtArr_desc.nGPUs = nGPUs
 *     for i, (gpu, size) in enumerate(zip(gpus, sizes)):             # <<<<<<<<<<<<<<
 *         prev_device = runtime.getDevice()
 *         runtime.setDevice(gpu)
*/
  __pyx_t_4 = 0;
  __pyx_t_5 = NULL;
  __Pyx_INCREF(__pyx_builtin_zip);
  __pyx_t_6 = __pyx_builtin_zip; 
  __pyx_t_7 = 1;
  {
    PyObject *__pyx_callargs[3] = {__pyx_t_5, __pyx_v_gpus, __pyx_v_sizes};
    __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_6, __pyx_callargs+__pyx_t_7, (3-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 309, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  if (likely(PyList_CheckExact(__pyx_t_1)) || PyTuple_CheckExact(__pyx_t_1)) {
    __pyx_t_6 = __pyx_t_1; __Pyx_INCREF(__pyx_t_6);
    __pyx_t_2 = 0;
    __pyx_t_8 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_6 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 309, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_8 = (CYTHON_COMPILING_IN_LIMITED_API) ? PyIter_Next : __Pyx_PyObject_GetIterNextFunc(__pyx_t_6); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 309, __pyx_L1_error)
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  for (;;) {
    if (likely(!__pyx_t_8)) {
      if (likely(PyList_CheckExact(__pyx_t_6))) {
        {
          Py_ssize_t __pyx_temp = __Pyx_PyList_GET_SIZE(__pyx_t_6);
          #if !CYTHON_ASSUME_SAFE_SIZE
          if (unlikely((__pyx_temp < 0))) __PYX_ERR(0, 309, __pyx_L1_error)
          #endif
          if (__pyx_t_2 >= __pyx_temp) break;
        }
        __pyx_t_1 = __Pyx_PyList_GetItemRef(__pyx_t_6, __pyx_t_2);
        ++__pyx_t_2;
      } else {
        {
          Py_ssize_t __pyx_temp = __Pyx_PyTuple_GET_SIZE(__pyx_t_6);
          #if !CYTHON_ASSUME_SAFE_SIZE
          if (unlikely((__pyx_temp < 0))) __PYX_ERR(0, 309, __pyx_L1_error)
          #endif
          if (__pyx_t_2 >= __pyx_temp) break;
        }
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_1 = __Pyx_NewRef(PyTuple_GET_ITEM(__pyx_t_6, __pyx_t_2));
        #else
        __pyx_t_1 = __Pyx_PySequence_ITEM(__pyx_t_6, __pyx_t_2);
        #endif
        ++__pyx_t_2;
      }
      if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 309, __pyx_L1_error)
    } else {
      __pyx_t_1 = __pyx_t_8(__pyx_t_6);
      if (unlikely(!__pyx_t_1)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (unlikely(!__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) __PYX_ERR(0, 309, __pyx_L1_error)
          PyErr_Clear();
        }
        break;
      }
    }
    __Pyx_GOTREF(__pyx_t_1);
    if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
      PyObject* sequence = __pyx_t_1;
      Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
      if (unlikely(size != 2)) {
        if (size > 2) __Pyx_RaiseTooManyValuesError(2);
        else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
        __PYX_ERR(0, 309, __pyx_L1_error)
      }
      #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
      if (likely(PyTuple_CheckExact(sequence))) {
        __pyx_t_5 = PyTuple_GET_ITEM(sequence, 0);
        __Pyx_INCREF(__pyx_t_5);
        __pyx_t_9 = PyTuple_GET_ITEM(sequence, 1);
        __Pyx_INCREF(__pyx_t_9);
      } else {
        __pyx_t_5 = __Pyx_PyList_GetItemRef(sequence, 0);
        if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 309, __pyx_L1_error)
        __Pyx_XGOTREF(__pyx_t_5);
        __pyx_t_9 = __Pyx_PyList_GetItemRef(sequence, 1);
        if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 309, __pyx_L1_error)
        __Pyx_XGOTREF(__pyx_t_9);
      }
      #else
      __pyx_t_5 = __Pyx_PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 309, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_9 = __Pyx_PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 309, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      #endif
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    } else {
      Py_ssize_t index = -1;
      __pyx_t_10 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 309, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_11 = (CYTHON_COMPILING_IN_LIMITED_API) ? PyIter_Next : __Pyx_PyObject_GetIterNextFunc(__pyx_t_10);
      index = 0; __pyx_t_5 = __pyx_t_11(__pyx_t_10); if (unlikely(!__pyx_t_5)) goto __pyx_L5_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_5);
      index = 1; __pyx_t_9 = __pyx_t_11(__pyx_t_10); if (unlikely(!__pyx_t_9)) goto __pyx_L5_unpacking_failed;
      __Pyx_GOTREF(__pyx_t_9);
      if (__Pyx_IternextUnpackEndCheck(__pyx_t_11(__pyx_t_10), 2) < (0)) __PYX_ERR(0, 309, __pyx_L1_error)
      __pyx_t_11 = NULL;
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      goto __pyx_L6_unpacking_done;
      __pyx_L5_unpacking_failed:;
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __pyx_t_11 = NULL;
      if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
      __PYX_ERR(0, 309, __pyx_L1_error)
      __pyx_L6_unpacking_done:;
    }
    __pyx_t_7 = __Pyx_PyLong_As_size_t(__pyx_t_9); if (unlikely((__pyx_t_7 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 309, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    __Pyx_XDECREF_SET(__pyx_v_gpu, __pyx_t_5);
    __pyx_t_5 = 0;
    __pyx_v_size = __pyx_t_7;
    __pyx_v_i = __pyx_t_4;
    __pyx_t_4 = (__pyx_t_4 + 1);

    /* "cupy/cuda/cufft.pyx":310
 *     xtArr_desc.nGPUs = nGPUs
 *     for i, (gpu, size) in enumerate(zip(gpus, sizes)):
 *         prev_device = runtime.getDevice()             # <<<<<<<<<<<<<<
 *         runtime.setDevice(gpu)
 *         try:
*/
    __pyx_t_9 = NULL;
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 310, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_getDevice); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 310, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_7 = 1;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_10))) {
      __pyx_t_9 = PyMethod_GET_SELF(__pyx_t_10);
      assert(__pyx_t_9);
      PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_10);
      __Pyx_INCREF(__pyx_t_9);
      __Pyx_INCREF(__pyx__function);
      __Pyx_DECREF_SET(__pyx_t_10, __pyx__function);
      __pyx_t_7 = 0;
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_9, NULL};
      __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_10, __pyx_callargs+__pyx_t_7, (1-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 310, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_XDECREF_SET(__pyx_v_prev_device, __pyx_t_1);
    __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":311
 *     for i, (gpu, size) in enumerate(zip(gpus, sizes)):
 *         prev_device = runtime.getDevice()
 *         runtime.setDevice(gpu)             # <<<<<<<<<<<<<<
 *         try:
 *             buf = memory.alloc(size)
*/
    __pyx_t_10 = NULL;
    __Pyx_GetModuleGlobalName(__pyx_t_9, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 311, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_9, __pyx_mstate_global->__pyx_n_u_setDevice); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 311, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    __pyx_t_7 = 1;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_10 = PyMethod_GET_SELF(__pyx_t_5);
      assert(__pyx_t_10);
      PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_10);
      __Pyx_INCREF(__pyx__function);
      __Pyx_DECREF_SET(__pyx_t_5, __pyx__function);
      __pyx_t_7 = 0;
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_10, __pyx_v_gpu};
      __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_5, __pyx_callargs+__pyx_t_7, (2-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 311, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":312
 *         prev_device = runtime.getDevice()
 *         runtime.setDevice(gpu)
 *         try:             # <<<<<<<<<<<<<<
 *             buf = memory.alloc(size)
 *         finally:
*/
    /*try:*/ {

      /* "cupy/cuda/cufft.pyx":313
 *         runtime.setDevice(gpu)
 *         try:
 *             buf = memory.alloc(size)             # <<<<<<<<<<<<<<
 *         finally:
 *             runtime.setDevice(prev_device)
*/
      __pyx_t_5 = NULL;
      __Pyx_GetModuleGlobalName(__pyx_t_10, __pyx_mstate_global->__pyx_n_u_memory); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 313, __pyx_L10_error)
      __Pyx_GOTREF(__pyx_t_10);
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_mstate_global->__pyx_n_u_alloc); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 313, __pyx_L10_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __pyx_t_10 = __Pyx_PyLong_FromSize_t(__pyx_v_size); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 313, __pyx_L10_error)
      __Pyx_GOTREF(__pyx_t_10);
      __pyx_t_7 = 1;
      #if CYTHON_UNPACK_METHODS
      if (unlikely(PyMethod_Check(__pyx_t_9))) {
        __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_9);
        assert(__pyx_t_5);
        PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_9);
        __Pyx_INCREF(__pyx_t_5);
        __Pyx_INCREF(__pyx__function);
        __Pyx_DECREF_SET(__pyx_t_9, __pyx__function);
        __pyx_t_7 = 0;
      }
      #endif
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_5, __pyx_t_10};
        __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_9, __pyx_callargs+__pyx_t_7, (2-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 313, __pyx_L10_error)
        __Pyx_GOTREF(__pyx_t_1);
      }
      __Pyx_XDECREF_SET(__pyx_v_buf, __pyx_t_1);
      __pyx_t_1 = 0;
    }

    /* "cupy/cuda/cufft.pyx":315
 *             buf = memory.alloc(size)
 *         finally:
 *             runtime.setDevice(prev_device)             # <<<<<<<<<<<<<<
 *         assert gpu == buf.device_id
 *         xtArr_buffer.append(buf)
*/
    /*finally:*/ {
      /*normal exit:*/{
        __pyx_t_9 = NULL;
        __Pyx_GetModuleGlobalName(__pyx_t_10, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 315, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_mstate_global->__pyx_n_u_setDevice); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 315, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        __pyx_t_7 = 1;
        #if CYTHON_UNPACK_METHODS
        if (unlikely(PyMethod_Check(__pyx_t_5))) {
          __pyx_t_9 = PyMethod_GET_SELF(__pyx_t_5);
          assert(__pyx_t_9);
          PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_5);
          __Pyx_INCREF(__pyx_t_9);
          __Pyx_INCREF(__pyx__function);
          __Pyx_DECREF_SET(__pyx_t_5, __pyx__function);
          __pyx_t_7 = 0;
        }
        #endif
        {
          PyObject *__pyx_callargs[2] = {__pyx_t_9, __pyx_v_prev_device};
          __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_5, __pyx_callargs+__pyx_t_7, (2-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
          __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 315, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
        }
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        goto __pyx_L11;
      }
      __pyx_L10_error:;
      /*exception exit:*/{
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0; __pyx_t_19 = 0; __pyx_t_20 = 0;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
         __Pyx_ExceptionSwap(&__pyx_t_18, &__pyx_t_19, &__pyx_t_20);
        if ( unlikely(__Pyx_GetException(&__pyx_t_15, &__pyx_t_16, &__pyx_t_17) < 0)) __Pyx_ErrFetch(&__pyx_t_15, &__pyx_t_16, &__pyx_t_17);
        __Pyx_XGOTREF(__pyx_t_15);
        __Pyx_XGOTREF(__pyx_t_16);
        __Pyx_XGOTREF(__pyx_t_17);
        __Pyx_XGOTREF(__pyx_t_18);
        __Pyx_XGOTREF(__pyx_t_19);
        __Pyx_XGOTREF(__pyx_t_20);
        __pyx_t_12 = __pyx_lineno; __pyx_t_13 = __pyx_clineno; __pyx_t_14 = __pyx_filename;
        {
          __pyx_t_5 = NULL;
          __Pyx_GetModuleGlobalName(__pyx_t_9, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 315, __pyx_L15_error)
          __Pyx_GOTREF(__pyx_t_9);
          __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_9, __pyx_mstate_global->__pyx_n_u_setDevice); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 315, __pyx_L15_error)
          __Pyx_GOTREF(__pyx_t_10);
          __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
          __pyx_t_7 = 1;
          #if CYTHON_UNPACK_METHODS
          if (unlikely(PyMethod_Check(__pyx_t_10))) {
            __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_10);
            assert(__pyx_t_5);
            PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_10);
            __Pyx_INCREF(__pyx_t_5);
            __Pyx_INCREF(__pyx__function);
            __Pyx_DECREF_SET(__pyx_t_10, __pyx__function);
            __pyx_t_7 = 0;
          }
          #endif
          {
            PyObject *__pyx_callargs[2] = {__pyx_t_5, __pyx_v_prev_device};
            __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_10, __pyx_callargs+__pyx_t_7, (2-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
            __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
            __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
            if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 315, __pyx_L15_error)
            __Pyx_GOTREF(__pyx_t_1);
          }
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        }
        __Pyx_XGIVEREF(__pyx_t_18);
        __Pyx_XGIVEREF(__pyx_t_19);
        __Pyx_XGIVEREF(__pyx_t_20);
        __Pyx_ExceptionReset(__pyx_t_18, __pyx_t_19, __pyx_t_20);
        __Pyx_XGIVEREF(__pyx_t_15);
        __Pyx_XGIVEREF(__pyx_t_16);
        __Pyx_XGIVEREF(__pyx_t_17);
        __Pyx_ErrRestore(__pyx_t_15, __pyx_t_16, __pyx_t_17);
        __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0; __pyx_t_19 = 0; __pyx_t_20 = 0;
        __pyx_lineno = __pyx_t_12; __pyx_clineno = __pyx_t_13; __pyx_filename = __pyx_t_14;
        goto __pyx_L1_error;
        __pyx_L15_error:;
        __Pyx_XGIVEREF(__pyx_t_18);
        __Pyx_XGIVEREF(__pyx_t_19);
        __Pyx_XGIVEREF(__pyx_t_20);
        __Pyx_ExceptionReset(__pyx_t_18, __pyx_t_19, __pyx_t_20);
        __Pyx_XDECREF(__pyx_t_15); __pyx_t_15 = 0;
        __Pyx_XDECREF(__pyx_t_16); __pyx_t_16 = 0;
        __Pyx_XDECREF(__pyx_t_17); __pyx_t_17 = 0;
        __pyx_t_18 = 0; __pyx_t_19 = 0; __pyx_t_20 = 0;
        goto __pyx_L1_error;
      }
      __pyx_L11:;
    }

    /* "cupy/cuda/cufft.pyx":316
 *         finally:
 *             runtime.setDevice(prev_device)
 *         assert gpu == buf.device_id             # <<<<<<<<<<<<<<
 *         xtArr_buffer.append(buf)
 *         xtArr_desc.GPUs[i] = gpu
*/
    #ifndef CYTHON_WITHOUT_ASSERTIONS
    if (unlikely(__pyx_assertions_enabled())) {
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_buf, __pyx_mstate_global->__pyx_n_u_device_id); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 316, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_10 = PyObject_RichCompare(__pyx_v_gpu, __pyx_t_1, Py_EQ); __Pyx_XGOTREF(__pyx_t_10); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 316, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_10); if (unlikely((__pyx_t_3 < 0))) __PYX_ERR(0, 316, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      if (unlikely(!__pyx_t_3)) {
        __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
        __PYX_ERR(0, 316, __pyx_L1_error)
      }
    }
    #else
    if ((1)); else __PYX_ERR(0, 316, __pyx_L1_error)
    #endif

    /* "cupy/cuda/cufft.pyx":317
 *             runtime.setDevice(prev_device)
 *         assert gpu == buf.device_id
 *         xtArr_buffer.append(buf)             # <<<<<<<<<<<<<<
 *         xtArr_desc.GPUs[i] = gpu
 *         xtArr_desc.data[i] = <void*><intptr_t>(buf.ptr)
*/
    __pyx_t_21 = __Pyx_PyList_Append(__pyx_v_xtArr_buffer, __pyx_v_buf); if (unlikely(__pyx_t_21 == ((int)-1))) __PYX_ERR(0, 317, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":318
 *         assert gpu == buf.device_id
 *         xtArr_buffer.append(buf)
 *         xtArr_desc.GPUs[i] = gpu             # <<<<<<<<<<<<<<
 *         xtArr_desc.data[i] = <void*><intptr_t>(buf.ptr)
 *         xtArr_desc.size[i] = size
*/
    __pyx_t_13 = __Pyx_PyLong_As_int(__pyx_v_gpu); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 318, __pyx_L1_error)
    (__pyx_v_xtArr_desc->GPUs[__pyx_v_i]) = __pyx_t_13;

    /* "cupy/cuda/cufft.pyx":319
 *         xtArr_buffer.append(buf)
 *         xtArr_desc.GPUs[i] = gpu
 *         xtArr_desc.data[i] = <void*><intptr_t>(buf.ptr)             # <<<<<<<<<<<<<<
 *         xtArr_desc.size[i] = size
 * 
*/
    __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_buf, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 319, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_22 = PyLong_AsSsize_t(__pyx_t_10); if (unlikely((__pyx_t_22 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 319, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    (__pyx_v_xtArr_desc->data[__pyx_v_i]) = ((void *)((intptr_t)__pyx_t_22));

    /* "cupy/cuda/cufft.pyx":320
 *         xtArr_desc.GPUs[i] = gpu
 *         xtArr_desc.data[i] = <void*><intptr_t>(buf.ptr)
 *         xtArr_desc.size[i] = size             # <<<<<<<<<<<<<<
 * 
 *     xtArr.descriptor = xtArr_desc
*/
    (__pyx_v_xtArr_desc->size[__pyx_v_i]) = __pyx_v_size;

    /* "cupy/cuda/cufft.pyx":309
 * 
 *     xtArr_desc.nGPUs = nGPUs
 *     for i, (gpu, size) in enumerate(zip(gpus, sizes)):             # <<<<<<<<<<<<<<
 *         prev_device = runtime.getDevice()
 *         runtime.setDevice(gpu)
*/
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

  /* "cupy/cuda/cufft.pyx":322
 *         xtArr_desc.size[i] = size
 * 
 *     xtArr.descriptor = xtArr_desc             # <<<<<<<<<<<<<<
 *     xtArr.subFormat = fmt
 * 
*/
  __pyx_v_xtArr->descriptor = __pyx_v_xtArr_desc;

  /* "cupy/cuda/cufft.pyx":323
 * 
 *     xtArr.descriptor = xtArr_desc
 *     xtArr.subFormat = fmt             # <<<<<<<<<<<<<<
 * 
 *     return <intptr_t>xtArr, xtArr_buffer
*/
  __pyx_v_xtArr->subFormat = __pyx_v_fmt;

  /* "cupy/cuda/cufft.pyx":325
 *     xtArr.subFormat = fmt
 * 
 *     return <intptr_t>xtArr, xtArr_buffer             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_6 = PyLong_FromSsize_t(((intptr_t)__pyx_v_xtArr)); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 325, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_t_10 = PyTuple_New(2); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 325, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_GIVEREF(__pyx_t_6);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_10, 0, __pyx_t_6) != (0)) __PYX_ERR(0, 325, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_xtArr_buffer);
  __Pyx_GIVEREF(__pyx_v_xtArr_buffer);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_10, 1, __pyx_v_xtArr_buffer) != (0)) __PYX_ERR(0, 325, __pyx_L1_error);
  __pyx_t_6 = 0;
  __pyx_r = __pyx_t_10;
  __pyx_t_10 = 0;
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":294
 * # We need to manage the buffers ourselves in order to 1. avoid excessive,
 * # unnecessary memory usage, and 2. use CuPy's memory pool.
 * cdef _XtMalloc(list gpus, list sizes, XtSubFormat fmt):             # <<<<<<<<<<<<<<
 *     cdef XtArrayDesc* xtArr_desc
 *     cdef XtArray* xtArr
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("cupy.cuda.cufft._XtMalloc", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_xtArr_buffer);
  __Pyx_XDECREF(__pyx_v_gpu);
  __Pyx_XDECREF(__pyx_v_prev_device);
  __Pyx_XDECREF(__pyx_v_buf);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":331
 * # We only free the C structs. The underlying GPU buffers are deallocated when
 * # going out of scope.
 * cdef _XtFree(intptr_t ptr):             # <<<<<<<<<<<<<<
 *     cdef XtArray* xtArr = <XtArray*>ptr
 *     cdef XtArrayDesc* xtArr_desc = xtArr.descriptor
*/

static PyObject *__pyx_f_4cupy_4cuda_5cufft__XtFree(intptr_t __pyx_v_ptr) {
  cudaLibXtDesc *__pyx_v_xtArr;
  cudaXtDesc *__pyx_v_xtArr_desc;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  cudaXtDesc *__pyx_t_1;
  __Pyx_RefNannySetupContext("_XtFree", 0);

  /* "cupy/cuda/cufft.pyx":332
 * # going out of scope.
 * cdef _XtFree(intptr_t ptr):
 *     cdef XtArray* xtArr = <XtArray*>ptr             # <<<<<<<<<<<<<<
 *     cdef XtArrayDesc* xtArr_desc = xtArr.descriptor
 *     PyMem_Free(xtArr_desc)
*/
  __pyx_v_xtArr = ((cudaLibXtDesc *)__pyx_v_ptr);

  /* "cupy/cuda/cufft.pyx":333
 * cdef _XtFree(intptr_t ptr):
 *     cdef XtArray* xtArr = <XtArray*>ptr
 *     cdef XtArrayDesc* xtArr_desc = xtArr.descriptor             # <<<<<<<<<<<<<<
 *     PyMem_Free(xtArr_desc)
 *     PyMem_Free(xtArr)
*/
  __pyx_t_1 = __pyx_v_xtArr->descriptor;
  __pyx_v_xtArr_desc = __pyx_t_1;

  /* "cupy/cuda/cufft.pyx":334
 *     cdef XtArray* xtArr = <XtArray*>ptr
 *     cdef XtArrayDesc* xtArr_desc = xtArr.descriptor
 *     PyMem_Free(xtArr_desc)             # <<<<<<<<<<<<<<
 *     PyMem_Free(xtArr)
 * 
*/
  PyMem_Free(__pyx_v_xtArr_desc);

  /* "cupy/cuda/cufft.pyx":335
 *     cdef XtArrayDesc* xtArr_desc = xtArr.descriptor
 *     PyMem_Free(xtArr_desc)
 *     PyMem_Free(xtArr)             # <<<<<<<<<<<<<<
 * 
 * 
*/
  PyMem_Free(__pyx_v_xtArr);

  /* "cupy/cuda/cufft.pyx":331
 * # We only free the C structs. The underlying GPU buffers are deallocated when
 * # going out of scope.
 * cdef _XtFree(intptr_t ptr):             # <<<<<<<<<<<<<<
 *     cdef XtArray* xtArr = <XtArray*>ptr
 *     cdef XtArrayDesc* xtArr_desc = xtArr.descriptor
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":339
 * 
 * cdef class Plan1d:
 *     def __init__(self, int nx, int fft_type, int batch, *,             # <<<<<<<<<<<<<<
 *                  devices=None, out=None, intptr_t prealloc_plan=0):
 *         cdef Handle plan
*/

/* Python wrapper */
static int __pyx_pw_4cupy_4cuda_5cufft_6Plan1d_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_4cupy_4cuda_5cufft_6Plan1d_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  int __pyx_v_nx;
  int __pyx_v_fft_type;
  int __pyx_v_batch;
  PyObject *__pyx_v_devices = 0;
  PyObject *__pyx_v_out = 0;
  intptr_t __pyx_v_prealloc_plan;
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[6] = {0,0,0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return -1;
  #endif
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_nx,&__pyx_mstate_global->__pyx_n_u_fft_type,&__pyx_mstate_global->__pyx_n_u_batch,&__pyx_mstate_global->__pyx_n_u_devices,&__pyx_mstate_global->__pyx_n_u_out,&__pyx_mstate_global->__pyx_n_u_prealloc_plan,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_VARARGS(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 339, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  3:
        values[2] = __Pyx_ArgRef_VARARGS(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 339, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_VARARGS(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 339, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_VARARGS(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 339, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "__init__", 0) < (0)) __PYX_ERR(0, 339, __pyx_L3_error)

      /* "cupy/cuda/cufft.pyx":340
 * cdef class Plan1d:
 *     def __init__(self, int nx, int fft_type, int batch, *,
 *                  devices=None, out=None, intptr_t prealloc_plan=0):             # <<<<<<<<<<<<<<
 *         cdef Handle plan
 *         cdef bint use_multi_gpus = 0 if devices is None else 1
*/
      if (!values[3]) values[3] = __Pyx_NewRef(((PyObject *)Py_None));
      if (!values[4]) values[4] = __Pyx_NewRef(((PyObject *)Py_None));
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("__init__", 1, 3, 3, i); __PYX_ERR(0, 339, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_VARARGS(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 339, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_VARARGS(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 339, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_VARARGS(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 339, __pyx_L3_error)
      if (!values[3]) values[3] = __Pyx_NewRef(((PyObject *)Py_None));
      if (!values[4]) values[4] = __Pyx_NewRef(((PyObject *)Py_None));
    }
    __pyx_v_nx = __Pyx_PyLong_As_int(values[0]); if (unlikely((__pyx_v_nx == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 339, __pyx_L3_error)
    __pyx_v_fft_type = __Pyx_PyLong_As_int(values[1]); if (unlikely((__pyx_v_fft_type == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 339, __pyx_L3_error)
    __pyx_v_batch = __Pyx_PyLong_As_int(values[2]); if (unlikely((__pyx_v_batch == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 339, __pyx_L3_error)
    __pyx_v_devices = values[3];
    __pyx_v_out = values[4];
    if (values[5]) {
      __pyx_v_prealloc_plan = PyLong_AsSsize_t(values[5]); if (unlikely((__pyx_v_prealloc_plan == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 340, __pyx_L3_error)
    } else {
      __pyx_v_prealloc_plan = ((intptr_t)0);
    }
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 1, 3, 3, __pyx_nargs); __PYX_ERR(0, 339, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d___init__(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self), __pyx_v_nx, __pyx_v_fft_type, __pyx_v_batch, __pyx_v_devices, __pyx_v_out, __pyx_v_prealloc_plan);

  /* "cupy/cuda/cufft.pyx":339
 * 
 * cdef class Plan1d:
 *     def __init__(self, int nx, int fft_type, int batch, *,             # <<<<<<<<<<<<<<
 *                  devices=None, out=None, intptr_t prealloc_plan=0):
 *         cdef Handle plan
*/

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_4cupy_4cuda_5cufft_6Plan1d___init__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, int __pyx_v_nx, int __pyx_v_fft_type, int __pyx_v_batch, PyObject *__pyx_v_devices, PyObject *__pyx_v_out, intptr_t __pyx_v_prealloc_plan) {
  cufftHandle __pyx_v_plan;
  int __pyx_v_use_multi_gpus;
  int __pyx_v_result;
  PyTypeObject *__pyx_7genexpr__pyx_v_i = NULL;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  size_t __pyx_t_7;
  Py_ssize_t __pyx_t_8;
  PyObject *(*__pyx_t_9)(PyObject *);
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "cupy/cuda/cufft.pyx":342
 *                  devices=None, out=None, intptr_t prealloc_plan=0):
 *         cdef Handle plan
 *         cdef bint use_multi_gpus = 0 if devices is None else 1             # <<<<<<<<<<<<<<
 *         cdef int result
 * 
*/
  __pyx_t_2 = (__pyx_v_devices == Py_None);
  if (__pyx_t_2) {
    __pyx_t_1 = 0;
  } else {
    __pyx_t_1 = 1;
  }
  __pyx_v_use_multi_gpus = __pyx_t_1;

  /* "cupy/cuda/cufft.pyx":345
 *         cdef int result
 * 
 *         self.handle = <intptr_t>0             # <<<<<<<<<<<<<<
 *         self.xtArr = <intptr_t>0  # pointer to metadata for multi-GPU buffer
 *         self.xtArr_buffer = None  # actual multi-GPU intermediate buffer
*/
  __pyx_v_self->handle = ((intptr_t)0);

  /* "cupy/cuda/cufft.pyx":346
 * 
 *         self.handle = <intptr_t>0
 *         self.xtArr = <intptr_t>0  # pointer to metadata for multi-GPU buffer             # <<<<<<<<<<<<<<
 *         self.xtArr_buffer = None  # actual multi-GPU intermediate buffer
 * 
*/
  __pyx_v_self->xtArr = ((intptr_t)0);

  /* "cupy/cuda/cufft.pyx":347
 *         self.handle = <intptr_t>0
 *         self.xtArr = <intptr_t>0  # pointer to metadata for multi-GPU buffer
 *         self.xtArr_buffer = None  # actual multi-GPU intermediate buffer             # <<<<<<<<<<<<<<
 * 
 *         if prealloc_plan:
*/
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->xtArr_buffer);
  __Pyx_DECREF(__pyx_v_self->xtArr_buffer);
  __pyx_v_self->xtArr_buffer = ((PyObject*)Py_None);

  /* "cupy/cuda/cufft.pyx":349
 *         self.xtArr_buffer = None  # actual multi-GPU intermediate buffer
 * 
 *         if prealloc_plan:             # <<<<<<<<<<<<<<
 *             plan = <Handle>prealloc_plan
 *         else:
*/
  __pyx_t_1 = (__pyx_v_prealloc_plan != 0);
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":350
 * 
 *         if prealloc_plan:
 *             plan = <Handle>prealloc_plan             # <<<<<<<<<<<<<<
 *         else:
 *             with nogil:
*/
    __pyx_v_plan = ((cufftHandle)__pyx_v_prealloc_plan);

    /* "cupy/cuda/cufft.pyx":349
 *         self.xtArr_buffer = None  # actual multi-GPU intermediate buffer
 * 
 *         if prealloc_plan:             # <<<<<<<<<<<<<<
 *             plan = <Handle>prealloc_plan
 *         else:
*/
    goto __pyx_L3;
  }

  /* "cupy/cuda/cufft.pyx":352
 *             plan = <Handle>prealloc_plan
 *         else:
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftCreate(&plan)
 *                 if result == 0:
*/
  /*else*/ {
    {
        PyThreadState *_save;
        _save = NULL;
        Py_UNBLOCK_THREADS
        __Pyx_FastGIL_Remember();
        /*try:*/ {

          /* "cupy/cuda/cufft.pyx":353
 *         else:
 *             with nogil:
 *                 result = cufftCreate(&plan)             # <<<<<<<<<<<<<<
 *                 if result == 0:
 *                     result = cufftSetAutoAllocation(plan, 0)
*/
          __pyx_v_result = cufftCreate((&__pyx_v_plan));

          /* "cupy/cuda/cufft.pyx":354
 *             with nogil:
 *                 result = cufftCreate(&plan)
 *                 if result == 0:             # <<<<<<<<<<<<<<
 *                     result = cufftSetAutoAllocation(plan, 0)
 *             check_result(result)
*/
          __pyx_t_1 = (__pyx_v_result == 0);
          if (__pyx_t_1) {

            /* "cupy/cuda/cufft.pyx":355
 *                 result = cufftCreate(&plan)
 *                 if result == 0:
 *                     result = cufftSetAutoAllocation(plan, 0)             # <<<<<<<<<<<<<<
 *             check_result(result)
 * 
*/
            __pyx_v_result = cufftSetAutoAllocation(__pyx_v_plan, 0);

            /* "cupy/cuda/cufft.pyx":354
 *             with nogil:
 *                 result = cufftCreate(&plan)
 *                 if result == 0:             # <<<<<<<<<<<<<<
 *                     result = cufftSetAutoAllocation(plan, 0)
 *             check_result(result)
*/
          }
        }

        /* "cupy/cuda/cufft.pyx":352
 *             plan = <Handle>prealloc_plan
 *         else:
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftCreate(&plan)
 *                 if result == 0:
*/
        /*finally:*/ {
          /*normal exit:*/{
            __Pyx_FastGIL_Forget();
            Py_BLOCK_THREADS
            goto __pyx_L6;
          }
          __pyx_L6:;
        }
    }

    /* "cupy/cuda/cufft.pyx":356
 *                 if result == 0:
 *                     result = cufftSetAutoAllocation(plan, 0)
 *             check_result(result)             # <<<<<<<<<<<<<<
 * 
 *         self.handle = <intptr_t>plan
*/
    __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 356, __pyx_L1_error)
  }
  __pyx_L3:;

  /* "cupy/cuda/cufft.pyx":358
 *             check_result(result)
 * 
 *         self.handle = <intptr_t>plan             # <<<<<<<<<<<<<<
 *         self.work_area = None
 *         self.gpus = None
*/
  __pyx_v_self->handle = ((intptr_t)__pyx_v_plan);

  /* "cupy/cuda/cufft.pyx":359
 * 
 *         self.handle = <intptr_t>plan
 *         self.work_area = None             # <<<<<<<<<<<<<<
 *         self.gpus = None
 * 
*/
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->work_area);
  __Pyx_DECREF(__pyx_v_self->work_area);
  __pyx_v_self->work_area = Py_None;

  /* "cupy/cuda/cufft.pyx":360
 *         self.handle = <intptr_t>plan
 *         self.work_area = None
 *         self.gpus = None             # <<<<<<<<<<<<<<
 * 
 *         self.gather_streams = None
*/
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->gpus);
  __Pyx_DECREF(__pyx_v_self->gpus);
  __pyx_v_self->gpus = ((PyObject*)Py_None);

  /* "cupy/cuda/cufft.pyx":362
 *         self.gpus = None
 * 
 *         self.gather_streams = None             # <<<<<<<<<<<<<<
 *         self.gather_events = None
 *         self.scatter_streams = None
*/
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->gather_streams);
  __Pyx_DECREF(__pyx_v_self->gather_streams);
  __pyx_v_self->gather_streams = ((PyObject*)Py_None);

  /* "cupy/cuda/cufft.pyx":363
 * 
 *         self.gather_streams = None
 *         self.gather_events = None             # <<<<<<<<<<<<<<
 *         self.scatter_streams = None
 *         self.scatter_events = None
*/
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->gather_events);
  __Pyx_DECREF(__pyx_v_self->gather_events);
  __pyx_v_self->gather_events = ((PyObject*)Py_None);

  /* "cupy/cuda/cufft.pyx":364
 *         self.gather_streams = None
 *         self.gather_events = None
 *         self.scatter_streams = None             # <<<<<<<<<<<<<<
 *         self.scatter_events = None
 * 
*/
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->scatter_streams);
  __Pyx_DECREF(__pyx_v_self->scatter_streams);
  __pyx_v_self->scatter_streams = ((PyObject*)Py_None);

  /* "cupy/cuda/cufft.pyx":365
 *         self.gather_events = None
 *         self.scatter_streams = None
 *         self.scatter_events = None             # <<<<<<<<<<<<<<
 * 
 *         if batch != 0:
*/
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->scatter_events);
  __Pyx_DECREF(__pyx_v_self->scatter_events);
  __pyx_v_self->scatter_events = ((PyObject*)Py_None);

  /* "cupy/cuda/cufft.pyx":367
 *         self.scatter_events = None
 * 
 *         if batch != 0:             # <<<<<<<<<<<<<<
 *             # set plan, work_area, gpus, streams, and events
 *             if not use_multi_gpus:
*/
  __pyx_t_1 = (__pyx_v_batch != 0);
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":369
 *         if batch != 0:
 *             # set plan, work_area, gpus, streams, and events
 *             if not use_multi_gpus:             # <<<<<<<<<<<<<<
 *                 self._single_gpu_get_plan(plan, nx, fft_type, batch)
 *             else:
*/
    __pyx_t_1 = (!__pyx_v_use_multi_gpus);
    if (__pyx_t_1) {

      /* "cupy/cuda/cufft.pyx":370
 *             # set plan, work_area, gpus, streams, and events
 *             if not use_multi_gpus:
 *                 self._single_gpu_get_plan(plan, nx, fft_type, batch)             # <<<<<<<<<<<<<<
 *             else:
 *                 self._multi_gpu_get_plan(
*/
      ((struct __pyx_vtabstruct_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self->__pyx_vtab)->_single_gpu_get_plan(__pyx_v_self, __pyx_v_plan, __pyx_v_nx, __pyx_v_fft_type, __pyx_v_batch); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 370, __pyx_L1_error)

      /* "cupy/cuda/cufft.pyx":369
 *         if batch != 0:
 *             # set plan, work_area, gpus, streams, and events
 *             if not use_multi_gpus:             # <<<<<<<<<<<<<<
 *                 self._single_gpu_get_plan(plan, nx, fft_type, batch)
 *             else:
*/
      goto __pyx_L9;
    }

    /* "cupy/cuda/cufft.pyx":372
 *                 self._single_gpu_get_plan(plan, nx, fft_type, batch)
 *             else:
 *                 self._multi_gpu_get_plan(             # <<<<<<<<<<<<<<
 *                     plan, nx, fft_type, batch, devices, out)
 *         else:
*/
    /*else*/ {

      /* "cupy/cuda/cufft.pyx":373
 *             else:
 *                 self._multi_gpu_get_plan(
 *                     plan, nx, fft_type, batch, devices, out)             # <<<<<<<<<<<<<<
 *         else:
 *             if use_multi_gpus:
*/
      ((struct __pyx_vtabstruct_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self->__pyx_vtab)->_multi_gpu_get_plan(__pyx_v_self, __pyx_v_plan, __pyx_v_nx, __pyx_v_fft_type, __pyx_v_batch, __pyx_v_devices, __pyx_v_out); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 372, __pyx_L1_error)
    }
    __pyx_L9:;

    /* "cupy/cuda/cufft.pyx":367
 *         self.scatter_events = None
 * 
 *         if batch != 0:             # <<<<<<<<<<<<<<
 *             # set plan, work_area, gpus, streams, and events
 *             if not use_multi_gpus:
*/
    goto __pyx_L8;
  }

  /* "cupy/cuda/cufft.pyx":375
 *                     plan, nx, fft_type, batch, devices, out)
 *         else:
 *             if use_multi_gpus:             # <<<<<<<<<<<<<<
 *                 # multi-GPU FFT cannot transform 0-size arrays, and attempting
 *                 # to create such a plan will error out, but we still need this
*/
  /*else*/ {
    if (__pyx_v_use_multi_gpus) {

      /* "cupy/cuda/cufft.pyx":379
 *                 # to create such a plan will error out, but we still need this
 *                 # for bookkeeping
 *                 if isinstance(devices, (tuple, list)):             # <<<<<<<<<<<<<<
 *                     self.gpus = list(devices)
 *                 elif isinstance(devices, int) and devices > 0:
*/
      __pyx_t_2 = PyTuple_Check(__pyx_v_devices); 
      if (!__pyx_t_2) {
      } else {
        __pyx_t_1 = __pyx_t_2;
        goto __pyx_L12_bool_binop_done;
      }
      __pyx_t_2 = PyList_Check(__pyx_v_devices); 
      __pyx_t_1 = __pyx_t_2;
      __pyx_L12_bool_binop_done:;
      if (__pyx_t_1) {

        /* "cupy/cuda/cufft.pyx":380
 *                 # for bookkeeping
 *                 if isinstance(devices, (tuple, list)):
 *                     self.gpus = list(devices)             # <<<<<<<<<<<<<<
 *                 elif isinstance(devices, int) and devices > 0:
 *                     self.gpus = [i for i in range(int)]
*/
        __pyx_t_3 = PySequence_List(__pyx_v_devices); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 380, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_GIVEREF(__pyx_t_3);
        __Pyx_GOTREF(__pyx_v_self->gpus);
        __Pyx_DECREF(__pyx_v_self->gpus);
        __pyx_v_self->gpus = ((PyObject*)__pyx_t_3);
        __pyx_t_3 = 0;

        /* "cupy/cuda/cufft.pyx":379
 *                 # to create such a plan will error out, but we still need this
 *                 # for bookkeeping
 *                 if isinstance(devices, (tuple, list)):             # <<<<<<<<<<<<<<
 *                     self.gpus = list(devices)
 *                 elif isinstance(devices, int) and devices > 0:
*/
        goto __pyx_L11;
      }

      /* "cupy/cuda/cufft.pyx":381
 *                 if isinstance(devices, (tuple, list)):
 *                     self.gpus = list(devices)
 *                 elif isinstance(devices, int) and devices > 0:             # <<<<<<<<<<<<<<
 *                     self.gpus = [i for i in range(int)]
 *                 else:
*/
      __pyx_t_2 = PyLong_Check(__pyx_v_devices); 
      if (__pyx_t_2) {
      } else {
        __pyx_t_1 = __pyx_t_2;
        goto __pyx_L14_bool_binop_done;
      }
      __pyx_t_3 = PyObject_RichCompare(__pyx_v_devices, __pyx_mstate_global->__pyx_int_0, Py_GT); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 381, __pyx_L1_error)
      __pyx_t_2 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_2 < 0))) __PYX_ERR(0, 381, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_1 = __pyx_t_2;
      __pyx_L14_bool_binop_done:;
      if (likely(__pyx_t_1)) {

        /* "cupy/cuda/cufft.pyx":382
 *                     self.gpus = list(devices)
 *                 elif isinstance(devices, int) and devices > 0:
 *                     self.gpus = [i for i in range(int)]             # <<<<<<<<<<<<<<
 *                 else:
 *                     raise ValueError
*/
        { /* enter inner scope */
          __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 382, __pyx_L18_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_5 = NULL;
          __Pyx_INCREF(__pyx_builtin_range);
          __pyx_t_6 = __pyx_builtin_range; 
          __pyx_t_7 = 1;
          {
            PyObject *__pyx_callargs[2] = {__pyx_t_5, ((PyObject *)(&PyLong_Type))};
            __pyx_t_4 = __Pyx_PyObject_FastCall(__pyx_t_6, __pyx_callargs+__pyx_t_7, (2-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
            __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
            __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
            if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 382, __pyx_L18_error)
            __Pyx_GOTREF(__pyx_t_4);
          }
          if (likely(PyList_CheckExact(__pyx_t_4)) || PyTuple_CheckExact(__pyx_t_4)) {
            __pyx_t_6 = __pyx_t_4; __Pyx_INCREF(__pyx_t_6);
            __pyx_t_8 = 0;
            __pyx_t_9 = NULL;
          } else {
            __pyx_t_8 = -1; __pyx_t_6 = PyObject_GetIter(__pyx_t_4); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 382, __pyx_L18_error)
            __Pyx_GOTREF(__pyx_t_6);
            __pyx_t_9 = (CYTHON_COMPILING_IN_LIMITED_API) ? PyIter_Next : __Pyx_PyObject_GetIterNextFunc(__pyx_t_6); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 382, __pyx_L18_error)
          }
          __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
          for (;;) {
            if (likely(!__pyx_t_9)) {
              if (likely(PyList_CheckExact(__pyx_t_6))) {
                {
                  Py_ssize_t __pyx_temp = __Pyx_PyList_GET_SIZE(__pyx_t_6);
                  #if !CYTHON_ASSUME_SAFE_SIZE
                  if (unlikely((__pyx_temp < 0))) __PYX_ERR(0, 382, __pyx_L18_error)
                  #endif
                  if (__pyx_t_8 >= __pyx_temp) break;
                }
                __pyx_t_4 = __Pyx_PyList_GetItemRef(__pyx_t_6, __pyx_t_8);
                ++__pyx_t_8;
              } else {
                {
                  Py_ssize_t __pyx_temp = __Pyx_PyTuple_GET_SIZE(__pyx_t_6);
                  #if !CYTHON_ASSUME_SAFE_SIZE
                  if (unlikely((__pyx_temp < 0))) __PYX_ERR(0, 382, __pyx_L18_error)
                  #endif
                  if (__pyx_t_8 >= __pyx_temp) break;
                }
                #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
                __pyx_t_4 = __Pyx_NewRef(PyTuple_GET_ITEM(__pyx_t_6, __pyx_t_8));
                #else
                __pyx_t_4 = __Pyx_PySequence_ITEM(__pyx_t_6, __pyx_t_8);
                #endif
                ++__pyx_t_8;
              }
              if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 382, __pyx_L18_error)
            } else {
              __pyx_t_4 = __pyx_t_9(__pyx_t_6);
              if (unlikely(!__pyx_t_4)) {
                PyObject* exc_type = PyErr_Occurred();
                if (exc_type) {
                  if (unlikely(!__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) __PYX_ERR(0, 382, __pyx_L18_error)
                  PyErr_Clear();
                }
                break;
              }
            }
            __Pyx_GOTREF(__pyx_t_4);
            if (!(likely(PyType_CheckExact(__pyx_t_4))||((__pyx_t_4) == Py_None) || __Pyx_RaiseUnexpectedTypeError("type", __pyx_t_4))) __PYX_ERR(0, 382, __pyx_L18_error)
            __Pyx_XDECREF_SET(__pyx_7genexpr__pyx_v_i, ((PyTypeObject*)__pyx_t_4));
            __pyx_t_4 = 0;
            if (unlikely(__Pyx_ListComp_Append(__pyx_t_3, (PyObject*)__pyx_7genexpr__pyx_v_i))) __PYX_ERR(0, 382, __pyx_L18_error)
          }
          __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
          __Pyx_XDECREF((PyObject *)__pyx_7genexpr__pyx_v_i); __pyx_7genexpr__pyx_v_i = 0;
          goto __pyx_L22_exit_scope;
          __pyx_L18_error:;
          __Pyx_XDECREF((PyObject *)__pyx_7genexpr__pyx_v_i); __pyx_7genexpr__pyx_v_i = 0;
          goto __pyx_L1_error;
          __pyx_L22_exit_scope:;
        } /* exit inner scope */
        __Pyx_GIVEREF(__pyx_t_3);
        __Pyx_GOTREF(__pyx_v_self->gpus);
        __Pyx_DECREF(__pyx_v_self->gpus);
        __pyx_v_self->gpus = ((PyObject*)__pyx_t_3);
        __pyx_t_3 = 0;

        /* "cupy/cuda/cufft.pyx":381
 *                 if isinstance(devices, (tuple, list)):
 *                     self.gpus = list(devices)
 *                 elif isinstance(devices, int) and devices > 0:             # <<<<<<<<<<<<<<
 *                     self.gpus = [i for i in range(int)]
 *                 else:
*/
        goto __pyx_L11;
      }

      /* "cupy/cuda/cufft.pyx":384
 *                     self.gpus = [i for i in range(int)]
 *                 else:
 *                     raise ValueError             # <<<<<<<<<<<<<<
 * 
 *         self.nx = nx
*/
      /*else*/ {
        __Pyx_Raise(__pyx_builtin_ValueError, 0, 0, 0);
        __PYX_ERR(0, 384, __pyx_L1_error)
      }
      __pyx_L11:;

      /* "cupy/cuda/cufft.pyx":375
 *                     plan, nx, fft_type, batch, devices, out)
 *         else:
 *             if use_multi_gpus:             # <<<<<<<<<<<<<<
 *                 # multi-GPU FFT cannot transform 0-size arrays, and attempting
 *                 # to create such a plan will error out, but we still need this
*/
    }
  }
  __pyx_L8:;

  /* "cupy/cuda/cufft.pyx":386
 *                     raise ValueError
 * 
 *         self.nx = nx             # <<<<<<<<<<<<<<
 *         self.fft_type = <Type>fft_type
 *         self.batch = batch
*/
  __pyx_v_self->nx = __pyx_v_nx;

  /* "cupy/cuda/cufft.pyx":387
 * 
 *         self.nx = nx
 *         self.fft_type = <Type>fft_type             # <<<<<<<<<<<<<<
 *         self.batch = batch
 *         self.batch_share = None
*/
  __pyx_v_self->fft_type = ((cufftType_t)__pyx_v_fft_type);

  /* "cupy/cuda/cufft.pyx":388
 *         self.nx = nx
 *         self.fft_type = <Type>fft_type
 *         self.batch = batch             # <<<<<<<<<<<<<<
 *         self.batch_share = None
 * 
*/
  __pyx_v_self->batch = __pyx_v_batch;

  /* "cupy/cuda/cufft.pyx":389
 *         self.fft_type = <Type>fft_type
 *         self.batch = batch
 *         self.batch_share = None             # <<<<<<<<<<<<<<
 * 
 *     cdef void _single_gpu_get_plan(self, Handle plan, int nx, int fft_type,
*/
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->batch_share);
  __Pyx_DECREF(__pyx_v_self->batch_share);
  __pyx_v_self->batch_share = ((PyObject*)Py_None);

  /* "cupy/cuda/cufft.pyx":339
 * 
 * cdef class Plan1d:
 *     def __init__(self, int nx, int fft_type, int batch, *,             # <<<<<<<<<<<<<<
 *                  devices=None, out=None, intptr_t prealloc_plan=0):
 *         cdef Handle plan
*/

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF((PyObject *)__pyx_7genexpr__pyx_v_i);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":391
 *         self.batch_share = None
 * 
 *     cdef void _single_gpu_get_plan(self, Handle plan, int nx, int fft_type,             # <<<<<<<<<<<<<<
 *                                    int batch) except*:
 *         cdef int result
*/

static void __pyx_f_4cupy_4cuda_5cufft_6Plan1d__single_gpu_get_plan(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, cufftHandle __pyx_v_plan, int __pyx_v_nx, int __pyx_v_fft_type, int __pyx_v_batch) {
  int __pyx_v_result;
  size_t __pyx_v_work_size;
  intptr_t __pyx_v_ptr;
  PyObject *__pyx_v_work_area = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  size_t __pyx_t_8;
  intptr_t __pyx_t_9;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_single_gpu_get_plan", 0);

  /* "cupy/cuda/cufft.pyx":397
 *         cdef intptr_t ptr
 * 
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,
 *                                      &work_size)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":398
 * 
 *         with nogil:
 *             result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,             # <<<<<<<<<<<<<<
 *                                      &work_size)
 * 
*/
        __pyx_v_result = cufftMakePlan1d(__pyx_v_plan, __pyx_v_nx, ((cufftType_t)__pyx_v_fft_type), __pyx_v_batch, (&__pyx_v_work_size));
      }

      /* "cupy/cuda/cufft.pyx":397
 *         cdef intptr_t ptr
 * 
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,
 *                                      &work_size)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "cupy/cuda/cufft.pyx":403
 *         # cufftMakePlan1d uses large memory when nx has large divisor.
 *         # See https://github.com/cupy/cupy/issues/1063
 *         if result == 2:             # <<<<<<<<<<<<<<
 *             cupy.get_default_memory_pool().free_all_blocks()
 *             with nogil:
*/
  __pyx_t_1 = (__pyx_v_result == 2);
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":404
 *         # See https://github.com/cupy/cupy/issues/1063
 *         if result == 2:
 *             cupy.get_default_memory_pool().free_all_blocks()             # <<<<<<<<<<<<<<
 *             with nogil:
 *                 result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,
*/
    __pyx_t_5 = NULL;
    __Pyx_GetModuleGlobalName(__pyx_t_6, __pyx_mstate_global->__pyx_n_u_cupy); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 404, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_6, __pyx_mstate_global->__pyx_n_u_get_default_memory_pool); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 404, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_8 = 1;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_7);
      assert(__pyx_t_5);
      PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_7);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(__pyx__function);
      __Pyx_DECREF_SET(__pyx_t_7, __pyx__function);
      __pyx_t_8 = 0;
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_5, NULL};
      __pyx_t_4 = __Pyx_PyObject_FastCall(__pyx_t_7, __pyx_callargs+__pyx_t_8, (1-__pyx_t_8) | (__pyx_t_8*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 404, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
    }
    __pyx_t_3 = __pyx_t_4;
    __Pyx_INCREF(__pyx_t_3);
    __pyx_t_8 = 0;
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_3, NULL};
      __pyx_t_2 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_free_all_blocks, __pyx_callargs+__pyx_t_8, (1-__pyx_t_8) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 404, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "cupy/cuda/cufft.pyx":405
 *         if result == 2:
 *             cupy.get_default_memory_pool().free_all_blocks()
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,
 *                                          &work_size)
*/
    {
        PyThreadState *_save;
        _save = NULL;
        Py_UNBLOCK_THREADS
        __Pyx_FastGIL_Remember();
        /*try:*/ {

          /* "cupy/cuda/cufft.pyx":406
 *             cupy.get_default_memory_pool().free_all_blocks()
 *             with nogil:
 *                 result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,             # <<<<<<<<<<<<<<
 *                                          &work_size)
 *         check_result(result)
*/
          __pyx_v_result = cufftMakePlan1d(__pyx_v_plan, __pyx_v_nx, ((cufftType_t)__pyx_v_fft_type), __pyx_v_batch, (&__pyx_v_work_size));
        }

        /* "cupy/cuda/cufft.pyx":405
 *         if result == 2:
 *             cupy.get_default_memory_pool().free_all_blocks()
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,
 *                                          &work_size)
*/
        /*finally:*/ {
          /*normal exit:*/{
            __Pyx_FastGIL_Forget();
            Py_BLOCK_THREADS
            goto __pyx_L9;
          }
          __pyx_L9:;
        }
    }

    /* "cupy/cuda/cufft.pyx":403
 *         # cufftMakePlan1d uses large memory when nx has large divisor.
 *         # See https://github.com/cupy/cupy/issues/1063
 *         if result == 2:             # <<<<<<<<<<<<<<
 *             cupy.get_default_memory_pool().free_all_blocks()
 *             with nogil:
*/
  }

  /* "cupy/cuda/cufft.pyx":408
 *                 result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,
 *                                          &work_size)
 *         check_result(result)             # <<<<<<<<<<<<<<
 * 
 *         work_area = memory.alloc(work_size)
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 408, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":410
 *         check_result(result)
 * 
 *         work_area = memory.alloc(work_size)             # <<<<<<<<<<<<<<
 *         ptr = <intptr_t>(work_area.ptr)
 *         with nogil:
*/
  __pyx_t_4 = NULL;
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_memory); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 410, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_alloc); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 410, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyLong_FromSize_t(__pyx_v_work_size); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 410, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_8 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_7))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_7);
    assert(__pyx_t_4);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_7);
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_7, __pyx__function);
    __pyx_t_8 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_4, __pyx_t_3};
    __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_7, __pyx_callargs+__pyx_t_8, (2-__pyx_t_8) | (__pyx_t_8*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 410, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
  }
  __pyx_v_work_area = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "cupy/cuda/cufft.pyx":411
 * 
 *         work_area = memory.alloc(work_size)
 *         ptr = <intptr_t>(work_area.ptr)             # <<<<<<<<<<<<<<
 *         with nogil:
 *             result = cufftSetWorkArea(plan, <void*>(ptr))
*/
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_work_area, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 411, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_9 = PyLong_AsSsize_t(__pyx_t_2); if (unlikely((__pyx_t_9 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 411, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr = ((intptr_t)__pyx_t_9);

  /* "cupy/cuda/cufft.pyx":412
 *         work_area = memory.alloc(work_size)
 *         ptr = <intptr_t>(work_area.ptr)
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftSetWorkArea(plan, <void*>(ptr))
 *         check_result(result)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":413
 *         ptr = <intptr_t>(work_area.ptr)
 *         with nogil:
 *             result = cufftSetWorkArea(plan, <void*>(ptr))             # <<<<<<<<<<<<<<
 *         check_result(result)
 * 
*/
        __pyx_v_result = cufftSetWorkArea(__pyx_v_plan, ((void *)__pyx_v_ptr));
      }

      /* "cupy/cuda/cufft.pyx":412
 *         work_area = memory.alloc(work_size)
 *         ptr = <intptr_t>(work_area.ptr)
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftSetWorkArea(plan, <void*>(ptr))
 *         check_result(result)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L12;
        }
        __pyx_L12:;
      }
  }

  /* "cupy/cuda/cufft.pyx":414
 *         with nogil:
 *             result = cufftSetWorkArea(plan, <void*>(ptr))
 *         check_result(result)             # <<<<<<<<<<<<<<
 * 
 *         self.work_area = work_area  # this is for cuFFT plan
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 414, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":416
 *         check_result(result)
 * 
 *         self.work_area = work_area  # this is for cuFFT plan             # <<<<<<<<<<<<<<
 * 
 *     cdef void _multi_gpu_get_plan(self, Handle plan, int nx, int fft_type,
*/
  __Pyx_INCREF(__pyx_v_work_area);
  __Pyx_GIVEREF(__pyx_v_work_area);
  __Pyx_GOTREF(__pyx_v_self->work_area);
  __Pyx_DECREF(__pyx_v_self->work_area);
  __pyx_v_self->work_area = __pyx_v_work_area;

  /* "cupy/cuda/cufft.pyx":391
 *         self.batch_share = None
 * 
 *     cdef void _single_gpu_get_plan(self, Handle plan, int nx, int fft_type,             # <<<<<<<<<<<<<<
 *                                    int batch) except*:
 *         cdef int result
*/

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d._single_gpu_get_plan", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_work_area);
  __Pyx_RefNannyFinishContext();
}

/* "cupy/cuda/cufft.pyx":418
 *         self.work_area = work_area  # this is for cuFFT plan
 * 
 *     cdef void _multi_gpu_get_plan(self, Handle plan, int nx, int fft_type,             # <<<<<<<<<<<<<<
 *                                   int batch, devices, out) except*:
 *         cdef int nGPUs, min_len, result
*/

static void __pyx_f_4cupy_4cuda_5cufft_6Plan1d__multi_gpu_get_plan(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, cufftHandle __pyx_v_plan, int __pyx_v_nx, int __pyx_v_fft_type, int __pyx_v_batch, PyObject *__pyx_v_devices, CYTHON_UNUSED PyObject *__pyx_v_out) {
  int __pyx_v_nGPUs;
  int __pyx_v_min_len;
  int __pyx_v_result;
  std::vector<int>  __pyx_v_gpus;
  std::vector<size_t>  __pyx_v_work_size;
  PyObject *__pyx_v_work_area = 0;
  PyObject *__pyx_v_gather_streams = 0;
  PyObject *__pyx_v_gather_events = 0;
  std::vector<void *>  __pyx_v_work_area_ptr;
  int __pyx_v_i;
  PyObject *__pyx_v_prev_device = NULL;
  PyObject *__pyx_v_buf = NULL;
  PyObject *__pyx_v_s = NULL;
  PyObject *__pyx_v_e = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  size_t __pyx_t_5;
  int __pyx_t_6;
  Py_ssize_t __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  int __pyx_t_10;
  int __pyx_t_11;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  int __pyx_t_17;
  char const *__pyx_t_18;
  PyObject *__pyx_t_19 = NULL;
  PyObject *__pyx_t_20 = NULL;
  PyObject *__pyx_t_21 = NULL;
  PyObject *__pyx_t_22 = NULL;
  PyObject *__pyx_t_23 = NULL;
  PyObject *__pyx_t_24 = NULL;
  int __pyx_t_25;
  intptr_t __pyx_t_26;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_multi_gpu_get_plan", 0);

  /* "cupy/cuda/cufft.pyx":423
 *         cdef vector.vector[int] gpus
 *         cdef vector.vector[size_t] work_size
 *         cdef list work_area = []             # <<<<<<<<<<<<<<
 *         cdef list gather_streams = []
 *         cdef list gather_events = []
*/
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 423, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_work_area = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":424
 *         cdef vector.vector[size_t] work_size
 *         cdef list work_area = []
 *         cdef list gather_streams = []             # <<<<<<<<<<<<<<
 *         cdef list gather_events = []
 *         cdef vector.vector[void*] work_area_ptr
*/
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 424, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_gather_streams = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":425
 *         cdef list work_area = []
 *         cdef list gather_streams = []
 *         cdef list gather_events = []             # <<<<<<<<<<<<<<
 *         cdef vector.vector[void*] work_area_ptr
 * 
*/
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 425, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_gather_events = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":429
 * 
 *         # some sanity checks
 *         if runtime.is_hip:             # <<<<<<<<<<<<<<
 *             raise RuntimeError('hipFFT/rocFFT does not support multi-GPU FFT')
 *         if fft_type != CUFFT_C2C and fft_type != CUFFT_Z2Z:
*/
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 429, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_is_hip); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 429, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_3 < 0))) __PYX_ERR(0, 429, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_3)) {

    /* "cupy/cuda/cufft.pyx":430
 *         # some sanity checks
 *         if runtime.is_hip:
 *             raise RuntimeError('hipFFT/rocFFT does not support multi-GPU FFT')             # <<<<<<<<<<<<<<
 *         if fft_type != CUFFT_C2C and fft_type != CUFFT_Z2Z:
 *             raise ValueError('Currently for multiple GPUs only C2C and Z2Z are'
*/
    __pyx_t_1 = NULL;
    __Pyx_INCREF(__pyx_builtin_RuntimeError);
    __pyx_t_4 = __pyx_builtin_RuntimeError; 
    __pyx_t_5 = 1;
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_1, __pyx_mstate_global->__pyx_kp_u_hipFFT_rocFFT_does_not_support_m};
      __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_4, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 430, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 430, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":429
 * 
 *         # some sanity checks
 *         if runtime.is_hip:             # <<<<<<<<<<<<<<
 *             raise RuntimeError('hipFFT/rocFFT does not support multi-GPU FFT')
 *         if fft_type != CUFFT_C2C and fft_type != CUFFT_Z2Z:
*/
  }

  /* "cupy/cuda/cufft.pyx":431
 *         if runtime.is_hip:
 *             raise RuntimeError('hipFFT/rocFFT does not support multi-GPU FFT')
 *         if fft_type != CUFFT_C2C and fft_type != CUFFT_Z2Z:             # <<<<<<<<<<<<<<
 *             raise ValueError('Currently for multiple GPUs only C2C and Z2Z are'
 *                              ' supported.')
*/
  switch (__pyx_v_fft_type) {
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_C2C:
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_Z2Z:
    __pyx_t_3 = 0;
    break;
    default:
    __pyx_t_3 = 1;
    break;
  }
  if (unlikely(__pyx_t_3)) {

    /* "cupy/cuda/cufft.pyx":432
 *             raise RuntimeError('hipFFT/rocFFT does not support multi-GPU FFT')
 *         if fft_type != CUFFT_C2C and fft_type != CUFFT_Z2Z:
 *             raise ValueError('Currently for multiple GPUs only C2C and Z2Z are'             # <<<<<<<<<<<<<<
 *                              ' supported.')
 *         if isinstance(devices, (tuple, list)):
*/
    __pyx_t_4 = NULL;
    __Pyx_INCREF(__pyx_builtin_ValueError);
    __pyx_t_1 = __pyx_builtin_ValueError; 
    __pyx_t_5 = 1;
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_4, __pyx_mstate_global->__pyx_kp_u_Currently_for_multiple_GPUs_only};
      __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 432, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 432, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":431
 *         if runtime.is_hip:
 *             raise RuntimeError('hipFFT/rocFFT does not support multi-GPU FFT')
 *         if fft_type != CUFFT_C2C and fft_type != CUFFT_Z2Z:             # <<<<<<<<<<<<<<
 *             raise ValueError('Currently for multiple GPUs only C2C and Z2Z are'
 *                              ' supported.')
*/
  }

  /* "cupy/cuda/cufft.pyx":434
 *             raise ValueError('Currently for multiple GPUs only C2C and Z2Z are'
 *                              ' supported.')
 *         if isinstance(devices, (tuple, list)):             # <<<<<<<<<<<<<<
 *             nGPUs = len(devices)
 *             for i in range(nGPUs):
*/
  __pyx_t_6 = PyTuple_Check(__pyx_v_devices); 
  if (!__pyx_t_6) {
  } else {
    __pyx_t_3 = __pyx_t_6;
    goto __pyx_L6_bool_binop_done;
  }
  __pyx_t_6 = PyList_Check(__pyx_v_devices); 
  __pyx_t_3 = __pyx_t_6;
  __pyx_L6_bool_binop_done:;
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":435
 *                              ' supported.')
 *         if isinstance(devices, (tuple, list)):
 *             nGPUs = len(devices)             # <<<<<<<<<<<<<<
 *             for i in range(nGPUs):
 *                 gpus.push_back(devices[i])
*/
    __pyx_t_7 = PyObject_Length(__pyx_v_devices); if (unlikely(__pyx_t_7 == ((Py_ssize_t)-1))) __PYX_ERR(0, 435, __pyx_L1_error)
    __pyx_v_nGPUs = __pyx_t_7;

    /* "cupy/cuda/cufft.pyx":436
 *         if isinstance(devices, (tuple, list)):
 *             nGPUs = len(devices)
 *             for i in range(nGPUs):             # <<<<<<<<<<<<<<
 *                 gpus.push_back(devices[i])
 *         elif isinstance(devices, int):
*/
    __pyx_t_8 = __pyx_v_nGPUs;
    __pyx_t_9 = __pyx_t_8;
    for (__pyx_t_10 = 0; __pyx_t_10 < __pyx_t_9; __pyx_t_10+=1) {
      __pyx_v_i = __pyx_t_10;

      /* "cupy/cuda/cufft.pyx":437
 *             nGPUs = len(devices)
 *             for i in range(nGPUs):
 *                 gpus.push_back(devices[i])             # <<<<<<<<<<<<<<
 *         elif isinstance(devices, int):
 *             nGPUs = devices
*/
      __pyx_t_2 = __Pyx_GetItemInt(__pyx_v_devices, __pyx_v_i, int, 1, __Pyx_PyLong_From_int, 0, 1, 1, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 437, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_11 = __Pyx_PyLong_As_int(__pyx_t_2); if (unlikely((__pyx_t_11 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 437, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      try {
        __pyx_v_gpus.push_back(__pyx_t_11);
      } catch(...) {
        __Pyx_CppExn2PyErr();
        __PYX_ERR(0, 437, __pyx_L1_error)
      }
    }

    /* "cupy/cuda/cufft.pyx":434
 *             raise ValueError('Currently for multiple GPUs only C2C and Z2Z are'
 *                              ' supported.')
 *         if isinstance(devices, (tuple, list)):             # <<<<<<<<<<<<<<
 *             nGPUs = len(devices)
 *             for i in range(nGPUs):
*/
    goto __pyx_L5;
  }

  /* "cupy/cuda/cufft.pyx":438
 *             for i in range(nGPUs):
 *                 gpus.push_back(devices[i])
 *         elif isinstance(devices, int):             # <<<<<<<<<<<<<<
 *             nGPUs = devices
 *             for i in range(nGPUs):
*/
  __pyx_t_3 = PyLong_Check(__pyx_v_devices); 
  if (likely(__pyx_t_3)) {

    /* "cupy/cuda/cufft.pyx":439
 *                 gpus.push_back(devices[i])
 *         elif isinstance(devices, int):
 *             nGPUs = devices             # <<<<<<<<<<<<<<
 *             for i in range(nGPUs):
 *                 gpus.push_back(i)
*/
    __pyx_t_8 = __Pyx_PyLong_As_int(__pyx_v_devices); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 439, __pyx_L1_error)
    __pyx_v_nGPUs = __pyx_t_8;

    /* "cupy/cuda/cufft.pyx":440
 *         elif isinstance(devices, int):
 *             nGPUs = devices
 *             for i in range(nGPUs):             # <<<<<<<<<<<<<<
 *                 gpus.push_back(i)
 *         else:
*/
    __pyx_t_8 = __pyx_v_nGPUs;
    __pyx_t_9 = __pyx_t_8;
    for (__pyx_t_10 = 0; __pyx_t_10 < __pyx_t_9; __pyx_t_10+=1) {
      __pyx_v_i = __pyx_t_10;

      /* "cupy/cuda/cufft.pyx":441
 *             nGPUs = devices
 *             for i in range(nGPUs):
 *                 gpus.push_back(i)             # <<<<<<<<<<<<<<
 *         else:
 *             raise ValueError('\"devices\" should be an int or an iterable '
*/
      try {
        __pyx_v_gpus.push_back(__pyx_v_i);
      } catch(...) {
        __Pyx_CppExn2PyErr();
        __PYX_ERR(0, 441, __pyx_L1_error)
      }
    }

    /* "cupy/cuda/cufft.pyx":438
 *             for i in range(nGPUs):
 *                 gpus.push_back(devices[i])
 *         elif isinstance(devices, int):             # <<<<<<<<<<<<<<
 *             nGPUs = devices
 *             for i in range(nGPUs):
*/
    goto __pyx_L5;
  }

  /* "cupy/cuda/cufft.pyx":443
 *                 gpus.push_back(i)
 *         else:
 *             raise ValueError('\"devices\" should be an int or an iterable '             # <<<<<<<<<<<<<<
 *                              'of int.')
 *         if batch == 1:
*/
  /*else*/ {
    __pyx_t_1 = NULL;
    __Pyx_INCREF(__pyx_builtin_ValueError);
    __pyx_t_4 = __pyx_builtin_ValueError; 
    __pyx_t_5 = 1;
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_1, __pyx_mstate_global->__pyx_kp_u_devices_should_be_an_int_or_an};
      __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_4, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 443, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 443, __pyx_L1_error)
  }
  __pyx_L5:;

  /* "cupy/cuda/cufft.pyx":445
 *             raise ValueError('\"devices\" should be an int or an iterable '
 *                              'of int.')
 *         if batch == 1:             # <<<<<<<<<<<<<<
 *             if (nx & (nx - 1)) != 0:
 *                 raise ValueError('For multi-GPU FFT with batch = 1, the array '
*/
  __pyx_t_3 = (__pyx_v_batch == 1);
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":446
 *                              'of int.')
 *         if batch == 1:
 *             if (nx & (nx - 1)) != 0:             # <<<<<<<<<<<<<<
 *                 raise ValueError('For multi-GPU FFT with batch = 1, the array '
 *                                  'size must be a power of 2.')
*/
    __pyx_t_3 = ((__pyx_v_nx & (__pyx_v_nx - 1)) != 0);
    if (unlikely(__pyx_t_3)) {

      /* "cupy/cuda/cufft.pyx":447
 *         if batch == 1:
 *             if (nx & (nx - 1)) != 0:
 *                 raise ValueError('For multi-GPU FFT with batch = 1, the array '             # <<<<<<<<<<<<<<
 *                                  'size must be a power of 2.')
 *             if nGPUs not in (2, 4, 8, 16):
*/
      __pyx_t_4 = NULL;
      __Pyx_INCREF(__pyx_builtin_ValueError);
      __pyx_t_1 = __pyx_builtin_ValueError; 
      __pyx_t_5 = 1;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_4, __pyx_mstate_global->__pyx_kp_u_For_multi_GPU_FFT_with_batch_1_t};
        __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 447, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_Raise(__pyx_t_2, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __PYX_ERR(0, 447, __pyx_L1_error)

      /* "cupy/cuda/cufft.pyx":446
 *                              'of int.')
 *         if batch == 1:
 *             if (nx & (nx - 1)) != 0:             # <<<<<<<<<<<<<<
 *                 raise ValueError('For multi-GPU FFT with batch = 1, the array '
 *                                  'size must be a power of 2.')
*/
    }

    /* "cupy/cuda/cufft.pyx":449
 *                 raise ValueError('For multi-GPU FFT with batch = 1, the array '
 *                                  'size must be a power of 2.')
 *             if nGPUs not in (2, 4, 8, 16):             # <<<<<<<<<<<<<<
 *                 raise ValueError('For multi-GPU FFT with batch = 1, the number'
 *                                  ' of devices must be 2, 4, 8, or 16.')
*/
    switch (__pyx_v_nGPUs) {
      case 2:
      case 4:
      case 8:
      case 16:
      __pyx_t_3 = 0;
      break;
      default:
      __pyx_t_3 = 1;
      break;
    }
    __pyx_t_6 = __pyx_t_3;
    if (unlikely(__pyx_t_6)) {

      /* "cupy/cuda/cufft.pyx":450
 *                                  'size must be a power of 2.')
 *             if nGPUs not in (2, 4, 8, 16):
 *                 raise ValueError('For multi-GPU FFT with batch = 1, the number'             # <<<<<<<<<<<<<<
 *                                  ' of devices must be 2, 4, 8, or 16.')
 *             if nGPUs in (2, 4):
*/
      __pyx_t_1 = NULL;
      __Pyx_INCREF(__pyx_builtin_ValueError);
      __pyx_t_4 = __pyx_builtin_ValueError; 
      __pyx_t_5 = 1;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_1, __pyx_mstate_global->__pyx_kp_u_For_multi_GPU_FFT_with_batch_1_t_2};
        __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_4, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 450, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_Raise(__pyx_t_2, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __PYX_ERR(0, 450, __pyx_L1_error)

      /* "cupy/cuda/cufft.pyx":449
 *                 raise ValueError('For multi-GPU FFT with batch = 1, the array '
 *                                  'size must be a power of 2.')
 *             if nGPUs not in (2, 4, 8, 16):             # <<<<<<<<<<<<<<
 *                 raise ValueError('For multi-GPU FFT with batch = 1, the number'
 *                                  ' of devices must be 2, 4, 8, or 16.')
*/
    }

    /* "cupy/cuda/cufft.pyx":452
 *                 raise ValueError('For multi-GPU FFT with batch = 1, the number'
 *                                  ' of devices must be 2, 4, 8, or 16.')
 *             if nGPUs in (2, 4):             # <<<<<<<<<<<<<<
 *                 min_len = 64
 *             elif nGPUs == 8:
*/
    switch (__pyx_v_nGPUs) {
      case 2:
      case 4:

      /* "cupy/cuda/cufft.pyx":453
 *                                  ' of devices must be 2, 4, 8, or 16.')
 *             if nGPUs in (2, 4):
 *                 min_len = 64             # <<<<<<<<<<<<<<
 *             elif nGPUs == 8:
 *                 min_len = 128
*/
      __pyx_v_min_len = 64;

      /* "cupy/cuda/cufft.pyx":452
 *                 raise ValueError('For multi-GPU FFT with batch = 1, the number'
 *                                  ' of devices must be 2, 4, 8, or 16.')
 *             if nGPUs in (2, 4):             # <<<<<<<<<<<<<<
 *                 min_len = 64
 *             elif nGPUs == 8:
*/
      break;
      case 8:

      /* "cupy/cuda/cufft.pyx":455
 *                 min_len = 64
 *             elif nGPUs == 8:
 *                 min_len = 128             # <<<<<<<<<<<<<<
 *             else:  # nGPU = 16
 *                 min_len = 1024
*/
      __pyx_v_min_len = 0x80;

      /* "cupy/cuda/cufft.pyx":454
 *             if nGPUs in (2, 4):
 *                 min_len = 64
 *             elif nGPUs == 8:             # <<<<<<<<<<<<<<
 *                 min_len = 128
 *             else:  # nGPU = 16
*/
      break;
      default:

      /* "cupy/cuda/cufft.pyx":457
 *                 min_len = 128
 *             else:  # nGPU = 16
 *                 min_len = 1024             # <<<<<<<<<<<<<<
 *             if nx < min_len:
 *                 raise ValueError('For {} GPUs, the array length must be at '
*/
      __pyx_v_min_len = 0x400;
      break;
    }

    /* "cupy/cuda/cufft.pyx":458
 *             else:  # nGPU = 16
 *                 min_len = 1024
 *             if nx < min_len:             # <<<<<<<<<<<<<<
 *                 raise ValueError('For {} GPUs, the array length must be at '
 *                                  'least {} (you have {}).'
*/
    __pyx_t_6 = (__pyx_v_nx < __pyx_v_min_len);
    if (unlikely(__pyx_t_6)) {

      /* "cupy/cuda/cufft.pyx":459
 *                 min_len = 1024
 *             if nx < min_len:
 *                 raise ValueError('For {} GPUs, the array length must be at '             # <<<<<<<<<<<<<<
 *                                  'least {} (you have {}).'
 *                                  .format(nGPUs, min_len, nx))
*/
      __pyx_t_4 = NULL;
      __Pyx_INCREF(__pyx_builtin_ValueError);
      __pyx_t_1 = __pyx_builtin_ValueError; 

      /* "cupy/cuda/cufft.pyx":461
 *                 raise ValueError('For {} GPUs, the array length must be at '
 *                                  'least {} (you have {}).'
 *                                  .format(nGPUs, min_len, nx))             # <<<<<<<<<<<<<<
 *         work_size.resize(nGPUs)
 * 
*/
      __pyx_t_13 = __pyx_mstate_global->__pyx_kp_u_For_GPUs_the_array_length_must_b;
      __Pyx_INCREF(__pyx_t_13);
      __pyx_t_14 = __Pyx_PyLong_From_int(__pyx_v_nGPUs); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 461, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_14);
      __pyx_t_15 = __Pyx_PyLong_From_int(__pyx_v_min_len); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 461, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_15);
      __pyx_t_16 = __Pyx_PyLong_From_int(__pyx_v_nx); if (unlikely(!__pyx_t_16)) __PYX_ERR(0, 461, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_16);
      __pyx_t_5 = 0;
      {
        PyObject *__pyx_callargs[4] = {__pyx_t_13, __pyx_t_14, __pyx_t_15, __pyx_t_16};
        __pyx_t_12 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_format, __pyx_callargs+__pyx_t_5, (4-__pyx_t_5) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
        __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
        __Pyx_DECREF(__pyx_t_16); __pyx_t_16 = 0;
        if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 461, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_12);
      }
      __pyx_t_5 = 1;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_4, __pyx_t_12};
        __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 459, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_Raise(__pyx_t_2, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __PYX_ERR(0, 459, __pyx_L1_error)

      /* "cupy/cuda/cufft.pyx":458
 *             else:  # nGPU = 16
 *                 min_len = 1024
 *             if nx < min_len:             # <<<<<<<<<<<<<<
 *                 raise ValueError('For {} GPUs, the array length must be at '
 *                                  'least {} (you have {}).'
*/
    }

    /* "cupy/cuda/cufft.pyx":445
 *             raise ValueError('\"devices\" should be an int or an iterable '
 *                              'of int.')
 *         if batch == 1:             # <<<<<<<<<<<<<<
 *             if (nx & (nx - 1)) != 0:
 *                 raise ValueError('For multi-GPU FFT with batch = 1, the array '
*/
  }

  /* "cupy/cuda/cufft.pyx":462
 *                                  'least {} (you have {}).'
 *                                  .format(nGPUs, min_len, nx))
 *         work_size.resize(nGPUs)             # <<<<<<<<<<<<<<
 * 
 *         with nogil:
*/
  try {
    __pyx_v_work_size.resize(__pyx_v_nGPUs);
  } catch(...) {
    __Pyx_CppExn2PyErr();
    __PYX_ERR(0, 462, __pyx_L1_error)
  }

  /* "cupy/cuda/cufft.pyx":464
 *         work_size.resize(nGPUs)
 * 
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftXtSetGPUs(plan, nGPUs, gpus.data())
 *             if result == 0:
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":465
 * 
 *         with nogil:
 *             result = cufftXtSetGPUs(plan, nGPUs, gpus.data())             # <<<<<<<<<<<<<<
 *             if result == 0:
 *                 result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,
*/
        __pyx_v_result = cufftXtSetGPUs(__pyx_v_plan, __pyx_v_nGPUs, __pyx_v_gpus.data());

        /* "cupy/cuda/cufft.pyx":466
 *         with nogil:
 *             result = cufftXtSetGPUs(plan, nGPUs, gpus.data())
 *             if result == 0:             # <<<<<<<<<<<<<<
 *                 result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,
 *                                          work_size.data())
*/
        __pyx_t_6 = (__pyx_v_result == 0);
        if (__pyx_t_6) {

          /* "cupy/cuda/cufft.pyx":467
 *             result = cufftXtSetGPUs(plan, nGPUs, gpus.data())
 *             if result == 0:
 *                 result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,             # <<<<<<<<<<<<<<
 *                                          work_size.data())
 * 
*/
          __pyx_v_result = cufftMakePlan1d(__pyx_v_plan, __pyx_v_nx, ((cufftType_t)__pyx_v_fft_type), __pyx_v_batch, __pyx_v_work_size.data());

          /* "cupy/cuda/cufft.pyx":466
 *         with nogil:
 *             result = cufftXtSetGPUs(plan, nGPUs, gpus.data())
 *             if result == 0:             # <<<<<<<<<<<<<<
 *                 result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,
 *                                          work_size.data())
*/
        }
      }

      /* "cupy/cuda/cufft.pyx":464
 *         work_size.resize(nGPUs)
 * 
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftXtSetGPUs(plan, nGPUs, gpus.data())
 *             if result == 0:
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L18;
        }
        __pyx_L18:;
      }
  }

  /* "cupy/cuda/cufft.pyx":472
 *         # cufftMakePlan1d uses large memory when nx has large divisor.
 *         # See https://github.com/cupy/cupy/issues/1063
 *         if result == 2:             # <<<<<<<<<<<<<<
 *             cupy.get_default_memory_pool().free_all_blocks()
 *             with nogil:
*/
  __pyx_t_6 = (__pyx_v_result == 2);
  if (__pyx_t_6) {

    /* "cupy/cuda/cufft.pyx":473
 *         # See https://github.com/cupy/cupy/issues/1063
 *         if result == 2:
 *             cupy.get_default_memory_pool().free_all_blocks()             # <<<<<<<<<<<<<<
 *             with nogil:
 *                 result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,
*/
    __pyx_t_4 = NULL;
    __Pyx_GetModuleGlobalName(__pyx_t_16, __pyx_mstate_global->__pyx_n_u_cupy); if (unlikely(!__pyx_t_16)) __PYX_ERR(0, 473, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_16);
    __pyx_t_15 = __Pyx_PyObject_GetAttrStr(__pyx_t_16, __pyx_mstate_global->__pyx_n_u_get_default_memory_pool); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 473, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_15);
    __Pyx_DECREF(__pyx_t_16); __pyx_t_16 = 0;
    __pyx_t_5 = 1;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_15))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_15);
      assert(__pyx_t_4);
      PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_15);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(__pyx__function);
      __Pyx_DECREF_SET(__pyx_t_15, __pyx__function);
      __pyx_t_5 = 0;
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_4, NULL};
      __pyx_t_12 = __Pyx_PyObject_FastCall(__pyx_t_15, __pyx_callargs+__pyx_t_5, (1-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
      if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 473, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_12);
    }
    __pyx_t_1 = __pyx_t_12;
    __Pyx_INCREF(__pyx_t_1);
    __pyx_t_5 = 0;
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_1, NULL};
      __pyx_t_2 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_free_all_blocks, __pyx_callargs+__pyx_t_5, (1-__pyx_t_5) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 473, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "cupy/cuda/cufft.pyx":474
 *         if result == 2:
 *             cupy.get_default_memory_pool().free_all_blocks()
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,
 *                                          work_size.data())
*/
    {
        PyThreadState *_save;
        _save = NULL;
        Py_UNBLOCK_THREADS
        __Pyx_FastGIL_Remember();
        /*try:*/ {

          /* "cupy/cuda/cufft.pyx":475
 *             cupy.get_default_memory_pool().free_all_blocks()
 *             with nogil:
 *                 result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,             # <<<<<<<<<<<<<<
 *                                          work_size.data())
 *         check_result(result)
*/
          __pyx_v_result = cufftMakePlan1d(__pyx_v_plan, __pyx_v_nx, ((cufftType_t)__pyx_v_fft_type), __pyx_v_batch, __pyx_v_work_size.data());
        }

        /* "cupy/cuda/cufft.pyx":474
 *         if result == 2:
 *             cupy.get_default_memory_pool().free_all_blocks()
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,
 *                                          work_size.data())
*/
        /*finally:*/ {
          /*normal exit:*/{
            __Pyx_FastGIL_Forget();
            Py_BLOCK_THREADS
            goto __pyx_L23;
          }
          __pyx_L23:;
        }
    }

    /* "cupy/cuda/cufft.pyx":472
 *         # cufftMakePlan1d uses large memory when nx has large divisor.
 *         # See https://github.com/cupy/cupy/issues/1063
 *         if result == 2:             # <<<<<<<<<<<<<<
 *             cupy.get_default_memory_pool().free_all_blocks()
 *             with nogil:
*/
  }

  /* "cupy/cuda/cufft.pyx":477
 *                 result = cufftMakePlan1d(plan, nx, <Type>fft_type, batch,
 *                                          work_size.data())
 *         check_result(result)             # <<<<<<<<<<<<<<
 * 
 *         for i in range(nGPUs):
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 477, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":479
 *         check_result(result)
 * 
 *         for i in range(nGPUs):             # <<<<<<<<<<<<<<
 *             prev_device = runtime.getDevice()
 *             runtime.setDevice(gpus[i])
*/
  __pyx_t_8 = __pyx_v_nGPUs;
  __pyx_t_9 = __pyx_t_8;
  for (__pyx_t_10 = 0; __pyx_t_10 < __pyx_t_9; __pyx_t_10+=1) {
    __pyx_v_i = __pyx_t_10;

    /* "cupy/cuda/cufft.pyx":480
 * 
 *         for i in range(nGPUs):
 *             prev_device = runtime.getDevice()             # <<<<<<<<<<<<<<
 *             runtime.setDevice(gpus[i])
 *             try:
*/
    __pyx_t_12 = NULL;
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 480, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_15 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_getDevice); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 480, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_15);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_5 = 1;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_15))) {
      __pyx_t_12 = PyMethod_GET_SELF(__pyx_t_15);
      assert(__pyx_t_12);
      PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_15);
      __Pyx_INCREF(__pyx_t_12);
      __Pyx_INCREF(__pyx__function);
      __Pyx_DECREF_SET(__pyx_t_15, __pyx__function);
      __pyx_t_5 = 0;
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_12, NULL};
      __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_15, __pyx_callargs+__pyx_t_5, (1-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
      __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 480, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_XDECREF_SET(__pyx_v_prev_device, __pyx_t_2);
    __pyx_t_2 = 0;

    /* "cupy/cuda/cufft.pyx":481
 *         for i in range(nGPUs):
 *             prev_device = runtime.getDevice()
 *             runtime.setDevice(gpus[i])             # <<<<<<<<<<<<<<
 *             try:
 *                 buf = memory.alloc(work_size[i])
*/
    __pyx_t_15 = NULL;
    __Pyx_GetModuleGlobalName(__pyx_t_12, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 481, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_12);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_12, __pyx_mstate_global->__pyx_n_u_setDevice); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 481, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
    __pyx_t_12 = __Pyx_PyLong_From_int((__pyx_v_gpus[__pyx_v_i])); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 481, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_12);
    __pyx_t_5 = 1;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_1))) {
      __pyx_t_15 = PyMethod_GET_SELF(__pyx_t_1);
      assert(__pyx_t_15);
      PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_1);
      __Pyx_INCREF(__pyx_t_15);
      __Pyx_INCREF(__pyx__function);
      __Pyx_DECREF_SET(__pyx_t_1, __pyx__function);
      __pyx_t_5 = 0;
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_15, __pyx_t_12};
      __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_15); __pyx_t_15 = 0;
      __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 481, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "cupy/cuda/cufft.pyx":482
 *             prev_device = runtime.getDevice()
 *             runtime.setDevice(gpus[i])
 *             try:             # <<<<<<<<<<<<<<
 *                 buf = memory.alloc(work_size[i])
 *                 s = stream.Stream()
*/
    /*try:*/ {

      /* "cupy/cuda/cufft.pyx":483
 *             runtime.setDevice(gpus[i])
 *             try:
 *                 buf = memory.alloc(work_size[i])             # <<<<<<<<<<<<<<
 *                 s = stream.Stream()
 *                 e = stream.Event()
*/
      __pyx_t_1 = NULL;
      __Pyx_GetModuleGlobalName(__pyx_t_12, __pyx_mstate_global->__pyx_n_u_memory); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 483, __pyx_L29_error)
      __Pyx_GOTREF(__pyx_t_12);
      __pyx_t_15 = __Pyx_PyObject_GetAttrStr(__pyx_t_12, __pyx_mstate_global->__pyx_n_u_alloc); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 483, __pyx_L29_error)
      __Pyx_GOTREF(__pyx_t_15);
      __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
      __pyx_t_12 = __Pyx_PyLong_FromSize_t((__pyx_v_work_size[__pyx_v_i])); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 483, __pyx_L29_error)
      __Pyx_GOTREF(__pyx_t_12);
      __pyx_t_5 = 1;
      #if CYTHON_UNPACK_METHODS
      if (unlikely(PyMethod_Check(__pyx_t_15))) {
        __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_15);
        assert(__pyx_t_1);
        PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_15);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(__pyx__function);
        __Pyx_DECREF_SET(__pyx_t_15, __pyx__function);
        __pyx_t_5 = 0;
      }
      #endif
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_1, __pyx_t_12};
        __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_15, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
        __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
        if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 483, __pyx_L29_error)
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_XDECREF_SET(__pyx_v_buf, __pyx_t_2);
      __pyx_t_2 = 0;

      /* "cupy/cuda/cufft.pyx":484
 *             try:
 *                 buf = memory.alloc(work_size[i])
 *                 s = stream.Stream()             # <<<<<<<<<<<<<<
 *                 e = stream.Event()
 *             finally:
*/
      __pyx_t_15 = NULL;
      __Pyx_GetModuleGlobalName(__pyx_t_12, __pyx_mstate_global->__pyx_n_u_stream); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 484, __pyx_L29_error)
      __Pyx_GOTREF(__pyx_t_12);
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_12, __pyx_mstate_global->__pyx_n_u_Stream); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 484, __pyx_L29_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
      __pyx_t_5 = 1;
      #if CYTHON_UNPACK_METHODS
      if (unlikely(PyMethod_Check(__pyx_t_1))) {
        __pyx_t_15 = PyMethod_GET_SELF(__pyx_t_1);
        assert(__pyx_t_15);
        PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_1);
        __Pyx_INCREF(__pyx_t_15);
        __Pyx_INCREF(__pyx__function);
        __Pyx_DECREF_SET(__pyx_t_1, __pyx__function);
        __pyx_t_5 = 0;
      }
      #endif
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_15, NULL};
        __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+__pyx_t_5, (1-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_15); __pyx_t_15 = 0;
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 484, __pyx_L29_error)
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_XDECREF_SET(__pyx_v_s, __pyx_t_2);
      __pyx_t_2 = 0;

      /* "cupy/cuda/cufft.pyx":485
 *                 buf = memory.alloc(work_size[i])
 *                 s = stream.Stream()
 *                 e = stream.Event()             # <<<<<<<<<<<<<<
 *             finally:
 *                 runtime.setDevice(prev_device)
*/
      __pyx_t_1 = NULL;
      __Pyx_GetModuleGlobalName(__pyx_t_15, __pyx_mstate_global->__pyx_n_u_stream); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 485, __pyx_L29_error)
      __Pyx_GOTREF(__pyx_t_15);
      __pyx_t_12 = __Pyx_PyObject_GetAttrStr(__pyx_t_15, __pyx_mstate_global->__pyx_n_u_Event); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 485, __pyx_L29_error)
      __Pyx_GOTREF(__pyx_t_12);
      __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
      __pyx_t_5 = 1;
      #if CYTHON_UNPACK_METHODS
      if (unlikely(PyMethod_Check(__pyx_t_12))) {
        __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_12);
        assert(__pyx_t_1);
        PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_12);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(__pyx__function);
        __Pyx_DECREF_SET(__pyx_t_12, __pyx__function);
        __pyx_t_5 = 0;
      }
      #endif
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_1, NULL};
        __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_12, __pyx_callargs+__pyx_t_5, (1-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
        if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 485, __pyx_L29_error)
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_XDECREF_SET(__pyx_v_e, __pyx_t_2);
      __pyx_t_2 = 0;
    }

    /* "cupy/cuda/cufft.pyx":487
 *                 e = stream.Event()
 *             finally:
 *                 runtime.setDevice(prev_device)             # <<<<<<<<<<<<<<
 *             work_area.append(buf)
 *             work_area_ptr.push_back(<void*><intptr_t>(buf.ptr))
*/
    /*finally:*/ {
      /*normal exit:*/{
        __pyx_t_12 = NULL;
        __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 487, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_15 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_setDevice); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 487, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_15);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_5 = 1;
        #if CYTHON_UNPACK_METHODS
        if (unlikely(PyMethod_Check(__pyx_t_15))) {
          __pyx_t_12 = PyMethod_GET_SELF(__pyx_t_15);
          assert(__pyx_t_12);
          PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_15);
          __Pyx_INCREF(__pyx_t_12);
          __Pyx_INCREF(__pyx__function);
          __Pyx_DECREF_SET(__pyx_t_15, __pyx__function);
          __pyx_t_5 = 0;
        }
        #endif
        {
          PyObject *__pyx_callargs[2] = {__pyx_t_12, __pyx_v_prev_device};
          __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_15, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
          __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
          __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
          if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 487, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
        }
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        goto __pyx_L30;
      }
      __pyx_L29_error:;
      /*exception exit:*/{
        __Pyx_PyThreadState_declare
        __Pyx_PyThreadState_assign
        __pyx_t_19 = 0; __pyx_t_20 = 0; __pyx_t_21 = 0; __pyx_t_22 = 0; __pyx_t_23 = 0; __pyx_t_24 = 0;
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
        __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
        __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
        __Pyx_XDECREF(__pyx_t_15); __pyx_t_15 = 0;
        __Pyx_XDECREF(__pyx_t_16); __pyx_t_16 = 0;
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
         __Pyx_ExceptionSwap(&__pyx_t_22, &__pyx_t_23, &__pyx_t_24);
        if ( unlikely(__Pyx_GetException(&__pyx_t_19, &__pyx_t_20, &__pyx_t_21) < 0)) __Pyx_ErrFetch(&__pyx_t_19, &__pyx_t_20, &__pyx_t_21);
        __Pyx_XGOTREF(__pyx_t_19);
        __Pyx_XGOTREF(__pyx_t_20);
        __Pyx_XGOTREF(__pyx_t_21);
        __Pyx_XGOTREF(__pyx_t_22);
        __Pyx_XGOTREF(__pyx_t_23);
        __Pyx_XGOTREF(__pyx_t_24);
        __pyx_t_11 = __pyx_lineno; __pyx_t_17 = __pyx_clineno; __pyx_t_18 = __pyx_filename;
        {
          __pyx_t_15 = NULL;
          __Pyx_GetModuleGlobalName(__pyx_t_12, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 487, __pyx_L34_error)
          __Pyx_GOTREF(__pyx_t_12);
          __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_12, __pyx_mstate_global->__pyx_n_u_setDevice); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 487, __pyx_L34_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
          __pyx_t_5 = 1;
          #if CYTHON_UNPACK_METHODS
          if (unlikely(PyMethod_Check(__pyx_t_1))) {
            __pyx_t_15 = PyMethod_GET_SELF(__pyx_t_1);
            assert(__pyx_t_15);
            PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_1);
            __Pyx_INCREF(__pyx_t_15);
            __Pyx_INCREF(__pyx__function);
            __Pyx_DECREF_SET(__pyx_t_1, __pyx__function);
            __pyx_t_5 = 0;
          }
          #endif
          {
            PyObject *__pyx_callargs[2] = {__pyx_t_15, __pyx_v_prev_device};
            __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
            __Pyx_XDECREF(__pyx_t_15); __pyx_t_15 = 0;
            __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
            if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 487, __pyx_L34_error)
            __Pyx_GOTREF(__pyx_t_2);
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        }
        __Pyx_XGIVEREF(__pyx_t_22);
        __Pyx_XGIVEREF(__pyx_t_23);
        __Pyx_XGIVEREF(__pyx_t_24);
        __Pyx_ExceptionReset(__pyx_t_22, __pyx_t_23, __pyx_t_24);
        __Pyx_XGIVEREF(__pyx_t_19);
        __Pyx_XGIVEREF(__pyx_t_20);
        __Pyx_XGIVEREF(__pyx_t_21);
        __Pyx_ErrRestore(__pyx_t_19, __pyx_t_20, __pyx_t_21);
        __pyx_t_19 = 0; __pyx_t_20 = 0; __pyx_t_21 = 0; __pyx_t_22 = 0; __pyx_t_23 = 0; __pyx_t_24 = 0;
        __pyx_lineno = __pyx_t_11; __pyx_clineno = __pyx_t_17; __pyx_filename = __pyx_t_18;
        goto __pyx_L1_error;
        __pyx_L34_error:;
        __Pyx_XGIVEREF(__pyx_t_22);
        __Pyx_XGIVEREF(__pyx_t_23);
        __Pyx_XGIVEREF(__pyx_t_24);
        __Pyx_ExceptionReset(__pyx_t_22, __pyx_t_23, __pyx_t_24);
        __Pyx_XDECREF(__pyx_t_19); __pyx_t_19 = 0;
        __Pyx_XDECREF(__pyx_t_20); __pyx_t_20 = 0;
        __Pyx_XDECREF(__pyx_t_21); __pyx_t_21 = 0;
        __pyx_t_22 = 0; __pyx_t_23 = 0; __pyx_t_24 = 0;
        goto __pyx_L1_error;
      }
      __pyx_L30:;
    }

    /* "cupy/cuda/cufft.pyx":488
 *             finally:
 *                 runtime.setDevice(prev_device)
 *             work_area.append(buf)             # <<<<<<<<<<<<<<
 *             work_area_ptr.push_back(<void*><intptr_t>(buf.ptr))
 *             gather_streams.append(s)
*/
    __pyx_t_25 = __Pyx_PyList_Append(__pyx_v_work_area, __pyx_v_buf); if (unlikely(__pyx_t_25 == ((int)-1))) __PYX_ERR(0, 488, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":489
 *                 runtime.setDevice(prev_device)
 *             work_area.append(buf)
 *             work_area_ptr.push_back(<void*><intptr_t>(buf.ptr))             # <<<<<<<<<<<<<<
 *             gather_streams.append(s)
 *             gather_events.append(e)
*/
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_buf, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 489, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_26 = PyLong_AsSsize_t(__pyx_t_2); if (unlikely((__pyx_t_26 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 489, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    try {
      __pyx_v_work_area_ptr.push_back(((void *)((intptr_t)__pyx_t_26)));
    } catch(...) {
      __Pyx_CppExn2PyErr();
      __PYX_ERR(0, 489, __pyx_L1_error)
    }

    /* "cupy/cuda/cufft.pyx":490
 *             work_area.append(buf)
 *             work_area_ptr.push_back(<void*><intptr_t>(buf.ptr))
 *             gather_streams.append(s)             # <<<<<<<<<<<<<<
 *             gather_events.append(e)
 *         with nogil:
*/
    __pyx_t_25 = __Pyx_PyList_Append(__pyx_v_gather_streams, __pyx_v_s); if (unlikely(__pyx_t_25 == ((int)-1))) __PYX_ERR(0, 490, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":491
 *             work_area_ptr.push_back(<void*><intptr_t>(buf.ptr))
 *             gather_streams.append(s)
 *             gather_events.append(e)             # <<<<<<<<<<<<<<
 *         with nogil:
 *             result = cufftXtSetWorkArea(plan, work_area_ptr.data())
*/
    __pyx_t_25 = __Pyx_PyList_Append(__pyx_v_gather_events, __pyx_v_e); if (unlikely(__pyx_t_25 == ((int)-1))) __PYX_ERR(0, 491, __pyx_L1_error)
  }

  /* "cupy/cuda/cufft.pyx":492
 *             gather_streams.append(s)
 *             gather_events.append(e)
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftXtSetWorkArea(plan, work_area_ptr.data())
 *         check_result(result)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":493
 *             gather_events.append(e)
 *         with nogil:
 *             result = cufftXtSetWorkArea(plan, work_area_ptr.data())             # <<<<<<<<<<<<<<
 *         check_result(result)
 * 
*/
        __pyx_v_result = cufftXtSetWorkArea(__pyx_v_plan, __pyx_v_work_area_ptr.data());
      }

      /* "cupy/cuda/cufft.pyx":492
 *             gather_streams.append(s)
 *             gather_events.append(e)
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftXtSetWorkArea(plan, work_area_ptr.data())
 *         check_result(result)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L37;
        }
        __pyx_L37:;
      }
  }

  /* "cupy/cuda/cufft.pyx":494
 *         with nogil:
 *             result = cufftXtSetWorkArea(plan, work_area_ptr.data())
 *         check_result(result)             # <<<<<<<<<<<<<<
 * 
 *         self.work_area = work_area  # this is for cuFFT plan
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 494, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":496
 *         check_result(result)
 * 
 *         self.work_area = work_area  # this is for cuFFT plan             # <<<<<<<<<<<<<<
 *         self.gpus = list(gpus)
 * 
*/
  __Pyx_INCREF(__pyx_v_work_area);
  __Pyx_GIVEREF(__pyx_v_work_area);
  __Pyx_GOTREF(__pyx_v_self->work_area);
  __Pyx_DECREF(__pyx_v_self->work_area);
  __pyx_v_self->work_area = __pyx_v_work_area;

  /* "cupy/cuda/cufft.pyx":497
 * 
 *         self.work_area = work_area  # this is for cuFFT plan
 *         self.gpus = list(gpus)             # <<<<<<<<<<<<<<
 * 
 *         # For async, overlapped copies. We need to distinguish scatter and
*/
  __pyx_t_2 = __pyx_convert_vector_to_py_int(__pyx_v_gpus); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 497, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PySequence_ListKeepNew(__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 497, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->gpus);
  __Pyx_DECREF(__pyx_v_self->gpus);
  __pyx_v_self->gpus = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":501
 *         # For async, overlapped copies. We need to distinguish scatter and
 *         # gather because for async memcpy, the stream is on the source device
 *         self.gather_streams = gather_streams             # <<<<<<<<<<<<<<
 *         self.gather_events = gather_events
 *         self.scatter_streams = {}
*/
  __Pyx_INCREF(__pyx_v_gather_streams);
  __Pyx_GIVEREF(__pyx_v_gather_streams);
  __Pyx_GOTREF(__pyx_v_self->gather_streams);
  __Pyx_DECREF(__pyx_v_self->gather_streams);
  __pyx_v_self->gather_streams = __pyx_v_gather_streams;

  /* "cupy/cuda/cufft.pyx":502
 *         # gather because for async memcpy, the stream is on the source device
 *         self.gather_streams = gather_streams
 *         self.gather_events = gather_events             # <<<<<<<<<<<<<<
 *         self.scatter_streams = {}
 *         self.scatter_events = {}
*/
  __Pyx_INCREF(__pyx_v_gather_events);
  __Pyx_GIVEREF(__pyx_v_gather_events);
  __Pyx_GOTREF(__pyx_v_self->gather_events);
  __Pyx_DECREF(__pyx_v_self->gather_events);
  __pyx_v_self->gather_events = __pyx_v_gather_events;

  /* "cupy/cuda/cufft.pyx":503
 *         self.gather_streams = gather_streams
 *         self.gather_events = gather_events
 *         self.scatter_streams = {}             # <<<<<<<<<<<<<<
 *         self.scatter_events = {}
 *         self._multi_gpu_get_scatter_streams_events(runtime.getDevice())
*/
  __pyx_t_1 = __Pyx_PyDict_NewPresized(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 503, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->scatter_streams);
  __Pyx_DECREF(__pyx_v_self->scatter_streams);
  __pyx_v_self->scatter_streams = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":504
 *         self.gather_events = gather_events
 *         self.scatter_streams = {}
 *         self.scatter_events = {}             # <<<<<<<<<<<<<<
 *         self._multi_gpu_get_scatter_streams_events(runtime.getDevice())
 * 
*/
  __pyx_t_1 = __Pyx_PyDict_NewPresized(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 504, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v_self->scatter_events);
  __Pyx_DECREF(__pyx_v_self->scatter_events);
  __pyx_v_self->scatter_events = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":505
 *         self.scatter_streams = {}
 *         self.scatter_events = {}
 *         self._multi_gpu_get_scatter_streams_events(runtime.getDevice())             # <<<<<<<<<<<<<<
 * 
 *     def _multi_gpu_get_scatter_streams_events(self, int curr_device):
*/
  __pyx_t_2 = ((PyObject *)__pyx_v_self);
  __Pyx_INCREF(__pyx_t_2);
  __pyx_t_12 = NULL;
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 505, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_16 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_getDevice); if (unlikely(!__pyx_t_16)) __PYX_ERR(0, 505, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_16);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_5 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_16))) {
    __pyx_t_12 = PyMethod_GET_SELF(__pyx_t_16);
    assert(__pyx_t_12);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_16);
    __Pyx_INCREF(__pyx_t_12);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_16, __pyx__function);
    __pyx_t_5 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_12, NULL};
    __pyx_t_15 = __Pyx_PyObject_FastCall(__pyx_t_16, __pyx_callargs+__pyx_t_5, (1-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
    __Pyx_DECREF(__pyx_t_16); __pyx_t_16 = 0;
    if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 505, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_15);
  }
  __pyx_t_5 = 0;
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_t_15};
    __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_multi_gpu_get_scatter_streams_e, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 505, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":418
 *         self.work_area = work_area  # this is for cuFFT plan
 * 
 *     cdef void _multi_gpu_get_plan(self, Handle plan, int nx, int fft_type,             # <<<<<<<<<<<<<<
 *                                   int batch, devices, out) except*:
 *         cdef int nGPUs, min_len, result
*/

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_12);
  __Pyx_XDECREF(__pyx_t_13);
  __Pyx_XDECREF(__pyx_t_14);
  __Pyx_XDECREF(__pyx_t_15);
  __Pyx_XDECREF(__pyx_t_16);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d._multi_gpu_get_plan", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_work_area);
  __Pyx_XDECREF(__pyx_v_gather_streams);
  __Pyx_XDECREF(__pyx_v_gather_events);
  __Pyx_XDECREF(__pyx_v_prev_device);
  __Pyx_XDECREF(__pyx_v_buf);
  __Pyx_XDECREF(__pyx_v_s);
  __Pyx_XDECREF(__pyx_v_e);
  __Pyx_RefNannyFinishContext();
}

/* "cupy/cuda/cufft.pyx":507
 *         self._multi_gpu_get_scatter_streams_events(runtime.getDevice())
 * 
 *     def _multi_gpu_get_scatter_streams_events(self, int curr_device):             # <<<<<<<<<<<<<<
 *         '''
 *         create a list of streams and events on the current device
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_3_multi_gpu_get_scatter_streams_events(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6Plan1d_2_multi_gpu_get_scatter_streams_events, "Plan1d._multi_gpu_get_scatter_streams_events(self, int curr_device)\n\ncreate a list of streams and events on the current device");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_3_multi_gpu_get_scatter_streams_events(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  int __pyx_v_curr_device;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[1] = {0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_multi_gpu_get_scatter_streams_events (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_curr_device,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 507, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 507, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "_multi_gpu_get_scatter_streams_events", 0) < (0)) __PYX_ERR(0, 507, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 1; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("_multi_gpu_get_scatter_streams_events", 1, 1, 1, i); __PYX_ERR(0, 507, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 1)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 507, __pyx_L3_error)
    }
    __pyx_v_curr_device = __Pyx_PyLong_As_int(values[0]); if (unlikely((__pyx_v_curr_device == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 507, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_multi_gpu_get_scatter_streams_events", 1, 1, 1, __pyx_nargs); __PYX_ERR(0, 507, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d._multi_gpu_get_scatter_streams_events", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_2_multi_gpu_get_scatter_streams_events(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self), __pyx_v_curr_device);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_2_multi_gpu_get_scatter_streams_events(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, int __pyx_v_curr_device) {
  CYTHON_UNUSED int __pyx_v_i;
  PyObject *__pyx_v_scatter_streams = 0;
  PyObject *__pyx_v_scatter_events = 0;
  PyObject *__pyx_v_prev_device = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  size_t __pyx_t_6;
  Py_ssize_t __pyx_t_7;
  int __pyx_t_8;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_t_10;
  int __pyx_t_11;
  char const *__pyx_t_12;
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  PyObject *__pyx_t_17 = NULL;
  PyObject *__pyx_t_18 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_multi_gpu_get_scatter_streams_events", 0);

  /* "cupy/cuda/cufft.pyx":512
 *         '''
 *         cdef int i
 *         cdef list scatter_streams = []             # <<<<<<<<<<<<<<
 *         cdef list scatter_events = []
 * 
*/
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 512, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_scatter_streams = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":513
 *         cdef int i
 *         cdef list scatter_streams = []
 *         cdef list scatter_events = []             # <<<<<<<<<<<<<<
 * 
 *         assert curr_device in self.gpus
*/
  __pyx_t_1 = PyList_New(0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 513, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_scatter_events = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":515
 *         cdef list scatter_events = []
 * 
 *         assert curr_device in self.gpus             # <<<<<<<<<<<<<<
 *         prev_device = runtime.getDevice()
 *         runtime.setDevice(curr_device)
*/
  #ifndef CYTHON_WITHOUT_ASSERTIONS
  if (unlikely(__pyx_assertions_enabled())) {
    __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_curr_device); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 515, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = (__Pyx_PySequence_ContainsTF(__pyx_t_1, __pyx_v_self->gpus, Py_EQ)); if (unlikely((__pyx_t_2 < 0))) __PYX_ERR(0, 515, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely(!__pyx_t_2)) {
      __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
      __PYX_ERR(0, 515, __pyx_L1_error)
    }
  }
  #else
  if ((1)); else __PYX_ERR(0, 515, __pyx_L1_error)
  #endif

  /* "cupy/cuda/cufft.pyx":516
 * 
 *         assert curr_device in self.gpus
 *         prev_device = runtime.getDevice()             # <<<<<<<<<<<<<<
 *         runtime.setDevice(curr_device)
 *         try:
*/
  __pyx_t_3 = NULL;
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 516, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_getDevice); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 516, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_6 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
    assert(__pyx_t_3);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_5);
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_5, __pyx__function);
    __pyx_t_6 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, NULL};
    __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_5, __pyx_callargs+__pyx_t_6, (1-__pyx_t_6) | (__pyx_t_6*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 516, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  __pyx_v_prev_device = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":517
 *         assert curr_device in self.gpus
 *         prev_device = runtime.getDevice()
 *         runtime.setDevice(curr_device)             # <<<<<<<<<<<<<<
 *         try:
 *             for i in self.gpus:
*/
  __pyx_t_5 = NULL;
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 517, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_setDevice); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 517, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyLong_From_int(__pyx_v_curr_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 517, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_6 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_4);
    assert(__pyx_t_5);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_4);
    __Pyx_INCREF(__pyx_t_5);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_4, __pyx__function);
    __pyx_t_6 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_5, __pyx_t_3};
    __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_4, __pyx_callargs+__pyx_t_6, (2-__pyx_t_6) | (__pyx_t_6*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 517, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":518
 *         prev_device = runtime.getDevice()
 *         runtime.setDevice(curr_device)
 *         try:             # <<<<<<<<<<<<<<
 *             for i in self.gpus:
 *                 scatter_streams.append(stream.Stream())
*/
  /*try:*/ {

    /* "cupy/cuda/cufft.pyx":519
 *         runtime.setDevice(curr_device)
 *         try:
 *             for i in self.gpus:             # <<<<<<<<<<<<<<
 *                 scatter_streams.append(stream.Stream())
 *                 scatter_events.append(stream.Event())
*/
    if (unlikely(__pyx_v_self->gpus == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not iterable");
      __PYX_ERR(0, 519, __pyx_L4_error)
    }
    __pyx_t_1 = __pyx_v_self->gpus; __Pyx_INCREF(__pyx_t_1);
    __pyx_t_7 = 0;
    for (;;) {
      {
        Py_ssize_t __pyx_temp = __Pyx_PyList_GET_SIZE(__pyx_t_1);
        #if !CYTHON_ASSUME_SAFE_SIZE
        if (unlikely((__pyx_temp < 0))) __PYX_ERR(0, 519, __pyx_L4_error)
        #endif
        if (__pyx_t_7 >= __pyx_temp) break;
      }
      __pyx_t_4 = __Pyx_PyList_GetItemRef(__pyx_t_1, __pyx_t_7);
      ++__pyx_t_7;
      if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 519, __pyx_L4_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_8 = __Pyx_PyLong_As_int(__pyx_t_4); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 519, __pyx_L4_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_v_i = __pyx_t_8;

      /* "cupy/cuda/cufft.pyx":520
 *         try:
 *             for i in self.gpus:
 *                 scatter_streams.append(stream.Stream())             # <<<<<<<<<<<<<<
 *                 scatter_events.append(stream.Event())
 *         finally:
*/
      __pyx_t_3 = NULL;
      __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_stream); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 520, __pyx_L4_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_Stream); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 520, __pyx_L4_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_6 = 1;
      #if CYTHON_UNPACK_METHODS
      if (unlikely(PyMethod_Check(__pyx_t_9))) {
        __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_9);
        assert(__pyx_t_3);
        PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_9);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(__pyx__function);
        __Pyx_DECREF_SET(__pyx_t_9, __pyx__function);
        __pyx_t_6 = 0;
      }
      #endif
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_3, NULL};
        __pyx_t_4 = __Pyx_PyObject_FastCall(__pyx_t_9, __pyx_callargs+__pyx_t_6, (1-__pyx_t_6) | (__pyx_t_6*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 520, __pyx_L4_error)
        __Pyx_GOTREF(__pyx_t_4);
      }
      __pyx_t_10 = __Pyx_PyList_Append(__pyx_v_scatter_streams, __pyx_t_4); if (unlikely(__pyx_t_10 == ((int)-1))) __PYX_ERR(0, 520, __pyx_L4_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

      /* "cupy/cuda/cufft.pyx":521
 *             for i in self.gpus:
 *                 scatter_streams.append(stream.Stream())
 *                 scatter_events.append(stream.Event())             # <<<<<<<<<<<<<<
 *         finally:
 *             runtime.setDevice(prev_device)
*/
      __pyx_t_9 = NULL;
      __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_stream); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 521, __pyx_L4_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_Event); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 521, __pyx_L4_error)
      __Pyx_GOTREF(__pyx_t_5);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_6 = 1;
      #if CYTHON_UNPACK_METHODS
      if (unlikely(PyMethod_Check(__pyx_t_5))) {
        __pyx_t_9 = PyMethod_GET_SELF(__pyx_t_5);
        assert(__pyx_t_9);
        PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_9);
        __Pyx_INCREF(__pyx__function);
        __Pyx_DECREF_SET(__pyx_t_5, __pyx__function);
        __pyx_t_6 = 0;
      }
      #endif
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_9, NULL};
        __pyx_t_4 = __Pyx_PyObject_FastCall(__pyx_t_5, __pyx_callargs+__pyx_t_6, (1-__pyx_t_6) | (__pyx_t_6*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 521, __pyx_L4_error)
        __Pyx_GOTREF(__pyx_t_4);
      }
      __pyx_t_10 = __Pyx_PyList_Append(__pyx_v_scatter_events, __pyx_t_4); if (unlikely(__pyx_t_10 == ((int)-1))) __PYX_ERR(0, 521, __pyx_L4_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

      /* "cupy/cuda/cufft.pyx":519
 *         runtime.setDevice(curr_device)
 *         try:
 *             for i in self.gpus:             # <<<<<<<<<<<<<<
 *                 scatter_streams.append(stream.Stream())
 *                 scatter_events.append(stream.Event())
*/
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }

  /* "cupy/cuda/cufft.pyx":523
 *                 scatter_events.append(stream.Event())
 *         finally:
 *             runtime.setDevice(prev_device)             # <<<<<<<<<<<<<<
 *         self.scatter_streams[curr_device] = scatter_streams
 *         self.scatter_events[curr_device] = scatter_events
*/
  /*finally:*/ {
    /*normal exit:*/{
      __pyx_t_4 = NULL;
      __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 523, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_setDevice); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 523, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __pyx_t_6 = 1;
      #if CYTHON_UNPACK_METHODS
      if (unlikely(PyMethod_Check(__pyx_t_9))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_9);
        assert(__pyx_t_4);
        PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_9);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(__pyx__function);
        __Pyx_DECREF_SET(__pyx_t_9, __pyx__function);
        __pyx_t_6 = 0;
      }
      #endif
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_4, __pyx_v_prev_device};
        __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_9, __pyx_callargs+__pyx_t_6, (2-__pyx_t_6) | (__pyx_t_6*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 523, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      goto __pyx_L5;
    }
    __pyx_L4_error:;
    /*exception exit:*/{
      __Pyx_PyThreadState_declare
      __Pyx_PyThreadState_assign
      __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0;
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
       __Pyx_ExceptionSwap(&__pyx_t_16, &__pyx_t_17, &__pyx_t_18);
      if ( unlikely(__Pyx_GetException(&__pyx_t_13, &__pyx_t_14, &__pyx_t_15) < 0)) __Pyx_ErrFetch(&__pyx_t_13, &__pyx_t_14, &__pyx_t_15);
      __Pyx_XGOTREF(__pyx_t_13);
      __Pyx_XGOTREF(__pyx_t_14);
      __Pyx_XGOTREF(__pyx_t_15);
      __Pyx_XGOTREF(__pyx_t_16);
      __Pyx_XGOTREF(__pyx_t_17);
      __Pyx_XGOTREF(__pyx_t_18);
      __pyx_t_8 = __pyx_lineno; __pyx_t_11 = __pyx_clineno; __pyx_t_12 = __pyx_filename;
      {
        __pyx_t_9 = NULL;
        __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 523, __pyx_L10_error)
        __Pyx_GOTREF(__pyx_t_4);
        __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_setDevice); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 523, __pyx_L10_error)
        __Pyx_GOTREF(__pyx_t_5);
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        __pyx_t_6 = 1;
        #if CYTHON_UNPACK_METHODS
        if (unlikely(PyMethod_Check(__pyx_t_5))) {
          __pyx_t_9 = PyMethod_GET_SELF(__pyx_t_5);
          assert(__pyx_t_9);
          PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_5);
          __Pyx_INCREF(__pyx_t_9);
          __Pyx_INCREF(__pyx__function);
          __Pyx_DECREF_SET(__pyx_t_5, __pyx__function);
          __pyx_t_6 = 0;
        }
        #endif
        {
          PyObject *__pyx_callargs[2] = {__pyx_t_9, __pyx_v_prev_device};
          __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_5, __pyx_callargs+__pyx_t_6, (2-__pyx_t_6) | (__pyx_t_6*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
          __Pyx_XDECREF(__pyx_t_9); __pyx_t_9 = 0;
          __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
          if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 523, __pyx_L10_error)
          __Pyx_GOTREF(__pyx_t_1);
        }
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      }
      __Pyx_XGIVEREF(__pyx_t_16);
      __Pyx_XGIVEREF(__pyx_t_17);
      __Pyx_XGIVEREF(__pyx_t_18);
      __Pyx_ExceptionReset(__pyx_t_16, __pyx_t_17, __pyx_t_18);
      __Pyx_XGIVEREF(__pyx_t_13);
      __Pyx_XGIVEREF(__pyx_t_14);
      __Pyx_XGIVEREF(__pyx_t_15);
      __Pyx_ErrRestore(__pyx_t_13, __pyx_t_14, __pyx_t_15);
      __pyx_t_13 = 0; __pyx_t_14 = 0; __pyx_t_15 = 0; __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0;
      __pyx_lineno = __pyx_t_8; __pyx_clineno = __pyx_t_11; __pyx_filename = __pyx_t_12;
      goto __pyx_L1_error;
      __pyx_L10_error:;
      __Pyx_XGIVEREF(__pyx_t_16);
      __Pyx_XGIVEREF(__pyx_t_17);
      __Pyx_XGIVEREF(__pyx_t_18);
      __Pyx_ExceptionReset(__pyx_t_16, __pyx_t_17, __pyx_t_18);
      __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
      __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
      __Pyx_XDECREF(__pyx_t_15); __pyx_t_15 = 0;
      __pyx_t_16 = 0; __pyx_t_17 = 0; __pyx_t_18 = 0;
      goto __pyx_L1_error;
    }
    __pyx_L5:;
  }

  /* "cupy/cuda/cufft.pyx":524
 *         finally:
 *             runtime.setDevice(prev_device)
 *         self.scatter_streams[curr_device] = scatter_streams             # <<<<<<<<<<<<<<
 *         self.scatter_events[curr_device] = scatter_events
 * 
*/
  if (unlikely(__pyx_v_self->scatter_streams == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(0, 524, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_curr_device); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 524, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (unlikely((PyDict_SetItem(__pyx_v_self->scatter_streams, __pyx_t_1, __pyx_v_scatter_streams) < 0))) __PYX_ERR(0, 524, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":525
 *             runtime.setDevice(prev_device)
 *         self.scatter_streams[curr_device] = scatter_streams
 *         self.scatter_events[curr_device] = scatter_events             # <<<<<<<<<<<<<<
 * 
 *     def __dealloc__(self):
*/
  if (unlikely(__pyx_v_self->scatter_events == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(0, 525, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_curr_device); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 525, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (unlikely((PyDict_SetItem(__pyx_v_self->scatter_events, __pyx_t_1, __pyx_v_scatter_events) < 0))) __PYX_ERR(0, 525, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":507
 *         self._multi_gpu_get_scatter_streams_events(runtime.getDevice())
 * 
 *     def _multi_gpu_get_scatter_streams_events(self, int curr_device):             # <<<<<<<<<<<<<<
 *         '''
 *         create a list of streams and events on the current device
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d._multi_gpu_get_scatter_streams_events", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_scatter_streams);
  __Pyx_XDECREF(__pyx_v_scatter_events);
  __Pyx_XDECREF(__pyx_v_prev_device);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":527
 *         self.scatter_events[curr_device] = scatter_events
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         cdef Handle plan = <Handle>self.handle
 *         cdef int dev, result
*/

/* Python wrapper */
static void __pyx_pw_4cupy_4cuda_5cufft_6Plan1d_5__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_4cupy_4cuda_5cufft_6Plan1d_5__dealloc__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_4__dealloc__(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_4__dealloc__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self) {
  cufftHandle __pyx_v_plan;
  int __pyx_v_dev;
  int __pyx_v_result;
  CYTHON_UNUSED PyObject *__pyx_v_e = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  size_t __pyx_t_9;
  int __pyx_t_10;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__dealloc__", 0);

  /* "cupy/cuda/cufft.pyx":528
 * 
 *     def __dealloc__(self):
 *         cdef Handle plan = <Handle>self.handle             # <<<<<<<<<<<<<<
 *         cdef int dev, result
 * 
*/
  __pyx_v_plan = ((cufftHandle)__pyx_v_self->handle);

  /* "cupy/cuda/cufft.pyx":531
 *         cdef int dev, result
 * 
 *         if self.xtArr != 0:             # <<<<<<<<<<<<<<
 *             _XtFree(self.xtArr)
 *             self.xtArr = 0
*/
  __pyx_t_1 = (__pyx_v_self->xtArr != 0);
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":532
 * 
 *         if self.xtArr != 0:
 *             _XtFree(self.xtArr)             # <<<<<<<<<<<<<<
 *             self.xtArr = 0
 * 
*/
    __pyx_t_2 = __pyx_f_4cupy_4cuda_5cufft__XtFree(__pyx_v_self->xtArr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 532, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "cupy/cuda/cufft.pyx":533
 *         if self.xtArr != 0:
 *             _XtFree(self.xtArr)
 *             self.xtArr = 0             # <<<<<<<<<<<<<<
 * 
 *         try:
*/
    __pyx_v_self->xtArr = 0;

    /* "cupy/cuda/cufft.pyx":531
 *         cdef int dev, result
 * 
 *         if self.xtArr != 0:             # <<<<<<<<<<<<<<
 *             _XtFree(self.xtArr)
 *             self.xtArr = 0
*/
  }

  /* "cupy/cuda/cufft.pyx":535
 *             self.xtArr = 0
 * 
 *         try:             # <<<<<<<<<<<<<<
 *             dev = runtime.getDevice()
 *         except Exception as e:
*/
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_3, &__pyx_t_4, &__pyx_t_5);
    __Pyx_XGOTREF(__pyx_t_3);
    __Pyx_XGOTREF(__pyx_t_4);
    __Pyx_XGOTREF(__pyx_t_5);
    /*try:*/ {

      /* "cupy/cuda/cufft.pyx":536
 * 
 *         try:
 *             dev = runtime.getDevice()             # <<<<<<<<<<<<<<
 *         except Exception as e:
 *             # hack: the runtime module is purged at interpreter shutdown,
*/
      __pyx_t_6 = NULL;
      __Pyx_GetModuleGlobalName(__pyx_t_7, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 536, __pyx_L4_error)
      __Pyx_GOTREF(__pyx_t_7);
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_mstate_global->__pyx_n_u_getDevice); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 536, __pyx_L4_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
      __pyx_t_9 = 1;
      #if CYTHON_UNPACK_METHODS
      if (unlikely(PyMethod_Check(__pyx_t_8))) {
        __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_8);
        assert(__pyx_t_6);
        PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_8);
        __Pyx_INCREF(__pyx_t_6);
        __Pyx_INCREF(__pyx__function);
        __Pyx_DECREF_SET(__pyx_t_8, __pyx__function);
        __pyx_t_9 = 0;
      }
      #endif
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_6, NULL};
        __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_8, __pyx_callargs+__pyx_t_9, (1-__pyx_t_9) | (__pyx_t_9*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 536, __pyx_L4_error)
        __Pyx_GOTREF(__pyx_t_2);
      }
      __pyx_t_10 = __Pyx_PyLong_As_int(__pyx_t_2); if (unlikely((__pyx_t_10 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 536, __pyx_L4_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_dev = __pyx_t_10;

      /* "cupy/cuda/cufft.pyx":535
 *             self.xtArr = 0
 * 
 *         try:             # <<<<<<<<<<<<<<
 *             dev = runtime.getDevice()
 *         except Exception as e:
*/
    }
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    goto __pyx_L9_try_end;
    __pyx_L4_error:;
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;

    /* "cupy/cuda/cufft.pyx":537
 *         try:
 *             dev = runtime.getDevice()
 *         except Exception as e:             # <<<<<<<<<<<<<<
 *             # hack: the runtime module is purged at interpreter shutdown,
 *             # since this is not a __del__ method, we can't use
*/
    __pyx_t_10 = __Pyx_PyErr_ExceptionMatches(((PyObject *)(((PyTypeObject*)PyExc_Exception))));
    if (__pyx_t_10) {
      __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.__dealloc__", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_2, &__pyx_t_8, &__pyx_t_6) < 0) __PYX_ERR(0, 537, __pyx_L6_except_error)
      __Pyx_XGOTREF(__pyx_t_2);
      __Pyx_XGOTREF(__pyx_t_8);
      __Pyx_XGOTREF(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_8);
      __pyx_v_e = __pyx_t_8;
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":541
 *             # since this is not a __del__ method, we can't use
 *             # cupy._util.is_shutting_down()...
 *             return             # <<<<<<<<<<<<<<
 * 
 *         if plan != <Handle>0:
*/
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        goto __pyx_L14_return;
      }

      /* "cupy/cuda/cufft.pyx":537
 *         try:
 *             dev = runtime.getDevice()
 *         except Exception as e:             # <<<<<<<<<<<<<<
 *             # hack: the runtime module is purged at interpreter shutdown,
 *             # since this is not a __del__ method, we can't use
*/
      /*finally:*/ {
        __pyx_L14_return: {
          __Pyx_DECREF(__pyx_v_e); __pyx_v_e = 0;
          goto __pyx_L7_except_return;
        }
      }
    }
    goto __pyx_L6_except_error;

    /* "cupy/cuda/cufft.pyx":535
 *             self.xtArr = 0
 * 
 *         try:             # <<<<<<<<<<<<<<
 *             dev = runtime.getDevice()
 *         except Exception as e:
*/
    __pyx_L6_except_error:;
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_XGIVEREF(__pyx_t_4);
    __Pyx_XGIVEREF(__pyx_t_5);
    __Pyx_ExceptionReset(__pyx_t_3, __pyx_t_4, __pyx_t_5);
    goto __pyx_L1_error;
    __pyx_L7_except_return:;
    __Pyx_XGIVEREF(__pyx_t_3);
    __Pyx_XGIVEREF(__pyx_t_4);
    __Pyx_XGIVEREF(__pyx_t_5);
    __Pyx_ExceptionReset(__pyx_t_3, __pyx_t_4, __pyx_t_5);
    goto __pyx_L0;
    __pyx_L9_try_end:;
  }

  /* "cupy/cuda/cufft.pyx":543
 *             return
 * 
 *         if plan != <Handle>0:             # <<<<<<<<<<<<<<
 *             with nogil:
 *                 result = cufftDestroy(plan)
*/
  __pyx_t_1 = (__pyx_v_plan != ((cufftHandle)0));
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":544
 * 
 *         if plan != <Handle>0:
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftDestroy(plan)
 *             check_result(result)
*/
    {
        PyThreadState *_save;
        _save = NULL;
        Py_UNBLOCK_THREADS
        __Pyx_FastGIL_Remember();
        /*try:*/ {

          /* "cupy/cuda/cufft.pyx":545
 *         if plan != <Handle>0:
 *             with nogil:
 *                 result = cufftDestroy(plan)             # <<<<<<<<<<<<<<
 *             check_result(result)
 *             self.handle = <intptr_t>0
*/
          __pyx_v_result = cufftDestroy(__pyx_v_plan);
        }

        /* "cupy/cuda/cufft.pyx":544
 * 
 *         if plan != <Handle>0:
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftDestroy(plan)
 *             check_result(result)
*/
        /*finally:*/ {
          /*normal exit:*/{
            __Pyx_FastGIL_Forget();
            Py_BLOCK_THREADS
            goto __pyx_L20;
          }
          __pyx_L20:;
        }
    }

    /* "cupy/cuda/cufft.pyx":546
 *             with nogil:
 *                 result = cufftDestroy(plan)
 *             check_result(result)             # <<<<<<<<<<<<<<
 *             self.handle = <intptr_t>0
 * 
*/
    __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 546, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":547
 *                 result = cufftDestroy(plan)
 *             check_result(result)
 *             self.handle = <intptr_t>0             # <<<<<<<<<<<<<<
 * 
 *         # cuFFT bug: after cufftDestroy(), the current device is mistakenly
*/
    __pyx_v_self->handle = ((intptr_t)0);

    /* "cupy/cuda/cufft.pyx":543
 *             return
 * 
 *         if plan != <Handle>0:             # <<<<<<<<<<<<<<
 *             with nogil:
 *                 result = cufftDestroy(plan)
*/
  }

  /* "cupy/cuda/cufft.pyx":553
 *         # https://github.com/cupy/cupy/pull/2644#discussion_r347567899 and
 *         # NVIDIA internal ticket 2761341.
 *         runtime.setDevice(dev)             # <<<<<<<<<<<<<<
 * 
 *     def __enter__(self):
*/
  __pyx_t_8 = NULL;
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 553, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_setDevice); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 553, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_v_dev); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 553, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_9 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_7))) {
    __pyx_t_8 = PyMethod_GET_SELF(__pyx_t_7);
    assert(__pyx_t_8);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_7);
    __Pyx_INCREF(__pyx_t_8);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_7, __pyx__function);
    __pyx_t_9 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_8, __pyx_t_2};
    __pyx_t_6 = __Pyx_PyObject_FastCall(__pyx_t_7, __pyx_callargs+__pyx_t_9, (2-__pyx_t_9) | (__pyx_t_9*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 553, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;

  /* "cupy/cuda/cufft.pyx":527
 *         self.scatter_events[curr_device] = scatter_events
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         cdef Handle plan = <Handle>self.handle
 *         cdef int dev, result
*/

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_WriteUnraisable("cupy.cuda.cufft.Plan1d.__dealloc__", __pyx_clineno, __pyx_lineno, __pyx_filename, 1, 0);
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_e);
  __Pyx_RefNannyFinishContext();
}

/* "cupy/cuda/cufft.pyx":555
 *         runtime.setDevice(dev)
 * 
 *     def __enter__(self):             # <<<<<<<<<<<<<<
 *         _thread_local._current_plan = self
 *         return self
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_7__enter__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6Plan1d_6__enter__, "Plan1d.__enter__(self)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_7__enter__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__enter__ (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  if (unlikely(__pyx_nargs > 0)) { __Pyx_RaiseArgtupleInvalid("__enter__", 1, 0, 0, __pyx_nargs); return NULL; }
  const Py_ssize_t __pyx_kwds_len = unlikely(__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
  if (unlikely(__pyx_kwds_len < 0)) return NULL;
  if (unlikely(__pyx_kwds_len > 0)) {__Pyx_RejectKeywords("__enter__", __pyx_kwds); return NULL;}
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_6__enter__(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_6__enter__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__enter__", 0);

  /* "cupy/cuda/cufft.pyx":556
 * 
 *     def __enter__(self):
 *         _thread_local._current_plan = self             # <<<<<<<<<<<<<<
 *         return self
 * 
*/
  if (__Pyx_PyObject_SetAttrStr(__pyx_v_4cupy_4cuda_5cufft__thread_local, __pyx_mstate_global->__pyx_n_u_current_plan, ((PyObject *)__pyx_v_self)) < (0)) __PYX_ERR(0, 556, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":557
 *     def __enter__(self):
 *         _thread_local._current_plan = self
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __exit__(self, exc_type, exc_value, traceback):
*/
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF((PyObject *)__pyx_v_self);
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":555
 *         runtime.setDevice(dev)
 * 
 *     def __enter__(self):             # <<<<<<<<<<<<<<
 *         _thread_local._current_plan = self
 *         return self
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.__enter__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":559
 *         return self
 * 
 *     def __exit__(self, exc_type, exc_value, traceback):             # <<<<<<<<<<<<<<
 *         _thread_local._current_plan = None
 * 
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_9__exit__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6Plan1d_8__exit__, "Plan1d.__exit__(self, exc_type, exc_value, traceback)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_9__exit__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  CYTHON_UNUSED PyObject *__pyx_v_exc_type = 0;
  CYTHON_UNUSED PyObject *__pyx_v_exc_value = 0;
  CYTHON_UNUSED PyObject *__pyx_v_traceback = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__exit__ (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_exc_type,&__pyx_mstate_global->__pyx_n_u_exc_value,&__pyx_mstate_global->__pyx_n_u_traceback,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 559, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 559, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 559, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 559, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "__exit__", 0) < (0)) __PYX_ERR(0, 559, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("__exit__", 1, 3, 3, i); __PYX_ERR(0, 559, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 559, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 559, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 559, __pyx_L3_error)
    }
    __pyx_v_exc_type = values[0];
    __pyx_v_exc_value = values[1];
    __pyx_v_traceback = values[2];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__exit__", 1, 3, 3, __pyx_nargs); __PYX_ERR(0, 559, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.__exit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_8__exit__(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self), __pyx_v_exc_type, __pyx_v_exc_value, __pyx_v_traceback);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_8__exit__(CYTHON_UNUSED struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v_exc_type, CYTHON_UNUSED PyObject *__pyx_v_exc_value, CYTHON_UNUSED PyObject *__pyx_v_traceback) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__exit__", 0);

  /* "cupy/cuda/cufft.pyx":560
 * 
 *     def __exit__(self, exc_type, exc_value, traceback):
 *         _thread_local._current_plan = None             # <<<<<<<<<<<<<<
 * 
 *     def fft(self, a, out, direction):
*/
  if (__Pyx_PyObject_SetAttrStr(__pyx_v_4cupy_4cuda_5cufft__thread_local, __pyx_mstate_global->__pyx_n_u_current_plan, Py_None) < (0)) __PYX_ERR(0, 560, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":559
 *         return self
 * 
 *     def __exit__(self, exc_type, exc_value, traceback):             # <<<<<<<<<<<<<<
 *         _thread_local._current_plan = None
 * 
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.__exit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":562
 *         _thread_local._current_plan = None
 * 
 *     def fft(self, a, out, direction):             # <<<<<<<<<<<<<<
 *         if self.gpus is not None:
 *             self._multi_gpu_fft(a, out, direction)
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_11fft(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6Plan1d_10fft, "Plan1d.fft(self, a, out, direction)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_11fft(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_a = 0;
  PyObject *__pyx_v_out = 0;
  PyObject *__pyx_v_direction = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("fft (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_a,&__pyx_mstate_global->__pyx_n_u_out,&__pyx_mstate_global->__pyx_n_u_direction,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 562, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 562, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 562, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 562, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "fft", 0) < (0)) __PYX_ERR(0, 562, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("fft", 1, 3, 3, i); __PYX_ERR(0, 562, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 562, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 562, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 562, __pyx_L3_error)
    }
    __pyx_v_a = values[0];
    __pyx_v_out = values[1];
    __pyx_v_direction = values[2];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("fft", 1, 3, 3, __pyx_nargs); __PYX_ERR(0, 562, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.fft", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_10fft(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self), __pyx_v_a, __pyx_v_out, __pyx_v_direction);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_10fft(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_out, PyObject *__pyx_v_direction) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  size_t __pyx_t_4;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("fft", 0);

  /* "cupy/cuda/cufft.pyx":563
 * 
 *     def fft(self, a, out, direction):
 *         if self.gpus is not None:             # <<<<<<<<<<<<<<
 *             self._multi_gpu_fft(a, out, direction)
 *         else:
*/
  __pyx_t_1 = (__pyx_v_self->gpus != ((PyObject*)Py_None));
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":564
 *     def fft(self, a, out, direction):
 *         if self.gpus is not None:
 *             self._multi_gpu_fft(a, out, direction)             # <<<<<<<<<<<<<<
 *         else:
 *             self._single_gpu_fft(a, out, direction)
*/
    __pyx_t_3 = ((PyObject *)__pyx_v_self);
    __Pyx_INCREF(__pyx_t_3);
    __pyx_t_4 = 0;
    {
      PyObject *__pyx_callargs[4] = {__pyx_t_3, __pyx_v_a, __pyx_v_out, __pyx_v_direction};
      __pyx_t_2 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_multi_gpu_fft, __pyx_callargs+__pyx_t_4, (4-__pyx_t_4) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 564, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "cupy/cuda/cufft.pyx":563
 * 
 *     def fft(self, a, out, direction):
 *         if self.gpus is not None:             # <<<<<<<<<<<<<<
 *             self._multi_gpu_fft(a, out, direction)
 *         else:
*/
    goto __pyx_L3;
  }

  /* "cupy/cuda/cufft.pyx":566
 *             self._multi_gpu_fft(a, out, direction)
 *         else:
 *             self._single_gpu_fft(a, out, direction)             # <<<<<<<<<<<<<<
 * 
 *     def _single_gpu_fft(self, a, out, direction):
*/
  /*else*/ {
    __pyx_t_3 = ((PyObject *)__pyx_v_self);
    __Pyx_INCREF(__pyx_t_3);
    __pyx_t_4 = 0;
    {
      PyObject *__pyx_callargs[4] = {__pyx_t_3, __pyx_v_a, __pyx_v_out, __pyx_v_direction};
      __pyx_t_2 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_single_gpu_fft, __pyx_callargs+__pyx_t_4, (4-__pyx_t_4) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 566, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  }
  __pyx_L3:;

  /* "cupy/cuda/cufft.pyx":562
 *         _thread_local._current_plan = None
 * 
 *     def fft(self, a, out, direction):             # <<<<<<<<<<<<<<
 *         if self.gpus is not None:
 *             self._multi_gpu_fft(a, out, direction)
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.fft", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":568
 *             self._single_gpu_fft(a, out, direction)
 * 
 *     def _single_gpu_fft(self, a, out, direction):             # <<<<<<<<<<<<<<
 *         cdef intptr_t plan = self.handle
 *         cdef intptr_t s = stream.get_current_stream().ptr
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_13_single_gpu_fft(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6Plan1d_12_single_gpu_fft, "Plan1d._single_gpu_fft(self, a, out, direction)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_13_single_gpu_fft(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_a = 0;
  PyObject *__pyx_v_out = 0;
  PyObject *__pyx_v_direction = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_single_gpu_fft (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_a,&__pyx_mstate_global->__pyx_n_u_out,&__pyx_mstate_global->__pyx_n_u_direction,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 568, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 568, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 568, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 568, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "_single_gpu_fft", 0) < (0)) __PYX_ERR(0, 568, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("_single_gpu_fft", 1, 3, 3, i); __PYX_ERR(0, 568, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 568, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 568, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 568, __pyx_L3_error)
    }
    __pyx_v_a = values[0];
    __pyx_v_out = values[1];
    __pyx_v_direction = values[2];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_single_gpu_fft", 1, 3, 3, __pyx_nargs); __PYX_ERR(0, 568, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d._single_gpu_fft", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_12_single_gpu_fft(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self), __pyx_v_a, __pyx_v_out, __pyx_v_direction);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_12_single_gpu_fft(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_out, PyObject *__pyx_v_direction) {
  intptr_t __pyx_v_plan;
  intptr_t __pyx_v_s;
  int __pyx_v_result;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  intptr_t __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  size_t __pyx_t_6;
  intptr_t __pyx_t_7;
  int __pyx_t_8;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_single_gpu_fft", 0);

  /* "cupy/cuda/cufft.pyx":569
 * 
 *     def _single_gpu_fft(self, a, out, direction):
 *         cdef intptr_t plan = self.handle             # <<<<<<<<<<<<<<
 *         cdef intptr_t s = stream.get_current_stream().ptr
 *         cdef int result
*/
  __pyx_t_1 = __pyx_v_self->handle;
  __pyx_v_plan = __pyx_t_1;

  /* "cupy/cuda/cufft.pyx":570
 *     def _single_gpu_fft(self, a, out, direction):
 *         cdef intptr_t plan = self.handle
 *         cdef intptr_t s = stream.get_current_stream().ptr             # <<<<<<<<<<<<<<
 *         cdef int result
 * 
*/
  __pyx_t_3 = NULL;
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_stream); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 570, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_get_current_stream); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 570, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_6 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
    assert(__pyx_t_3);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_5);
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_5, __pyx__function);
    __pyx_t_6 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, NULL};
    __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_5, __pyx_callargs+__pyx_t_6, (1-__pyx_t_6) | (__pyx_t_6*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 570, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
  }
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 570, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_1 = PyLong_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_1 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 570, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_s = __pyx_t_1;

  /* "cupy/cuda/cufft.pyx":573
 *         cdef int result
 * 
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftSetStream(<Handle>plan, <Stream>s)
 *         check_result(result)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":574
 * 
 *         with nogil:
 *             result = cufftSetStream(<Handle>plan, <Stream>s)             # <<<<<<<<<<<<<<
 *         check_result(result)
 * 
*/
        __pyx_v_result = cufftSetStream(((cufftHandle)__pyx_v_plan), ((cudaStream_t)__pyx_v_s));
      }

      /* "cupy/cuda/cufft.pyx":573
 *         cdef int result
 * 
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftSetStream(<Handle>plan, <Stream>s)
 *         check_result(result)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "cupy/cuda/cufft.pyx":575
 *         with nogil:
 *             result = cufftSetStream(<Handle>plan, <Stream>s)
 *         check_result(result)             # <<<<<<<<<<<<<<
 * 
 *         if self.fft_type == CUFFT_C2C:
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 575, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":577
 *         check_result(result)
 * 
 *         if self.fft_type == CUFFT_C2C:             # <<<<<<<<<<<<<<
 *             execC2C(plan, a.data.ptr, out.data.ptr, direction)
 *         elif self.fft_type == CUFFT_R2C:
*/
  switch (__pyx_v_self->fft_type) {
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_C2C:

    /* "cupy/cuda/cufft.pyx":578
 * 
 *         if self.fft_type == CUFFT_C2C:
 *             execC2C(plan, a.data.ptr, out.data.ptr, direction)             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_R2C:
 *             execR2C(plan, a.data.ptr, out.data.ptr)
*/
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 578, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 578, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_1 = PyLong_AsSsize_t(__pyx_t_2); if (unlikely((__pyx_t_1 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 578, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 578, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 578, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_7 = PyLong_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_7 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 578, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_8 = __Pyx_PyLong_As_int(__pyx_v_direction); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 578, __pyx_L1_error)
    __pyx_t_5 = __pyx_f_4cupy_4cuda_5cufft_execC2C(__pyx_v_plan, __pyx_t_1, __pyx_t_7, __pyx_t_8, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 578, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "cupy/cuda/cufft.pyx":577
 *         check_result(result)
 * 
 *         if self.fft_type == CUFFT_C2C:             # <<<<<<<<<<<<<<
 *             execC2C(plan, a.data.ptr, out.data.ptr, direction)
 *         elif self.fft_type == CUFFT_R2C:
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_R2C:

    /* "cupy/cuda/cufft.pyx":580
 *             execC2C(plan, a.data.ptr, out.data.ptr, direction)
 *         elif self.fft_type == CUFFT_R2C:
 *             execR2C(plan, a.data.ptr, out.data.ptr)             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_C2R:
 *             execC2R(plan, a.data.ptr, out.data.ptr)
*/
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_7 = PyLong_AsSsize_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_1 = PyLong_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_1 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __pyx_f_4cupy_4cuda_5cufft_execR2C(__pyx_v_plan, __pyx_t_7, __pyx_t_1, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 580, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "cupy/cuda/cufft.pyx":579
 *         if self.fft_type == CUFFT_C2C:
 *             execC2C(plan, a.data.ptr, out.data.ptr, direction)
 *         elif self.fft_type == CUFFT_R2C:             # <<<<<<<<<<<<<<
 *             execR2C(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_C2R:
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_C2R:

    /* "cupy/cuda/cufft.pyx":582
 *             execR2C(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_C2R:
 *             execC2R(plan, a.data.ptr, out.data.ptr)             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_Z2Z:
 *             execZ2Z(plan, a.data.ptr, out.data.ptr, direction)
*/
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 582, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 582, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_1 = PyLong_AsSsize_t(__pyx_t_2); if (unlikely((__pyx_t_1 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 582, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 582, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 582, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_7 = PyLong_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_7 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 582, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __pyx_f_4cupy_4cuda_5cufft_execC2R(__pyx_v_plan, __pyx_t_1, __pyx_t_7, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 582, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "cupy/cuda/cufft.pyx":581
 *         elif self.fft_type == CUFFT_R2C:
 *             execR2C(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_C2R:             # <<<<<<<<<<<<<<
 *             execC2R(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_Z2Z:
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_Z2Z:

    /* "cupy/cuda/cufft.pyx":584
 *             execC2R(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_Z2Z:
 *             execZ2Z(plan, a.data.ptr, out.data.ptr, direction)             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_D2Z:
 *             execD2Z(plan, a.data.ptr, out.data.ptr)
*/
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 584, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 584, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_7 = PyLong_AsSsize_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 584, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 584, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 584, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_1 = PyLong_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_1 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 584, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_8 = __Pyx_PyLong_As_int(__pyx_v_direction); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 584, __pyx_L1_error)
    __pyx_t_5 = __pyx_f_4cupy_4cuda_5cufft_execZ2Z(__pyx_v_plan, __pyx_t_7, __pyx_t_1, __pyx_t_8, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 584, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "cupy/cuda/cufft.pyx":583
 *         elif self.fft_type == CUFFT_C2R:
 *             execC2R(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_Z2Z:             # <<<<<<<<<<<<<<
 *             execZ2Z(plan, a.data.ptr, out.data.ptr, direction)
 *         elif self.fft_type == CUFFT_D2Z:
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_D2Z:

    /* "cupy/cuda/cufft.pyx":586
 *             execZ2Z(plan, a.data.ptr, out.data.ptr, direction)
 *         elif self.fft_type == CUFFT_D2Z:
 *             execD2Z(plan, a.data.ptr, out.data.ptr)             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_Z2D:
 *             execZ2D(plan, a.data.ptr, out.data.ptr)
*/
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 586, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 586, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_1 = PyLong_AsSsize_t(__pyx_t_2); if (unlikely((__pyx_t_1 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 586, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 586, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 586, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_7 = PyLong_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_7 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 586, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __pyx_f_4cupy_4cuda_5cufft_execD2Z(__pyx_v_plan, __pyx_t_1, __pyx_t_7, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 586, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "cupy/cuda/cufft.pyx":585
 *         elif self.fft_type == CUFFT_Z2Z:
 *             execZ2Z(plan, a.data.ptr, out.data.ptr, direction)
 *         elif self.fft_type == CUFFT_D2Z:             # <<<<<<<<<<<<<<
 *             execD2Z(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_Z2D:
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_Z2D:

    /* "cupy/cuda/cufft.pyx":588
 *             execD2Z(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_Z2D:
 *             execZ2D(plan, a.data.ptr, out.data.ptr)             # <<<<<<<<<<<<<<
 *         else:
 *             raise ValueError
*/
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 588, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 588, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_7 = PyLong_AsSsize_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 588, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 588, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 588, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_1 = PyLong_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_1 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 588, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __pyx_f_4cupy_4cuda_5cufft_execZ2D(__pyx_v_plan, __pyx_t_7, __pyx_t_1, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 588, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "cupy/cuda/cufft.pyx":587
 *         elif self.fft_type == CUFFT_D2Z:
 *             execD2Z(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_Z2D:             # <<<<<<<<<<<<<<
 *             execZ2D(plan, a.data.ptr, out.data.ptr)
 *         else:
*/
    break;
    default:

    /* "cupy/cuda/cufft.pyx":590
 *             execZ2D(plan, a.data.ptr, out.data.ptr)
 *         else:
 *             raise ValueError             # <<<<<<<<<<<<<<
 * 
 *     def _multi_gpu_setup_buffer(self, a):
*/
    __Pyx_Raise(__pyx_builtin_ValueError, 0, 0, 0);
    __PYX_ERR(0, 590, __pyx_L1_error)
    break;
  }

  /* "cupy/cuda/cufft.pyx":568
 *             self._single_gpu_fft(a, out, direction)
 * 
 *     def _single_gpu_fft(self, a, out, direction):             # <<<<<<<<<<<<<<
 *         cdef intptr_t plan = self.handle
 *         cdef intptr_t s = stream.get_current_stream().ptr
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d._single_gpu_fft", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":592
 *             raise ValueError
 * 
 *     def _multi_gpu_setup_buffer(self, a):             # <<<<<<<<<<<<<<
 *         cdef XtArrayDesc* xtArr_desc
 *         cdef XtArray* xtArr
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_15_multi_gpu_setup_buffer(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6Plan1d_14_multi_gpu_setup_buffer, "Plan1d._multi_gpu_setup_buffer(self, a)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_15_multi_gpu_setup_buffer(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_a = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[1] = {0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_multi_gpu_setup_buffer (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_a,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 592, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 592, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "_multi_gpu_setup_buffer", 0) < (0)) __PYX_ERR(0, 592, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 1; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("_multi_gpu_setup_buffer", 1, 1, 1, i); __PYX_ERR(0, 592, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 1)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 592, __pyx_L3_error)
    }
    __pyx_v_a = values[0];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_multi_gpu_setup_buffer", 1, 1, 1, __pyx_nargs); __PYX_ERR(0, 592, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d._multi_gpu_setup_buffer", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_14_multi_gpu_setup_buffer(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self), __pyx_v_a);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_14_multi_gpu_setup_buffer(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v_a) {
  cudaXtDesc *__pyx_v_xtArr_desc;
  cudaLibXtDesc *__pyx_v_xtArr;
  intptr_t __pyx_v_ptr;
  PyObject *__pyx_v_xtArr_buffer = 0;
  PyObject *__pyx_v_share = 0;
  PyObject *__pyx_v_sizes = 0;
  int __pyx_v_i;
  int __pyx_v_nGPUs;
  cufftXtSubFormat __pyx_v_fmt;
  int __pyx_8genexpr1__pyx_v_i;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  Py_ssize_t __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  PyObject *(*__pyx_t_12)(PyObject *);
  intptr_t __pyx_t_13;
  cudaXtDesc *__pyx_t_14;
  size_t __pyx_t_15;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_multi_gpu_setup_buffer", 0);

  /* "cupy/cuda/cufft.pyx":605
 *         # in-place transforms, and are re-used (lifetime tied to the plan).
 * 
 *         if isinstance(a, cupy.ndarray) or isinstance(a, numpy.ndarray):             # <<<<<<<<<<<<<<
 *             if self.xtArr == 0 and self.xtArr_buffer is None:
 *                 nGPUs = len(self.gpus)
*/
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_cupy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 605, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ndarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 605, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_a, __pyx_t_3); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 605, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (!__pyx_t_4) {
  } else {
    __pyx_t_1 = __pyx_t_4;
    goto __pyx_L4_bool_binop_done;
  }
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 605, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_ndarray); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 605, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_4 = PyObject_IsInstance(__pyx_v_a, __pyx_t_2); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 605, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_1 = __pyx_t_4;
  __pyx_L4_bool_binop_done:;
  if (likely(__pyx_t_1)) {

    /* "cupy/cuda/cufft.pyx":606
 * 
 *         if isinstance(a, cupy.ndarray) or isinstance(a, numpy.ndarray):
 *             if self.xtArr == 0 and self.xtArr_buffer is None:             # <<<<<<<<<<<<<<
 *                 nGPUs = len(self.gpus)
 * 
*/
    __pyx_t_4 = (__pyx_v_self->xtArr == 0);
    if (__pyx_t_4) {
    } else {
      __pyx_t_1 = __pyx_t_4;
      goto __pyx_L7_bool_binop_done;
    }
    __pyx_t_4 = (__pyx_v_self->xtArr_buffer == ((PyObject*)Py_None));
    __pyx_t_1 = __pyx_t_4;
    __pyx_L7_bool_binop_done:;
    if (__pyx_t_1) {

      /* "cupy/cuda/cufft.pyx":607
 *         if isinstance(a, cupy.ndarray) or isinstance(a, numpy.ndarray):
 *             if self.xtArr == 0 and self.xtArr_buffer is None:
 *                 nGPUs = len(self.gpus)             # <<<<<<<<<<<<<<
 * 
 *                 # this is the rule for distributing the workload
*/
      __pyx_t_2 = __pyx_v_self->gpus;
      __Pyx_INCREF(__pyx_t_2);
      if (unlikely(__pyx_t_2 == Py_None)) {
        PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
        __PYX_ERR(0, 607, __pyx_L1_error)
      }
      __pyx_t_5 = __Pyx_PyList_GET_SIZE(__pyx_t_2); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(0, 607, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_nGPUs = __pyx_t_5;

      /* "cupy/cuda/cufft.pyx":610
 * 
 *                 # this is the rule for distributing the workload
 *                 if self.batch > 1:             # <<<<<<<<<<<<<<
 *                     share = [self.batch // nGPUs] * nGPUs
 *                     for i in range(self.batch % nGPUs):
*/
      __pyx_t_1 = (__pyx_v_self->batch > 1);
      if (__pyx_t_1) {

        /* "cupy/cuda/cufft.pyx":611
 *                 # this is the rule for distributing the workload
 *                 if self.batch > 1:
 *                     share = [self.batch // nGPUs] * nGPUs             # <<<<<<<<<<<<<<
 *                     for i in range(self.batch % nGPUs):
 *                         share[i] += 1
*/
        if (unlikely(__pyx_v_nGPUs == 0)) {
          PyErr_SetString(PyExc_ZeroDivisionError, "integer division or modulo by zero");
          __PYX_ERR(0, 611, __pyx_L1_error)
        }
        else if (sizeof(int) == sizeof(long) && (!(((int)-1) > 0)) && unlikely(__pyx_v_nGPUs == (int)-1)  && unlikely(__Pyx_UNARY_NEG_WOULD_OVERFLOW(__pyx_v_self->batch))) {
          PyErr_SetString(PyExc_OverflowError, "value too large to perform division");
          __PYX_ERR(0, 611, __pyx_L1_error)
        }
        __pyx_t_2 = __Pyx_PyLong_From_int(__Pyx_div_int(__pyx_v_self->batch, __pyx_v_nGPUs, 0)); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 611, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_3 = PyList_New(1 * ((__pyx_v_nGPUs<0) ? 0:__pyx_v_nGPUs)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 611, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        { Py_ssize_t __pyx_temp;
          for (__pyx_temp=0; __pyx_temp < __pyx_v_nGPUs; __pyx_temp++) {
            __Pyx_INCREF(__pyx_t_2);
            __Pyx_GIVEREF(__pyx_t_2);
            if (__Pyx_PyList_SET_ITEM(__pyx_t_3, __pyx_temp, __pyx_t_2) != (0)) __PYX_ERR(0, 611, __pyx_L1_error);
          }
        }
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_v_share = ((PyObject*)__pyx_t_3);
        __pyx_t_3 = 0;

        /* "cupy/cuda/cufft.pyx":612
 *                 if self.batch > 1:
 *                     share = [self.batch // nGPUs] * nGPUs
 *                     for i in range(self.batch % nGPUs):             # <<<<<<<<<<<<<<
 *                         share[i] += 1
 *                 else:
*/
        if (unlikely(__pyx_v_nGPUs == 0)) {
          PyErr_SetString(PyExc_ZeroDivisionError, "integer division or modulo by zero");
          __PYX_ERR(0, 612, __pyx_L1_error)
        }
        __pyx_t_6 = __Pyx_mod_int(__pyx_v_self->batch, __pyx_v_nGPUs, 0);
        __pyx_t_7 = __pyx_t_6;
        for (__pyx_t_8 = 0; __pyx_t_8 < __pyx_t_7; __pyx_t_8+=1) {
          __pyx_v_i = __pyx_t_8;

          /* "cupy/cuda/cufft.pyx":613
 *                     share = [self.batch // nGPUs] * nGPUs
 *                     for i in range(self.batch % nGPUs):
 *                         share[i] += 1             # <<<<<<<<<<<<<<
 *                 else:
 *                     share = [1.0 / nGPUs] * nGPUs
*/
          __pyx_t_9 = __pyx_v_i;
          __pyx_t_3 = __Pyx_GetItemInt_List(__pyx_v_share, __pyx_t_9, int, 1, __Pyx_PyLong_From_int, 1, 1, 1, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 613, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
          __pyx_t_2 = __Pyx_PyLong_AddObjC(__pyx_t_3, __pyx_mstate_global->__pyx_int_1, 1, 1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 613, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          if (unlikely((__Pyx_SetItemInt(__pyx_v_share, __pyx_t_9, __pyx_t_2, int, 1, __Pyx_PyLong_From_int, 1, 1, 1, 1) < 0))) __PYX_ERR(0, 613, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        }

        /* "cupy/cuda/cufft.pyx":610
 * 
 *                 # this is the rule for distributing the workload
 *                 if self.batch > 1:             # <<<<<<<<<<<<<<
 *                     share = [self.batch // nGPUs] * nGPUs
 *                     for i in range(self.batch % nGPUs):
*/
        goto __pyx_L9;
      }

      /* "cupy/cuda/cufft.pyx":615
 *                         share[i] += 1
 *                 else:
 *                     share = [1.0 / nGPUs] * nGPUs             # <<<<<<<<<<<<<<
 *                 sizes = [int(share[i] * self.nx * a.dtype.itemsize)
 *                          for i in range(nGPUs)]
*/
      /*else*/ {
        if (unlikely(__pyx_v_nGPUs == 0)) {
          PyErr_SetString(PyExc_ZeroDivisionError, "float division");
          __PYX_ERR(0, 615, __pyx_L1_error)
        }
        __pyx_t_2 = PyFloat_FromDouble((1.0 / ((double)__pyx_v_nGPUs))); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 615, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_3 = PyList_New(1 * ((__pyx_v_nGPUs<0) ? 0:__pyx_v_nGPUs)); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 615, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        { Py_ssize_t __pyx_temp;
          for (__pyx_temp=0; __pyx_temp < __pyx_v_nGPUs; __pyx_temp++) {
            __Pyx_INCREF(__pyx_t_2);
            __Pyx_GIVEREF(__pyx_t_2);
            if (__Pyx_PyList_SET_ITEM(__pyx_t_3, __pyx_temp, __pyx_t_2) != (0)) __PYX_ERR(0, 615, __pyx_L1_error);
          }
        }
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_v_share = ((PyObject*)__pyx_t_3);
        __pyx_t_3 = 0;
      }
      __pyx_L9:;

      /* "cupy/cuda/cufft.pyx":616
 *                 else:
 *                     share = [1.0 / nGPUs] * nGPUs
 *                 sizes = [int(share[i] * self.nx * a.dtype.itemsize)             # <<<<<<<<<<<<<<
 *                          for i in range(nGPUs)]
 * 
*/
      { /* enter inner scope */
        __pyx_t_3 = PyList_New(0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 616, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);

        /* "cupy/cuda/cufft.pyx":617
 *                     share = [1.0 / nGPUs] * nGPUs
 *                 sizes = [int(share[i] * self.nx * a.dtype.itemsize)
 *                          for i in range(nGPUs)]             # <<<<<<<<<<<<<<
 * 
 *                 # get buffer
*/
        __pyx_t_6 = __pyx_v_nGPUs;
        __pyx_t_7 = __pyx_t_6;
        for (__pyx_t_8 = 0; __pyx_t_8 < __pyx_t_7; __pyx_t_8+=1) {
          __pyx_8genexpr1__pyx_v_i = __pyx_t_8;

          /* "cupy/cuda/cufft.pyx":616
 *                 else:
 *                     share = [1.0 / nGPUs] * nGPUs
 *                 sizes = [int(share[i] * self.nx * a.dtype.itemsize)             # <<<<<<<<<<<<<<
 *                          for i in range(nGPUs)]
 * 
*/
          __pyx_t_2 = __Pyx_GetItemInt_List(__pyx_v_share, __pyx_8genexpr1__pyx_v_i, int, 1, __Pyx_PyLong_From_int, 1, 1, 1, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 616, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __pyx_t_10 = __Pyx_PyLong_From_int(__pyx_v_self->nx); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 616, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_10);
          __pyx_t_11 = PyNumber_Multiply(__pyx_t_2, __pyx_t_10); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 616, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_11);
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_dtype); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 616, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_10);
          __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_mstate_global->__pyx_n_u_itemsize); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 616, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          __pyx_t_10 = PyNumber_Multiply(__pyx_t_11, __pyx_t_2); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 616, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_10);
          __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          __pyx_t_2 = __Pyx_PyNumber_Int(__pyx_t_10); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 616, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          if (unlikely(__Pyx_ListComp_Append(__pyx_t_3, (PyObject*)__pyx_t_2))) __PYX_ERR(0, 616, __pyx_L1_error)
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        }
      } /* exit inner scope */
      __pyx_v_sizes = ((PyObject*)__pyx_t_3);
      __pyx_t_3 = 0;

      /* "cupy/cuda/cufft.pyx":620
 * 
 *                 # get buffer
 *                 if isinstance(a, cupy.ndarray):             # <<<<<<<<<<<<<<
 *                     fmt = CUFFT_XT_FORMAT_INPLACE
 *                 else:  # from numpy
*/
      __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_cupy); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 620, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_ndarray); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 620, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_1 = PyObject_IsInstance(__pyx_v_a, __pyx_t_2); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 620, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (__pyx_t_1) {

        /* "cupy/cuda/cufft.pyx":621
 *                 # get buffer
 *                 if isinstance(a, cupy.ndarray):
 *                     fmt = CUFFT_XT_FORMAT_INPLACE             # <<<<<<<<<<<<<<
 *                 else:  # from numpy
 *                     fmt = CUFFT_XT_FORMAT_1D_INPUT_SHUFFLED
*/
        __pyx_v_fmt = CUFFT_XT_FORMAT_INPLACE;

        /* "cupy/cuda/cufft.pyx":620
 * 
 *                 # get buffer
 *                 if isinstance(a, cupy.ndarray):             # <<<<<<<<<<<<<<
 *                     fmt = CUFFT_XT_FORMAT_INPLACE
 *                 else:  # from numpy
*/
        goto __pyx_L14;
      }

      /* "cupy/cuda/cufft.pyx":623
 *                     fmt = CUFFT_XT_FORMAT_INPLACE
 *                 else:  # from numpy
 *                     fmt = CUFFT_XT_FORMAT_1D_INPUT_SHUFFLED             # <<<<<<<<<<<<<<
 *                 ptr, xtArr_buffer = _XtMalloc(self.gpus, sizes, fmt)
 * 
*/
      /*else*/ {
        __pyx_v_fmt = CUFFT_XT_FORMAT_1D_INPUT_SHUFFLED;
      }
      __pyx_L14:;

      /* "cupy/cuda/cufft.pyx":624
 *                 else:  # from numpy
 *                     fmt = CUFFT_XT_FORMAT_1D_INPUT_SHUFFLED
 *                 ptr, xtArr_buffer = _XtMalloc(self.gpus, sizes, fmt)             # <<<<<<<<<<<<<<
 * 
 *                 xtArr = <XtArray*>ptr
*/
      __pyx_t_2 = __pyx_v_self->gpus;
      __Pyx_INCREF(__pyx_t_2);
      __pyx_t_3 = __pyx_f_4cupy_4cuda_5cufft__XtMalloc(((PyObject*)__pyx_t_2), __pyx_v_sizes, __pyx_v_fmt); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 624, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if ((likely(PyTuple_CheckExact(__pyx_t_3))) || (PyList_CheckExact(__pyx_t_3))) {
        PyObject* sequence = __pyx_t_3;
        Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
        if (unlikely(size != 2)) {
          if (size > 2) __Pyx_RaiseTooManyValuesError(2);
          else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
          __PYX_ERR(0, 624, __pyx_L1_error)
        }
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        if (likely(PyTuple_CheckExact(sequence))) {
          __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0);
          __Pyx_INCREF(__pyx_t_2);
          __pyx_t_10 = PyTuple_GET_ITEM(sequence, 1);
          __Pyx_INCREF(__pyx_t_10);
        } else {
          __pyx_t_2 = __Pyx_PyList_GetItemRef(sequence, 0);
          if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 624, __pyx_L1_error)
          __Pyx_XGOTREF(__pyx_t_2);
          __pyx_t_10 = __Pyx_PyList_GetItemRef(sequence, 1);
          if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 624, __pyx_L1_error)
          __Pyx_XGOTREF(__pyx_t_10);
        }
        #else
        __pyx_t_2 = __Pyx_PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 624, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_10 = __Pyx_PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 624, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        #endif
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      } else {
        Py_ssize_t index = -1;
        __pyx_t_11 = PyObject_GetIter(__pyx_t_3); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 624, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_11);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_12 = (CYTHON_COMPILING_IN_LIMITED_API) ? PyIter_Next : __Pyx_PyObject_GetIterNextFunc(__pyx_t_11);
        index = 0; __pyx_t_2 = __pyx_t_12(__pyx_t_11); if (unlikely(!__pyx_t_2)) goto __pyx_L15_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_2);
        index = 1; __pyx_t_10 = __pyx_t_12(__pyx_t_11); if (unlikely(!__pyx_t_10)) goto __pyx_L15_unpacking_failed;
        __Pyx_GOTREF(__pyx_t_10);
        if (__Pyx_IternextUnpackEndCheck(__pyx_t_12(__pyx_t_11), 2) < (0)) __PYX_ERR(0, 624, __pyx_L1_error)
        __pyx_t_12 = NULL;
        __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
        goto __pyx_L16_unpacking_done;
        __pyx_L15_unpacking_failed:;
        __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
        __pyx_t_12 = NULL;
        if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
        __PYX_ERR(0, 624, __pyx_L1_error)
        __pyx_L16_unpacking_done:;
      }
      __pyx_t_13 = PyLong_AsSsize_t(__pyx_t_2); if (unlikely((__pyx_t_13 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 624, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (!(likely(PyList_CheckExact(__pyx_t_10))||((__pyx_t_10) == Py_None) || __Pyx_RaiseUnexpectedTypeError("list", __pyx_t_10))) __PYX_ERR(0, 624, __pyx_L1_error)
      __pyx_v_ptr = __pyx_t_13;
      __pyx_v_xtArr_buffer = ((PyObject*)__pyx_t_10);
      __pyx_t_10 = 0;

      /* "cupy/cuda/cufft.pyx":626
 *                 ptr, xtArr_buffer = _XtMalloc(self.gpus, sizes, fmt)
 * 
 *                 xtArr = <XtArray*>ptr             # <<<<<<<<<<<<<<
 *                 xtArr_desc = xtArr.descriptor
 *                 assert xtArr_desc.nGPUs == nGPUs
*/
      __pyx_v_xtArr = ((cudaLibXtDesc *)__pyx_v_ptr);

      /* "cupy/cuda/cufft.pyx":627
 * 
 *                 xtArr = <XtArray*>ptr
 *                 xtArr_desc = xtArr.descriptor             # <<<<<<<<<<<<<<
 *                 assert xtArr_desc.nGPUs == nGPUs
 * 
*/
      __pyx_t_14 = __pyx_v_xtArr->descriptor;
      __pyx_v_xtArr_desc = __pyx_t_14;

      /* "cupy/cuda/cufft.pyx":628
 *                 xtArr = <XtArray*>ptr
 *                 xtArr_desc = xtArr.descriptor
 *                 assert xtArr_desc.nGPUs == nGPUs             # <<<<<<<<<<<<<<
 * 
 *                 self.batch_share = share
*/
      #ifndef CYTHON_WITHOUT_ASSERTIONS
      if (unlikely(__pyx_assertions_enabled())) {
        __pyx_t_1 = (__pyx_v_xtArr_desc->nGPUs == __pyx_v_nGPUs);
        if (unlikely(!__pyx_t_1)) {
          __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
          __PYX_ERR(0, 628, __pyx_L1_error)
        }
      }
      #else
      if ((1)); else __PYX_ERR(0, 628, __pyx_L1_error)
      #endif

      /* "cupy/cuda/cufft.pyx":630
 *                 assert xtArr_desc.nGPUs == nGPUs
 * 
 *                 self.batch_share = share             # <<<<<<<<<<<<<<
 *                 self.xtArr = ptr
 *                 self.xtArr_buffer = xtArr_buffer  # kept to ensure lifetime
*/
      __Pyx_INCREF(__pyx_v_share);
      __Pyx_GIVEREF(__pyx_v_share);
      __Pyx_GOTREF(__pyx_v_self->batch_share);
      __Pyx_DECREF(__pyx_v_self->batch_share);
      __pyx_v_self->batch_share = __pyx_v_share;

      /* "cupy/cuda/cufft.pyx":631
 * 
 *                 self.batch_share = share
 *                 self.xtArr = ptr             # <<<<<<<<<<<<<<
 *                 self.xtArr_buffer = xtArr_buffer  # kept to ensure lifetime
 *             else:
*/
      __pyx_v_self->xtArr = __pyx_v_ptr;

      /* "cupy/cuda/cufft.pyx":632
 *                 self.batch_share = share
 *                 self.xtArr = ptr
 *                 self.xtArr_buffer = xtArr_buffer  # kept to ensure lifetime             # <<<<<<<<<<<<<<
 *             else:
 *                 # After FFT the subFormat flag is silently changed to
*/
      __Pyx_INCREF(__pyx_v_xtArr_buffer);
      __Pyx_GIVEREF(__pyx_v_xtArr_buffer);
      __Pyx_GOTREF(__pyx_v_self->xtArr_buffer);
      __Pyx_DECREF(__pyx_v_self->xtArr_buffer);
      __pyx_v_self->xtArr_buffer = __pyx_v_xtArr_buffer;

      /* "cupy/cuda/cufft.pyx":606
 * 
 *         if isinstance(a, cupy.ndarray) or isinstance(a, numpy.ndarray):
 *             if self.xtArr == 0 and self.xtArr_buffer is None:             # <<<<<<<<<<<<<<
 *                 nGPUs = len(self.gpus)
 * 
*/
      goto __pyx_L6;
    }

    /* "cupy/cuda/cufft.pyx":638
 *                 # it, otherwise in the next run we would encounter
 *                 # CUFFT_INVALID_TYPE!
 *                 ptr = self.xtArr             # <<<<<<<<<<<<<<
 *                 xtArr = <XtArray*>ptr
 *                 if self.batch == 1:
*/
    /*else*/ {
      __pyx_t_13 = __pyx_v_self->xtArr;
      __pyx_v_ptr = __pyx_t_13;

      /* "cupy/cuda/cufft.pyx":639
 *                 # CUFFT_INVALID_TYPE!
 *                 ptr = self.xtArr
 *                 xtArr = <XtArray*>ptr             # <<<<<<<<<<<<<<
 *                 if self.batch == 1:
 *                     if isinstance(a, cupy.ndarray):
*/
      __pyx_v_xtArr = ((cudaLibXtDesc *)__pyx_v_ptr);

      /* "cupy/cuda/cufft.pyx":640
 *                 ptr = self.xtArr
 *                 xtArr = <XtArray*>ptr
 *                 if self.batch == 1:             # <<<<<<<<<<<<<<
 *                     if isinstance(a, cupy.ndarray):
 *                         fmt = CUFFT_XT_FORMAT_INPLACE
*/
      __pyx_t_1 = (__pyx_v_self->batch == 1);
      if (__pyx_t_1) {

        /* "cupy/cuda/cufft.pyx":641
 *                 xtArr = <XtArray*>ptr
 *                 if self.batch == 1:
 *                     if isinstance(a, cupy.ndarray):             # <<<<<<<<<<<<<<
 *                         fmt = CUFFT_XT_FORMAT_INPLACE
 *                     else:  # from numpy
*/
        __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_cupy); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 641, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_ndarray); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 641, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_1 = PyObject_IsInstance(__pyx_v_a, __pyx_t_10); if (unlikely(__pyx_t_1 == ((int)-1))) __PYX_ERR(0, 641, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        if (__pyx_t_1) {

          /* "cupy/cuda/cufft.pyx":642
 *                 if self.batch == 1:
 *                     if isinstance(a, cupy.ndarray):
 *                         fmt = CUFFT_XT_FORMAT_INPLACE             # <<<<<<<<<<<<<<
 *                     else:  # from numpy
 *                         fmt = CUFFT_XT_FORMAT_1D_INPUT_SHUFFLED
*/
          __pyx_v_fmt = CUFFT_XT_FORMAT_INPLACE;

          /* "cupy/cuda/cufft.pyx":641
 *                 xtArr = <XtArray*>ptr
 *                 if self.batch == 1:
 *                     if isinstance(a, cupy.ndarray):             # <<<<<<<<<<<<<<
 *                         fmt = CUFFT_XT_FORMAT_INPLACE
 *                     else:  # from numpy
*/
          goto __pyx_L18;
        }

        /* "cupy/cuda/cufft.pyx":644
 *                         fmt = CUFFT_XT_FORMAT_INPLACE
 *                     else:  # from numpy
 *                         fmt = CUFFT_XT_FORMAT_1D_INPUT_SHUFFLED             # <<<<<<<<<<<<<<
 *                     xtArr.subFormat = fmt
 *         elif isinstance(a, list):
*/
        /*else*/ {
          __pyx_v_fmt = CUFFT_XT_FORMAT_1D_INPUT_SHUFFLED;
        }
        __pyx_L18:;

        /* "cupy/cuda/cufft.pyx":645
 *                     else:  # from numpy
 *                         fmt = CUFFT_XT_FORMAT_1D_INPUT_SHUFFLED
 *                     xtArr.subFormat = fmt             # <<<<<<<<<<<<<<
 *         elif isinstance(a, list):
 *             # TODO(leofang): For users running Plan1d.fft() (bypassing all
*/
        __pyx_v_xtArr->subFormat = __pyx_v_fmt;

        /* "cupy/cuda/cufft.pyx":640
 *                 ptr = self.xtArr
 *                 xtArr = <XtArray*>ptr
 *                 if self.batch == 1:             # <<<<<<<<<<<<<<
 *                     if isinstance(a, cupy.ndarray):
 *                         fmt = CUFFT_XT_FORMAT_INPLACE
*/
      }
    }
    __pyx_L6:;

    /* "cupy/cuda/cufft.pyx":605
 *         # in-place transforms, and are re-used (lifetime tied to the plan).
 * 
 *         if isinstance(a, cupy.ndarray) or isinstance(a, numpy.ndarray):             # <<<<<<<<<<<<<<
 *             if self.xtArr == 0 and self.xtArr_buffer is None:
 *                 nGPUs = len(self.gpus)
*/
    goto __pyx_L3;
  }

  /* "cupy/cuda/cufft.pyx":646
 *                         fmt = CUFFT_XT_FORMAT_1D_INPUT_SHUFFLED
 *                     xtArr.subFormat = fmt
 *         elif isinstance(a, list):             # <<<<<<<<<<<<<<
 *             # TODO(leofang): For users running Plan1d.fft() (bypassing all
 *             # checks in cupy.fft.fft), they are allowed to send in a list of
*/
  __pyx_t_1 = PyList_Check(__pyx_v_a); 
  if (unlikely(__pyx_t_1)) {

    /* "cupy/cuda/cufft.pyx":651
 *             # ndarrays, each of which is on a different GPU. Then, no data
 *             # copy is needed, just replace the pointers in the descriptor.
 *             raise NotImplementedError('User-managed buffer area is not yet '             # <<<<<<<<<<<<<<
 *                                       'supported.')
 *         else:
*/
    __pyx_t_3 = NULL;
    __Pyx_INCREF(__pyx_builtin_NotImplementedError);
    __pyx_t_2 = __pyx_builtin_NotImplementedError; 
    __pyx_t_15 = 1;
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_3, __pyx_mstate_global->__pyx_kp_u_User_managed_buffer_area_is_not};
      __pyx_t_10 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+__pyx_t_15, (2-__pyx_t_15) | (__pyx_t_15*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 651, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
    }
    __Pyx_Raise(__pyx_t_10, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __PYX_ERR(0, 651, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":646
 *                         fmt = CUFFT_XT_FORMAT_1D_INPUT_SHUFFLED
 *                     xtArr.subFormat = fmt
 *         elif isinstance(a, list):             # <<<<<<<<<<<<<<
 *             # TODO(leofang): For users running Plan1d.fft() (bypassing all
 *             # checks in cupy.fft.fft), they are allowed to send in a list of
*/
  }

  /* "cupy/cuda/cufft.pyx":654
 *                                       'supported.')
 *         else:
 *             raise ValueError('Impossible to reach.')             # <<<<<<<<<<<<<<
 * 
 *     def _multi_gpu_memcpy(self, a, str action):
*/
  /*else*/ {
    __pyx_t_2 = NULL;
    __Pyx_INCREF(__pyx_builtin_ValueError);
    __pyx_t_3 = __pyx_builtin_ValueError; 
    __pyx_t_15 = 1;
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_mstate_global->__pyx_kp_u_Impossible_to_reach};
      __pyx_t_10 = __Pyx_PyObject_FastCall(__pyx_t_3, __pyx_callargs+__pyx_t_15, (2-__pyx_t_15) | (__pyx_t_15*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 654, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
    }
    __Pyx_Raise(__pyx_t_10, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __PYX_ERR(0, 654, __pyx_L1_error)
  }
  __pyx_L3:;

  /* "cupy/cuda/cufft.pyx":592
 *             raise ValueError
 * 
 *     def _multi_gpu_setup_buffer(self, a):             # <<<<<<<<<<<<<<
 *         cdef XtArrayDesc* xtArr_desc
 *         cdef XtArray* xtArr
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d._multi_gpu_setup_buffer", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_xtArr_buffer);
  __Pyx_XDECREF(__pyx_v_share);
  __Pyx_XDECREF(__pyx_v_sizes);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":656
 *             raise ValueError('Impossible to reach.')
 * 
 *     def _multi_gpu_memcpy(self, a, str action):             # <<<<<<<<<<<<<<
 *         cdef Handle plan = <Handle>self.handle
 *         cdef list xtArr_buffer, share
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_17_multi_gpu_memcpy(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6Plan1d_16_multi_gpu_memcpy, "Plan1d._multi_gpu_memcpy(self, a, str action)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_17_multi_gpu_memcpy(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_a = 0;
  PyObject *__pyx_v_action = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[2] = {0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_multi_gpu_memcpy (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_a,&__pyx_mstate_global->__pyx_n_u_action,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 656, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 656, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 656, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "_multi_gpu_memcpy", 0) < (0)) __PYX_ERR(0, 656, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 2; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("_multi_gpu_memcpy", 1, 2, 2, i); __PYX_ERR(0, 656, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 2)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 656, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 656, __pyx_L3_error)
    }
    __pyx_v_a = values[0];
    __pyx_v_action = ((PyObject*)values[1]);
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_multi_gpu_memcpy", 1, 2, 2, __pyx_nargs); __PYX_ERR(0, 656, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d._multi_gpu_memcpy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_action), (&PyUnicode_Type), 1, "action", 1))) __PYX_ERR(0, 656, __pyx_L1_error)
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_16_multi_gpu_memcpy(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self), __pyx_v_a, __pyx_v_action);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  goto __pyx_L7_cleaned_up;
  __pyx_L0:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __pyx_L7_cleaned_up:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_16_multi_gpu_memcpy(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_action) {
  cufftHandle __pyx_v_plan;
  PyObject *__pyx_v_xtArr_buffer = 0;
  PyObject *__pyx_v_share = 0;
  int __pyx_v_nGPUs;
  int __pyx_v_dev;
  int __pyx_v_s_device;
  int __pyx_v_start;
  int __pyx_v_count;
  int __pyx_v_result;
  cudaLibXtDesc *__pyx_v_arr;
  intptr_t __pyx_v_ptr;
  intptr_t __pyx_v_ptr2;
  size_t __pyx_v_size;
  PyObject *__pyx_v_b = NULL;
  PyObject *__pyx_v_outer_stream = NULL;
  PyObject *__pyx_v_curr_stream = NULL;
  PyObject *__pyx_v_curr_event = NULL;
  PyObject *__pyx_v_prev_event = NULL;
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  int __pyx_t_5;
  size_t __pyx_t_6;
  intptr_t __pyx_t_7;
  Py_ssize_t __pyx_t_8;
  int __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  int __pyx_t_11;
  int __pyx_t_12;
  int __pyx_t_13;
  PyObject *__pyx_t_14 = NULL;
  long __pyx_t_15;
  PyObject *(*__pyx_t_16)(PyObject *);
  PyObject *__pyx_t_17 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_multi_gpu_memcpy", 0);

  /* "cupy/cuda/cufft.pyx":657
 * 
 *     def _multi_gpu_memcpy(self, a, str action):
 *         cdef Handle plan = <Handle>self.handle             # <<<<<<<<<<<<<<
 *         cdef list xtArr_buffer, share
 *         cdef int nGPUs, dev, s_device, start, count, result
*/
  __pyx_v_plan = ((cufftHandle)__pyx_v_self->handle);

  /* "cupy/cuda/cufft.pyx":664
 *         cdef size_t size
 * 
 *         assert isinstance(a, (cupy.ndarray, numpy.ndarray))             # <<<<<<<<<<<<<<
 * 
 *         start = 0
*/
  #ifndef CYTHON_WITHOUT_ASSERTIONS
  if (unlikely(__pyx_assertions_enabled())) {
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_cupy); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 664, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_ndarray); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 664, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 664, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_ndarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 664, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_5 = PyObject_IsInstance(__pyx_v_a, __pyx_t_2); 
    if (!__pyx_t_5) {
    } else {
      __pyx_t_4 = __pyx_t_5;
      goto __pyx_L3_bool_binop_done;
    }
    __pyx_t_5 = PyObject_IsInstance(__pyx_v_a, __pyx_t_3); 
    __pyx_t_4 = __pyx_t_5;
    __pyx_L3_bool_binop_done:;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_4)) {
      __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
      __PYX_ERR(0, 664, __pyx_L1_error)
    }
  }
  #else
  if ((1)); else __PYX_ERR(0, 664, __pyx_L1_error)
  #endif

  /* "cupy/cuda/cufft.pyx":666
 *         assert isinstance(a, (cupy.ndarray, numpy.ndarray))
 * 
 *         start = 0             # <<<<<<<<<<<<<<
 *         assert a.flags.c_contiguous  # NumPy does not have _c_contiguous
 *         b = a.ravel()
*/
  __pyx_v_start = 0;

  /* "cupy/cuda/cufft.pyx":667
 * 
 *         start = 0
 *         assert a.flags.c_contiguous  # NumPy does not have _c_contiguous             # <<<<<<<<<<<<<<
 *         b = a.ravel()
 *         assert b.flags['OWNDATA'] is False
*/
  #ifndef CYTHON_WITHOUT_ASSERTIONS
  if (unlikely(__pyx_assertions_enabled())) {
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_flags); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 667, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_c_contiguous); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 667, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 667, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_4)) {
      __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
      __PYX_ERR(0, 667, __pyx_L1_error)
    }
  }
  #else
  if ((1)); else __PYX_ERR(0, 667, __pyx_L1_error)
  #endif

  /* "cupy/cuda/cufft.pyx":668
 *         start = 0
 *         assert a.flags.c_contiguous  # NumPy does not have _c_contiguous
 *         b = a.ravel()             # <<<<<<<<<<<<<<
 *         assert b.flags['OWNDATA'] is False
 *         assert self.xtArr_buffer is not None
*/
  __pyx_t_2 = __pyx_v_a;
  __Pyx_INCREF(__pyx_t_2);
  __pyx_t_6 = 0;
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, NULL};
    __pyx_t_3 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_ravel, __pyx_callargs+__pyx_t_6, (1-__pyx_t_6) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 668, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
  }
  __pyx_v_b = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "cupy/cuda/cufft.pyx":669
 *         assert a.flags.c_contiguous  # NumPy does not have _c_contiguous
 *         b = a.ravel()
 *         assert b.flags['OWNDATA'] is False             # <<<<<<<<<<<<<<
 *         assert self.xtArr_buffer is not None
 *         ptr = self.xtArr
*/
  #ifndef CYTHON_WITHOUT_ASSERTIONS
  if (unlikely(__pyx_assertions_enabled())) {
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_b, __pyx_mstate_global->__pyx_n_u_flags); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 669, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_2 = __Pyx_PyObject_Dict_GetItem(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_OWNDATA); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 669, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_4 = (__pyx_t_2 == Py_False);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_4)) {
      __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
      __PYX_ERR(0, 669, __pyx_L1_error)
    }
  }
  #else
  if ((1)); else __PYX_ERR(0, 669, __pyx_L1_error)
  #endif

  /* "cupy/cuda/cufft.pyx":670
 *         b = a.ravel()
 *         assert b.flags['OWNDATA'] is False
 *         assert self.xtArr_buffer is not None             # <<<<<<<<<<<<<<
 *         ptr = self.xtArr
 *         arr = <XtArray*>ptr
*/
  #ifndef CYTHON_WITHOUT_ASSERTIONS
  if (unlikely(__pyx_assertions_enabled())) {
    __pyx_t_4 = (__pyx_v_self->xtArr_buffer != ((PyObject*)Py_None));
    if (unlikely(!__pyx_t_4)) {
      __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
      __PYX_ERR(0, 670, __pyx_L1_error)
    }
  }
  #else
  if ((1)); else __PYX_ERR(0, 670, __pyx_L1_error)
  #endif

  /* "cupy/cuda/cufft.pyx":671
 *         assert b.flags['OWNDATA'] is False
 *         assert self.xtArr_buffer is not None
 *         ptr = self.xtArr             # <<<<<<<<<<<<<<
 *         arr = <XtArray*>ptr
 *         xtArr_buffer = self.xtArr_buffer
*/
  __pyx_t_7 = __pyx_v_self->xtArr;
  __pyx_v_ptr = __pyx_t_7;

  /* "cupy/cuda/cufft.pyx":672
 *         assert self.xtArr_buffer is not None
 *         ptr = self.xtArr
 *         arr = <XtArray*>ptr             # <<<<<<<<<<<<<<
 *         xtArr_buffer = self.xtArr_buffer
 *         nGPUs = len(self.gpus)
*/
  __pyx_v_arr = ((cudaLibXtDesc *)__pyx_v_ptr);

  /* "cupy/cuda/cufft.pyx":673
 *         ptr = self.xtArr
 *         arr = <XtArray*>ptr
 *         xtArr_buffer = self.xtArr_buffer             # <<<<<<<<<<<<<<
 *         nGPUs = len(self.gpus)
 *         share = self.batch_share
*/
  __pyx_t_2 = __pyx_v_self->xtArr_buffer;
  __Pyx_INCREF(__pyx_t_2);
  __pyx_v_xtArr_buffer = ((PyObject*)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "cupy/cuda/cufft.pyx":674
 *         arr = <XtArray*>ptr
 *         xtArr_buffer = self.xtArr_buffer
 *         nGPUs = len(self.gpus)             # <<<<<<<<<<<<<<
 *         share = self.batch_share
 * 
*/
  __pyx_t_2 = __pyx_v_self->gpus;
  __Pyx_INCREF(__pyx_t_2);
  if (unlikely(__pyx_t_2 == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(0, 674, __pyx_L1_error)
  }
  __pyx_t_8 = __Pyx_PyList_GET_SIZE(__pyx_t_2); if (unlikely(__pyx_t_8 == ((Py_ssize_t)-1))) __PYX_ERR(0, 674, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_nGPUs = __pyx_t_8;

  /* "cupy/cuda/cufft.pyx":675
 *         xtArr_buffer = self.xtArr_buffer
 *         nGPUs = len(self.gpus)
 *         share = self.batch_share             # <<<<<<<<<<<<<<
 * 
 *         if action == 'scatter':
*/
  __pyx_t_2 = __pyx_v_self->batch_share;
  __Pyx_INCREF(__pyx_t_2);
  __pyx_v_share = ((PyObject*)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "cupy/cuda/cufft.pyx":677
 *         share = self.batch_share
 * 
 *         if action == 'scatter':             # <<<<<<<<<<<<<<
 *             if isinstance(a, cupy.ndarray):
 *                 s_device = b.data.device_id
*/
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_v_action, __pyx_mstate_global->__pyx_n_u_scatter, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 677, __pyx_L1_error)
  if (__pyx_t_4) {

    /* "cupy/cuda/cufft.pyx":678
 * 
 *         if action == 'scatter':
 *             if isinstance(a, cupy.ndarray):             # <<<<<<<<<<<<<<
 *                 s_device = b.data.device_id
 *                 if s_device not in self.scatter_streams:
*/
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_cupy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 678, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ndarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 678, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_4 = PyObject_IsInstance(__pyx_v_a, __pyx_t_3); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 678, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (__pyx_t_4) {

      /* "cupy/cuda/cufft.pyx":679
 *         if action == 'scatter':
 *             if isinstance(a, cupy.ndarray):
 *                 s_device = b.data.device_id             # <<<<<<<<<<<<<<
 *                 if s_device not in self.scatter_streams:
 *                     self._multi_gpu_get_scatter_streams_events(s_device)
*/
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_b, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 679, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_device_id); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 679, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_9 = __Pyx_PyLong_As_int(__pyx_t_2); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 679, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_v_s_device = __pyx_t_9;

      /* "cupy/cuda/cufft.pyx":680
 *             if isinstance(a, cupy.ndarray):
 *                 s_device = b.data.device_id
 *                 if s_device not in self.scatter_streams:             # <<<<<<<<<<<<<<
 *                     self._multi_gpu_get_scatter_streams_events(s_device)
 * 
*/
      __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_v_s_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 680, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      if (unlikely(__pyx_v_self->scatter_streams == Py_None)) {
        PyErr_SetString(PyExc_TypeError, "'NoneType' object is not iterable");
        __PYX_ERR(0, 680, __pyx_L1_error)
      }
      __pyx_t_4 = (__Pyx_PyDict_ContainsTF(__pyx_t_2, __pyx_v_self->scatter_streams, Py_NE)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 680, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (__pyx_t_4) {

        /* "cupy/cuda/cufft.pyx":681
 *                 s_device = b.data.device_id
 *                 if s_device not in self.scatter_streams:
 *                     self._multi_gpu_get_scatter_streams_events(s_device)             # <<<<<<<<<<<<<<
 * 
 *                 # When we come here, another stream could still be
*/
        __pyx_t_3 = ((PyObject *)__pyx_v_self);
        __Pyx_INCREF(__pyx_t_3);
        __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_s_device); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 681, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_6 = 0;
        {
          PyObject *__pyx_callargs[2] = {__pyx_t_3, __pyx_t_1};
          __pyx_t_2 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_multi_gpu_get_scatter_streams_e, __pyx_callargs+__pyx_t_6, (2-__pyx_t_6) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
          __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 681, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
        }
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

        /* "cupy/cuda/cufft.pyx":680
 *             if isinstance(a, cupy.ndarray):
 *                 s_device = b.data.device_id
 *                 if s_device not in self.scatter_streams:             # <<<<<<<<<<<<<<
 *                     self._multi_gpu_get_scatter_streams_events(s_device)
 * 
*/
      }

      /* "cupy/cuda/cufft.pyx":685
 *                 # When we come here, another stream could still be
 *                 # copying data for us, so we wait patiently...
 *                 outer_stream = stream.get_current_stream()             # <<<<<<<<<<<<<<
 *                 outer_stream.synchronize()
 * 
*/
      __pyx_t_1 = NULL;
      __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_stream); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 685, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_get_current_stream); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 685, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_6 = 1;
      #if CYTHON_UNPACK_METHODS
      if (unlikely(PyMethod_Check(__pyx_t_10))) {
        __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_10);
        assert(__pyx_t_1);
        PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_10);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(__pyx__function);
        __Pyx_DECREF_SET(__pyx_t_10, __pyx__function);
        __pyx_t_6 = 0;
      }
      #endif
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_1, NULL};
        __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_10, __pyx_callargs+__pyx_t_6, (1-__pyx_t_6) | (__pyx_t_6*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 685, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      }
      __pyx_v_outer_stream = __pyx_t_2;
      __pyx_t_2 = 0;

      /* "cupy/cuda/cufft.pyx":686
 *                 # copying data for us, so we wait patiently...
 *                 outer_stream = stream.get_current_stream()
 *                 outer_stream.synchronize()             # <<<<<<<<<<<<<<
 * 
 *                 for dev in range(nGPUs):
*/
      __pyx_t_10 = __pyx_v_outer_stream;
      __Pyx_INCREF(__pyx_t_10);
      __pyx_t_6 = 0;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_10, NULL};
        __pyx_t_2 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_synchronize, __pyx_callargs+__pyx_t_6, (1-__pyx_t_6) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 686, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

      /* "cupy/cuda/cufft.pyx":688
 *                 outer_stream.synchronize()
 * 
 *                 for dev in range(nGPUs):             # <<<<<<<<<<<<<<
 *                     count = int(share[dev] * self.nx)
 *                     size = count * b.dtype.itemsize
*/
      __pyx_t_9 = __pyx_v_nGPUs;
      __pyx_t_11 = __pyx_t_9;
      for (__pyx_t_12 = 0; __pyx_t_12 < __pyx_t_11; __pyx_t_12+=1) {
        __pyx_v_dev = __pyx_t_12;

        /* "cupy/cuda/cufft.pyx":689
 * 
 *                 for dev in range(nGPUs):
 *                     count = int(share[dev] * self.nx)             # <<<<<<<<<<<<<<
 *                     size = count * b.dtype.itemsize
 *                     curr_stream = self.scatter_streams[s_device][dev]
*/
        if (unlikely(__pyx_v_share == Py_None)) {
          PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
          __PYX_ERR(0, 689, __pyx_L1_error)
        }
        __pyx_t_2 = __Pyx_GetItemInt_List(__pyx_v_share, __pyx_v_dev, int, 1, __Pyx_PyLong_From_int, 1, 1, 1, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 689, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_10 = __Pyx_PyLong_From_int(__pyx_v_self->nx); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 689, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        __pyx_t_1 = PyNumber_Multiply(__pyx_t_2, __pyx_t_10); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 689, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        __pyx_t_10 = __Pyx_PyNumber_Int(__pyx_t_1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 689, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_13 = __Pyx_PyLong_As_int(__pyx_t_10); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 689, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        __pyx_v_count = __pyx_t_13;

        /* "cupy/cuda/cufft.pyx":690
 *                 for dev in range(nGPUs):
 *                     count = int(share[dev] * self.nx)
 *                     size = count * b.dtype.itemsize             # <<<<<<<<<<<<<<
 *                     curr_stream = self.scatter_streams[s_device][dev]
 *                     curr_event = self.scatter_events[s_device][dev]
*/
        __pyx_t_10 = __Pyx_PyLong_From_int(__pyx_v_count); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 690, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_b, __pyx_mstate_global->__pyx_n_u_dtype); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 690, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_itemsize); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 690, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_1 = PyNumber_Multiply(__pyx_t_10, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 690, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_6 = __Pyx_PyLong_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 690, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_v_size = __pyx_t_6;

        /* "cupy/cuda/cufft.pyx":691
 *                     count = int(share[dev] * self.nx)
 *                     size = count * b.dtype.itemsize
 *                     curr_stream = self.scatter_streams[s_device][dev]             # <<<<<<<<<<<<<<
 *                     curr_event = self.scatter_events[s_device][dev]
 *                     xtArr_buffer[dev].copy_from_device_async(
*/
        if (unlikely(__pyx_v_self->scatter_streams == Py_None)) {
          PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
          __PYX_ERR(0, 691, __pyx_L1_error)
        }
        __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_s_device); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 691, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_2 = __Pyx_PyDict_GetItem(__pyx_v_self->scatter_streams, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 691, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, __pyx_v_dev, int, 1, __Pyx_PyLong_From_int, 0, 1, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 691, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_XDECREF_SET(__pyx_v_curr_stream, __pyx_t_1);
        __pyx_t_1 = 0;

        /* "cupy/cuda/cufft.pyx":692
 *                     size = count * b.dtype.itemsize
 *                     curr_stream = self.scatter_streams[s_device][dev]
 *                     curr_event = self.scatter_events[s_device][dev]             # <<<<<<<<<<<<<<
 *                     xtArr_buffer[dev].copy_from_device_async(
 *                         b[start:start+count].data, size, curr_stream)
*/
        if (unlikely(__pyx_v_self->scatter_events == Py_None)) {
          PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
          __PYX_ERR(0, 692, __pyx_L1_error)
        }
        __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_s_device); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 692, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_2 = __Pyx_PyDict_GetItem(__pyx_v_self->scatter_events, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 692, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, __pyx_v_dev, int, 1, __Pyx_PyLong_From_int, 0, 1, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 692, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_XDECREF_SET(__pyx_v_curr_event, __pyx_t_1);
        __pyx_t_1 = 0;

        /* "cupy/cuda/cufft.pyx":693
 *                     curr_stream = self.scatter_streams[s_device][dev]
 *                     curr_event = self.scatter_events[s_device][dev]
 *                     xtArr_buffer[dev].copy_from_device_async(             # <<<<<<<<<<<<<<
 *                         b[start:start+count].data, size, curr_stream)
 *                     if dev != 0:
*/
        if (unlikely(__pyx_v_xtArr_buffer == Py_None)) {
          PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
          __PYX_ERR(0, 693, __pyx_L1_error)
        }
        __pyx_t_10 = __Pyx_GetItemInt_List(__pyx_v_xtArr_buffer, __pyx_v_dev, int, 1, __Pyx_PyLong_From_int, 1, 1, 1, 1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 693, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        __pyx_t_2 = __pyx_t_10;
        __Pyx_INCREF(__pyx_t_2);

        /* "cupy/cuda/cufft.pyx":694
 *                     curr_event = self.scatter_events[s_device][dev]
 *                     xtArr_buffer[dev].copy_from_device_async(
 *                         b[start:start+count].data, size, curr_stream)             # <<<<<<<<<<<<<<
 *                     if dev != 0:
 *                         prev_event = self.scatter_events[s_device][dev-1]
*/
        __pyx_t_3 = __Pyx_PyObject_GetSlice(__pyx_v_b, __pyx_v_start, (__pyx_v_start + __pyx_v_count), NULL, NULL, NULL, 1, 1, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 694, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_14 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 694, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_14);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_3 = __Pyx_PyLong_FromSize_t(__pyx_v_size); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 694, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_6 = 0;
        {
          PyObject *__pyx_callargs[4] = {__pyx_t_2, __pyx_t_14, __pyx_t_3, __pyx_v_curr_stream};
          __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_copy_from_device_async, __pyx_callargs+__pyx_t_6, (4-__pyx_t_6) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
          __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
          __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 693, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
        }
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

        /* "cupy/cuda/cufft.pyx":695
 *                     xtArr_buffer[dev].copy_from_device_async(
 *                         b[start:start+count].data, size, curr_stream)
 *                     if dev != 0:             # <<<<<<<<<<<<<<
 *                         prev_event = self.scatter_events[s_device][dev-1]
 *                         curr_stream.wait_event(prev_event)
*/
        __pyx_t_4 = (__pyx_v_dev != 0);
        if (__pyx_t_4) {

          /* "cupy/cuda/cufft.pyx":696
 *                         b[start:start+count].data, size, curr_stream)
 *                     if dev != 0:
 *                         prev_event = self.scatter_events[s_device][dev-1]             # <<<<<<<<<<<<<<
 *                         curr_stream.wait_event(prev_event)
 *                     curr_event.record(curr_stream)
*/
          if (unlikely(__pyx_v_self->scatter_events == Py_None)) {
            PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
            __PYX_ERR(0, 696, __pyx_L1_error)
          }
          __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_s_device); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 696, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __pyx_t_10 = __Pyx_PyDict_GetItem(__pyx_v_self->scatter_events, __pyx_t_1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 696, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_10);
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
          __pyx_t_15 = (__pyx_v_dev - 1);
          __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_10, __pyx_t_15, long, 1, __Pyx_PyLong_From_long, 0, 1, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 696, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          __Pyx_XDECREF_SET(__pyx_v_prev_event, __pyx_t_1);
          __pyx_t_1 = 0;

          /* "cupy/cuda/cufft.pyx":697
 *                     if dev != 0:
 *                         prev_event = self.scatter_events[s_device][dev-1]
 *                         curr_stream.wait_event(prev_event)             # <<<<<<<<<<<<<<
 *                     curr_event.record(curr_stream)
 *                     start += count
*/
          __pyx_t_10 = __pyx_v_curr_stream;
          __Pyx_INCREF(__pyx_t_10);
          __pyx_t_6 = 0;
          {
            PyObject *__pyx_callargs[2] = {__pyx_t_10, __pyx_v_prev_event};
            __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_wait_event, __pyx_callargs+__pyx_t_6, (2-__pyx_t_6) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
            __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
            if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 697, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_1);
          }
          __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

          /* "cupy/cuda/cufft.pyx":695
 *                     xtArr_buffer[dev].copy_from_device_async(
 *                         b[start:start+count].data, size, curr_stream)
 *                     if dev != 0:             # <<<<<<<<<<<<<<
 *                         prev_event = self.scatter_events[s_device][dev-1]
 *                         curr_stream.wait_event(prev_event)
*/
        }

        /* "cupy/cuda/cufft.pyx":698
 *                         prev_event = self.scatter_events[s_device][dev-1]
 *                         curr_stream.wait_event(prev_event)
 *                     curr_event.record(curr_stream)             # <<<<<<<<<<<<<<
 *                     start += count
 *                 assert start == b.size
*/
        __pyx_t_10 = __pyx_v_curr_event;
        __Pyx_INCREF(__pyx_t_10);
        __pyx_t_6 = 0;
        {
          PyObject *__pyx_callargs[2] = {__pyx_t_10, __pyx_v_curr_stream};
          __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_record, __pyx_callargs+__pyx_t_6, (2-__pyx_t_6) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
          __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
          if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 698, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_1);
        }
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

        /* "cupy/cuda/cufft.pyx":699
 *                         curr_stream.wait_event(prev_event)
 *                     curr_event.record(curr_stream)
 *                     start += count             # <<<<<<<<<<<<<<
 *                 assert start == b.size
 *                 self.scatter_events[s_device][-1].synchronize()
*/
        __pyx_v_start = (__pyx_v_start + __pyx_v_count);
      }

      /* "cupy/cuda/cufft.pyx":700
 *                     curr_event.record(curr_stream)
 *                     start += count
 *                 assert start == b.size             # <<<<<<<<<<<<<<
 *                 self.scatter_events[s_device][-1].synchronize()
 *             else:  # numpy
*/
      #ifndef CYTHON_WITHOUT_ASSERTIONS
      if (unlikely(__pyx_assertions_enabled())) {
        __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_start); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 700, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_v_b, __pyx_mstate_global->__pyx_n_u_size); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 700, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        __pyx_t_3 = PyObject_RichCompare(__pyx_t_1, __pyx_t_10, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 700, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 700, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        if (unlikely(!__pyx_t_4)) {
          __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
          __PYX_ERR(0, 700, __pyx_L1_error)
        }
      }
      #else
      if ((1)); else __PYX_ERR(0, 700, __pyx_L1_error)
      #endif

      /* "cupy/cuda/cufft.pyx":701
 *                     start += count
 *                 assert start == b.size
 *                 self.scatter_events[s_device][-1].synchronize()             # <<<<<<<<<<<<<<
 *             else:  # numpy
 *                 ptr2 = b.ctypes.data
*/
      if (unlikely(__pyx_v_self->scatter_events == Py_None)) {
        PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
        __PYX_ERR(0, 701, __pyx_L1_error)
      }
      __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_s_device); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 701, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_14 = __Pyx_PyDict_GetItem(__pyx_v_self->scatter_events, __pyx_t_1); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 701, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_14);
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_14, -1L, long, 1, __Pyx_PyLong_From_long, 0, 1, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 701, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
      __pyx_t_10 = __pyx_t_1;
      __Pyx_INCREF(__pyx_t_10);
      __pyx_t_6 = 0;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_10, NULL};
        __pyx_t_3 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_synchronize, __pyx_callargs+__pyx_t_6, (1-__pyx_t_6) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 701, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
      }
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "cupy/cuda/cufft.pyx":678
 * 
 *         if action == 'scatter':
 *             if isinstance(a, cupy.ndarray):             # <<<<<<<<<<<<<<
 *                 s_device = b.data.device_id
 *                 if s_device not in self.scatter_streams:
*/
      goto __pyx_L6;
    }

    /* "cupy/cuda/cufft.pyx":703
 *                 self.scatter_events[s_device][-1].synchronize()
 *             else:  # numpy
 *                 ptr2 = b.ctypes.data             # <<<<<<<<<<<<<<
 *                 with nogil:
 *                     result = cufftXtMemcpy(
*/
    /*else*/ {
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_b, __pyx_mstate_global->__pyx_n_u_ctypes); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 703, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 703, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_7 = PyLong_AsSsize_t(__pyx_t_1); if (unlikely((__pyx_t_7 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 703, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_ptr2 = __pyx_t_7;

      /* "cupy/cuda/cufft.pyx":704
 *             else:  # numpy
 *                 ptr2 = b.ctypes.data
 *                 with nogil:             # <<<<<<<<<<<<<<
 *                     result = cufftXtMemcpy(
 *                         plan, <void*>arr, <void*>ptr2,
*/
      {
          PyThreadState *_save;
          _save = NULL;
          Py_UNBLOCK_THREADS
          __Pyx_FastGIL_Remember();
          /*try:*/ {

            /* "cupy/cuda/cufft.pyx":705
 *                 ptr2 = b.ctypes.data
 *                 with nogil:
 *                     result = cufftXtMemcpy(             # <<<<<<<<<<<<<<
 *                         plan, <void*>arr, <void*>ptr2,
 *                         CUFFT_COPY_HOST_TO_DEVICE)
*/
            __pyx_v_result = cufftXtMemcpy(__pyx_v_plan, ((void *)__pyx_v_arr), ((void *)__pyx_v_ptr2), CUFFT_COPY_HOST_TO_DEVICE);
          }

          /* "cupy/cuda/cufft.pyx":704
 *             else:  # numpy
 *                 ptr2 = b.ctypes.data
 *                 with nogil:             # <<<<<<<<<<<<<<
 *                     result = cufftXtMemcpy(
 *                         plan, <void*>arr, <void*>ptr2,
*/
          /*finally:*/ {
            /*normal exit:*/{
              __Pyx_FastGIL_Forget();
              Py_BLOCK_THREADS
              goto __pyx_L13;
            }
            __pyx_L13:;
          }
      }

      /* "cupy/cuda/cufft.pyx":708
 *                         plan, <void*>arr, <void*>ptr2,
 *                         CUFFT_COPY_HOST_TO_DEVICE)
 *                 check_result(result)             # <<<<<<<<<<<<<<
 *         elif action == 'gather':
 *             if isinstance(a, cupy.ndarray):
*/
      __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 708, __pyx_L1_error)
    }
    __pyx_L6:;

    /* "cupy/cuda/cufft.pyx":677
 *         share = self.batch_share
 * 
 *         if action == 'scatter':             # <<<<<<<<<<<<<<
 *             if isinstance(a, cupy.ndarray):
 *                 s_device = b.data.device_id
*/
    goto __pyx_L5;
  }

  /* "cupy/cuda/cufft.pyx":709
 *                         CUFFT_COPY_HOST_TO_DEVICE)
 *                 check_result(result)
 *         elif action == 'gather':             # <<<<<<<<<<<<<<
 *             if isinstance(a, cupy.ndarray):
 *                 if self.batch == 1:
*/
  __pyx_t_4 = (__Pyx_PyUnicode_Equals(__pyx_v_action, __pyx_mstate_global->__pyx_n_u_gather, Py_EQ)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 709, __pyx_L1_error)
  if (likely(__pyx_t_4)) {

    /* "cupy/cuda/cufft.pyx":710
 *                 check_result(result)
 *         elif action == 'gather':
 *             if isinstance(a, cupy.ndarray):             # <<<<<<<<<<<<<<
 *                 if self.batch == 1:
 *                     _reorder_buffers(plan, self.xtArr, xtArr_buffer)
*/
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_cupy); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 710, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_ndarray); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 710, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_4 = PyObject_IsInstance(__pyx_v_a, __pyx_t_3); if (unlikely(__pyx_t_4 == ((int)-1))) __PYX_ERR(0, 710, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (__pyx_t_4) {

      /* "cupy/cuda/cufft.pyx":711
 *         elif action == 'gather':
 *             if isinstance(a, cupy.ndarray):
 *                 if self.batch == 1:             # <<<<<<<<<<<<<<
 *                     _reorder_buffers(plan, self.xtArr, xtArr_buffer)
 * 
*/
      __pyx_t_4 = (__pyx_v_self->batch == 1);
      if (__pyx_t_4) {

        /* "cupy/cuda/cufft.pyx":712
 *             if isinstance(a, cupy.ndarray):
 *                 if self.batch == 1:
 *                     _reorder_buffers(plan, self.xtArr, xtArr_buffer)             # <<<<<<<<<<<<<<
 * 
 *                 # When we come here, another stream could still be
*/
        __pyx_t_3 = __pyx_f_4cupy_4cuda_5cufft__reorder_buffers(__pyx_v_plan, __pyx_v_self->xtArr, __pyx_v_xtArr_buffer); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 712, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

        /* "cupy/cuda/cufft.pyx":711
 *         elif action == 'gather':
 *             if isinstance(a, cupy.ndarray):
 *                 if self.batch == 1:             # <<<<<<<<<<<<<<
 *                     _reorder_buffers(plan, self.xtArr, xtArr_buffer)
 * 
*/
      }

      /* "cupy/cuda/cufft.pyx":716
 *                 # When we come here, another stream could still be
 *                 # copying data for us, so we wait patiently...
 *                 outer_stream = stream.get_current_stream()             # <<<<<<<<<<<<<<
 *                 outer_stream.synchronize()
 * 
*/
      __pyx_t_1 = NULL;
      __Pyx_GetModuleGlobalName(__pyx_t_10, __pyx_mstate_global->__pyx_n_u_stream); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 716, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      __pyx_t_14 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_mstate_global->__pyx_n_u_get_current_stream); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 716, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_14);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __pyx_t_6 = 1;
      #if CYTHON_UNPACK_METHODS
      if (unlikely(PyMethod_Check(__pyx_t_14))) {
        __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_14);
        assert(__pyx_t_1);
        PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_14);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(__pyx__function);
        __Pyx_DECREF_SET(__pyx_t_14, __pyx__function);
        __pyx_t_6 = 0;
      }
      #endif
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_1, NULL};
        __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_14, __pyx_callargs+__pyx_t_6, (1-__pyx_t_6) | (__pyx_t_6*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
        if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 716, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
      }
      __pyx_v_outer_stream = __pyx_t_3;
      __pyx_t_3 = 0;

      /* "cupy/cuda/cufft.pyx":717
 *                 # copying data for us, so we wait patiently...
 *                 outer_stream = stream.get_current_stream()
 *                 outer_stream.synchronize()             # <<<<<<<<<<<<<<
 * 
 *                 for i in range(nGPUs):
*/
      __pyx_t_14 = __pyx_v_outer_stream;
      __Pyx_INCREF(__pyx_t_14);
      __pyx_t_6 = 0;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_14, NULL};
        __pyx_t_3 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_synchronize, __pyx_callargs+__pyx_t_6, (1-__pyx_t_6) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
        if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 717, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
      }
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

      /* "cupy/cuda/cufft.pyx":719
 *                 outer_stream.synchronize()
 * 
 *                 for i in range(nGPUs):             # <<<<<<<<<<<<<<
 *                     count = int(share[i] * self.nx)
 *                     size = count * b.dtype.itemsize
*/
      __pyx_t_14 = NULL;
      __Pyx_INCREF(__pyx_builtin_range);
      __pyx_t_1 = __pyx_builtin_range; 
      __pyx_t_10 = __Pyx_PyLong_From_int(__pyx_v_nGPUs); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 719, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      __pyx_t_6 = 1;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_14, __pyx_t_10};
        __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_1, __pyx_callargs+__pyx_t_6, (2-__pyx_t_6) | (__pyx_t_6*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 719, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
      }
      if (likely(PyList_CheckExact(__pyx_t_3)) || PyTuple_CheckExact(__pyx_t_3)) {
        __pyx_t_1 = __pyx_t_3; __Pyx_INCREF(__pyx_t_1);
        __pyx_t_8 = 0;
        __pyx_t_16 = NULL;
      } else {
        __pyx_t_8 = -1; __pyx_t_1 = PyObject_GetIter(__pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 719, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_16 = (CYTHON_COMPILING_IN_LIMITED_API) ? PyIter_Next : __Pyx_PyObject_GetIterNextFunc(__pyx_t_1); if (unlikely(!__pyx_t_16)) __PYX_ERR(0, 719, __pyx_L1_error)
      }
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      for (;;) {
        if (likely(!__pyx_t_16)) {
          if (likely(PyList_CheckExact(__pyx_t_1))) {
            {
              Py_ssize_t __pyx_temp = __Pyx_PyList_GET_SIZE(__pyx_t_1);
              #if !CYTHON_ASSUME_SAFE_SIZE
              if (unlikely((__pyx_temp < 0))) __PYX_ERR(0, 719, __pyx_L1_error)
              #endif
              if (__pyx_t_8 >= __pyx_temp) break;
            }
            __pyx_t_3 = __Pyx_PyList_GetItemRef(__pyx_t_1, __pyx_t_8);
            ++__pyx_t_8;
          } else {
            {
              Py_ssize_t __pyx_temp = __Pyx_PyTuple_GET_SIZE(__pyx_t_1);
              #if !CYTHON_ASSUME_SAFE_SIZE
              if (unlikely((__pyx_temp < 0))) __PYX_ERR(0, 719, __pyx_L1_error)
              #endif
              if (__pyx_t_8 >= __pyx_temp) break;
            }
            #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
            __pyx_t_3 = __Pyx_NewRef(PyTuple_GET_ITEM(__pyx_t_1, __pyx_t_8));
            #else
            __pyx_t_3 = __Pyx_PySequence_ITEM(__pyx_t_1, __pyx_t_8);
            #endif
            ++__pyx_t_8;
          }
          if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 719, __pyx_L1_error)
        } else {
          __pyx_t_3 = __pyx_t_16(__pyx_t_1);
          if (unlikely(!__pyx_t_3)) {
            PyObject* exc_type = PyErr_Occurred();
            if (exc_type) {
              if (unlikely(!__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) __PYX_ERR(0, 719, __pyx_L1_error)
              PyErr_Clear();
            }
            break;
          }
        }
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_3);
        __pyx_t_3 = 0;

        /* "cupy/cuda/cufft.pyx":720
 * 
 *                 for i in range(nGPUs):
 *                     count = int(share[i] * self.nx)             # <<<<<<<<<<<<<<
 *                     size = count * b.dtype.itemsize
 *                     curr_stream = self.gather_streams[i]
*/
        if (unlikely(__pyx_v_share == Py_None)) {
          PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
          __PYX_ERR(0, 720, __pyx_L1_error)
        }
        __pyx_t_3 = __Pyx_PyObject_GetItem(__pyx_v_share, __pyx_v_i); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 720, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __pyx_t_10 = __Pyx_PyLong_From_int(__pyx_v_self->nx); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 720, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        __pyx_t_14 = PyNumber_Multiply(__pyx_t_3, __pyx_t_10); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 720, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_14);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        __pyx_t_10 = __Pyx_PyNumber_Int(__pyx_t_14); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 720, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
        __pyx_t_9 = __Pyx_PyLong_As_int(__pyx_t_10); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 720, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        __pyx_v_count = __pyx_t_9;

        /* "cupy/cuda/cufft.pyx":721
 *                 for i in range(nGPUs):
 *                     count = int(share[i] * self.nx)
 *                     size = count * b.dtype.itemsize             # <<<<<<<<<<<<<<
 *                     curr_stream = self.gather_streams[i]
 *                     curr_event = self.gather_events[i]
*/
        __pyx_t_10 = __Pyx_PyLong_From_int(__pyx_v_count); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 721, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        __pyx_t_14 = __Pyx_PyObject_GetAttrStr(__pyx_v_b, __pyx_mstate_global->__pyx_n_u_dtype); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 721, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_14);
        __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_14, __pyx_mstate_global->__pyx_n_u_itemsize); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 721, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
        __pyx_t_14 = PyNumber_Multiply(__pyx_t_10, __pyx_t_3); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 721, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_14);
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __pyx_t_6 = __Pyx_PyLong_As_size_t(__pyx_t_14); if (unlikely((__pyx_t_6 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 721, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
        __pyx_v_size = __pyx_t_6;

        /* "cupy/cuda/cufft.pyx":722
 *                     count = int(share[i] * self.nx)
 *                     size = count * b.dtype.itemsize
 *                     curr_stream = self.gather_streams[i]             # <<<<<<<<<<<<<<
 *                     curr_event = self.gather_events[i]
 *                     b[start:start+count].data.copy_from_device_async(
*/
        if (unlikely(__pyx_v_self->gather_streams == Py_None)) {
          PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
          __PYX_ERR(0, 722, __pyx_L1_error)
        }
        __pyx_t_14 = __Pyx_PyObject_GetItem(__pyx_v_self->gather_streams, __pyx_v_i); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 722, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_14);
        __Pyx_XDECREF_SET(__pyx_v_curr_stream, __pyx_t_14);
        __pyx_t_14 = 0;

        /* "cupy/cuda/cufft.pyx":723
 *                     size = count * b.dtype.itemsize
 *                     curr_stream = self.gather_streams[i]
 *                     curr_event = self.gather_events[i]             # <<<<<<<<<<<<<<
 *                     b[start:start+count].data.copy_from_device_async(
 *                         xtArr_buffer[i], size, curr_stream)
*/
        if (unlikely(__pyx_v_self->gather_events == Py_None)) {
          PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
          __PYX_ERR(0, 723, __pyx_L1_error)
        }
        __pyx_t_14 = __Pyx_PyObject_GetItem(__pyx_v_self->gather_events, __pyx_v_i); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 723, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_14);
        __Pyx_XDECREF_SET(__pyx_v_curr_event, __pyx_t_14);
        __pyx_t_14 = 0;

        /* "cupy/cuda/cufft.pyx":724
 *                     curr_stream = self.gather_streams[i]
 *                     curr_event = self.gather_events[i]
 *                     b[start:start+count].data.copy_from_device_async(             # <<<<<<<<<<<<<<
 *                         xtArr_buffer[i], size, curr_stream)
 *                     if i != 0:
*/
        __pyx_t_10 = __Pyx_PyObject_GetSlice(__pyx_v_b, __pyx_v_start, (__pyx_v_start + __pyx_v_count), NULL, NULL, NULL, 1, 1, 1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 724, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 724, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        __pyx_t_3 = __pyx_t_2;
        __Pyx_INCREF(__pyx_t_3);

        /* "cupy/cuda/cufft.pyx":725
 *                     curr_event = self.gather_events[i]
 *                     b[start:start+count].data.copy_from_device_async(
 *                         xtArr_buffer[i], size, curr_stream)             # <<<<<<<<<<<<<<
 *                     if i != 0:
 *                         prev_event = self.gather_events[i-1]
*/
        if (unlikely(__pyx_v_xtArr_buffer == Py_None)) {
          PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
          __PYX_ERR(0, 725, __pyx_L1_error)
        }
        __pyx_t_10 = __Pyx_PyObject_GetItem(__pyx_v_xtArr_buffer, __pyx_v_i); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 725, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
        __pyx_t_17 = __Pyx_PyLong_FromSize_t(__pyx_v_size); if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 725, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_17);
        __pyx_t_6 = 0;
        {
          PyObject *__pyx_callargs[4] = {__pyx_t_3, __pyx_t_10, __pyx_t_17, __pyx_v_curr_stream};
          __pyx_t_14 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_copy_from_device_async, __pyx_callargs+__pyx_t_6, (4-__pyx_t_6) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
          __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          __Pyx_DECREF(__pyx_t_17); __pyx_t_17 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 724, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_14);
        }
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;

        /* "cupy/cuda/cufft.pyx":726
 *                     b[start:start+count].data.copy_from_device_async(
 *                         xtArr_buffer[i], size, curr_stream)
 *                     if i != 0:             # <<<<<<<<<<<<<<
 *                         prev_event = self.gather_events[i-1]
 *                         curr_stream.wait_event(prev_event)
*/
        __pyx_t_4 = (__Pyx_PyLong_BoolNeObjC(__pyx_v_i, __pyx_mstate_global->__pyx_int_0, 0, 0)); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 726, __pyx_L1_error)
        if (__pyx_t_4) {

          /* "cupy/cuda/cufft.pyx":727
 *                         xtArr_buffer[i], size, curr_stream)
 *                     if i != 0:
 *                         prev_event = self.gather_events[i-1]             # <<<<<<<<<<<<<<
 *                         curr_stream.wait_event(prev_event)
 *                     curr_event.record(curr_stream)
*/
          if (unlikely(__pyx_v_self->gather_events == Py_None)) {
            PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
            __PYX_ERR(0, 727, __pyx_L1_error)
          }
          __pyx_t_14 = __Pyx_PyLong_SubtractObjC(__pyx_v_i, __pyx_mstate_global->__pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 727, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_14);
          __pyx_t_2 = __Pyx_PyObject_GetItem(__pyx_v_self->gather_events, __pyx_t_14); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 727, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
          __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
          __Pyx_XDECREF_SET(__pyx_v_prev_event, __pyx_t_2);
          __pyx_t_2 = 0;

          /* "cupy/cuda/cufft.pyx":728
 *                     if i != 0:
 *                         prev_event = self.gather_events[i-1]
 *                         curr_stream.wait_event(prev_event)             # <<<<<<<<<<<<<<
 *                     curr_event.record(curr_stream)
 *                     start += count
*/
          __pyx_t_14 = __pyx_v_curr_stream;
          __Pyx_INCREF(__pyx_t_14);
          __pyx_t_6 = 0;
          {
            PyObject *__pyx_callargs[2] = {__pyx_t_14, __pyx_v_prev_event};
            __pyx_t_2 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_wait_event, __pyx_callargs+__pyx_t_6, (2-__pyx_t_6) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
            __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
            if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 728, __pyx_L1_error)
            __Pyx_GOTREF(__pyx_t_2);
          }
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

          /* "cupy/cuda/cufft.pyx":726
 *                     b[start:start+count].data.copy_from_device_async(
 *                         xtArr_buffer[i], size, curr_stream)
 *                     if i != 0:             # <<<<<<<<<<<<<<
 *                         prev_event = self.gather_events[i-1]
 *                         curr_stream.wait_event(prev_event)
*/
        }

        /* "cupy/cuda/cufft.pyx":729
 *                         prev_event = self.gather_events[i-1]
 *                         curr_stream.wait_event(prev_event)
 *                     curr_event.record(curr_stream)             # <<<<<<<<<<<<<<
 *                     start += count
 *                 assert start == b.size
*/
        __pyx_t_14 = __pyx_v_curr_event;
        __Pyx_INCREF(__pyx_t_14);
        __pyx_t_6 = 0;
        {
          PyObject *__pyx_callargs[2] = {__pyx_t_14, __pyx_v_curr_stream};
          __pyx_t_2 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_record, __pyx_callargs+__pyx_t_6, (2-__pyx_t_6) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
          __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
          if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 729, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_2);
        }
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

        /* "cupy/cuda/cufft.pyx":730
 *                         curr_stream.wait_event(prev_event)
 *                     curr_event.record(curr_stream)
 *                     start += count             # <<<<<<<<<<<<<<
 *                 assert start == b.size
 *                 self.gather_events[-1].synchronize()
*/
        __pyx_v_start = (__pyx_v_start + __pyx_v_count);

        /* "cupy/cuda/cufft.pyx":719
 *                 outer_stream.synchronize()
 * 
 *                 for i in range(nGPUs):             # <<<<<<<<<<<<<<
 *                     count = int(share[i] * self.nx)
 *                     size = count * b.dtype.itemsize
*/
      }
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

      /* "cupy/cuda/cufft.pyx":731
 *                     curr_event.record(curr_stream)
 *                     start += count
 *                 assert start == b.size             # <<<<<<<<<<<<<<
 *                 self.gather_events[-1].synchronize()
 *             else:  # numpy
*/
      #ifndef CYTHON_WITHOUT_ASSERTIONS
      if (unlikely(__pyx_assertions_enabled())) {
        __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_start); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 731, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_1);
        __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_b, __pyx_mstate_global->__pyx_n_u_size); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 731, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
        __pyx_t_14 = PyObject_RichCompare(__pyx_t_1, __pyx_t_2, Py_EQ); __Pyx_XGOTREF(__pyx_t_14); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 731, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        __pyx_t_4 = __Pyx_PyObject_IsTrue(__pyx_t_14); if (unlikely((__pyx_t_4 < 0))) __PYX_ERR(0, 731, __pyx_L1_error)
        __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
        if (unlikely(!__pyx_t_4)) {
          __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
          __PYX_ERR(0, 731, __pyx_L1_error)
        }
      }
      #else
      if ((1)); else __PYX_ERR(0, 731, __pyx_L1_error)
      #endif

      /* "cupy/cuda/cufft.pyx":732
 *                     start += count
 *                 assert start == b.size
 *                 self.gather_events[-1].synchronize()             # <<<<<<<<<<<<<<
 *             else:  # numpy
 *                 ptr2 = b.ctypes.data
*/
      if (unlikely(__pyx_v_self->gather_events == Py_None)) {
        PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
        __PYX_ERR(0, 732, __pyx_L1_error)
      }
      __pyx_t_1 = __Pyx_GetItemInt_List(__pyx_v_self->gather_events, -1L, long, 1, __Pyx_PyLong_From_long, 1, 1, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 732, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __pyx_t_2 = __pyx_t_1;
      __Pyx_INCREF(__pyx_t_2);
      __pyx_t_6 = 0;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_2, NULL};
        __pyx_t_14 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_synchronize, __pyx_callargs+__pyx_t_6, (1-__pyx_t_6) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
        if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 732, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_14);
      }
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;

      /* "cupy/cuda/cufft.pyx":710
 *                 check_result(result)
 *         elif action == 'gather':
 *             if isinstance(a, cupy.ndarray):             # <<<<<<<<<<<<<<
 *                 if self.batch == 1:
 *                     _reorder_buffers(plan, self.xtArr, xtArr_buffer)
*/
      goto __pyx_L14;
    }

    /* "cupy/cuda/cufft.pyx":734
 *                 self.gather_events[-1].synchronize()
 *             else:  # numpy
 *                 ptr2 = b.ctypes.data             # <<<<<<<<<<<<<<
 *                 with nogil:
 *                     result = cufftXtMemcpy(
*/
    /*else*/ {
      __pyx_t_14 = __Pyx_PyObject_GetAttrStr(__pyx_v_b, __pyx_mstate_global->__pyx_n_u_ctypes); if (unlikely(!__pyx_t_14)) __PYX_ERR(0, 734, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_14);
      __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_14, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 734, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_14); __pyx_t_14 = 0;
      __pyx_t_7 = PyLong_AsSsize_t(__pyx_t_1); if (unlikely((__pyx_t_7 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 734, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __pyx_v_ptr2 = __pyx_t_7;

      /* "cupy/cuda/cufft.pyx":735
 *             else:  # numpy
 *                 ptr2 = b.ctypes.data
 *                 with nogil:             # <<<<<<<<<<<<<<
 *                     result = cufftXtMemcpy(
 *                         plan, <void*>ptr2, <void*>arr,
*/
      {
          PyThreadState *_save;
          _save = NULL;
          Py_UNBLOCK_THREADS
          __Pyx_FastGIL_Remember();
          /*try:*/ {

            /* "cupy/cuda/cufft.pyx":736
 *                 ptr2 = b.ctypes.data
 *                 with nogil:
 *                     result = cufftXtMemcpy(             # <<<<<<<<<<<<<<
 *                         plan, <void*>ptr2, <void*>arr,
 *                         CUFFT_COPY_DEVICE_TO_HOST)
*/
            __pyx_v_result = cufftXtMemcpy(__pyx_v_plan, ((void *)__pyx_v_ptr2), ((void *)__pyx_v_arr), CUFFT_COPY_DEVICE_TO_HOST);
          }

          /* "cupy/cuda/cufft.pyx":735
 *             else:  # numpy
 *                 ptr2 = b.ctypes.data
 *                 with nogil:             # <<<<<<<<<<<<<<
 *                     result = cufftXtMemcpy(
 *                         plan, <void*>ptr2, <void*>arr,
*/
          /*finally:*/ {
            /*normal exit:*/{
              __Pyx_FastGIL_Forget();
              Py_BLOCK_THREADS
              goto __pyx_L22;
            }
            __pyx_L22:;
          }
      }

      /* "cupy/cuda/cufft.pyx":739
 *                         plan, <void*>ptr2, <void*>arr,
 *                         CUFFT_COPY_DEVICE_TO_HOST)
 *                 check_result(result)             # <<<<<<<<<<<<<<
 *         else:
 *             raise ValueError
*/
      __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 739, __pyx_L1_error)
    }
    __pyx_L14:;

    /* "cupy/cuda/cufft.pyx":709
 *                         CUFFT_COPY_HOST_TO_DEVICE)
 *                 check_result(result)
 *         elif action == 'gather':             # <<<<<<<<<<<<<<
 *             if isinstance(a, cupy.ndarray):
 *                 if self.batch == 1:
*/
    goto __pyx_L5;
  }

  /* "cupy/cuda/cufft.pyx":741
 *                 check_result(result)
 *         else:
 *             raise ValueError             # <<<<<<<<<<<<<<
 * 
 *     def _multi_gpu_fft(self, a, out, direction):
*/
  /*else*/ {
    __Pyx_Raise(__pyx_builtin_ValueError, 0, 0, 0);
    __PYX_ERR(0, 741, __pyx_L1_error)
  }
  __pyx_L5:;

  /* "cupy/cuda/cufft.pyx":656
 *             raise ValueError('Impossible to reach.')
 * 
 *     def _multi_gpu_memcpy(self, a, str action):             # <<<<<<<<<<<<<<
 *         cdef Handle plan = <Handle>self.handle
 *         cdef list xtArr_buffer, share
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_14);
  __Pyx_XDECREF(__pyx_t_17);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d._multi_gpu_memcpy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_xtArr_buffer);
  __Pyx_XDECREF(__pyx_v_share);
  __Pyx_XDECREF(__pyx_v_b);
  __Pyx_XDECREF(__pyx_v_outer_stream);
  __Pyx_XDECREF(__pyx_v_curr_stream);
  __Pyx_XDECREF(__pyx_v_curr_event);
  __Pyx_XDECREF(__pyx_v_prev_event);
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":743
 *             raise ValueError
 * 
 *     def _multi_gpu_fft(self, a, out, direction):             # <<<<<<<<<<<<<<
 *         # When we arrive here, the normal CuPy call path ensures a and out
 *         # reside on the same GPU -> must distribute a to all of the GPUs
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_19_multi_gpu_fft(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6Plan1d_18_multi_gpu_fft, "Plan1d._multi_gpu_fft(self, a, out, direction)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_19_multi_gpu_fft(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_a = 0;
  PyObject *__pyx_v_out = 0;
  PyObject *__pyx_v_direction = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_multi_gpu_fft (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_a,&__pyx_mstate_global->__pyx_n_u_out,&__pyx_mstate_global->__pyx_n_u_direction,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 743, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 743, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 743, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 743, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "_multi_gpu_fft", 0) < (0)) __PYX_ERR(0, 743, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("_multi_gpu_fft", 1, 3, 3, i); __PYX_ERR(0, 743, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 743, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 743, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 743, __pyx_L3_error)
    }
    __pyx_v_a = values[0];
    __pyx_v_out = values[1];
    __pyx_v_direction = values[2];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_multi_gpu_fft", 1, 3, 3, __pyx_nargs); __PYX_ERR(0, 743, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d._multi_gpu_fft", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_18_multi_gpu_fft(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self), __pyx_v_a, __pyx_v_out, __pyx_v_direction);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_18_multi_gpu_fft(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_out, PyObject *__pyx_v_direction) {
  intptr_t __pyx_v_plan;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  size_t __pyx_t_3;
  intptr_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_multi_gpu_fft", 0);

  /* "cupy/cuda/cufft.pyx":746
 *         # When we arrive here, the normal CuPy call path ensures a and out
 *         # reside on the same GPU -> must distribute a to all of the GPUs
 *         self._multi_gpu_setup_buffer(a)             # <<<<<<<<<<<<<<
 * 
 *         # Next, copy data to buffer
*/
  __pyx_t_2 = ((PyObject *)__pyx_v_self);
  __Pyx_INCREF(__pyx_t_2);
  __pyx_t_3 = 0;
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_v_a};
    __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_multi_gpu_setup_buffer, __pyx_callargs+__pyx_t_3, (2-__pyx_t_3) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 746, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":749
 * 
 *         # Next, copy data to buffer
 *         self._multi_gpu_memcpy(a, 'scatter')             # <<<<<<<<<<<<<<
 * 
 *         # Actual workhorses
*/
  __pyx_t_2 = ((PyObject *)__pyx_v_self);
  __Pyx_INCREF(__pyx_t_2);
  __pyx_t_3 = 0;
  {
    PyObject *__pyx_callargs[3] = {__pyx_t_2, __pyx_v_a, __pyx_mstate_global->__pyx_n_u_scatter};
    __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_multi_gpu_memcpy, __pyx_callargs+__pyx_t_3, (3-__pyx_t_3) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 749, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":753
 *         # Actual workhorses
 *         # Note: mult-GPU plans cannot set stream
 *         cdef intptr_t plan = self.handle             # <<<<<<<<<<<<<<
 *         if self.fft_type == CUFFT_C2C:
 *             multi_gpu_execC2C(plan, self.xtArr, self.xtArr, direction)
*/
  __pyx_t_4 = __pyx_v_self->handle;
  __pyx_v_plan = __pyx_t_4;

  /* "cupy/cuda/cufft.pyx":754
 *         # Note: mult-GPU plans cannot set stream
 *         cdef intptr_t plan = self.handle
 *         if self.fft_type == CUFFT_C2C:             # <<<<<<<<<<<<<<
 *             multi_gpu_execC2C(plan, self.xtArr, self.xtArr, direction)
 *         elif self.fft_type == CUFFT_Z2Z:
*/
  switch (__pyx_v_self->fft_type) {
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_C2C:

    /* "cupy/cuda/cufft.pyx":755
 *         cdef intptr_t plan = self.handle
 *         if self.fft_type == CUFFT_C2C:
 *             multi_gpu_execC2C(plan, self.xtArr, self.xtArr, direction)             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_Z2Z:
 *             multi_gpu_execZ2Z(plan, self.xtArr, self.xtArr, direction)
*/
    __pyx_t_5 = __Pyx_PyLong_As_int(__pyx_v_direction); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 755, __pyx_L1_error)
    __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_multi_gpu_execC2C(__pyx_v_plan, __pyx_v_self->xtArr, __pyx_v_self->xtArr, __pyx_t_5, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 755, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":754
 *         # Note: mult-GPU plans cannot set stream
 *         cdef intptr_t plan = self.handle
 *         if self.fft_type == CUFFT_C2C:             # <<<<<<<<<<<<<<
 *             multi_gpu_execC2C(plan, self.xtArr, self.xtArr, direction)
 *         elif self.fft_type == CUFFT_Z2Z:
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_Z2Z:

    /* "cupy/cuda/cufft.pyx":757
 *             multi_gpu_execC2C(plan, self.xtArr, self.xtArr, direction)
 *         elif self.fft_type == CUFFT_Z2Z:
 *             multi_gpu_execZ2Z(plan, self.xtArr, self.xtArr, direction)             # <<<<<<<<<<<<<<
 *         else:
 *             raise ValueError
*/
    __pyx_t_5 = __Pyx_PyLong_As_int(__pyx_v_direction); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 757, __pyx_L1_error)
    __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_multi_gpu_execZ2Z(__pyx_v_plan, __pyx_v_self->xtArr, __pyx_v_self->xtArr, __pyx_t_5, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 757, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":756
 *         if self.fft_type == CUFFT_C2C:
 *             multi_gpu_execC2C(plan, self.xtArr, self.xtArr, direction)
 *         elif self.fft_type == CUFFT_Z2Z:             # <<<<<<<<<<<<<<
 *             multi_gpu_execZ2Z(plan, self.xtArr, self.xtArr, direction)
 *         else:
*/
    break;
    default:

    /* "cupy/cuda/cufft.pyx":759
 *             multi_gpu_execZ2Z(plan, self.xtArr, self.xtArr, direction)
 *         else:
 *             raise ValueError             # <<<<<<<<<<<<<<
 * 
 *         # Gather the distributed outputs
*/
    __Pyx_Raise(__pyx_builtin_ValueError, 0, 0, 0);
    __PYX_ERR(0, 759, __pyx_L1_error)
    break;
  }

  /* "cupy/cuda/cufft.pyx":762
 * 
 *         # Gather the distributed outputs
 *         self._multi_gpu_memcpy(out, 'gather')             # <<<<<<<<<<<<<<
 * 
 *     def _output_dtype_and_shape(self, a):
*/
  __pyx_t_2 = ((PyObject *)__pyx_v_self);
  __Pyx_INCREF(__pyx_t_2);
  __pyx_t_3 = 0;
  {
    PyObject *__pyx_callargs[3] = {__pyx_t_2, __pyx_v_out, __pyx_mstate_global->__pyx_n_u_gather};
    __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_multi_gpu_memcpy, __pyx_callargs+__pyx_t_3, (3-__pyx_t_3) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 762, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":743
 *             raise ValueError
 * 
 *     def _multi_gpu_fft(self, a, out, direction):             # <<<<<<<<<<<<<<
 *         # When we arrive here, the normal CuPy call path ensures a and out
 *         # reside on the same GPU -> must distribute a to all of the GPUs
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d._multi_gpu_fft", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":764
 *         self._multi_gpu_memcpy(out, 'gather')
 * 
 *     def _output_dtype_and_shape(self, a):             # <<<<<<<<<<<<<<
 *         shape = list(a.shape)
 *         if self.fft_type == CUFFT_C2C:
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_21_output_dtype_and_shape(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6Plan1d_20_output_dtype_and_shape, "Plan1d._output_dtype_and_shape(self, a)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_21_output_dtype_and_shape(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_a = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[1] = {0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_output_dtype_and_shape (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_a,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 764, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 764, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "_output_dtype_and_shape", 0) < (0)) __PYX_ERR(0, 764, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 1; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("_output_dtype_and_shape", 1, 1, 1, i); __PYX_ERR(0, 764, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 1)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 764, __pyx_L3_error)
    }
    __pyx_v_a = values[0];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_output_dtype_and_shape", 1, 1, 1, __pyx_nargs); __PYX_ERR(0, 764, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d._output_dtype_and_shape", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_20_output_dtype_and_shape(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self), __pyx_v_a);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_20_output_dtype_and_shape(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v_a) {
  PyObject *__pyx_v_shape = NULL;
  PyObject *__pyx_v_dtype = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_output_dtype_and_shape", 0);

  /* "cupy/cuda/cufft.pyx":765
 * 
 *     def _output_dtype_and_shape(self, a):
 *         shape = list(a.shape)             # <<<<<<<<<<<<<<
 *         if self.fft_type == CUFFT_C2C:
 *             dtype = numpy.complex64
*/
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 765, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PySequence_ListKeepNew(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 765, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_shape = ((PyObject*)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "cupy/cuda/cufft.pyx":766
 *     def _output_dtype_and_shape(self, a):
 *         shape = list(a.shape)
 *         if self.fft_type == CUFFT_C2C:             # <<<<<<<<<<<<<<
 *             dtype = numpy.complex64
 *         elif self.fft_type == CUFFT_R2C:
*/
  switch (__pyx_v_self->fft_type) {
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_C2C:

    /* "cupy/cuda/cufft.pyx":767
 *         shape = list(a.shape)
 *         if self.fft_type == CUFFT_C2C:
 *             dtype = numpy.complex64             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_R2C:
 *             shape[-1] = shape[-1] // 2 + 1
*/
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 767, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_complex64); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 767, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_dtype = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":766
 *     def _output_dtype_and_shape(self, a):
 *         shape = list(a.shape)
 *         if self.fft_type == CUFFT_C2C:             # <<<<<<<<<<<<<<
 *             dtype = numpy.complex64
 *         elif self.fft_type == CUFFT_R2C:
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_R2C:

    /* "cupy/cuda/cufft.pyx":769
 *             dtype = numpy.complex64
 *         elif self.fft_type == CUFFT_R2C:
 *             shape[-1] = shape[-1] // 2 + 1             # <<<<<<<<<<<<<<
 *             dtype = numpy.complex64
 *         elif self.fft_type == CUFFT_C2R:
*/
    __pyx_t_1 = __Pyx_GetItemInt_List(__pyx_v_shape, -1L, long, 1, __Pyx_PyLong_From_long, 1, 1, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 769, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyLong_FloorDivideObjC(__pyx_t_1, __pyx_mstate_global->__pyx_int_2, 2, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 769, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyLong_AddObjC(__pyx_t_2, __pyx_mstate_global->__pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 769, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely((__Pyx_SetItemInt(__pyx_v_shape, -1L, __pyx_t_1, long, 1, __Pyx_PyLong_From_long, 1, 1, 1, 1) < 0))) __PYX_ERR(0, 769, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":770
 *         elif self.fft_type == CUFFT_R2C:
 *             shape[-1] = shape[-1] // 2 + 1
 *             dtype = numpy.complex64             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_C2R:
 *             shape[-1] = self.nx
*/
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 770, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_complex64); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 770, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_dtype = __pyx_t_2;
    __pyx_t_2 = 0;

    /* "cupy/cuda/cufft.pyx":768
 *         if self.fft_type == CUFFT_C2C:
 *             dtype = numpy.complex64
 *         elif self.fft_type == CUFFT_R2C:             # <<<<<<<<<<<<<<
 *             shape[-1] = shape[-1] // 2 + 1
 *             dtype = numpy.complex64
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_C2R:

    /* "cupy/cuda/cufft.pyx":772
 *             dtype = numpy.complex64
 *         elif self.fft_type == CUFFT_C2R:
 *             shape[-1] = self.nx             # <<<<<<<<<<<<<<
 *             dtype = numpy.float32
 *         elif self.fft_type == CUFFT_Z2Z:
*/
    __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_v_self->nx); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 772, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (unlikely((__Pyx_SetItemInt(__pyx_v_shape, -1L, __pyx_t_2, long, 1, __Pyx_PyLong_From_long, 1, 1, 1, 1) < 0))) __PYX_ERR(0, 772, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "cupy/cuda/cufft.pyx":773
 *         elif self.fft_type == CUFFT_C2R:
 *             shape[-1] = self.nx
 *             dtype = numpy.float32             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_Z2Z:
 *             dtype = numpy.complex128
*/
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 773, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_float32); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 773, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_dtype = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":771
 *             shape[-1] = shape[-1] // 2 + 1
 *             dtype = numpy.complex64
 *         elif self.fft_type == CUFFT_C2R:             # <<<<<<<<<<<<<<
 *             shape[-1] = self.nx
 *             dtype = numpy.float32
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_Z2Z:

    /* "cupy/cuda/cufft.pyx":775
 *             dtype = numpy.float32
 *         elif self.fft_type == CUFFT_Z2Z:
 *             dtype = numpy.complex128             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_D2Z:
 *             shape[-1] = shape[-1] // 2 + 1
*/
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 775, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_complex128); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 775, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_dtype = __pyx_t_2;
    __pyx_t_2 = 0;

    /* "cupy/cuda/cufft.pyx":774
 *             shape[-1] = self.nx
 *             dtype = numpy.float32
 *         elif self.fft_type == CUFFT_Z2Z:             # <<<<<<<<<<<<<<
 *             dtype = numpy.complex128
 *         elif self.fft_type == CUFFT_D2Z:
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_D2Z:

    /* "cupy/cuda/cufft.pyx":777
 *             dtype = numpy.complex128
 *         elif self.fft_type == CUFFT_D2Z:
 *             shape[-1] = shape[-1] // 2 + 1             # <<<<<<<<<<<<<<
 *             dtype = numpy.complex128
 *         else:
*/
    __pyx_t_2 = __Pyx_GetItemInt_List(__pyx_v_shape, -1L, long, 1, __Pyx_PyLong_From_long, 1, 1, 1, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 777, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyLong_FloorDivideObjC(__pyx_t_2, __pyx_mstate_global->__pyx_int_2, 2, 0, 0); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 777, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyLong_AddObjC(__pyx_t_1, __pyx_mstate_global->__pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 777, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    if (unlikely((__Pyx_SetItemInt(__pyx_v_shape, -1L, __pyx_t_2, long, 1, __Pyx_PyLong_From_long, 1, 1, 1, 1) < 0))) __PYX_ERR(0, 777, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "cupy/cuda/cufft.pyx":778
 *         elif self.fft_type == CUFFT_D2Z:
 *             shape[-1] = shape[-1] // 2 + 1
 *             dtype = numpy.complex128             # <<<<<<<<<<<<<<
 *         else:
 *             shape[-1] = self.nx
*/
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 778, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_complex128); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 778, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_dtype = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":776
 *         elif self.fft_type == CUFFT_Z2Z:
 *             dtype = numpy.complex128
 *         elif self.fft_type == CUFFT_D2Z:             # <<<<<<<<<<<<<<
 *             shape[-1] = shape[-1] // 2 + 1
 *             dtype = numpy.complex128
*/
    break;
    default:

    /* "cupy/cuda/cufft.pyx":780
 *             dtype = numpy.complex128
 *         else:
 *             shape[-1] = self.nx             # <<<<<<<<<<<<<<
 *             dtype = numpy.float64
 *         return tuple(shape), dtype
*/
    __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_self->nx); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 780, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (unlikely((__Pyx_SetItemInt(__pyx_v_shape, -1L, __pyx_t_1, long, 1, __Pyx_PyLong_From_long, 1, 1, 1, 1) < 0))) __PYX_ERR(0, 780, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":781
 *         else:
 *             shape[-1] = self.nx
 *             dtype = numpy.float64             # <<<<<<<<<<<<<<
 *         return tuple(shape), dtype
 * 
*/
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 781, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_float64); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 781, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_dtype = __pyx_t_2;
    __pyx_t_2 = 0;
    break;
  }

  /* "cupy/cuda/cufft.pyx":782
 *             shape[-1] = self.nx
 *             dtype = numpy.float64
 *         return tuple(shape), dtype             # <<<<<<<<<<<<<<
 * 
 *     def get_output_array(self, a):
*/
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = PyList_AsTuple(__pyx_v_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 782, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 782, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2) != (0)) __PYX_ERR(0, 782, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_dtype);
  __Pyx_GIVEREF(__pyx_v_dtype);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_v_dtype) != (0)) __PYX_ERR(0, 782, __pyx_L1_error);
  __pyx_t_2 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":764
 *         self._multi_gpu_memcpy(out, 'gather')
 * 
 *     def _output_dtype_and_shape(self, a):             # <<<<<<<<<<<<<<
 *         shape = list(a.shape)
 *         if self.fft_type == CUFFT_C2C:
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d._output_dtype_and_shape", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XDECREF(__pyx_v_dtype);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":784
 *         return tuple(shape), dtype
 * 
 *     def get_output_array(self, a):             # <<<<<<<<<<<<<<
 *         shape, dtype = self._output_dtype_and_shape(a)
 *         return cupy.empty(shape, dtype)
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_23get_output_array(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6Plan1d_22get_output_array, "Plan1d.get_output_array(self, a)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_23get_output_array(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_a = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[1] = {0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_output_array (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_a,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 784, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 784, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "get_output_array", 0) < (0)) __PYX_ERR(0, 784, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 1; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("get_output_array", 1, 1, 1, i); __PYX_ERR(0, 784, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 1)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 784, __pyx_L3_error)
    }
    __pyx_v_a = values[0];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("get_output_array", 1, 1, 1, __pyx_nargs); __PYX_ERR(0, 784, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.get_output_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_22get_output_array(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self), __pyx_v_a);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_22get_output_array(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v_a) {
  PyObject *__pyx_v_shape = NULL;
  PyObject *__pyx_v_dtype = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  size_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *(*__pyx_t_6)(PyObject *);
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get_output_array", 0);

  /* "cupy/cuda/cufft.pyx":785
 * 
 *     def get_output_array(self, a):
 *         shape, dtype = self._output_dtype_and_shape(a)             # <<<<<<<<<<<<<<
 *         return cupy.empty(shape, dtype)
 * 
*/
  __pyx_t_2 = ((PyObject *)__pyx_v_self);
  __Pyx_INCREF(__pyx_t_2);
  __pyx_t_3 = 0;
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_v_a};
    __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_output_dtype_and_shape, __pyx_callargs+__pyx_t_3, (2-__pyx_t_3) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 785, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 785, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0);
      __Pyx_INCREF(__pyx_t_2);
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 1);
      __Pyx_INCREF(__pyx_t_4);
    } else {
      __pyx_t_2 = __Pyx_PyList_GetItemRef(sequence, 0);
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 785, __pyx_L1_error)
      __Pyx_XGOTREF(__pyx_t_2);
      __pyx_t_4 = __Pyx_PyList_GetItemRef(sequence, 1);
      if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 785, __pyx_L1_error)
      __Pyx_XGOTREF(__pyx_t_4);
    }
    #else
    __pyx_t_2 = __Pyx_PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 785, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 785, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_5 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 785, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_6 = (CYTHON_COMPILING_IN_LIMITED_API) ? PyIter_Next : __Pyx_PyObject_GetIterNextFunc(__pyx_t_5);
    index = 0; __pyx_t_2 = __pyx_t_6(__pyx_t_5); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 1; __pyx_t_4 = __pyx_t_6(__pyx_t_5); if (unlikely(!__pyx_t_4)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_4);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_6(__pyx_t_5), 2) < (0)) __PYX_ERR(0, 785, __pyx_L1_error)
    __pyx_t_6 = NULL;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_6 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 785, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_shape = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_dtype = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "cupy/cuda/cufft.pyx":786
 *     def get_output_array(self, a):
 *         shape, dtype = self._output_dtype_and_shape(a)
 *         return cupy.empty(shape, dtype)             # <<<<<<<<<<<<<<
 * 
 *     def check_output_array(self, a, out):
*/
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_4 = NULL;
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_cupy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 786, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_empty); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 786, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    assert(__pyx_t_4);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_5);
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_5, __pyx__function);
    __pyx_t_3 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[3] = {__pyx_t_4, __pyx_v_shape, __pyx_v_dtype};
    __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_5, __pyx_callargs+__pyx_t_3, (3-__pyx_t_3) | (__pyx_t_3*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 786, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":784
 *         return tuple(shape), dtype
 * 
 *     def get_output_array(self, a):             # <<<<<<<<<<<<<<
 *         shape, dtype = self._output_dtype_and_shape(a)
 *         return cupy.empty(shape, dtype)
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.get_output_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XDECREF(__pyx_v_dtype);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":788
 *         return cupy.empty(shape, dtype)
 * 
 *     def check_output_array(self, a, out):             # <<<<<<<<<<<<<<
 *         """Verify shape and dtype of the output array.
 * 
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_25check_output_array(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6Plan1d_24check_output_array, "Plan1d.check_output_array(self, a, out)\n\nVerify shape and dtype of the output array.\n\nParameters\n----------\na : cupy.array\n    The input to the transform\nout : cupy.array\n    The array where the output of the transform will be stored.");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_25check_output_array(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_a = 0;
  PyObject *__pyx_v_out = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[2] = {0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("check_output_array (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_a,&__pyx_mstate_global->__pyx_n_u_out,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 788, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 788, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 788, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "check_output_array", 0) < (0)) __PYX_ERR(0, 788, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 2; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("check_output_array", 1, 2, 2, i); __PYX_ERR(0, 788, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 2)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 788, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 788, __pyx_L3_error)
    }
    __pyx_v_a = values[0];
    __pyx_v_out = values[1];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("check_output_array", 1, 2, 2, __pyx_nargs); __PYX_ERR(0, 788, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.check_output_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_24check_output_array(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self), __pyx_v_a, __pyx_v_out);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_24check_output_array(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_out) {
  PyObject *__pyx_v_shape = NULL;
  PyObject *__pyx_v_dtype = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  size_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *(*__pyx_t_6)(PyObject *);
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("check_output_array", 0);

  /* "cupy/cuda/cufft.pyx":798
 *             The array where the output of the transform will be stored.
 *         """
 *         shape, dtype = self._output_dtype_and_shape(a)             # <<<<<<<<<<<<<<
 *         if out.shape != shape:
 *             raise ValueError(
*/
  __pyx_t_2 = ((PyObject *)__pyx_v_self);
  __Pyx_INCREF(__pyx_t_2);
  __pyx_t_3 = 0;
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_v_a};
    __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_output_dtype_and_shape, __pyx_callargs+__pyx_t_3, (2-__pyx_t_3) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 798, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 798, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0);
      __Pyx_INCREF(__pyx_t_2);
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 1);
      __Pyx_INCREF(__pyx_t_4);
    } else {
      __pyx_t_2 = __Pyx_PyList_GetItemRef(sequence, 0);
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 798, __pyx_L1_error)
      __Pyx_XGOTREF(__pyx_t_2);
      __pyx_t_4 = __Pyx_PyList_GetItemRef(sequence, 1);
      if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 798, __pyx_L1_error)
      __Pyx_XGOTREF(__pyx_t_4);
    }
    #else
    __pyx_t_2 = __Pyx_PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 798, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 798, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_5 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 798, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_6 = (CYTHON_COMPILING_IN_LIMITED_API) ? PyIter_Next : __Pyx_PyObject_GetIterNextFunc(__pyx_t_5);
    index = 0; __pyx_t_2 = __pyx_t_6(__pyx_t_5); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 1; __pyx_t_4 = __pyx_t_6(__pyx_t_5); if (unlikely(!__pyx_t_4)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_4);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_6(__pyx_t_5), 2) < (0)) __PYX_ERR(0, 798, __pyx_L1_error)
    __pyx_t_6 = NULL;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_6 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 798, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_shape = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_dtype = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "cupy/cuda/cufft.pyx":799
 *         """
 *         shape, dtype = self._output_dtype_and_shape(a)
 *         if out.shape != shape:             # <<<<<<<<<<<<<<
 *             raise ValueError(
 *                 ('out must have shape {}.').format(shape))
*/
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 799, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = PyObject_RichCompare(__pyx_t_1, __pyx_v_shape, Py_NE); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 799, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(0, 799, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  if (unlikely(__pyx_t_7)) {

    /* "cupy/cuda/cufft.pyx":800
 *         shape, dtype = self._output_dtype_and_shape(a)
 *         if out.shape != shape:
 *             raise ValueError(             # <<<<<<<<<<<<<<
 *                 ('out must have shape {}.').format(shape))
 *         if out.dtype != dtype:
*/
    __pyx_t_1 = NULL;
    __Pyx_INCREF(__pyx_builtin_ValueError);
    __pyx_t_2 = __pyx_builtin_ValueError; 

    /* "cupy/cuda/cufft.pyx":801
 *         if out.shape != shape:
 *             raise ValueError(
 *                 ('out must have shape {}.').format(shape))             # <<<<<<<<<<<<<<
 *         if out.dtype != dtype:
 *             raise ValueError(
*/
    __pyx_t_8 = __pyx_mstate_global->__pyx_kp_u_out_must_have_shape;
    __Pyx_INCREF(__pyx_t_8);
    __pyx_t_3 = 0;
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_8, __pyx_v_shape};
      __pyx_t_5 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_format, __pyx_callargs+__pyx_t_3, (2-__pyx_t_3) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 801, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
    }
    __pyx_t_3 = 1;
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_1, __pyx_t_5};
      __pyx_t_4 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+__pyx_t_3, (2-__pyx_t_3) | (__pyx_t_3*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 800, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
    }
    __Pyx_Raise(__pyx_t_4, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __PYX_ERR(0, 800, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":799
 *         """
 *         shape, dtype = self._output_dtype_and_shape(a)
 *         if out.shape != shape:             # <<<<<<<<<<<<<<
 *             raise ValueError(
 *                 ('out must have shape {}.').format(shape))
*/
  }

  /* "cupy/cuda/cufft.pyx":802
 *             raise ValueError(
 *                 ('out must have shape {}.').format(shape))
 *         if out.dtype != dtype:             # <<<<<<<<<<<<<<
 *             raise ValueError(
 *                 'out dtype mismatch: found {}, expected {}'.format(
*/
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_dtype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 802, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_4, __pyx_v_dtype, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 802, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_7 < 0))) __PYX_ERR(0, 802, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (unlikely(__pyx_t_7)) {

    /* "cupy/cuda/cufft.pyx":803
 *                 ('out must have shape {}.').format(shape))
 *         if out.dtype != dtype:
 *             raise ValueError(             # <<<<<<<<<<<<<<
 *                 'out dtype mismatch: found {}, expected {}'.format(
 *                     out.dtype, dtype))
*/
    __pyx_t_4 = NULL;
    __Pyx_INCREF(__pyx_builtin_ValueError);
    __pyx_t_5 = __pyx_builtin_ValueError; 

    /* "cupy/cuda/cufft.pyx":804
 *         if out.dtype != dtype:
 *             raise ValueError(
 *                 'out dtype mismatch: found {}, expected {}'.format(             # <<<<<<<<<<<<<<
 *                     out.dtype, dtype))
 * 
*/
    __pyx_t_8 = __pyx_mstate_global->__pyx_kp_u_out_dtype_mismatch_found_expecte;
    __Pyx_INCREF(__pyx_t_8);

    /* "cupy/cuda/cufft.pyx":805
 *             raise ValueError(
 *                 'out dtype mismatch: found {}, expected {}'.format(
 *                     out.dtype, dtype))             # <<<<<<<<<<<<<<
 * 
 * 
*/
    __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_dtype); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 805, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __pyx_t_3 = 0;
    {
      PyObject *__pyx_callargs[3] = {__pyx_t_8, __pyx_t_9, __pyx_v_dtype};
      __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_format, __pyx_callargs+__pyx_t_3, (3-__pyx_t_3) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 804, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
    }
    __pyx_t_3 = 1;
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_4, __pyx_t_1};
      __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_5, __pyx_callargs+__pyx_t_3, (2-__pyx_t_3) | (__pyx_t_3*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 803, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
    }
    __Pyx_Raise(__pyx_t_2, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __PYX_ERR(0, 803, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":802
 *             raise ValueError(
 *                 ('out must have shape {}.').format(shape))
 *         if out.dtype != dtype:             # <<<<<<<<<<<<<<
 *             raise ValueError(
 *                 'out dtype mismatch: found {}, expected {}'.format(
*/
  }

  /* "cupy/cuda/cufft.pyx":788
 *         return cupy.empty(shape, dtype)
 * 
 *     def check_output_array(self, a, out):             # <<<<<<<<<<<<<<
 *         """Verify shape and dtype of the output array.
 * 
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.check_output_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XDECREF(__pyx_v_dtype);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":54
 * cdef class Plan1d:
 *     cdef:
 *         readonly intptr_t handle             # <<<<<<<<<<<<<<
 *         readonly object work_area  # can be MemoryPointer or a list of it
 *         readonly int nx
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_6handle_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_6handle_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_6handle___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_6handle___get__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyLong_FromSsize_t(__pyx_v_self->handle); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 54, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.handle.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":55
 *     cdef:
 *         readonly intptr_t handle
 *         readonly object work_area  # can be MemoryPointer or a list of it             # <<<<<<<<<<<<<<
 *         readonly int nx
 *         readonly int batch
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_9work_area_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_9work_area_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_9work_area___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_9work_area___get__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->work_area);
  __pyx_r = __pyx_v_self->work_area;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":56
 *         readonly intptr_t handle
 *         readonly object work_area  # can be MemoryPointer or a list of it
 *         readonly int nx             # <<<<<<<<<<<<<<
 *         readonly int batch
 *         readonly Type fft_type
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_2nx_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_2nx_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_2nx___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_2nx___get__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_self->nx); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 56, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.nx.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":57
 *         readonly object work_area  # can be MemoryPointer or a list of it
 *         readonly int nx
 *         readonly int batch             # <<<<<<<<<<<<<<
 *         readonly Type fft_type
 * 
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_5batch_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_5batch_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_5batch___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_5batch___get__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_self->batch); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 57, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.batch.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":58
 *         readonly int nx
 *         readonly int batch
 *         readonly Type fft_type             # <<<<<<<<<<<<<<
 * 
 *         readonly list gpus
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_8fft_type_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_8fft_type_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_8fft_type___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_8fft_type___get__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyLong_From_cufftType_t(__pyx_v_self->fft_type); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 58, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.fft_type.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":60
 *         readonly Type fft_type
 * 
 *         readonly list gpus             # <<<<<<<<<<<<<<
 *         list batch_share
 *         list gather_streams
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_4gpus_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_4gpus_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_4gpus___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_4gpus___get__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->gpus);
  __pyx_r = __pyx_v_self->gpus;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":1
 * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
 *     cdef tuple state
 *     cdef object _dict
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_27__reduce_cython__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6Plan1d_26__reduce_cython__, "Plan1d.__reduce_cython__(self)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_27__reduce_cython__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce_cython__ (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  if (unlikely(__pyx_nargs > 0)) { __Pyx_RaiseArgtupleInvalid("__reduce_cython__", 1, 0, 0, __pyx_nargs); return NULL; }
  const Py_ssize_t __pyx_kwds_len = unlikely(__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
  if (unlikely(__pyx_kwds_len < 0)) return NULL;
  if (unlikely(__pyx_kwds_len > 0)) {__Pyx_RejectKeywords("__reduce_cython__", __pyx_kwds); return NULL;}
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_26__reduce_cython__(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_26__reduce_cython__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self) {
  PyObject *__pyx_v_state = 0;
  PyObject *__pyx_v__dict = 0;
  int __pyx_v_use_setstate;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  int __pyx_t_8;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__reduce_cython__", 0);

  /* "(tree fragment)":5
 *     cdef object _dict
 *     cdef bint use_setstate
 *     state = (self.batch, self.batch_share, self.fft_type, self.gather_events, self.gather_streams, self.gpus, self.handle, self.nx, self.scatter_events, self.scatter_streams, self.work_area, self.xtArr, self.xtArr_buffer)             # <<<<<<<<<<<<<<
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:
*/
  __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_self->batch); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyLong_From_cufftType_t(__pyx_v_self->fft_type); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = PyLong_FromSsize_t(__pyx_v_self->handle); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyLong_From_int(__pyx_v_self->nx); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = PyLong_FromSsize_t(__pyx_v_self->xtArr); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = PyTuple_New(13); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_GIVEREF(__pyx_t_1);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_1) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->batch_share);
  __Pyx_GIVEREF(__pyx_v_self->batch_share);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_v_self->batch_share) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_2);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_t_2) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->gather_events);
  __Pyx_GIVEREF(__pyx_v_self->gather_events);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 3, __pyx_v_self->gather_events) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->gather_streams);
  __Pyx_GIVEREF(__pyx_v_self->gather_streams);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 4, __pyx_v_self->gather_streams) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->gpus);
  __Pyx_GIVEREF(__pyx_v_self->gpus);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 5, __pyx_v_self->gpus) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_3);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 6, __pyx_t_3) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_4);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 7, __pyx_t_4) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->scatter_events);
  __Pyx_GIVEREF(__pyx_v_self->scatter_events);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 8, __pyx_v_self->scatter_events) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->scatter_streams);
  __Pyx_GIVEREF(__pyx_v_self->scatter_streams);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 9, __pyx_v_self->scatter_streams) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->work_area);
  __Pyx_GIVEREF(__pyx_v_self->work_area);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 10, __pyx_v_self->work_area) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_5);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 11, __pyx_t_5) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->xtArr_buffer);
  __Pyx_GIVEREF(__pyx_v_self->xtArr_buffer);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 12, __pyx_v_self->xtArr_buffer) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __pyx_t_1 = 0;
  __pyx_t_2 = 0;
  __pyx_t_3 = 0;
  __pyx_t_4 = 0;
  __pyx_t_5 = 0;
  __pyx_v_state = ((PyObject*)__pyx_t_6);
  __pyx_t_6 = 0;

  /* "(tree fragment)":6
 *     cdef bint use_setstate
 *     state = (self.batch, self.batch_share, self.fft_type, self.gather_events, self.gather_streams, self.gpus, self.handle, self.nx, self.scatter_events, self.scatter_streams, self.work_area, self.xtArr, self.xtArr_buffer)
 *     _dict = getattr(self, '__dict__', None)             # <<<<<<<<<<<<<<
 *     if _dict is not None:
 *         state += (_dict,)
*/
  __pyx_t_6 = __Pyx_GetAttr3(((PyObject *)__pyx_v_self), __pyx_mstate_global->__pyx_n_u_dict, Py_None); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 6, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_v__dict = __pyx_t_6;
  __pyx_t_6 = 0;

  /* "(tree fragment)":7
 *     state = (self.batch, self.batch_share, self.fft_type, self.gather_events, self.gather_streams, self.gpus, self.handle, self.nx, self.scatter_events, self.scatter_streams, self.work_area, self.xtArr, self.xtArr_buffer)
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:             # <<<<<<<<<<<<<<
 *         state += (_dict,)
 *         use_setstate = True
*/
  __pyx_t_7 = (__pyx_v__dict != Py_None);
  if (__pyx_t_7) {

    /* "(tree fragment)":8
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:
 *         state += (_dict,)             # <<<<<<<<<<<<<<
 *         use_setstate = True
 *     else:
*/
    __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 8, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_INCREF(__pyx_v__dict);
    __Pyx_GIVEREF(__pyx_v__dict);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_v__dict) != (0)) __PYX_ERR(1, 8, __pyx_L1_error);
    __pyx_t_5 = PyNumber_InPlaceAdd(__pyx_v_state, __pyx_t_6); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 8, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF_SET(__pyx_v_state, ((PyObject*)__pyx_t_5));
    __pyx_t_5 = 0;

    /* "(tree fragment)":9
 *     if _dict is not None:
 *         state += (_dict,)
 *         use_setstate = True             # <<<<<<<<<<<<<<
 *     else:
 *         use_setstate = self.batch_share is not None or self.gather_events is not None or self.gather_streams is not None or self.gpus is not None or self.scatter_events is not None or self.scatter_streams is not None or self.work_area is not None or self.xtArr_buffer is not None
*/
    __pyx_v_use_setstate = 1;

    /* "(tree fragment)":7
 *     state = (self.batch, self.batch_share, self.fft_type, self.gather_events, self.gather_streams, self.gpus, self.handle, self.nx, self.scatter_events, self.scatter_streams, self.work_area, self.xtArr, self.xtArr_buffer)
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:             # <<<<<<<<<<<<<<
 *         state += (_dict,)
 *         use_setstate = True
*/
    goto __pyx_L3;
  }

  /* "(tree fragment)":11
 *         use_setstate = True
 *     else:
 *         use_setstate = self.batch_share is not None or self.gather_events is not None or self.gather_streams is not None or self.gpus is not None or self.scatter_events is not None or self.scatter_streams is not None or self.work_area is not None or self.xtArr_buffer is not None             # <<<<<<<<<<<<<<
 *     if use_setstate:
 *         return __pyx_unpickle_Plan1d, (type(self), 0xbdeb9ba, None), state
*/
  /*else*/ {
    __pyx_t_8 = (__pyx_v_self->batch_share != ((PyObject*)Py_None));
    if (!__pyx_t_8) {
    } else {
      __pyx_t_7 = __pyx_t_8;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_8 = (__pyx_v_self->gather_events != ((PyObject*)Py_None));
    if (!__pyx_t_8) {
    } else {
      __pyx_t_7 = __pyx_t_8;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_8 = (__pyx_v_self->gather_streams != ((PyObject*)Py_None));
    if (!__pyx_t_8) {
    } else {
      __pyx_t_7 = __pyx_t_8;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_8 = (__pyx_v_self->gpus != ((PyObject*)Py_None));
    if (!__pyx_t_8) {
    } else {
      __pyx_t_7 = __pyx_t_8;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_8 = (__pyx_v_self->scatter_events != ((PyObject*)Py_None));
    if (!__pyx_t_8) {
    } else {
      __pyx_t_7 = __pyx_t_8;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_8 = (__pyx_v_self->scatter_streams != ((PyObject*)Py_None));
    if (!__pyx_t_8) {
    } else {
      __pyx_t_7 = __pyx_t_8;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_8 = (__pyx_v_self->work_area != Py_None);
    if (!__pyx_t_8) {
    } else {
      __pyx_t_7 = __pyx_t_8;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_8 = (__pyx_v_self->xtArr_buffer != ((PyObject*)Py_None));
    __pyx_t_7 = __pyx_t_8;
    __pyx_L4_bool_binop_done:;
    __pyx_v_use_setstate = __pyx_t_7;
  }
  __pyx_L3:;

  /* "(tree fragment)":12
 *     else:
 *         use_setstate = self.batch_share is not None or self.gather_events is not None or self.gather_streams is not None or self.gpus is not None or self.scatter_events is not None or self.scatter_streams is not None or self.work_area is not None or self.xtArr_buffer is not None
 *     if use_setstate:             # <<<<<<<<<<<<<<
 *         return __pyx_unpickle_Plan1d, (type(self), 0xbdeb9ba, None), state
 *     else:
*/
  if (__pyx_v_use_setstate) {

    /* "(tree fragment)":13
 *         use_setstate = self.batch_share is not None or self.gather_events is not None or self.gather_streams is not None or self.gpus is not None or self.scatter_events is not None or self.scatter_streams is not None or self.work_area is not None or self.xtArr_buffer is not None
 *     if use_setstate:
 *         return __pyx_unpickle_Plan1d, (type(self), 0xbdeb9ba, None), state             # <<<<<<<<<<<<<<
 *     else:
 *         return __pyx_unpickle_Plan1d, (type(self), 0xbdeb9ba, state)
*/
    __Pyx_XDECREF(__pyx_r);
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_pyx_unpickle_Plan1d); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 13, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = PyTuple_New(3); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 13, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_INCREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    __Pyx_GIVEREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 0, ((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self)))) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __Pyx_INCREF(__pyx_mstate_global->__pyx_int_199145914);
    __Pyx_GIVEREF(__pyx_mstate_global->__pyx_int_199145914);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_mstate_global->__pyx_int_199145914) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 2, Py_None) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __pyx_t_4 = PyTuple_New(3); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 13, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_5);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_5) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_6);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_t_6) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __Pyx_INCREF(__pyx_v_state);
    __Pyx_GIVEREF(__pyx_v_state);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 2, __pyx_v_state) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __pyx_t_5 = 0;
    __pyx_t_6 = 0;
    __pyx_r = __pyx_t_4;
    __pyx_t_4 = 0;
    goto __pyx_L0;

    /* "(tree fragment)":12
 *     else:
 *         use_setstate = self.batch_share is not None or self.gather_events is not None or self.gather_streams is not None or self.gpus is not None or self.scatter_events is not None or self.scatter_streams is not None or self.work_area is not None or self.xtArr_buffer is not None
 *     if use_setstate:             # <<<<<<<<<<<<<<
 *         return __pyx_unpickle_Plan1d, (type(self), 0xbdeb9ba, None), state
 *     else:
*/
  }

  /* "(tree fragment)":15
 *         return __pyx_unpickle_Plan1d, (type(self), 0xbdeb9ba, None), state
 *     else:
 *         return __pyx_unpickle_Plan1d, (type(self), 0xbdeb9ba, state)             # <<<<<<<<<<<<<<
 * def __setstate_cython__(self, __pyx_state):
 *     __pyx_unpickle_Plan1d__set_state(self, __pyx_state)
*/
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_pyx_unpickle_Plan1d); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 15, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = PyTuple_New(3); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 15, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_INCREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    __Pyx_GIVEREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 0, ((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self)))) != (0)) __PYX_ERR(1, 15, __pyx_L1_error);
    __Pyx_INCREF(__pyx_mstate_global->__pyx_int_199145914);
    __Pyx_GIVEREF(__pyx_mstate_global->__pyx_int_199145914);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_mstate_global->__pyx_int_199145914) != (0)) __PYX_ERR(1, 15, __pyx_L1_error);
    __Pyx_INCREF(__pyx_v_state);
    __Pyx_GIVEREF(__pyx_v_state);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_v_state) != (0)) __PYX_ERR(1, 15, __pyx_L1_error);
    __pyx_t_5 = PyTuple_New(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 15, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_GIVEREF(__pyx_t_4);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4) != (0)) __PYX_ERR(1, 15, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_6);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_t_6) != (0)) __PYX_ERR(1, 15, __pyx_L1_error);
    __pyx_t_4 = 0;
    __pyx_t_6 = 0;
    __pyx_r = __pyx_t_5;
    __pyx_t_5 = 0;
    goto __pyx_L0;
  }

  /* "(tree fragment)":1
 * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
 *     cdef tuple state
 *     cdef object _dict
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.__reduce_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_state);
  __Pyx_XDECREF(__pyx_v__dict);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":16
 *     else:
 *         return __pyx_unpickle_Plan1d, (type(self), 0xbdeb9ba, state)
 * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_unpickle_Plan1d__set_state(self, __pyx_state)
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_29__setstate_cython__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6Plan1d_28__setstate_cython__, "Plan1d.__setstate_cython__(self, __pyx_state)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_29__setstate_cython__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v___pyx_state = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[1] = {0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__setstate_cython__ (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_pyx_state,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(1, 16, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(1, 16, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "__setstate_cython__", 0) < (0)) __PYX_ERR(1, 16, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 1; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("__setstate_cython__", 1, 1, 1, i); __PYX_ERR(1, 16, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 1)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(1, 16, __pyx_L3_error)
    }
    __pyx_v___pyx_state = values[0];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__setstate_cython__", 1, 1, 1, __pyx_nargs); __PYX_ERR(1, 16, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.__setstate_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6Plan1d_28__setstate_cython__(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v_self), __pyx_v___pyx_state);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6Plan1d_28__setstate_cython__(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v_self, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__setstate_cython__", 0);

  /* "(tree fragment)":17
 *         return __pyx_unpickle_Plan1d, (type(self), 0xbdeb9ba, state)
 * def __setstate_cython__(self, __pyx_state):
 *     __pyx_unpickle_Plan1d__set_state(self, __pyx_state)             # <<<<<<<<<<<<<<
*/
  if (!(likely(PyTuple_CheckExact(__pyx_v___pyx_state))||((__pyx_v___pyx_state) == Py_None) || __Pyx_RaiseUnexpectedTypeError("tuple", __pyx_v___pyx_state))) __PYX_ERR(1, 17, __pyx_L1_error)
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft___pyx_unpickle_Plan1d__set_state(__pyx_v_self, ((PyObject*)__pyx_v___pyx_state)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 17, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "(tree fragment)":16
 *     else:
 *         return __pyx_unpickle_Plan1d, (type(self), 0xbdeb9ba, state)
 * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_unpickle_Plan1d__set_state(self, __pyx_state)
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.Plan1d.__setstate_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":809
 * 
 * cdef class PlanNd:
 *     def __init__(self, object shape, object inembed, int istride,             # <<<<<<<<<<<<<<
 *                  int idist, object onembed, int ostride, int odist,
 *                  int fft_type, int batch, str order, int last_axis, last_size,
*/

/* Python wrapper */
static int __pyx_pw_4cupy_4cuda_5cufft_6PlanNd_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_4cupy_4cuda_5cufft_6PlanNd_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_shape = 0;
  PyObject *__pyx_v_inembed = 0;
  int __pyx_v_istride;
  int __pyx_v_idist;
  PyObject *__pyx_v_onembed = 0;
  int __pyx_v_ostride;
  int __pyx_v_odist;
  int __pyx_v_fft_type;
  int __pyx_v_batch;
  PyObject *__pyx_v_order = 0;
  int __pyx_v_last_axis;
  PyObject *__pyx_v_last_size = 0;
  intptr_t __pyx_v_prealloc_plan;
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[13] = {0,0,0,0,0,0,0,0,0,0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return -1;
  #endif
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_shape,&__pyx_mstate_global->__pyx_n_u_inembed,&__pyx_mstate_global->__pyx_n_u_istride,&__pyx_mstate_global->__pyx_n_u_idist,&__pyx_mstate_global->__pyx_n_u_onembed,&__pyx_mstate_global->__pyx_n_u_ostride,&__pyx_mstate_global->__pyx_n_u_odist,&__pyx_mstate_global->__pyx_n_u_fft_type,&__pyx_mstate_global->__pyx_n_u_batch,&__pyx_mstate_global->__pyx_n_u_order,&__pyx_mstate_global->__pyx_n_u_last_axis,&__pyx_mstate_global->__pyx_n_u_last_size,&__pyx_mstate_global->__pyx_n_u_prealloc_plan,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_VARARGS(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 809, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case 12:
        values[11] = __Pyx_ArgRef_VARARGS(__pyx_args, 11);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[11])) __PYX_ERR(0, 809, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case 11:
        values[10] = __Pyx_ArgRef_VARARGS(__pyx_args, 10);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[10])) __PYX_ERR(0, 809, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case 10:
        values[9] = __Pyx_ArgRef_VARARGS(__pyx_args, 9);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[9])) __PYX_ERR(0, 809, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  9:
        values[8] = __Pyx_ArgRef_VARARGS(__pyx_args, 8);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[8])) __PYX_ERR(0, 809, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  8:
        values[7] = __Pyx_ArgRef_VARARGS(__pyx_args, 7);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[7])) __PYX_ERR(0, 809, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  7:
        values[6] = __Pyx_ArgRef_VARARGS(__pyx_args, 6);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[6])) __PYX_ERR(0, 809, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  6:
        values[5] = __Pyx_ArgRef_VARARGS(__pyx_args, 5);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[5])) __PYX_ERR(0, 809, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  5:
        values[4] = __Pyx_ArgRef_VARARGS(__pyx_args, 4);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[4])) __PYX_ERR(0, 809, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  4:
        values[3] = __Pyx_ArgRef_VARARGS(__pyx_args, 3);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 809, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  3:
        values[2] = __Pyx_ArgRef_VARARGS(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 809, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_VARARGS(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 809, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_VARARGS(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 809, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "__init__", 0) < (0)) __PYX_ERR(0, 809, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 12; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("__init__", 1, 12, 12, i); __PYX_ERR(0, 809, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 12)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_VARARGS(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 809, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_VARARGS(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 809, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_VARARGS(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 809, __pyx_L3_error)
      values[3] = __Pyx_ArgRef_VARARGS(__pyx_args, 3);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 809, __pyx_L3_error)
      values[4] = __Pyx_ArgRef_VARARGS(__pyx_args, 4);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[4])) __PYX_ERR(0, 809, __pyx_L3_error)
      values[5] = __Pyx_ArgRef_VARARGS(__pyx_args, 5);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[5])) __PYX_ERR(0, 809, __pyx_L3_error)
      values[6] = __Pyx_ArgRef_VARARGS(__pyx_args, 6);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[6])) __PYX_ERR(0, 809, __pyx_L3_error)
      values[7] = __Pyx_ArgRef_VARARGS(__pyx_args, 7);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[7])) __PYX_ERR(0, 809, __pyx_L3_error)
      values[8] = __Pyx_ArgRef_VARARGS(__pyx_args, 8);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[8])) __PYX_ERR(0, 809, __pyx_L3_error)
      values[9] = __Pyx_ArgRef_VARARGS(__pyx_args, 9);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[9])) __PYX_ERR(0, 809, __pyx_L3_error)
      values[10] = __Pyx_ArgRef_VARARGS(__pyx_args, 10);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[10])) __PYX_ERR(0, 809, __pyx_L3_error)
      values[11] = __Pyx_ArgRef_VARARGS(__pyx_args, 11);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[11])) __PYX_ERR(0, 809, __pyx_L3_error)
    }
    __pyx_v_shape = values[0];
    __pyx_v_inembed = values[1];
    __pyx_v_istride = __Pyx_PyLong_As_int(values[2]); if (unlikely((__pyx_v_istride == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 809, __pyx_L3_error)
    __pyx_v_idist = __Pyx_PyLong_As_int(values[3]); if (unlikely((__pyx_v_idist == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 810, __pyx_L3_error)
    __pyx_v_onembed = values[4];
    __pyx_v_ostride = __Pyx_PyLong_As_int(values[5]); if (unlikely((__pyx_v_ostride == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 810, __pyx_L3_error)
    __pyx_v_odist = __Pyx_PyLong_As_int(values[6]); if (unlikely((__pyx_v_odist == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 810, __pyx_L3_error)
    __pyx_v_fft_type = __Pyx_PyLong_As_int(values[7]); if (unlikely((__pyx_v_fft_type == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 811, __pyx_L3_error)
    __pyx_v_batch = __Pyx_PyLong_As_int(values[8]); if (unlikely((__pyx_v_batch == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 811, __pyx_L3_error)
    __pyx_v_order = ((PyObject*)values[9]);
    __pyx_v_last_axis = __Pyx_PyLong_As_int(values[10]); if (unlikely((__pyx_v_last_axis == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 811, __pyx_L3_error)
    __pyx_v_last_size = values[11];
    if (values[12]) {
      __pyx_v_prealloc_plan = PyLong_AsSsize_t(values[12]); if (unlikely((__pyx_v_prealloc_plan == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 812, __pyx_L3_error)
    } else {
      __pyx_v_prealloc_plan = ((intptr_t)0);
    }
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 1, 12, 12, __pyx_nargs); __PYX_ERR(0, 809, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_order), (&PyUnicode_Type), 1, "order", 1))) __PYX_ERR(0, 811, __pyx_L1_error)
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd___init__(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self), __pyx_v_shape, __pyx_v_inembed, __pyx_v_istride, __pyx_v_idist, __pyx_v_onembed, __pyx_v_ostride, __pyx_v_odist, __pyx_v_fft_type, __pyx_v_batch, __pyx_v_order, __pyx_v_last_axis, __pyx_v_last_size, __pyx_v_prealloc_plan);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = -1;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  goto __pyx_L7_cleaned_up;
  __pyx_L0:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __pyx_L7_cleaned_up:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_4cupy_4cuda_5cufft_6PlanNd___init__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self, PyObject *__pyx_v_shape, PyObject *__pyx_v_inembed, int __pyx_v_istride, int __pyx_v_idist, PyObject *__pyx_v_onembed, int __pyx_v_ostride, int __pyx_v_odist, int __pyx_v_fft_type, int __pyx_v_batch, PyObject *__pyx_v_order, int __pyx_v_last_axis, PyObject *__pyx_v_last_size, intptr_t __pyx_v_prealloc_plan) {
  cufftHandle __pyx_v_plan;
  size_t __pyx_v_work_size;
  int __pyx_v_ndim;
  int __pyx_v_result;
  std::vector<int>  __pyx_v_shape_arr;
  std::vector<int>  __pyx_v_inembed_arr;
  std::vector<int>  __pyx_v_onembed_arr;
  int *__pyx_v_shape_ptr;
  int *__pyx_v_inembed_ptr;
  int *__pyx_v_onembed_ptr;
  intptr_t __pyx_v_ptr;
  PyObject *__pyx_v_work_area = NULL;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  std::vector<int>  __pyx_t_1;
  Py_ssize_t __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  size_t __pyx_t_10;
  intptr_t __pyx_t_11;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "cupy/cuda/cufft.pyx":816
 *         cdef size_t work_size
 *         cdef int ndim, result
 *         cdef vector.vector[int] shape_arr = shape             # <<<<<<<<<<<<<<
 *         cdef vector.vector[int] inembed_arr
 *         cdef vector.vector[int] onembed_arr
*/
  __pyx_t_1 = __pyx_convert_vector_from_py_int(__pyx_v_shape); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 816, __pyx_L1_error)
  __pyx_v_shape_arr = __PYX_STD_MOVE_IF_SUPPORTED(__pyx_t_1);

  /* "cupy/cuda/cufft.pyx":819
 *         cdef vector.vector[int] inembed_arr
 *         cdef vector.vector[int] onembed_arr
 *         cdef int* shape_ptr = shape_arr.data()             # <<<<<<<<<<<<<<
 *         cdef int* inembed_ptr
 *         cdef int* onembed_ptr
*/
  __pyx_v_shape_ptr = __pyx_v_shape_arr.data();

  /* "cupy/cuda/cufft.pyx":824
 *         cdef intptr_t ptr
 * 
 *         self.handle = <intptr_t>0             # <<<<<<<<<<<<<<
 *         ndim = len(shape)
 * 
*/
  __pyx_v_self->handle = ((intptr_t)0);

  /* "cupy/cuda/cufft.pyx":825
 * 
 *         self.handle = <intptr_t>0
 *         ndim = len(shape)             # <<<<<<<<<<<<<<
 * 
 *         if inembed is None:
*/
  __pyx_t_2 = PyObject_Length(__pyx_v_shape); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 825, __pyx_L1_error)
  __pyx_v_ndim = __pyx_t_2;

  /* "cupy/cuda/cufft.pyx":827
 *         ndim = len(shape)
 * 
 *         if inembed is None:             # <<<<<<<<<<<<<<
 *             inembed_ptr = NULL  # ignore istride and use default strides
 *         else:
*/
  __pyx_t_3 = (__pyx_v_inembed == Py_None);
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":828
 * 
 *         if inembed is None:
 *             inembed_ptr = NULL  # ignore istride and use default strides             # <<<<<<<<<<<<<<
 *         else:
 *             inembed_arr = inembed
*/
    __pyx_v_inembed_ptr = NULL;

    /* "cupy/cuda/cufft.pyx":827
 *         ndim = len(shape)
 * 
 *         if inembed is None:             # <<<<<<<<<<<<<<
 *             inembed_ptr = NULL  # ignore istride and use default strides
 *         else:
*/
    goto __pyx_L3;
  }

  /* "cupy/cuda/cufft.pyx":830
 *             inembed_ptr = NULL  # ignore istride and use default strides
 *         else:
 *             inembed_arr = inembed             # <<<<<<<<<<<<<<
 *             inembed_ptr = inembed_arr.data()
 * 
*/
  /*else*/ {
    __pyx_t_1 = __pyx_convert_vector_from_py_int(__pyx_v_inembed); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 830, __pyx_L1_error)
    __pyx_v_inembed_arr = __PYX_STD_MOVE_IF_SUPPORTED(__pyx_t_1);

    /* "cupy/cuda/cufft.pyx":831
 *         else:
 *             inembed_arr = inembed
 *             inembed_ptr = inembed_arr.data()             # <<<<<<<<<<<<<<
 * 
 *         if onembed is None:
*/
    __pyx_v_inembed_ptr = __pyx_v_inembed_arr.data();
  }
  __pyx_L3:;

  /* "cupy/cuda/cufft.pyx":833
 *             inembed_ptr = inembed_arr.data()
 * 
 *         if onembed is None:             # <<<<<<<<<<<<<<
 *             onembed_ptr = NULL  # ignore ostride and use default strides
 *         else:
*/
  __pyx_t_3 = (__pyx_v_onembed == Py_None);
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":834
 * 
 *         if onembed is None:
 *             onembed_ptr = NULL  # ignore ostride and use default strides             # <<<<<<<<<<<<<<
 *         else:
 *             onembed_arr = onembed
*/
    __pyx_v_onembed_ptr = NULL;

    /* "cupy/cuda/cufft.pyx":833
 *             inembed_ptr = inembed_arr.data()
 * 
 *         if onembed is None:             # <<<<<<<<<<<<<<
 *             onembed_ptr = NULL  # ignore ostride and use default strides
 *         else:
*/
    goto __pyx_L4;
  }

  /* "cupy/cuda/cufft.pyx":836
 *             onembed_ptr = NULL  # ignore ostride and use default strides
 *         else:
 *             onembed_arr = onembed             # <<<<<<<<<<<<<<
 *             onembed_ptr = onembed_arr.data()
 * 
*/
  /*else*/ {
    __pyx_t_1 = __pyx_convert_vector_from_py_int(__pyx_v_onembed); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 836, __pyx_L1_error)
    __pyx_v_onembed_arr = __PYX_STD_MOVE_IF_SUPPORTED(__pyx_t_1);

    /* "cupy/cuda/cufft.pyx":837
 *         else:
 *             onembed_arr = onembed
 *             onembed_ptr = onembed_arr.data()             # <<<<<<<<<<<<<<
 * 
 *         if prealloc_plan:
*/
    __pyx_v_onembed_ptr = __pyx_v_onembed_arr.data();
  }
  __pyx_L4:;

  /* "cupy/cuda/cufft.pyx":839
 *             onembed_ptr = onembed_arr.data()
 * 
 *         if prealloc_plan:             # <<<<<<<<<<<<<<
 *             plan = <Handle>prealloc_plan
 *         else:
*/
  __pyx_t_3 = (__pyx_v_prealloc_plan != 0);
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":840
 * 
 *         if prealloc_plan:
 *             plan = <Handle>prealloc_plan             # <<<<<<<<<<<<<<
 *         else:
 *             with nogil:
*/
    __pyx_v_plan = ((cufftHandle)__pyx_v_prealloc_plan);

    /* "cupy/cuda/cufft.pyx":839
 *             onembed_ptr = onembed_arr.data()
 * 
 *         if prealloc_plan:             # <<<<<<<<<<<<<<
 *             plan = <Handle>prealloc_plan
 *         else:
*/
    goto __pyx_L5;
  }

  /* "cupy/cuda/cufft.pyx":842
 *             plan = <Handle>prealloc_plan
 *         else:
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftCreate(&plan)
 *                 if result == 0:
*/
  /*else*/ {
    {
        PyThreadState *_save;
        _save = NULL;
        Py_UNBLOCK_THREADS
        __Pyx_FastGIL_Remember();
        /*try:*/ {

          /* "cupy/cuda/cufft.pyx":843
 *         else:
 *             with nogil:
 *                 result = cufftCreate(&plan)             # <<<<<<<<<<<<<<
 *                 if result == 0:
 *                     result = cufftSetAutoAllocation(plan, 0)
*/
          __pyx_v_result = cufftCreate((&__pyx_v_plan));

          /* "cupy/cuda/cufft.pyx":844
 *             with nogil:
 *                 result = cufftCreate(&plan)
 *                 if result == 0:             # <<<<<<<<<<<<<<
 *                     result = cufftSetAutoAllocation(plan, 0)
 *             check_result(result)
*/
          __pyx_t_3 = (__pyx_v_result == 0);
          if (__pyx_t_3) {

            /* "cupy/cuda/cufft.pyx":845
 *                 result = cufftCreate(&plan)
 *                 if result == 0:
 *                     result = cufftSetAutoAllocation(plan, 0)             # <<<<<<<<<<<<<<
 *             check_result(result)
 * 
*/
            __pyx_v_result = cufftSetAutoAllocation(__pyx_v_plan, 0);

            /* "cupy/cuda/cufft.pyx":844
 *             with nogil:
 *                 result = cufftCreate(&plan)
 *                 if result == 0:             # <<<<<<<<<<<<<<
 *                     result = cufftSetAutoAllocation(plan, 0)
 *             check_result(result)
*/
          }
        }

        /* "cupy/cuda/cufft.pyx":842
 *             plan = <Handle>prealloc_plan
 *         else:
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftCreate(&plan)
 *                 if result == 0:
*/
        /*finally:*/ {
          /*normal exit:*/{
            __Pyx_FastGIL_Forget();
            Py_BLOCK_THREADS
            goto __pyx_L8;
          }
          __pyx_L8:;
        }
    }

    /* "cupy/cuda/cufft.pyx":846
 *                 if result == 0:
 *                     result = cufftSetAutoAllocation(plan, 0)
 *             check_result(result)             # <<<<<<<<<<<<<<
 * 
 *         self.handle = <intptr_t>plan
*/
    __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 846, __pyx_L1_error)
  }
  __pyx_L5:;

  /* "cupy/cuda/cufft.pyx":848
 *             check_result(result)
 * 
 *         self.handle = <intptr_t>plan             # <<<<<<<<<<<<<<
 *         self.gpus = None  # TODO(leofang): support multi-GPU PlanNd
 * 
*/
  __pyx_v_self->handle = ((intptr_t)__pyx_v_plan);

  /* "cupy/cuda/cufft.pyx":849
 * 
 *         self.handle = <intptr_t>plan
 *         self.gpus = None  # TODO(leofang): support multi-GPU PlanNd             # <<<<<<<<<<<<<<
 * 
 *         if batch == 0:
*/
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->gpus);
  __Pyx_DECREF(__pyx_v_self->gpus);
  __pyx_v_self->gpus = ((PyObject*)Py_None);

  /* "cupy/cuda/cufft.pyx":851
 *         self.gpus = None  # TODO(leofang): support multi-GPU PlanNd
 * 
 *         if batch == 0:             # <<<<<<<<<<<<<<
 *             work_size = 0
 *         else:
*/
  __pyx_t_3 = (__pyx_v_batch == 0);
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":852
 * 
 *         if batch == 0:
 *             work_size = 0             # <<<<<<<<<<<<<<
 *         else:
 *             with nogil:
*/
    __pyx_v_work_size = 0;

    /* "cupy/cuda/cufft.pyx":851
 *         self.gpus = None  # TODO(leofang): support multi-GPU PlanNd
 * 
 *         if batch == 0:             # <<<<<<<<<<<<<<
 *             work_size = 0
 *         else:
*/
    goto __pyx_L10;
  }

  /* "cupy/cuda/cufft.pyx":854
 *             work_size = 0
 *         else:
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftMakePlanMany(plan, ndim, shape_ptr,
 *                                            inembed_ptr, istride, idist,
*/
  /*else*/ {
    {
        PyThreadState *_save;
        _save = NULL;
        Py_UNBLOCK_THREADS
        __Pyx_FastGIL_Remember();
        /*try:*/ {

          /* "cupy/cuda/cufft.pyx":855
 *         else:
 *             with nogil:
 *                 result = cufftMakePlanMany(plan, ndim, shape_ptr,             # <<<<<<<<<<<<<<
 *                                            inembed_ptr, istride, idist,
 *                                            onembed_ptr, ostride, odist,
*/
          __pyx_v_result = cufftMakePlanMany(__pyx_v_plan, __pyx_v_ndim, __pyx_v_shape_ptr, __pyx_v_inembed_ptr, __pyx_v_istride, __pyx_v_idist, __pyx_v_onembed_ptr, __pyx_v_ostride, __pyx_v_odist, ((cufftType_t)__pyx_v_fft_type), __pyx_v_batch, (&__pyx_v_work_size));
        }

        /* "cupy/cuda/cufft.pyx":854
 *             work_size = 0
 *         else:
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftMakePlanMany(plan, ndim, shape_ptr,
 *                                            inembed_ptr, istride, idist,
*/
        /*finally:*/ {
          /*normal exit:*/{
            __Pyx_FastGIL_Forget();
            Py_BLOCK_THREADS
            goto __pyx_L13;
          }
          __pyx_L13:;
        }
    }

    /* "cupy/cuda/cufft.pyx":862
 * 
 *             # cufftMakePlanMany could use a large amount of memory
 *             if result == 2:             # <<<<<<<<<<<<<<
 *                 cupy.get_default_memory_pool().free_all_blocks()
 *                 with nogil:
*/
    __pyx_t_3 = (__pyx_v_result == 2);
    if (__pyx_t_3) {

      /* "cupy/cuda/cufft.pyx":863
 *             # cufftMakePlanMany could use a large amount of memory
 *             if result == 2:
 *                 cupy.get_default_memory_pool().free_all_blocks()             # <<<<<<<<<<<<<<
 *                 with nogil:
 *                     result = cufftMakePlanMany(plan, ndim, shape_ptr,
*/
      __pyx_t_7 = NULL;
      __Pyx_GetModuleGlobalName(__pyx_t_8, __pyx_mstate_global->__pyx_n_u_cupy); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 863, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_t_8, __pyx_mstate_global->__pyx_n_u_get_default_memory_pool); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 863, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_9);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_10 = 1;
      #if CYTHON_UNPACK_METHODS
      if (unlikely(PyMethod_Check(__pyx_t_9))) {
        __pyx_t_7 = PyMethod_GET_SELF(__pyx_t_9);
        assert(__pyx_t_7);
        PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_9);
        __Pyx_INCREF(__pyx_t_7);
        __Pyx_INCREF(__pyx__function);
        __Pyx_DECREF_SET(__pyx_t_9, __pyx__function);
        __pyx_t_10 = 0;
      }
      #endif
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_7, NULL};
        __pyx_t_6 = __Pyx_PyObject_FastCall(__pyx_t_9, __pyx_callargs+__pyx_t_10, (1-__pyx_t_10) | (__pyx_t_10*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
        __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
        if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 863, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
      }
      __pyx_t_5 = __pyx_t_6;
      __Pyx_INCREF(__pyx_t_5);
      __pyx_t_10 = 0;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_5, NULL};
        __pyx_t_4 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_free_all_blocks, __pyx_callargs+__pyx_t_10, (1-__pyx_t_10) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 863, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
      }
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

      /* "cupy/cuda/cufft.pyx":864
 *             if result == 2:
 *                 cupy.get_default_memory_pool().free_all_blocks()
 *                 with nogil:             # <<<<<<<<<<<<<<
 *                     result = cufftMakePlanMany(plan, ndim, shape_ptr,
 *                                                inembed_ptr, istride, idist,
*/
      {
          PyThreadState *_save;
          _save = NULL;
          Py_UNBLOCK_THREADS
          __Pyx_FastGIL_Remember();
          /*try:*/ {

            /* "cupy/cuda/cufft.pyx":865
 *                 cupy.get_default_memory_pool().free_all_blocks()
 *                 with nogil:
 *                     result = cufftMakePlanMany(plan, ndim, shape_ptr,             # <<<<<<<<<<<<<<
 *                                                inembed_ptr, istride, idist,
 *                                                onembed_ptr, ostride, odist,
*/
            __pyx_v_result = cufftMakePlanMany(__pyx_v_plan, __pyx_v_ndim, __pyx_v_shape_ptr, __pyx_v_inembed_ptr, __pyx_v_istride, __pyx_v_idist, __pyx_v_onembed_ptr, __pyx_v_ostride, __pyx_v_odist, ((cufftType_t)__pyx_v_fft_type), __pyx_v_batch, (&__pyx_v_work_size));
          }

          /* "cupy/cuda/cufft.pyx":864
 *             if result == 2:
 *                 cupy.get_default_memory_pool().free_all_blocks()
 *                 with nogil:             # <<<<<<<<<<<<<<
 *                     result = cufftMakePlanMany(plan, ndim, shape_ptr,
 *                                                inembed_ptr, istride, idist,
*/
          /*finally:*/ {
            /*normal exit:*/{
              __Pyx_FastGIL_Forget();
              Py_BLOCK_THREADS
              goto __pyx_L17;
            }
            __pyx_L17:;
          }
      }

      /* "cupy/cuda/cufft.pyx":862
 * 
 *             # cufftMakePlanMany could use a large amount of memory
 *             if result == 2:             # <<<<<<<<<<<<<<
 *                 cupy.get_default_memory_pool().free_all_blocks()
 *                 with nogil:
*/
    }

    /* "cupy/cuda/cufft.pyx":870
 *                                                <Type>fft_type, batch,
 *                                                &work_size)
 *             check_result(result)             # <<<<<<<<<<<<<<
 * 
 *         # TODO: for CUDA>=9.2 could also allow setting a work area policy
*/
    __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 870, __pyx_L1_error)
  }
  __pyx_L10:;

  /* "cupy/cuda/cufft.pyx":875
 *         # result = cufftXtSetWorkAreaPolicy(plan, policy, &work_size)
 * 
 *         work_area = memory.alloc(work_size)             # <<<<<<<<<<<<<<
 *         ptr = <intptr_t>(work_area.ptr)
 *         with nogil:
*/
  __pyx_t_6 = NULL;
  __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_memory); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 875, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_9 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_alloc); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 875, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_9);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyLong_FromSize_t(__pyx_v_work_size); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 875, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_10 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_9))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_9);
    assert(__pyx_t_6);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_9);
    __Pyx_INCREF(__pyx_t_6);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_9, __pyx__function);
    __pyx_t_10 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_6, __pyx_t_5};
    __pyx_t_4 = __Pyx_PyObject_FastCall(__pyx_t_9, __pyx_callargs+__pyx_t_10, (2-__pyx_t_10) | (__pyx_t_10*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
    if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 875, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
  }
  __pyx_v_work_area = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "cupy/cuda/cufft.pyx":876
 * 
 *         work_area = memory.alloc(work_size)
 *         ptr = <intptr_t>(work_area.ptr)             # <<<<<<<<<<<<<<
 *         with nogil:
 *             result = cufftSetWorkArea(plan, <void*>(ptr))
*/
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_work_area, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 876, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_11 = PyLong_AsSsize_t(__pyx_t_4); if (unlikely((__pyx_t_11 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 876, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_ptr = ((intptr_t)__pyx_t_11);

  /* "cupy/cuda/cufft.pyx":877
 *         work_area = memory.alloc(work_size)
 *         ptr = <intptr_t>(work_area.ptr)
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftSetWorkArea(plan, <void*>(ptr))
 *         check_result(result)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":878
 *         ptr = <intptr_t>(work_area.ptr)
 *         with nogil:
 *             result = cufftSetWorkArea(plan, <void*>(ptr))             # <<<<<<<<<<<<<<
 *         check_result(result)
 * 
*/
        __pyx_v_result = cufftSetWorkArea(__pyx_v_plan, ((void *)__pyx_v_ptr));
      }

      /* "cupy/cuda/cufft.pyx":877
 *         work_area = memory.alloc(work_size)
 *         ptr = <intptr_t>(work_area.ptr)
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftSetWorkArea(plan, <void*>(ptr))
 *         check_result(result)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L20;
        }
        __pyx_L20:;
      }
  }

  /* "cupy/cuda/cufft.pyx":879
 *         with nogil:
 *             result = cufftSetWorkArea(plan, <void*>(ptr))
 *         check_result(result)             # <<<<<<<<<<<<<<
 * 
 *         self.shape = tuple(shape)
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 879, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":881
 *         check_result(result)
 * 
 *         self.shape = tuple(shape)             # <<<<<<<<<<<<<<
 *         self.fft_type = <Type>fft_type
 *         self.work_area = work_area
*/
  __pyx_t_4 = __Pyx_PySequence_Tuple(__pyx_v_shape); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 881, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_4);
  __Pyx_GOTREF(__pyx_v_self->shape);
  __Pyx_DECREF(__pyx_v_self->shape);
  __pyx_v_self->shape = ((PyObject*)__pyx_t_4);
  __pyx_t_4 = 0;

  /* "cupy/cuda/cufft.pyx":882
 * 
 *         self.shape = tuple(shape)
 *         self.fft_type = <Type>fft_type             # <<<<<<<<<<<<<<
 *         self.work_area = work_area
 *         self.order = order  # either 'C' or 'F'
*/
  __pyx_v_self->fft_type = ((cufftType_t)__pyx_v_fft_type);

  /* "cupy/cuda/cufft.pyx":883
 *         self.shape = tuple(shape)
 *         self.fft_type = <Type>fft_type
 *         self.work_area = work_area             # <<<<<<<<<<<<<<
 *         self.order = order  # either 'C' or 'F'
 *         self.last_axis = last_axis  # ignored for C2C
*/
  __Pyx_INCREF(__pyx_v_work_area);
  __Pyx_GIVEREF(__pyx_v_work_area);
  __Pyx_GOTREF(__pyx_v_self->work_area);
  __Pyx_DECREF(__pyx_v_self->work_area);
  __pyx_v_self->work_area = __pyx_v_work_area;

  /* "cupy/cuda/cufft.pyx":884
 *         self.fft_type = <Type>fft_type
 *         self.work_area = work_area
 *         self.order = order  # either 'C' or 'F'             # <<<<<<<<<<<<<<
 *         self.last_axis = last_axis  # ignored for C2C
 *         self.last_size = last_size  # = None (and ignored) for C2C
*/
  __Pyx_INCREF(__pyx_v_order);
  __Pyx_GIVEREF(__pyx_v_order);
  __Pyx_GOTREF(__pyx_v_self->order);
  __Pyx_DECREF(__pyx_v_self->order);
  __pyx_v_self->order = __pyx_v_order;

  /* "cupy/cuda/cufft.pyx":885
 *         self.work_area = work_area
 *         self.order = order  # either 'C' or 'F'
 *         self.last_axis = last_axis  # ignored for C2C             # <<<<<<<<<<<<<<
 *         self.last_size = last_size  # = None (and ignored) for C2C
 * 
*/
  __pyx_v_self->last_axis = __pyx_v_last_axis;

  /* "cupy/cuda/cufft.pyx":886
 *         self.order = order  # either 'C' or 'F'
 *         self.last_axis = last_axis  # ignored for C2C
 *         self.last_size = last_size  # = None (and ignored) for C2C             # <<<<<<<<<<<<<<
 * 
 *     def __dealloc__(self):
*/
  __Pyx_INCREF(__pyx_v_last_size);
  __Pyx_GIVEREF(__pyx_v_last_size);
  __Pyx_GOTREF(__pyx_v_self->last_size);
  __Pyx_DECREF(__pyx_v_self->last_size);
  __pyx_v_self->last_size = __pyx_v_last_size;

  /* "cupy/cuda/cufft.pyx":809
 * 
 * cdef class PlanNd:
 *     def __init__(self, object shape, object inembed, int istride,             # <<<<<<<<<<<<<<
 *                  int idist, object onembed, int ostride, int odist,
 *                  int fft_type, int batch, str order, int last_axis, last_size,
*/

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_work_area);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":888
 *         self.last_size = last_size  # = None (and ignored) for C2C
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         cdef Handle plan = <Handle>self.handle
 *         cdef int result
*/

/* Python wrapper */
static void __pyx_pw_4cupy_4cuda_5cufft_6PlanNd_3__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_4cupy_4cuda_5cufft_6PlanNd_3__dealloc__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_2__dealloc__(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_2__dealloc__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self) {
  cufftHandle __pyx_v_plan;
  int __pyx_v_result;
  int __pyx_t_1;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;

  /* "cupy/cuda/cufft.pyx":889
 * 
 *     def __dealloc__(self):
 *         cdef Handle plan = <Handle>self.handle             # <<<<<<<<<<<<<<
 *         cdef int result
 * 
*/
  __pyx_v_plan = ((cufftHandle)__pyx_v_self->handle);

  /* "cupy/cuda/cufft.pyx":892
 *         cdef int result
 * 
 *         if plan != <Handle>0:             # <<<<<<<<<<<<<<
 *             with nogil:
 *                 result = cufftDestroy(plan)
*/
  __pyx_t_1 = (__pyx_v_plan != ((cufftHandle)0));
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":893
 * 
 *         if plan != <Handle>0:
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftDestroy(plan)
 *             check_result(result)
*/
    {
        PyThreadState *_save;
        _save = NULL;
        Py_UNBLOCK_THREADS
        __Pyx_FastGIL_Remember();
        /*try:*/ {

          /* "cupy/cuda/cufft.pyx":894
 *         if plan != <Handle>0:
 *             with nogil:
 *                 result = cufftDestroy(plan)             # <<<<<<<<<<<<<<
 *             check_result(result)
 *             self.handle = <intptr_t>0
*/
          __pyx_v_result = cufftDestroy(__pyx_v_plan);
        }

        /* "cupy/cuda/cufft.pyx":893
 * 
 *         if plan != <Handle>0:
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftDestroy(plan)
 *             check_result(result)
*/
        /*finally:*/ {
          /*normal exit:*/{
            __Pyx_FastGIL_Forget();
            Py_BLOCK_THREADS
            goto __pyx_L6;
          }
          __pyx_L6:;
        }
    }

    /* "cupy/cuda/cufft.pyx":895
 *             with nogil:
 *                 result = cufftDestroy(plan)
 *             check_result(result)             # <<<<<<<<<<<<<<
 *             self.handle = <intptr_t>0
 * 
*/
    __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 895, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":896
 *                 result = cufftDestroy(plan)
 *             check_result(result)
 *             self.handle = <intptr_t>0             # <<<<<<<<<<<<<<
 * 
 *     def __enter__(self):
*/
    __pyx_v_self->handle = ((intptr_t)0);

    /* "cupy/cuda/cufft.pyx":892
 *         cdef int result
 * 
 *         if plan != <Handle>0:             # <<<<<<<<<<<<<<
 *             with nogil:
 *                 result = cufftDestroy(plan)
*/
  }

  /* "cupy/cuda/cufft.pyx":888
 *         self.last_size = last_size  # = None (and ignored) for C2C
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         cdef Handle plan = <Handle>self.handle
 *         cdef int result
*/

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_WriteUnraisable("cupy.cuda.cufft.PlanNd.__dealloc__", __pyx_clineno, __pyx_lineno, __pyx_filename, 1, 0);
  __pyx_L0:;
}

/* "cupy/cuda/cufft.pyx":898
 *             self.handle = <intptr_t>0
 * 
 *     def __enter__(self):             # <<<<<<<<<<<<<<
 *         _thread_local._current_plan = self
 *         return self
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_5__enter__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6PlanNd_4__enter__, "PlanNd.__enter__(self)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_5__enter__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__enter__ (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  if (unlikely(__pyx_nargs > 0)) { __Pyx_RaiseArgtupleInvalid("__enter__", 1, 0, 0, __pyx_nargs); return NULL; }
  const Py_ssize_t __pyx_kwds_len = unlikely(__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
  if (unlikely(__pyx_kwds_len < 0)) return NULL;
  if (unlikely(__pyx_kwds_len > 0)) {__Pyx_RejectKeywords("__enter__", __pyx_kwds); return NULL;}
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_4__enter__(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_4__enter__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__enter__", 0);

  /* "cupy/cuda/cufft.pyx":899
 * 
 *     def __enter__(self):
 *         _thread_local._current_plan = self             # <<<<<<<<<<<<<<
 *         return self
 * 
*/
  if (__Pyx_PyObject_SetAttrStr(__pyx_v_4cupy_4cuda_5cufft__thread_local, __pyx_mstate_global->__pyx_n_u_current_plan, ((PyObject *)__pyx_v_self)) < (0)) __PYX_ERR(0, 899, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":900
 *     def __enter__(self):
 *         _thread_local._current_plan = self
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __exit__(self, exc_type, exc_value, traceback):
*/
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF((PyObject *)__pyx_v_self);
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":898
 *             self.handle = <intptr_t>0
 * 
 *     def __enter__(self):             # <<<<<<<<<<<<<<
 *         _thread_local._current_plan = self
 *         return self
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.__enter__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":902
 *         return self
 * 
 *     def __exit__(self, exc_type, exc_value, traceback):             # <<<<<<<<<<<<<<
 *         _thread_local._current_plan = None
 * 
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_7__exit__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6PlanNd_6__exit__, "PlanNd.__exit__(self, exc_type, exc_value, traceback)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_7__exit__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  CYTHON_UNUSED PyObject *__pyx_v_exc_type = 0;
  CYTHON_UNUSED PyObject *__pyx_v_exc_value = 0;
  CYTHON_UNUSED PyObject *__pyx_v_traceback = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__exit__ (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_exc_type,&__pyx_mstate_global->__pyx_n_u_exc_value,&__pyx_mstate_global->__pyx_n_u_traceback,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 902, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 902, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 902, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 902, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "__exit__", 0) < (0)) __PYX_ERR(0, 902, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("__exit__", 1, 3, 3, i); __PYX_ERR(0, 902, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 902, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 902, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 902, __pyx_L3_error)
    }
    __pyx_v_exc_type = values[0];
    __pyx_v_exc_value = values[1];
    __pyx_v_traceback = values[2];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__exit__", 1, 3, 3, __pyx_nargs); __PYX_ERR(0, 902, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.__exit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_6__exit__(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self), __pyx_v_exc_type, __pyx_v_exc_value, __pyx_v_traceback);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_6__exit__(CYTHON_UNUSED struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v_exc_type, CYTHON_UNUSED PyObject *__pyx_v_exc_value, CYTHON_UNUSED PyObject *__pyx_v_traceback) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__exit__", 0);

  /* "cupy/cuda/cufft.pyx":903
 * 
 *     def __exit__(self, exc_type, exc_value, traceback):
 *         _thread_local._current_plan = None             # <<<<<<<<<<<<<<
 * 
 *     def fft(self, a, out, direction):
*/
  if (__Pyx_PyObject_SetAttrStr(__pyx_v_4cupy_4cuda_5cufft__thread_local, __pyx_mstate_global->__pyx_n_u_current_plan, Py_None) < (0)) __PYX_ERR(0, 903, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":902
 *         return self
 * 
 *     def __exit__(self, exc_type, exc_value, traceback):             # <<<<<<<<<<<<<<
 *         _thread_local._current_plan = None
 * 
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.__exit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":905
 *         _thread_local._current_plan = None
 * 
 *     def fft(self, a, out, direction):             # <<<<<<<<<<<<<<
 *         cdef intptr_t plan = self.handle
 *         cdef intptr_t s = stream.get_current_stream().ptr
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_9fft(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6PlanNd_8fft, "PlanNd.fft(self, a, out, direction)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_9fft(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_a = 0;
  PyObject *__pyx_v_out = 0;
  PyObject *__pyx_v_direction = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("fft (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_a,&__pyx_mstate_global->__pyx_n_u_out,&__pyx_mstate_global->__pyx_n_u_direction,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 905, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 905, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 905, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 905, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "fft", 0) < (0)) __PYX_ERR(0, 905, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("fft", 1, 3, 3, i); __PYX_ERR(0, 905, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 905, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 905, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 905, __pyx_L3_error)
    }
    __pyx_v_a = values[0];
    __pyx_v_out = values[1];
    __pyx_v_direction = values[2];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("fft", 1, 3, 3, __pyx_nargs); __PYX_ERR(0, 905, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.fft", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_8fft(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self), __pyx_v_a, __pyx_v_out, __pyx_v_direction);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_8fft(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_out, PyObject *__pyx_v_direction) {
  intptr_t __pyx_v_plan;
  intptr_t __pyx_v_s;
  int __pyx_v_result;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  intptr_t __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  size_t __pyx_t_6;
  intptr_t __pyx_t_7;
  int __pyx_t_8;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("fft", 0);

  /* "cupy/cuda/cufft.pyx":906
 * 
 *     def fft(self, a, out, direction):
 *         cdef intptr_t plan = self.handle             # <<<<<<<<<<<<<<
 *         cdef intptr_t s = stream.get_current_stream().ptr
 *         cdef int result
*/
  __pyx_t_1 = __pyx_v_self->handle;
  __pyx_v_plan = __pyx_t_1;

  /* "cupy/cuda/cufft.pyx":907
 *     def fft(self, a, out, direction):
 *         cdef intptr_t plan = self.handle
 *         cdef intptr_t s = stream.get_current_stream().ptr             # <<<<<<<<<<<<<<
 *         cdef int result
 * 
*/
  __pyx_t_3 = NULL;
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_stream); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 907, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_get_current_stream); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 907, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_6 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
    assert(__pyx_t_3);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_5);
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_5, __pyx__function);
    __pyx_t_6 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, NULL};
    __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_5, __pyx_callargs+__pyx_t_6, (1-__pyx_t_6) | (__pyx_t_6*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 907, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
  }
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 907, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_1 = PyLong_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_1 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 907, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_s = __pyx_t_1;

  /* "cupy/cuda/cufft.pyx":910
 *         cdef int result
 * 
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftSetStream(<Handle>plan, <Stream>s)
 *         check_result(result)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":911
 * 
 *         with nogil:
 *             result = cufftSetStream(<Handle>plan, <Stream>s)             # <<<<<<<<<<<<<<
 *         check_result(result)
 * 
*/
        __pyx_v_result = cufftSetStream(((cufftHandle)__pyx_v_plan), ((cudaStream_t)__pyx_v_s));
      }

      /* "cupy/cuda/cufft.pyx":910
 *         cdef int result
 * 
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftSetStream(<Handle>plan, <Stream>s)
 *         check_result(result)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "cupy/cuda/cufft.pyx":912
 *         with nogil:
 *             result = cufftSetStream(<Handle>plan, <Stream>s)
 *         check_result(result)             # <<<<<<<<<<<<<<
 * 
 *         if self.fft_type == CUFFT_C2C:
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 912, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":914
 *         check_result(result)
 * 
 *         if self.fft_type == CUFFT_C2C:             # <<<<<<<<<<<<<<
 *             execC2C(plan, a.data.ptr, out.data.ptr, direction)
 *         elif self.fft_type == CUFFT_R2C:
*/
  switch (__pyx_v_self->fft_type) {
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_C2C:

    /* "cupy/cuda/cufft.pyx":915
 * 
 *         if self.fft_type == CUFFT_C2C:
 *             execC2C(plan, a.data.ptr, out.data.ptr, direction)             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_R2C:
 *             execR2C(plan, a.data.ptr, out.data.ptr)
*/
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 915, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 915, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_1 = PyLong_AsSsize_t(__pyx_t_2); if (unlikely((__pyx_t_1 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 915, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 915, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 915, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_7 = PyLong_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_7 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 915, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_8 = __Pyx_PyLong_As_int(__pyx_v_direction); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 915, __pyx_L1_error)
    __pyx_t_5 = __pyx_f_4cupy_4cuda_5cufft_execC2C(__pyx_v_plan, __pyx_t_1, __pyx_t_7, __pyx_t_8, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 915, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "cupy/cuda/cufft.pyx":914
 *         check_result(result)
 * 
 *         if self.fft_type == CUFFT_C2C:             # <<<<<<<<<<<<<<
 *             execC2C(plan, a.data.ptr, out.data.ptr, direction)
 *         elif self.fft_type == CUFFT_R2C:
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_R2C:

    /* "cupy/cuda/cufft.pyx":917
 *             execC2C(plan, a.data.ptr, out.data.ptr, direction)
 *         elif self.fft_type == CUFFT_R2C:
 *             execR2C(plan, a.data.ptr, out.data.ptr)             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_C2R:
 *             execC2R(plan, a.data.ptr, out.data.ptr)
*/
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 917, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 917, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_7 = PyLong_AsSsize_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 917, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 917, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 917, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_1 = PyLong_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_1 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 917, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __pyx_f_4cupy_4cuda_5cufft_execR2C(__pyx_v_plan, __pyx_t_7, __pyx_t_1, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 917, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "cupy/cuda/cufft.pyx":916
 *         if self.fft_type == CUFFT_C2C:
 *             execC2C(plan, a.data.ptr, out.data.ptr, direction)
 *         elif self.fft_type == CUFFT_R2C:             # <<<<<<<<<<<<<<
 *             execR2C(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_C2R:
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_C2R:

    /* "cupy/cuda/cufft.pyx":919
 *             execR2C(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_C2R:
 *             execC2R(plan, a.data.ptr, out.data.ptr)             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_Z2Z:
 *             execZ2Z(plan, a.data.ptr, out.data.ptr, direction)
*/
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 919, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 919, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_1 = PyLong_AsSsize_t(__pyx_t_2); if (unlikely((__pyx_t_1 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 919, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 919, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 919, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_7 = PyLong_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_7 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 919, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __pyx_f_4cupy_4cuda_5cufft_execC2R(__pyx_v_plan, __pyx_t_1, __pyx_t_7, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 919, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "cupy/cuda/cufft.pyx":918
 *         elif self.fft_type == CUFFT_R2C:
 *             execR2C(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_C2R:             # <<<<<<<<<<<<<<
 *             execC2R(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_Z2Z:
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_Z2Z:

    /* "cupy/cuda/cufft.pyx":921
 *             execC2R(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_Z2Z:
 *             execZ2Z(plan, a.data.ptr, out.data.ptr, direction)             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_D2Z:
 *             execD2Z(plan, a.data.ptr, out.data.ptr)
*/
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 921, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 921, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_7 = PyLong_AsSsize_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 921, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 921, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 921, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_1 = PyLong_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_1 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 921, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_8 = __Pyx_PyLong_As_int(__pyx_v_direction); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 921, __pyx_L1_error)
    __pyx_t_5 = __pyx_f_4cupy_4cuda_5cufft_execZ2Z(__pyx_v_plan, __pyx_t_7, __pyx_t_1, __pyx_t_8, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 921, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "cupy/cuda/cufft.pyx":920
 *         elif self.fft_type == CUFFT_C2R:
 *             execC2R(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_Z2Z:             # <<<<<<<<<<<<<<
 *             execZ2Z(plan, a.data.ptr, out.data.ptr, direction)
 *         elif self.fft_type == CUFFT_D2Z:
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_D2Z:

    /* "cupy/cuda/cufft.pyx":923
 *             execZ2Z(plan, a.data.ptr, out.data.ptr, direction)
 *         elif self.fft_type == CUFFT_D2Z:
 *             execD2Z(plan, a.data.ptr, out.data.ptr)             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_Z2D:
 *             execZ2D(plan, a.data.ptr, out.data.ptr)
*/
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 923, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 923, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_1 = PyLong_AsSsize_t(__pyx_t_2); if (unlikely((__pyx_t_1 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 923, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 923, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 923, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_7 = PyLong_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_7 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 923, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __pyx_f_4cupy_4cuda_5cufft_execD2Z(__pyx_v_plan, __pyx_t_1, __pyx_t_7, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 923, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "cupy/cuda/cufft.pyx":922
 *         elif self.fft_type == CUFFT_Z2Z:
 *             execZ2Z(plan, a.data.ptr, out.data.ptr, direction)
 *         elif self.fft_type == CUFFT_D2Z:             # <<<<<<<<<<<<<<
 *             execD2Z(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_Z2D:
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_Z2D:

    /* "cupy/cuda/cufft.pyx":925
 *             execD2Z(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_Z2D:
 *             execZ2D(plan, a.data.ptr, out.data.ptr)             # <<<<<<<<<<<<<<
 *         else:
 *             raise ValueError
*/
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 925, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 925, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_7 = PyLong_AsSsize_t(__pyx_t_2); if (unlikely((__pyx_t_7 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 925, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 925, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 925, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_1 = PyLong_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_1 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 925, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_5 = __pyx_f_4cupy_4cuda_5cufft_execZ2D(__pyx_v_plan, __pyx_t_7, __pyx_t_1, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 925, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

    /* "cupy/cuda/cufft.pyx":924
 *         elif self.fft_type == CUFFT_D2Z:
 *             execD2Z(plan, a.data.ptr, out.data.ptr)
 *         elif self.fft_type == CUFFT_Z2D:             # <<<<<<<<<<<<<<
 *             execZ2D(plan, a.data.ptr, out.data.ptr)
 *         else:
*/
    break;
    default:

    /* "cupy/cuda/cufft.pyx":927
 *             execZ2D(plan, a.data.ptr, out.data.ptr)
 *         else:
 *             raise ValueError             # <<<<<<<<<<<<<<
 * 
 *     def _output_dtype_and_shape(self, a):
*/
    __Pyx_Raise(__pyx_builtin_ValueError, 0, 0, 0);
    __PYX_ERR(0, 927, __pyx_L1_error)
    break;
  }

  /* "cupy/cuda/cufft.pyx":905
 *         _thread_local._current_plan = None
 * 
 *     def fft(self, a, out, direction):             # <<<<<<<<<<<<<<
 *         cdef intptr_t plan = self.handle
 *         cdef intptr_t s = stream.get_current_stream().ptr
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.fft", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":929
 *             raise ValueError
 * 
 *     def _output_dtype_and_shape(self, a):             # <<<<<<<<<<<<<<
 *         shape = list(a.shape)
 *         if self.fft_type == CUFFT_C2C:
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_11_output_dtype_and_shape(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6PlanNd_10_output_dtype_and_shape, "PlanNd._output_dtype_and_shape(self, a)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_11_output_dtype_and_shape(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_a = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[1] = {0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_output_dtype_and_shape (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_a,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 929, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 929, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "_output_dtype_and_shape", 0) < (0)) __PYX_ERR(0, 929, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 1; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("_output_dtype_and_shape", 1, 1, 1, i); __PYX_ERR(0, 929, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 1)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 929, __pyx_L3_error)
    }
    __pyx_v_a = values[0];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_output_dtype_and_shape", 1, 1, 1, __pyx_nargs); __PYX_ERR(0, 929, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd._output_dtype_and_shape", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_10_output_dtype_and_shape(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self), __pyx_v_a);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_10_output_dtype_and_shape(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self, PyObject *__pyx_v_a) {
  PyObject *__pyx_v_shape = NULL;
  PyObject *__pyx_v_dtype = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_output_dtype_and_shape", 0);

  /* "cupy/cuda/cufft.pyx":930
 * 
 *     def _output_dtype_and_shape(self, a):
 *         shape = list(a.shape)             # <<<<<<<<<<<<<<
 *         if self.fft_type == CUFFT_C2C:
 *             dtype = numpy.complex64
*/
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 930, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PySequence_ListKeepNew(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 930, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_shape = ((PyObject*)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "cupy/cuda/cufft.pyx":931
 *     def _output_dtype_and_shape(self, a):
 *         shape = list(a.shape)
 *         if self.fft_type == CUFFT_C2C:             # <<<<<<<<<<<<<<
 *             dtype = numpy.complex64
 *         elif self.fft_type == CUFFT_R2C:
*/
  switch (__pyx_v_self->fft_type) {
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_C2C:

    /* "cupy/cuda/cufft.pyx":932
 *         shape = list(a.shape)
 *         if self.fft_type == CUFFT_C2C:
 *             dtype = numpy.complex64             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_R2C:
 *             shape[self.last_axis] = self.last_size
*/
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 932, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_complex64); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 932, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_dtype = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":931
 *     def _output_dtype_and_shape(self, a):
 *         shape = list(a.shape)
 *         if self.fft_type == CUFFT_C2C:             # <<<<<<<<<<<<<<
 *             dtype = numpy.complex64
 *         elif self.fft_type == CUFFT_R2C:
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_R2C:

    /* "cupy/cuda/cufft.pyx":934
 *             dtype = numpy.complex64
 *         elif self.fft_type == CUFFT_R2C:
 *             shape[self.last_axis] = self.last_size             # <<<<<<<<<<<<<<
 *             dtype = numpy.complex64
 *         elif self.fft_type == CUFFT_C2R:
*/
    __pyx_t_1 = __pyx_v_self->last_size;
    __Pyx_INCREF(__pyx_t_1);
    if (unlikely((__Pyx_SetItemInt(__pyx_v_shape, __pyx_v_self->last_axis, __pyx_t_1, int, 1, __Pyx_PyLong_From_int, 1, 1, 1, 1) < 0))) __PYX_ERR(0, 934, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":935
 *         elif self.fft_type == CUFFT_R2C:
 *             shape[self.last_axis] = self.last_size
 *             dtype = numpy.complex64             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_C2R:
 *             shape[self.last_axis] = self.last_size
*/
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 935, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_complex64); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 935, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_dtype = __pyx_t_2;
    __pyx_t_2 = 0;

    /* "cupy/cuda/cufft.pyx":933
 *         if self.fft_type == CUFFT_C2C:
 *             dtype = numpy.complex64
 *         elif self.fft_type == CUFFT_R2C:             # <<<<<<<<<<<<<<
 *             shape[self.last_axis] = self.last_size
 *             dtype = numpy.complex64
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_C2R:

    /* "cupy/cuda/cufft.pyx":937
 *             dtype = numpy.complex64
 *         elif self.fft_type == CUFFT_C2R:
 *             shape[self.last_axis] = self.last_size             # <<<<<<<<<<<<<<
 *             dtype = numpy.float32
 *         elif self.fft_type == CUFFT_Z2Z:
*/
    __pyx_t_2 = __pyx_v_self->last_size;
    __Pyx_INCREF(__pyx_t_2);
    if (unlikely((__Pyx_SetItemInt(__pyx_v_shape, __pyx_v_self->last_axis, __pyx_t_2, int, 1, __Pyx_PyLong_From_int, 1, 1, 1, 1) < 0))) __PYX_ERR(0, 937, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "cupy/cuda/cufft.pyx":938
 *         elif self.fft_type == CUFFT_C2R:
 *             shape[self.last_axis] = self.last_size
 *             dtype = numpy.float32             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_Z2Z:
 *             dtype = numpy.complex128
*/
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 938, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_float32); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 938, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_dtype = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":936
 *             shape[self.last_axis] = self.last_size
 *             dtype = numpy.complex64
 *         elif self.fft_type == CUFFT_C2R:             # <<<<<<<<<<<<<<
 *             shape[self.last_axis] = self.last_size
 *             dtype = numpy.float32
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_Z2Z:

    /* "cupy/cuda/cufft.pyx":940
 *             dtype = numpy.float32
 *         elif self.fft_type == CUFFT_Z2Z:
 *             dtype = numpy.complex128             # <<<<<<<<<<<<<<
 *         elif self.fft_type == CUFFT_D2Z:
 *             shape[self.last_axis] = self.last_size
*/
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 940, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_complex128); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 940, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_dtype = __pyx_t_2;
    __pyx_t_2 = 0;

    /* "cupy/cuda/cufft.pyx":939
 *             shape[self.last_axis] = self.last_size
 *             dtype = numpy.float32
 *         elif self.fft_type == CUFFT_Z2Z:             # <<<<<<<<<<<<<<
 *             dtype = numpy.complex128
 *         elif self.fft_type == CUFFT_D2Z:
*/
    break;
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_D2Z:

    /* "cupy/cuda/cufft.pyx":942
 *             dtype = numpy.complex128
 *         elif self.fft_type == CUFFT_D2Z:
 *             shape[self.last_axis] = self.last_size             # <<<<<<<<<<<<<<
 *             dtype = numpy.complex128
 *         else:  # CUFFT_Z2D
*/
    __pyx_t_2 = __pyx_v_self->last_size;
    __Pyx_INCREF(__pyx_t_2);
    if (unlikely((__Pyx_SetItemInt(__pyx_v_shape, __pyx_v_self->last_axis, __pyx_t_2, int, 1, __Pyx_PyLong_From_int, 1, 1, 1, 1) < 0))) __PYX_ERR(0, 942, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "cupy/cuda/cufft.pyx":943
 *         elif self.fft_type == CUFFT_D2Z:
 *             shape[self.last_axis] = self.last_size
 *             dtype = numpy.complex128             # <<<<<<<<<<<<<<
 *         else:  # CUFFT_Z2D
 *             shape[self.last_axis] = self.last_size
*/
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 943, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_complex128); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 943, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_dtype = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":941
 *         elif self.fft_type == CUFFT_Z2Z:
 *             dtype = numpy.complex128
 *         elif self.fft_type == CUFFT_D2Z:             # <<<<<<<<<<<<<<
 *             shape[self.last_axis] = self.last_size
 *             dtype = numpy.complex128
*/
    break;
    default:

    /* "cupy/cuda/cufft.pyx":945
 *             dtype = numpy.complex128
 *         else:  # CUFFT_Z2D
 *             shape[self.last_axis] = self.last_size             # <<<<<<<<<<<<<<
 *             dtype = numpy.float64
 *         return tuple(shape), dtype
*/
    __pyx_t_1 = __pyx_v_self->last_size;
    __Pyx_INCREF(__pyx_t_1);
    if (unlikely((__Pyx_SetItemInt(__pyx_v_shape, __pyx_v_self->last_axis, __pyx_t_1, int, 1, __Pyx_PyLong_From_int, 1, 1, 1, 1) < 0))) __PYX_ERR(0, 945, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":946
 *         else:  # CUFFT_Z2D
 *             shape[self.last_axis] = self.last_size
 *             dtype = numpy.float64             # <<<<<<<<<<<<<<
 *         return tuple(shape), dtype
 * 
*/
    __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 946, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_float64); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 946, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_dtype = __pyx_t_2;
    __pyx_t_2 = 0;
    break;
  }

  /* "cupy/cuda/cufft.pyx":947
 *             shape[self.last_axis] = self.last_size
 *             dtype = numpy.float64
 *         return tuple(shape), dtype             # <<<<<<<<<<<<<<
 * 
 *     def get_output_array(self, a, order='C'):
*/
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2 = PyList_AsTuple(__pyx_v_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 947, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = PyTuple_New(2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 947, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_2);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2) != (0)) __PYX_ERR(0, 947, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_dtype);
  __Pyx_GIVEREF(__pyx_v_dtype);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_1, 1, __pyx_v_dtype) != (0)) __PYX_ERR(0, 947, __pyx_L1_error);
  __pyx_t_2 = 0;
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":929
 *             raise ValueError
 * 
 *     def _output_dtype_and_shape(self, a):             # <<<<<<<<<<<<<<
 *         shape = list(a.shape)
 *         if self.fft_type == CUFFT_C2C:
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd._output_dtype_and_shape", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XDECREF(__pyx_v_dtype);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":949
 *         return tuple(shape), dtype
 * 
 *     def get_output_array(self, a, order='C'):             # <<<<<<<<<<<<<<
 *         shape, dtype = self._output_dtype_and_shape(a)
 *         return cupy.empty(shape, dtype, order=order)
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_13get_output_array(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6PlanNd_12get_output_array, "PlanNd.get_output_array(self, a, order='C')");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_13get_output_array(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_a = 0;
  PyObject *__pyx_v_order = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[2] = {0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_output_array (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_a,&__pyx_mstate_global->__pyx_n_u_order,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 949, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 949, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 949, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "get_output_array", 0) < (0)) __PYX_ERR(0, 949, __pyx_L3_error)
      if (!values[1]) values[1] = __Pyx_NewRef(((PyObject *)__pyx_mstate_global->__pyx_n_u_C));
      for (Py_ssize_t i = __pyx_nargs; i < 1; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("get_output_array", 0, 1, 2, i); __PYX_ERR(0, 949, __pyx_L3_error) }
      }
    } else {
      switch (__pyx_nargs) {
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 949, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 949, __pyx_L3_error)
        break;
        default: goto __pyx_L5_argtuple_error;
      }
      if (!values[1]) values[1] = __Pyx_NewRef(((PyObject *)__pyx_mstate_global->__pyx_n_u_C));
    }
    __pyx_v_a = values[0];
    __pyx_v_order = values[1];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("get_output_array", 0, 1, 2, __pyx_nargs); __PYX_ERR(0, 949, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.get_output_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_12get_output_array(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self), __pyx_v_a, __pyx_v_order);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_12get_output_array(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_order) {
  PyObject *__pyx_v_shape = NULL;
  PyObject *__pyx_v_dtype = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  size_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *(*__pyx_t_6)(PyObject *);
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get_output_array", 0);

  /* "cupy/cuda/cufft.pyx":950
 * 
 *     def get_output_array(self, a, order='C'):
 *         shape, dtype = self._output_dtype_and_shape(a)             # <<<<<<<<<<<<<<
 *         return cupy.empty(shape, dtype, order=order)
 * 
*/
  __pyx_t_2 = ((PyObject *)__pyx_v_self);
  __Pyx_INCREF(__pyx_t_2);
  __pyx_t_3 = 0;
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_v_a};
    __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_output_dtype_and_shape, __pyx_callargs+__pyx_t_3, (2-__pyx_t_3) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 950, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 950, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0);
      __Pyx_INCREF(__pyx_t_2);
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 1);
      __Pyx_INCREF(__pyx_t_4);
    } else {
      __pyx_t_2 = __Pyx_PyList_GetItemRef(sequence, 0);
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 950, __pyx_L1_error)
      __Pyx_XGOTREF(__pyx_t_2);
      __pyx_t_4 = __Pyx_PyList_GetItemRef(sequence, 1);
      if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 950, __pyx_L1_error)
      __Pyx_XGOTREF(__pyx_t_4);
    }
    #else
    __pyx_t_2 = __Pyx_PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 950, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 950, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_5 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 950, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_6 = (CYTHON_COMPILING_IN_LIMITED_API) ? PyIter_Next : __Pyx_PyObject_GetIterNextFunc(__pyx_t_5);
    index = 0; __pyx_t_2 = __pyx_t_6(__pyx_t_5); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 1; __pyx_t_4 = __pyx_t_6(__pyx_t_5); if (unlikely(!__pyx_t_4)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_4);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_6(__pyx_t_5), 2) < (0)) __PYX_ERR(0, 950, __pyx_L1_error)
    __pyx_t_6 = NULL;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_6 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 950, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_shape = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_dtype = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "cupy/cuda/cufft.pyx":951
 *     def get_output_array(self, a, order='C'):
 *         shape, dtype = self._output_dtype_and_shape(a)
 *         return cupy.empty(shape, dtype, order=order)             # <<<<<<<<<<<<<<
 * 
 *     def check_output_array(self, a, out):
*/
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_4 = NULL;
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_cupy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 951, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_empty); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 951, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    assert(__pyx_t_4);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_5);
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_5, __pyx__function);
    __pyx_t_3 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[3 + ((CYTHON_VECTORCALL) ? 1 : 0)] = {__pyx_t_4, __pyx_v_shape, __pyx_v_dtype};
    __pyx_t_2 = __Pyx_MakeVectorcallBuilderKwds(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 951, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (__Pyx_VectorcallBuilder_AddArg(__pyx_mstate_global->__pyx_n_u_order, __pyx_v_order, __pyx_t_2, __pyx_callargs+3, 0) < (0)) __PYX_ERR(0, 951, __pyx_L1_error)
    __pyx_t_1 = __Pyx_Object_Vectorcall_CallFromBuilder(__pyx_t_5, __pyx_callargs+__pyx_t_3, (3-__pyx_t_3) | (__pyx_t_3*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET), __pyx_t_2);
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 951, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":949
 *         return tuple(shape), dtype
 * 
 *     def get_output_array(self, a, order='C'):             # <<<<<<<<<<<<<<
 *         shape, dtype = self._output_dtype_and_shape(a)
 *         return cupy.empty(shape, dtype, order=order)
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.get_output_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XDECREF(__pyx_v_dtype);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":953
 *         return cupy.empty(shape, dtype, order=order)
 * 
 *     def check_output_array(self, a, out):             # <<<<<<<<<<<<<<
 *         if out is a:
 *             # TODO(leofang): think about in-place transforms for C2R & R2C
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_15check_output_array(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6PlanNd_14check_output_array, "PlanNd.check_output_array(self, a, out)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_15check_output_array(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_a = 0;
  PyObject *__pyx_v_out = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[2] = {0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("check_output_array (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_a,&__pyx_mstate_global->__pyx_n_u_out,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 953, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 953, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 953, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "check_output_array", 0) < (0)) __PYX_ERR(0, 953, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 2; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("check_output_array", 1, 2, 2, i); __PYX_ERR(0, 953, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 2)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 953, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 953, __pyx_L3_error)
    }
    __pyx_v_a = values[0];
    __pyx_v_out = values[1];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("check_output_array", 1, 2, 2, __pyx_nargs); __PYX_ERR(0, 953, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.check_output_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_14check_output_array(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self), __pyx_v_a, __pyx_v_out);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_14check_output_array(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_out) {
  PyObject *__pyx_v_i = NULL;
  PyObject *__pyx_v_size = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  size_t __pyx_t_5;
  Py_ssize_t __pyx_t_6;
  PyObject *(*__pyx_t_7)(PyObject *);
  PyObject *__pyx_t_8 = NULL;
  int __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("check_output_array", 0);

  /* "cupy/cuda/cufft.pyx":954
 * 
 *     def check_output_array(self, a, out):
 *         if out is a:             # <<<<<<<<<<<<<<
 *             # TODO(leofang): think about in-place transforms for C2R & R2C
 *             return
*/
  __pyx_t_1 = (__pyx_v_out == __pyx_v_a);
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":956
 *         if out is a:
 *             # TODO(leofang): think about in-place transforms for C2R & R2C
 *             return             # <<<<<<<<<<<<<<
 *         if self.fft_type in (CUFFT_C2C, CUFFT_Z2Z):
 *             if out.shape != a.shape:
*/
    __Pyx_XDECREF(__pyx_r);
    __pyx_r = Py_None; __Pyx_INCREF(Py_None);
    goto __pyx_L0;

    /* "cupy/cuda/cufft.pyx":954
 * 
 *     def check_output_array(self, a, out):
 *         if out is a:             # <<<<<<<<<<<<<<
 *             # TODO(leofang): think about in-place transforms for C2R & R2C
 *             return
*/
  }

  /* "cupy/cuda/cufft.pyx":957
 *             # TODO(leofang): think about in-place transforms for C2R & R2C
 *             return
 *         if self.fft_type in (CUFFT_C2C, CUFFT_Z2Z):             # <<<<<<<<<<<<<<
 *             if out.shape != a.shape:
 *                 raise ValueError('output shape mismatch')
*/
  switch (__pyx_v_self->fft_type) {
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_C2C:
    case __pyx_e_4cupy_4cuda_5cufft_CUFFT_Z2Z:

    /* "cupy/cuda/cufft.pyx":958
 *             return
 *         if self.fft_type in (CUFFT_C2C, CUFFT_Z2Z):
 *             if out.shape != a.shape:             # <<<<<<<<<<<<<<
 *                 raise ValueError('output shape mismatch')
 *             if out.dtype != a.dtype:
*/
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 958, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 958, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = PyObject_RichCompare(__pyx_t_2, __pyx_t_3, Py_NE); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 958, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 958, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(__pyx_t_1)) {

      /* "cupy/cuda/cufft.pyx":959
 *         if self.fft_type in (CUFFT_C2C, CUFFT_Z2Z):
 *             if out.shape != a.shape:
 *                 raise ValueError('output shape mismatch')             # <<<<<<<<<<<<<<
 *             if out.dtype != a.dtype:
 *                 raise ValueError('output dtype mismatch')
*/
      __pyx_t_3 = NULL;
      __Pyx_INCREF(__pyx_builtin_ValueError);
      __pyx_t_2 = __pyx_builtin_ValueError; 
      __pyx_t_5 = 1;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_3, __pyx_mstate_global->__pyx_kp_u_output_shape_mismatch};
        __pyx_t_4 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
        if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 959, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
      }
      __Pyx_Raise(__pyx_t_4, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __PYX_ERR(0, 959, __pyx_L1_error)

      /* "cupy/cuda/cufft.pyx":958
 *             return
 *         if self.fft_type in (CUFFT_C2C, CUFFT_Z2Z):
 *             if out.shape != a.shape:             # <<<<<<<<<<<<<<
 *                 raise ValueError('output shape mismatch')
 *             if out.dtype != a.dtype:
*/
    }

    /* "cupy/cuda/cufft.pyx":960
 *             if out.shape != a.shape:
 *                 raise ValueError('output shape mismatch')
 *             if out.dtype != a.dtype:             # <<<<<<<<<<<<<<
 *                 raise ValueError('output dtype mismatch')
 *         else:
*/
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_dtype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 960, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 960, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PyObject_RichCompare(__pyx_t_4, __pyx_t_2, Py_NE); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 960, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 960, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(__pyx_t_1)) {

      /* "cupy/cuda/cufft.pyx":961
 *                 raise ValueError('output shape mismatch')
 *             if out.dtype != a.dtype:
 *                 raise ValueError('output dtype mismatch')             # <<<<<<<<<<<<<<
 *         else:
 *             if out.ndim != a.ndim:
*/
      __pyx_t_2 = NULL;
      __Pyx_INCREF(__pyx_builtin_ValueError);
      __pyx_t_4 = __pyx_builtin_ValueError; 
      __pyx_t_5 = 1;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_mstate_global->__pyx_kp_u_output_dtype_mismatch};
        __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_4, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 961, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
      }
      __Pyx_Raise(__pyx_t_3, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __PYX_ERR(0, 961, __pyx_L1_error)

      /* "cupy/cuda/cufft.pyx":960
 *             if out.shape != a.shape:
 *                 raise ValueError('output shape mismatch')
 *             if out.dtype != a.dtype:             # <<<<<<<<<<<<<<
 *                 raise ValueError('output dtype mismatch')
 *         else:
*/
    }

    /* "cupy/cuda/cufft.pyx":957
 *             # TODO(leofang): think about in-place transforms for C2R & R2C
 *             return
 *         if self.fft_type in (CUFFT_C2C, CUFFT_Z2Z):             # <<<<<<<<<<<<<<
 *             if out.shape != a.shape:
 *                 raise ValueError('output shape mismatch')
*/
    break;
    default:

    /* "cupy/cuda/cufft.pyx":963
 *                 raise ValueError('output dtype mismatch')
 *         else:
 *             if out.ndim != a.ndim:             # <<<<<<<<<<<<<<
 *                 raise ValueError('output dimension mismatch')
 *             for i, size in enumerate(out.shape):
*/
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_ndim); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 963, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_ndim); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 963, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_2 = PyObject_RichCompare(__pyx_t_3, __pyx_t_4, Py_NE); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 963, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 963, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(__pyx_t_1)) {

      /* "cupy/cuda/cufft.pyx":964
 *         else:
 *             if out.ndim != a.ndim:
 *                 raise ValueError('output dimension mismatch')             # <<<<<<<<<<<<<<
 *             for i, size in enumerate(out.shape):
 *                 if (i != self.last_axis and size != a.shape[i]) or \
*/
      __pyx_t_4 = NULL;
      __Pyx_INCREF(__pyx_builtin_ValueError);
      __pyx_t_3 = __pyx_builtin_ValueError; 
      __pyx_t_5 = 1;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_4, __pyx_mstate_global->__pyx_kp_u_output_dimension_mismatch};
        __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_3, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 964, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      }
      __Pyx_Raise(__pyx_t_2, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __PYX_ERR(0, 964, __pyx_L1_error)

      /* "cupy/cuda/cufft.pyx":963
 *                 raise ValueError('output dtype mismatch')
 *         else:
 *             if out.ndim != a.ndim:             # <<<<<<<<<<<<<<
 *                 raise ValueError('output dimension mismatch')
 *             for i, size in enumerate(out.shape):
*/
    }

    /* "cupy/cuda/cufft.pyx":965
 *             if out.ndim != a.ndim:
 *                 raise ValueError('output dimension mismatch')
 *             for i, size in enumerate(out.shape):             # <<<<<<<<<<<<<<
 *                 if (i != self.last_axis and size != a.shape[i]) or \
 *                    (i == self.last_axis and size != self.last_size):
*/
    __Pyx_INCREF(__pyx_mstate_global->__pyx_int_0);
    __pyx_t_2 = __pyx_mstate_global->__pyx_int_0;
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 965, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    if (likely(PyList_CheckExact(__pyx_t_3)) || PyTuple_CheckExact(__pyx_t_3)) {
      __pyx_t_4 = __pyx_t_3; __Pyx_INCREF(__pyx_t_4);
      __pyx_t_6 = 0;
      __pyx_t_7 = NULL;
    } else {
      __pyx_t_6 = -1; __pyx_t_4 = PyObject_GetIter(__pyx_t_3); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 965, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_7 = (CYTHON_COMPILING_IN_LIMITED_API) ? PyIter_Next : __Pyx_PyObject_GetIterNextFunc(__pyx_t_4); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 965, __pyx_L1_error)
    }
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    for (;;) {
      if (likely(!__pyx_t_7)) {
        if (likely(PyList_CheckExact(__pyx_t_4))) {
          {
            Py_ssize_t __pyx_temp = __Pyx_PyList_GET_SIZE(__pyx_t_4);
            #if !CYTHON_ASSUME_SAFE_SIZE
            if (unlikely((__pyx_temp < 0))) __PYX_ERR(0, 965, __pyx_L1_error)
            #endif
            if (__pyx_t_6 >= __pyx_temp) break;
          }
          __pyx_t_3 = __Pyx_PyList_GetItemRef(__pyx_t_4, __pyx_t_6);
          ++__pyx_t_6;
        } else {
          {
            Py_ssize_t __pyx_temp = __Pyx_PyTuple_GET_SIZE(__pyx_t_4);
            #if !CYTHON_ASSUME_SAFE_SIZE
            if (unlikely((__pyx_temp < 0))) __PYX_ERR(0, 965, __pyx_L1_error)
            #endif
            if (__pyx_t_6 >= __pyx_temp) break;
          }
          #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
          __pyx_t_3 = __Pyx_NewRef(PyTuple_GET_ITEM(__pyx_t_4, __pyx_t_6));
          #else
          __pyx_t_3 = __Pyx_PySequence_ITEM(__pyx_t_4, __pyx_t_6);
          #endif
          ++__pyx_t_6;
        }
        if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 965, __pyx_L1_error)
      } else {
        __pyx_t_3 = __pyx_t_7(__pyx_t_4);
        if (unlikely(!__pyx_t_3)) {
          PyObject* exc_type = PyErr_Occurred();
          if (exc_type) {
            if (unlikely(!__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) __PYX_ERR(0, 965, __pyx_L1_error)
            PyErr_Clear();
          }
          break;
        }
      }
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_XDECREF_SET(__pyx_v_size, __pyx_t_3);
      __pyx_t_3 = 0;
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_XDECREF_SET(__pyx_v_i, __pyx_t_2);
      __pyx_t_3 = __Pyx_PyLong_AddObjC(__pyx_t_2, __pyx_mstate_global->__pyx_int_1, 1, 0, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 965, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2);
      __pyx_t_2 = __pyx_t_3;
      __pyx_t_3 = 0;

      /* "cupy/cuda/cufft.pyx":966
 *                 raise ValueError('output dimension mismatch')
 *             for i, size in enumerate(out.shape):
 *                 if (i != self.last_axis and size != a.shape[i]) or \             # <<<<<<<<<<<<<<
 *                    (i == self.last_axis and size != self.last_size):
 *                     raise ValueError('output shape is incorrecct')
*/
      __pyx_t_3 = __Pyx_PyLong_From_int(__pyx_v_self->last_axis); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 966, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __pyx_t_8 = PyObject_RichCompare(__pyx_v_i, __pyx_t_3, Py_NE); __Pyx_XGOTREF(__pyx_t_8); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 966, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_8); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(0, 966, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      if (!__pyx_t_9) {
        goto __pyx_L11_next_or;
      } else {
      }
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_shape); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 966, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_3 = __Pyx_PyObject_GetItem(__pyx_t_8, __pyx_v_i); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 966, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_8 = PyObject_RichCompare(__pyx_v_size, __pyx_t_3, Py_NE); __Pyx_XGOTREF(__pyx_t_8); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 966, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_8); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(0, 966, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      if (!__pyx_t_9) {
      } else {
        __pyx_t_1 = __pyx_t_9;
        goto __pyx_L10_bool_binop_done;
      }
      __pyx_L11_next_or:;

      /* "cupy/cuda/cufft.pyx":967
 *             for i, size in enumerate(out.shape):
 *                 if (i != self.last_axis and size != a.shape[i]) or \
 *                    (i == self.last_axis and size != self.last_size):             # <<<<<<<<<<<<<<
 *                     raise ValueError('output shape is incorrecct')
 *             if self.fft_type in (CUFFT_R2C, CUFFT_D2Z):
*/
      __pyx_t_8 = __Pyx_PyLong_From_int(__pyx_v_self->last_axis); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 967, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_3 = PyObject_RichCompare(__pyx_v_i, __pyx_t_8, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 967, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(0, 967, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (__pyx_t_9) {
      } else {
        __pyx_t_1 = __pyx_t_9;
        goto __pyx_L10_bool_binop_done;
      }
      __pyx_t_3 = PyObject_RichCompare(__pyx_v_size, __pyx_v_self->last_size, Py_NE); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 967, __pyx_L1_error)
      __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(0, 967, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_1 = __pyx_t_9;
      __pyx_L10_bool_binop_done:;

      /* "cupy/cuda/cufft.pyx":966
 *                 raise ValueError('output dimension mismatch')
 *             for i, size in enumerate(out.shape):
 *                 if (i != self.last_axis and size != a.shape[i]) or \             # <<<<<<<<<<<<<<
 *                    (i == self.last_axis and size != self.last_size):
 *                     raise ValueError('output shape is incorrecct')
*/
      if (unlikely(__pyx_t_1)) {

        /* "cupy/cuda/cufft.pyx":968
 *                 if (i != self.last_axis and size != a.shape[i]) or \
 *                    (i == self.last_axis and size != self.last_size):
 *                     raise ValueError('output shape is incorrecct')             # <<<<<<<<<<<<<<
 *             if self.fft_type in (CUFFT_R2C, CUFFT_D2Z):
 *                 if out.dtype != cupy.dtype(a.dtype.char.upper()):
*/
        __pyx_t_8 = NULL;
        __Pyx_INCREF(__pyx_builtin_ValueError);
        __pyx_t_10 = __pyx_builtin_ValueError; 
        __pyx_t_5 = 1;
        {
          PyObject *__pyx_callargs[2] = {__pyx_t_8, __pyx_mstate_global->__pyx_kp_u_output_shape_is_incorrecct};
          __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_10, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
          __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
          __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
          if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 968, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
        }
        __Pyx_Raise(__pyx_t_3, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __PYX_ERR(0, 968, __pyx_L1_error)

        /* "cupy/cuda/cufft.pyx":966
 *                 raise ValueError('output dimension mismatch')
 *             for i, size in enumerate(out.shape):
 *                 if (i != self.last_axis and size != a.shape[i]) or \             # <<<<<<<<<<<<<<
 *                    (i == self.last_axis and size != self.last_size):
 *                     raise ValueError('output shape is incorrecct')
*/
      }

      /* "cupy/cuda/cufft.pyx":965
 *             if out.ndim != a.ndim:
 *                 raise ValueError('output dimension mismatch')
 *             for i, size in enumerate(out.shape):             # <<<<<<<<<<<<<<
 *                 if (i != self.last_axis and size != a.shape[i]) or \
 *                    (i == self.last_axis and size != self.last_size):
*/
    }
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "cupy/cuda/cufft.pyx":969
 *                    (i == self.last_axis and size != self.last_size):
 *                     raise ValueError('output shape is incorrecct')
 *             if self.fft_type in (CUFFT_R2C, CUFFT_D2Z):             # <<<<<<<<<<<<<<
 *                 if out.dtype != cupy.dtype(a.dtype.char.upper()):
 *                     raise ValueError('output dtype is unexpected')
*/
    switch (__pyx_v_self->fft_type) {
      case __pyx_e_4cupy_4cuda_5cufft_CUFFT_R2C:
      case __pyx_e_4cupy_4cuda_5cufft_CUFFT_D2Z:

      /* "cupy/cuda/cufft.pyx":970
 *                     raise ValueError('output shape is incorrecct')
 *             if self.fft_type in (CUFFT_R2C, CUFFT_D2Z):
 *                 if out.dtype != cupy.dtype(a.dtype.char.upper()):             # <<<<<<<<<<<<<<
 *                     raise ValueError('output dtype is unexpected')
 *             else:  # CUFFT_C2R or CUFFT_Z2D
*/
      __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_dtype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 970, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = NULL;
      __Pyx_GetModuleGlobalName(__pyx_t_10, __pyx_mstate_global->__pyx_n_u_cupy); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 970, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_mstate_global->__pyx_n_u_dtype); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 970, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __pyx_t_12 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_dtype); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 970, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_12);
      __pyx_t_13 = __Pyx_PyObject_GetAttrStr(__pyx_t_12, __pyx_mstate_global->__pyx_n_u_char); if (unlikely(!__pyx_t_13)) __PYX_ERR(0, 970, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_13);
      __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
      __pyx_t_11 = __pyx_t_13;
      __Pyx_INCREF(__pyx_t_11);
      __pyx_t_5 = 0;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_11, NULL};
        __pyx_t_10 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_upper, __pyx_callargs+__pyx_t_5, (1-__pyx_t_5) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_11); __pyx_t_11 = 0;
        __Pyx_DECREF(__pyx_t_13); __pyx_t_13 = 0;
        if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 970, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
      }
      __pyx_t_5 = 1;
      #if CYTHON_UNPACK_METHODS
      if (unlikely(PyMethod_Check(__pyx_t_8))) {
        __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_8);
        assert(__pyx_t_3);
        PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_8);
        __Pyx_INCREF(__pyx_t_3);
        __Pyx_INCREF(__pyx__function);
        __Pyx_DECREF_SET(__pyx_t_8, __pyx__function);
        __pyx_t_5 = 0;
      }
      #endif
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_3, __pyx_t_10};
        __pyx_t_4 = __Pyx_PyObject_FastCall(__pyx_t_8, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 970, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_4);
      }
      __pyx_t_8 = PyObject_RichCompare(__pyx_t_2, __pyx_t_4, Py_NE); __Pyx_XGOTREF(__pyx_t_8); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 970, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_8); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 970, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      if (unlikely(__pyx_t_1)) {

        /* "cupy/cuda/cufft.pyx":971
 *             if self.fft_type in (CUFFT_R2C, CUFFT_D2Z):
 *                 if out.dtype != cupy.dtype(a.dtype.char.upper()):
 *                     raise ValueError('output dtype is unexpected')             # <<<<<<<<<<<<<<
 *             else:  # CUFFT_C2R or CUFFT_Z2D
 *                 if out.dtype != cupy.dtype(a.dtype.char.lower()):
*/
        __pyx_t_4 = NULL;
        __Pyx_INCREF(__pyx_builtin_ValueError);
        __pyx_t_2 = __pyx_builtin_ValueError; 
        __pyx_t_5 = 1;
        {
          PyObject *__pyx_callargs[2] = {__pyx_t_4, __pyx_mstate_global->__pyx_kp_u_output_dtype_is_unexpected};
          __pyx_t_8 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
          __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
          __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
          if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 971, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_8);
        }
        __Pyx_Raise(__pyx_t_8, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
        __PYX_ERR(0, 971, __pyx_L1_error)

        /* "cupy/cuda/cufft.pyx":970
 *                     raise ValueError('output shape is incorrecct')
 *             if self.fft_type in (CUFFT_R2C, CUFFT_D2Z):
 *                 if out.dtype != cupy.dtype(a.dtype.char.upper()):             # <<<<<<<<<<<<<<
 *                     raise ValueError('output dtype is unexpected')
 *             else:  # CUFFT_C2R or CUFFT_Z2D
*/
      }

      /* "cupy/cuda/cufft.pyx":969
 *                    (i == self.last_axis and size != self.last_size):
 *                     raise ValueError('output shape is incorrecct')
 *             if self.fft_type in (CUFFT_R2C, CUFFT_D2Z):             # <<<<<<<<<<<<<<
 *                 if out.dtype != cupy.dtype(a.dtype.char.upper()):
 *                     raise ValueError('output dtype is unexpected')
*/
      break;
      default:

      /* "cupy/cuda/cufft.pyx":973
 *                     raise ValueError('output dtype is unexpected')
 *             else:  # CUFFT_C2R or CUFFT_Z2D
 *                 if out.dtype != cupy.dtype(a.dtype.char.lower()):             # <<<<<<<<<<<<<<
 *                     raise ValueError('output dtype is unexpected')
 *         if not ((out.flags.f_contiguous == a.flags.f_contiguous) and
*/
      __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_dtype); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 973, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_8);
      __pyx_t_4 = NULL;
      __Pyx_GetModuleGlobalName(__pyx_t_10, __pyx_mstate_global->__pyx_n_u_cupy); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 973, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_10);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_10, __pyx_mstate_global->__pyx_n_u_dtype); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 973, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_dtype); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 973, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_11);
      __pyx_t_12 = __Pyx_PyObject_GetAttrStr(__pyx_t_11, __pyx_mstate_global->__pyx_n_u_char); if (unlikely(!__pyx_t_12)) __PYX_ERR(0, 973, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_12);
      __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
      __pyx_t_13 = __pyx_t_12;
      __Pyx_INCREF(__pyx_t_13);
      __pyx_t_5 = 0;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_13, NULL};
        __pyx_t_10 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_lower, __pyx_callargs+__pyx_t_5, (1-__pyx_t_5) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
        __Pyx_DECREF(__pyx_t_12); __pyx_t_12 = 0;
        if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 973, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_10);
      }
      __pyx_t_5 = 1;
      #if CYTHON_UNPACK_METHODS
      if (unlikely(PyMethod_Check(__pyx_t_3))) {
        __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_3);
        assert(__pyx_t_4);
        PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_3);
        __Pyx_INCREF(__pyx_t_4);
        __Pyx_INCREF(__pyx__function);
        __Pyx_DECREF_SET(__pyx_t_3, __pyx__function);
        __pyx_t_5 = 0;
      }
      #endif
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_4, __pyx_t_10};
        __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_3, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 973, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_2);
      }
      __pyx_t_3 = PyObject_RichCompare(__pyx_t_8, __pyx_t_2, Py_NE); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 973, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 973, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      if (unlikely(__pyx_t_1)) {

        /* "cupy/cuda/cufft.pyx":974
 *             else:  # CUFFT_C2R or CUFFT_Z2D
 *                 if out.dtype != cupy.dtype(a.dtype.char.lower()):
 *                     raise ValueError('output dtype is unexpected')             # <<<<<<<<<<<<<<
 *         if not ((out.flags.f_contiguous == a.flags.f_contiguous) and
 *                 (out.flags.c_contiguous == a.flags.c_contiguous)):
*/
        __pyx_t_2 = NULL;
        __Pyx_INCREF(__pyx_builtin_ValueError);
        __pyx_t_8 = __pyx_builtin_ValueError; 
        __pyx_t_5 = 1;
        {
          PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_mstate_global->__pyx_kp_u_output_dtype_is_unexpected};
          __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_8, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
          __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
          __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
          if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 974, __pyx_L1_error)
          __Pyx_GOTREF(__pyx_t_3);
        }
        __Pyx_Raise(__pyx_t_3, 0, 0, 0);
        __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
        __PYX_ERR(0, 974, __pyx_L1_error)

        /* "cupy/cuda/cufft.pyx":973
 *                     raise ValueError('output dtype is unexpected')
 *             else:  # CUFFT_C2R or CUFFT_Z2D
 *                 if out.dtype != cupy.dtype(a.dtype.char.lower()):             # <<<<<<<<<<<<<<
 *                     raise ValueError('output dtype is unexpected')
 *         if not ((out.flags.f_contiguous == a.flags.f_contiguous) and
*/
      }
      break;
    }
    break;
  }

  /* "cupy/cuda/cufft.pyx":975
 *                 if out.dtype != cupy.dtype(a.dtype.char.lower()):
 *                     raise ValueError('output dtype is unexpected')
 *         if not ((out.flags.f_contiguous == a.flags.f_contiguous) and             # <<<<<<<<<<<<<<
 *                 (out.flags.c_contiguous == a.flags.c_contiguous)):
 *             raise ValueError('output contiguity mismatch')
*/
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_flags); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 975, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_f_contiguous); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 975, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_flags); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 975, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_f_contiguous); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 975, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_8, __pyx_t_2, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 975, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(0, 975, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_9) {
  } else {
    __pyx_t_1 = __pyx_t_9;
    goto __pyx_L18_bool_binop_done;
  }

  /* "cupy/cuda/cufft.pyx":976
 *                     raise ValueError('output dtype is unexpected')
 *         if not ((out.flags.f_contiguous == a.flags.f_contiguous) and
 *                 (out.flags.c_contiguous == a.flags.c_contiguous)):             # <<<<<<<<<<<<<<
 *             raise ValueError('output contiguity mismatch')
 * 
*/
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_flags); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 976, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_c_contiguous); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 976, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_flags); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 976, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_8 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_c_contiguous); if (unlikely(!__pyx_t_8)) __PYX_ERR(0, 976, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_8);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_2, __pyx_t_8, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 976, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_9 < 0))) __PYX_ERR(0, 976, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_1 = __pyx_t_9;
  __pyx_L18_bool_binop_done:;

  /* "cupy/cuda/cufft.pyx":975
 *                 if out.dtype != cupy.dtype(a.dtype.char.lower()):
 *                     raise ValueError('output dtype is unexpected')
 *         if not ((out.flags.f_contiguous == a.flags.f_contiguous) and             # <<<<<<<<<<<<<<
 *                 (out.flags.c_contiguous == a.flags.c_contiguous)):
 *             raise ValueError('output contiguity mismatch')
*/
  __pyx_t_9 = (!__pyx_t_1);
  if (unlikely(__pyx_t_9)) {

    /* "cupy/cuda/cufft.pyx":977
 *         if not ((out.flags.f_contiguous == a.flags.f_contiguous) and
 *                 (out.flags.c_contiguous == a.flags.c_contiguous)):
 *             raise ValueError('output contiguity mismatch')             # <<<<<<<<<<<<<<
 * 
 * 
*/
    __pyx_t_8 = NULL;
    __Pyx_INCREF(__pyx_builtin_ValueError);
    __pyx_t_2 = __pyx_builtin_ValueError; 
    __pyx_t_5 = 1;
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_8, __pyx_mstate_global->__pyx_kp_u_output_contiguity_mismatch};
      __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 977, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
    }
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 977, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":975
 *                 if out.dtype != cupy.dtype(a.dtype.char.lower()):
 *                     raise ValueError('output dtype is unexpected')
 *         if not ((out.flags.f_contiguous == a.flags.f_contiguous) and             # <<<<<<<<<<<<<<
 *                 (out.flags.c_contiguous == a.flags.c_contiguous)):
 *             raise ValueError('output contiguity mismatch')
*/
  }

  /* "cupy/cuda/cufft.pyx":953
 *         return cupy.empty(shape, dtype, order=order)
 * 
 *     def check_output_array(self, a, out):             # <<<<<<<<<<<<<<
 *         if out is a:
 *             # TODO(leofang): think about in-place transforms for C2R & R2C
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_XDECREF(__pyx_t_12);
  __Pyx_XDECREF(__pyx_t_13);
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.check_output_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_i);
  __Pyx_XDECREF(__pyx_v_size);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":78
 * cdef class PlanNd:
 *     cdef:
 *         readonly intptr_t handle             # <<<<<<<<<<<<<<
 *         readonly object work_area  # memory.MemoryPointer
 *         readonly tuple shape
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_6handle_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_6handle_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_6handle___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_6handle___get__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyLong_FromSsize_t(__pyx_v_self->handle); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 78, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.handle.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":79
 *     cdef:
 *         readonly intptr_t handle
 *         readonly object work_area  # memory.MemoryPointer             # <<<<<<<<<<<<<<
 *         readonly tuple shape
 *         readonly Type fft_type
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_9work_area_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_9work_area_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_9work_area___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_9work_area___get__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->work_area);
  __pyx_r = __pyx_v_self->work_area;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":80
 *         readonly intptr_t handle
 *         readonly object work_area  # memory.MemoryPointer
 *         readonly tuple shape             # <<<<<<<<<<<<<<
 *         readonly Type fft_type
 *         readonly str order
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_5shape_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_5shape_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_5shape___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_5shape___get__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->shape);
  __pyx_r = __pyx_v_self->shape;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":81
 *         readonly object work_area  # memory.MemoryPointer
 *         readonly tuple shape
 *         readonly Type fft_type             # <<<<<<<<<<<<<<
 *         readonly str order
 *         readonly int last_axis
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_8fft_type_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_8fft_type_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_8fft_type___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_8fft_type___get__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyLong_From_cufftType_t(__pyx_v_self->fft_type); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 81, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.fft_type.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":82
 *         readonly tuple shape
 *         readonly Type fft_type
 *         readonly str order             # <<<<<<<<<<<<<<
 *         readonly int last_axis
 *         readonly object last_size
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_5order_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_5order_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_5order___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_5order___get__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->order);
  __pyx_r = __pyx_v_self->order;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":83
 *         readonly Type fft_type
 *         readonly str order
 *         readonly int last_axis             # <<<<<<<<<<<<<<
 *         readonly object last_size
 * 
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_9last_axis_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_9last_axis_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_9last_axis___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_9last_axis___get__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_self->last_axis); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 83, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.last_axis.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":84
 *         readonly str order
 *         readonly int last_axis
 *         readonly object last_size             # <<<<<<<<<<<<<<
 * 
 *         # TODO(leofang): support multi-GPU transforms
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_9last_size_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_9last_size_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_9last_size___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_9last_size___get__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->last_size);
  __pyx_r = __pyx_v_self->last_size;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":87
 * 
 *         # TODO(leofang): support multi-GPU transforms
 *         readonly list gpus             # <<<<<<<<<<<<<<
 * 
 * 
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_4gpus_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_4gpus_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_4gpus___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_4gpus___get__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->gpus);
  __pyx_r = __pyx_v_self->gpus;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":1
 * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
 *     cdef tuple state
 *     cdef object _dict
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_17__reduce_cython__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6PlanNd_16__reduce_cython__, "PlanNd.__reduce_cython__(self)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_17__reduce_cython__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce_cython__ (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  if (unlikely(__pyx_nargs > 0)) { __Pyx_RaiseArgtupleInvalid("__reduce_cython__", 1, 0, 0, __pyx_nargs); return NULL; }
  const Py_ssize_t __pyx_kwds_len = unlikely(__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
  if (unlikely(__pyx_kwds_len < 0)) return NULL;
  if (unlikely(__pyx_kwds_len > 0)) {__Pyx_RejectKeywords("__reduce_cython__", __pyx_kwds); return NULL;}
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_16__reduce_cython__(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_16__reduce_cython__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self) {
  PyObject *__pyx_v_state = 0;
  PyObject *__pyx_v__dict = 0;
  int __pyx_v_use_setstate;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  int __pyx_t_6;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__reduce_cython__", 0);

  /* "(tree fragment)":5
 *     cdef object _dict
 *     cdef bint use_setstate
 *     state = (self.fft_type, self.gpus, self.handle, self.last_axis, self.last_size, self.order, self.shape, self.work_area)             # <<<<<<<<<<<<<<
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:
*/
  __pyx_t_1 = __Pyx_PyLong_From_cufftType_t(__pyx_v_self->fft_type); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyLong_FromSsize_t(__pyx_v_self->handle); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyLong_From_int(__pyx_v_self->last_axis); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = PyTuple_New(8); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GIVEREF(__pyx_t_1);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_1) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->gpus);
  __Pyx_GIVEREF(__pyx_v_self->gpus);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_v_self->gpus) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_2);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 2, __pyx_t_2) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_3);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 3, __pyx_t_3) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->last_size);
  __Pyx_GIVEREF(__pyx_v_self->last_size);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 4, __pyx_v_self->last_size) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->order);
  __Pyx_GIVEREF(__pyx_v_self->order);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 5, __pyx_v_self->order) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->shape);
  __Pyx_GIVEREF(__pyx_v_self->shape);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 6, __pyx_v_self->shape) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->work_area);
  __Pyx_GIVEREF(__pyx_v_self->work_area);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 7, __pyx_v_self->work_area) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __pyx_t_1 = 0;
  __pyx_t_2 = 0;
  __pyx_t_3 = 0;
  __pyx_v_state = ((PyObject*)__pyx_t_4);
  __pyx_t_4 = 0;

  /* "(tree fragment)":6
 *     cdef bint use_setstate
 *     state = (self.fft_type, self.gpus, self.handle, self.last_axis, self.last_size, self.order, self.shape, self.work_area)
 *     _dict = getattr(self, '__dict__', None)             # <<<<<<<<<<<<<<
 *     if _dict is not None:
 *         state += (_dict,)
*/
  __pyx_t_4 = __Pyx_GetAttr3(((PyObject *)__pyx_v_self), __pyx_mstate_global->__pyx_n_u_dict, Py_None); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 6, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_v__dict = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "(tree fragment)":7
 *     state = (self.fft_type, self.gpus, self.handle, self.last_axis, self.last_size, self.order, self.shape, self.work_area)
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:             # <<<<<<<<<<<<<<
 *         state += (_dict,)
 *         use_setstate = True
*/
  __pyx_t_5 = (__pyx_v__dict != Py_None);
  if (__pyx_t_5) {

    /* "(tree fragment)":8
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:
 *         state += (_dict,)             # <<<<<<<<<<<<<<
 *         use_setstate = True
 *     else:
*/
    __pyx_t_4 = PyTuple_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 8, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_INCREF(__pyx_v__dict);
    __Pyx_GIVEREF(__pyx_v__dict);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_v__dict) != (0)) __PYX_ERR(1, 8, __pyx_L1_error);
    __pyx_t_3 = PyNumber_InPlaceAdd(__pyx_v_state, __pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 8, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF_SET(__pyx_v_state, ((PyObject*)__pyx_t_3));
    __pyx_t_3 = 0;

    /* "(tree fragment)":9
 *     if _dict is not None:
 *         state += (_dict,)
 *         use_setstate = True             # <<<<<<<<<<<<<<
 *     else:
 *         use_setstate = self.gpus is not None or self.last_size is not None or self.order is not None or self.shape is not None or self.work_area is not None
*/
    __pyx_v_use_setstate = 1;

    /* "(tree fragment)":7
 *     state = (self.fft_type, self.gpus, self.handle, self.last_axis, self.last_size, self.order, self.shape, self.work_area)
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:             # <<<<<<<<<<<<<<
 *         state += (_dict,)
 *         use_setstate = True
*/
    goto __pyx_L3;
  }

  /* "(tree fragment)":11
 *         use_setstate = True
 *     else:
 *         use_setstate = self.gpus is not None or self.last_size is not None or self.order is not None or self.shape is not None or self.work_area is not None             # <<<<<<<<<<<<<<
 *     if use_setstate:
 *         return __pyx_unpickle_PlanNd, (type(self), 0xc57f9e5, None), state
*/
  /*else*/ {
    __pyx_t_6 = (__pyx_v_self->gpus != ((PyObject*)Py_None));
    if (!__pyx_t_6) {
    } else {
      __pyx_t_5 = __pyx_t_6;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_6 = (__pyx_v_self->last_size != Py_None);
    if (!__pyx_t_6) {
    } else {
      __pyx_t_5 = __pyx_t_6;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_6 = (__pyx_v_self->order != ((PyObject*)Py_None));
    if (!__pyx_t_6) {
    } else {
      __pyx_t_5 = __pyx_t_6;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_6 = (__pyx_v_self->shape != ((PyObject*)Py_None));
    if (!__pyx_t_6) {
    } else {
      __pyx_t_5 = __pyx_t_6;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_6 = (__pyx_v_self->work_area != Py_None);
    __pyx_t_5 = __pyx_t_6;
    __pyx_L4_bool_binop_done:;
    __pyx_v_use_setstate = __pyx_t_5;
  }
  __pyx_L3:;

  /* "(tree fragment)":12
 *     else:
 *         use_setstate = self.gpus is not None or self.last_size is not None or self.order is not None or self.shape is not None or self.work_area is not None
 *     if use_setstate:             # <<<<<<<<<<<<<<
 *         return __pyx_unpickle_PlanNd, (type(self), 0xc57f9e5, None), state
 *     else:
*/
  if (__pyx_v_use_setstate) {

    /* "(tree fragment)":13
 *         use_setstate = self.gpus is not None or self.last_size is not None or self.order is not None or self.shape is not None or self.work_area is not None
 *     if use_setstate:
 *         return __pyx_unpickle_PlanNd, (type(self), 0xc57f9e5, None), state             # <<<<<<<<<<<<<<
 *     else:
 *         return __pyx_unpickle_PlanNd, (type(self), 0xc57f9e5, state)
*/
    __Pyx_XDECREF(__pyx_r);
    __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_pyx_unpickle_PlanNd); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 13, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = PyTuple_New(3); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 13, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_INCREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    __Pyx_GIVEREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 0, ((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self)))) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __Pyx_INCREF(__pyx_mstate_global->__pyx_int_207092197);
    __Pyx_GIVEREF(__pyx_mstate_global->__pyx_int_207092197);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_mstate_global->__pyx_int_207092197) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 2, Py_None) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __pyx_t_2 = PyTuple_New(3); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 13, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_GIVEREF(__pyx_t_3);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_3) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_4);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_t_4) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __Pyx_INCREF(__pyx_v_state);
    __Pyx_GIVEREF(__pyx_v_state);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_2, 2, __pyx_v_state) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __pyx_t_3 = 0;
    __pyx_t_4 = 0;
    __pyx_r = __pyx_t_2;
    __pyx_t_2 = 0;
    goto __pyx_L0;

    /* "(tree fragment)":12
 *     else:
 *         use_setstate = self.gpus is not None or self.last_size is not None or self.order is not None or self.shape is not None or self.work_area is not None
 *     if use_setstate:             # <<<<<<<<<<<<<<
 *         return __pyx_unpickle_PlanNd, (type(self), 0xc57f9e5, None), state
 *     else:
*/
  }

  /* "(tree fragment)":15
 *         return __pyx_unpickle_PlanNd, (type(self), 0xc57f9e5, None), state
 *     else:
 *         return __pyx_unpickle_PlanNd, (type(self), 0xc57f9e5, state)             # <<<<<<<<<<<<<<
 * def __setstate_cython__(self, __pyx_state):
 *     __pyx_unpickle_PlanNd__set_state(self, __pyx_state)
*/
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_pyx_unpickle_PlanNd); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 15, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = PyTuple_New(3); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 15, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_INCREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    __Pyx_GIVEREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 0, ((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self)))) != (0)) __PYX_ERR(1, 15, __pyx_L1_error);
    __Pyx_INCREF(__pyx_mstate_global->__pyx_int_207092197);
    __Pyx_GIVEREF(__pyx_mstate_global->__pyx_int_207092197);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_mstate_global->__pyx_int_207092197) != (0)) __PYX_ERR(1, 15, __pyx_L1_error);
    __Pyx_INCREF(__pyx_v_state);
    __Pyx_GIVEREF(__pyx_v_state);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 2, __pyx_v_state) != (0)) __PYX_ERR(1, 15, __pyx_L1_error);
    __pyx_t_3 = PyTuple_New(2); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 15, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_GIVEREF(__pyx_t_2);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_3, 0, __pyx_t_2) != (0)) __PYX_ERR(1, 15, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_4);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_3, 1, __pyx_t_4) != (0)) __PYX_ERR(1, 15, __pyx_L1_error);
    __pyx_t_2 = 0;
    __pyx_t_4 = 0;
    __pyx_r = __pyx_t_3;
    __pyx_t_3 = 0;
    goto __pyx_L0;
  }

  /* "(tree fragment)":1
 * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
 *     cdef tuple state
 *     cdef object _dict
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.__reduce_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_state);
  __Pyx_XDECREF(__pyx_v__dict);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":16
 *     else:
 *         return __pyx_unpickle_PlanNd, (type(self), 0xc57f9e5, state)
 * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_unpickle_PlanNd__set_state(self, __pyx_state)
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_19__setstate_cython__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6PlanNd_18__setstate_cython__, "PlanNd.__setstate_cython__(self, __pyx_state)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_19__setstate_cython__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v___pyx_state = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[1] = {0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__setstate_cython__ (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_pyx_state,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(1, 16, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(1, 16, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "__setstate_cython__", 0) < (0)) __PYX_ERR(1, 16, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 1; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("__setstate_cython__", 1, 1, 1, i); __PYX_ERR(1, 16, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 1)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(1, 16, __pyx_L3_error)
    }
    __pyx_v___pyx_state = values[0];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__setstate_cython__", 1, 1, 1, __pyx_nargs); __PYX_ERR(1, 16, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.__setstate_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6PlanNd_18__setstate_cython__(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v_self), __pyx_v___pyx_state);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6PlanNd_18__setstate_cython__(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v_self, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__setstate_cython__", 0);

  /* "(tree fragment)":17
 *         return __pyx_unpickle_PlanNd, (type(self), 0xc57f9e5, state)
 * def __setstate_cython__(self, __pyx_state):
 *     __pyx_unpickle_PlanNd__set_state(self, __pyx_state)             # <<<<<<<<<<<<<<
*/
  if (!(likely(PyTuple_CheckExact(__pyx_v___pyx_state))||((__pyx_v___pyx_state) == Py_None) || __Pyx_RaiseUnexpectedTypeError("tuple", __pyx_v___pyx_state))) __PYX_ERR(1, 17, __pyx_L1_error)
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft___pyx_unpickle_PlanNd__set_state(__pyx_v_self, ((PyObject*)__pyx_v___pyx_state)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 17, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "(tree fragment)":16
 *     else:
 *         return __pyx_unpickle_PlanNd, (type(self), 0xc57f9e5, state)
 * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_unpickle_PlanNd__set_state(self, __pyx_state)
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.PlanNd.__setstate_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":983
 * # TODO(leofang): support cufftXtSetGPUs?
 * cdef class XtPlanNd:
 *     def __init__(self, shape,             # <<<<<<<<<<<<<<
 *                  inembed, long long int istride, long long int idist, idtype,
 *                  onembed, long long int ostride, long long int odist, odtype,
*/

/* Python wrapper */
static int __pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static int __pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_1__init__(PyObject *__pyx_v_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_shape = 0;
  PyObject *__pyx_v_inembed = 0;
  PY_LONG_LONG __pyx_v_istride;
  PY_LONG_LONG __pyx_v_idist;
  PyObject *__pyx_v_idtype = 0;
  PyObject *__pyx_v_onembed = 0;
  PY_LONG_LONG __pyx_v_ostride;
  PY_LONG_LONG __pyx_v_odist;
  PyObject *__pyx_v_odtype = 0;
  PY_LONG_LONG __pyx_v_batch;
  PyObject *__pyx_v_edtype = 0;
  PyObject *__pyx_v_order = 0;
  int __pyx_v_last_axis;
  PyObject *__pyx_v_last_size = 0;
  intptr_t __pyx_v_prealloc_plan;
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[15] = {0,0,0,0,0,0,0,0,0,0,0,0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__init__ (wrapper)", 0);
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return -1;
  #endif
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_shape,&__pyx_mstate_global->__pyx_n_u_inembed,&__pyx_mstate_global->__pyx_n_u_istride,&__pyx_mstate_global->__pyx_n_u_idist,&__pyx_mstate_global->__pyx_n_u_idtype,&__pyx_mstate_global->__pyx_n_u_onembed,&__pyx_mstate_global->__pyx_n_u_ostride,&__pyx_mstate_global->__pyx_n_u_odist,&__pyx_mstate_global->__pyx_n_u_odtype,&__pyx_mstate_global->__pyx_n_u_batch,&__pyx_mstate_global->__pyx_n_u_edtype,&__pyx_mstate_global->__pyx_n_u_order,&__pyx_mstate_global->__pyx_n_u_last_axis,&__pyx_mstate_global->__pyx_n_u_last_size,&__pyx_mstate_global->__pyx_n_u_prealloc_plan,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_VARARGS(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 983, __pyx_L3_error)
    if (likely(__pyx_kwds_len > 0)) {
      switch (__pyx_nargs) {
        case 11:
        values[10] = __Pyx_ArgRef_VARARGS(__pyx_args, 10);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[10])) __PYX_ERR(0, 983, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case 10:
        values[9] = __Pyx_ArgRef_VARARGS(__pyx_args, 9);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[9])) __PYX_ERR(0, 983, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  9:
        values[8] = __Pyx_ArgRef_VARARGS(__pyx_args, 8);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[8])) __PYX_ERR(0, 983, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  8:
        values[7] = __Pyx_ArgRef_VARARGS(__pyx_args, 7);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[7])) __PYX_ERR(0, 983, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  7:
        values[6] = __Pyx_ArgRef_VARARGS(__pyx_args, 6);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[6])) __PYX_ERR(0, 983, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  6:
        values[5] = __Pyx_ArgRef_VARARGS(__pyx_args, 5);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[5])) __PYX_ERR(0, 983, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  5:
        values[4] = __Pyx_ArgRef_VARARGS(__pyx_args, 4);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[4])) __PYX_ERR(0, 983, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  4:
        values[3] = __Pyx_ArgRef_VARARGS(__pyx_args, 3);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 983, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  3:
        values[2] = __Pyx_ArgRef_VARARGS(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 983, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_VARARGS(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 983, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_VARARGS(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 983, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "__init__", 0) < (0)) __PYX_ERR(0, 983, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 11; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("__init__", 1, 11, 11, i); __PYX_ERR(0, 983, __pyx_L3_error) }
      }
      for (Py_ssize_t i = 11; i < 14; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseKeywordRequired("__init__", *(__pyx_pyargnames[i - 0])); __PYX_ERR(0, 983, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 11)) {
      goto __pyx_L5_argtuple_error;
    } else {
      __Pyx_RaiseKeywordRequired("__init__", __pyx_mstate_global->__pyx_n_u_order); __PYX_ERR(0, 983, __pyx_L3_error)
    }
    __pyx_v_shape = values[0];
    __pyx_v_inembed = values[1];
    __pyx_v_istride = __Pyx_PyLong_As_PY_LONG_LONG(values[2]); if (unlikely((__pyx_v_istride == (PY_LONG_LONG)-1) && PyErr_Occurred())) __PYX_ERR(0, 984, __pyx_L3_error)
    __pyx_v_idist = __Pyx_PyLong_As_PY_LONG_LONG(values[3]); if (unlikely((__pyx_v_idist == (PY_LONG_LONG)-1) && PyErr_Occurred())) __PYX_ERR(0, 984, __pyx_L3_error)
    __pyx_v_idtype = values[4];
    __pyx_v_onembed = values[5];
    __pyx_v_ostride = __Pyx_PyLong_As_PY_LONG_LONG(values[6]); if (unlikely((__pyx_v_ostride == (PY_LONG_LONG)-1) && PyErr_Occurred())) __PYX_ERR(0, 985, __pyx_L3_error)
    __pyx_v_odist = __Pyx_PyLong_As_PY_LONG_LONG(values[7]); if (unlikely((__pyx_v_odist == (PY_LONG_LONG)-1) && PyErr_Occurred())) __PYX_ERR(0, 985, __pyx_L3_error)
    __pyx_v_odtype = values[8];
    __pyx_v_batch = __Pyx_PyLong_As_PY_LONG_LONG(values[9]); if (unlikely((__pyx_v_batch == (PY_LONG_LONG)-1) && PyErr_Occurred())) __PYX_ERR(0, 986, __pyx_L3_error)
    __pyx_v_edtype = values[10];
    __pyx_v_order = ((PyObject*)values[11]);
    __pyx_v_last_axis = __Pyx_PyLong_As_int(values[12]); if (unlikely((__pyx_v_last_axis == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 987, __pyx_L3_error)
    __pyx_v_last_size = values[13];
    if (values[14]) {
      __pyx_v_prealloc_plan = PyLong_AsSsize_t(values[14]); if (unlikely((__pyx_v_prealloc_plan == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 988, __pyx_L3_error)
    } else {
      __pyx_v_prealloc_plan = ((intptr_t)0);
    }
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__init__", 1, 11, 11, __pyx_nargs); __PYX_ERR(0, 983, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return -1;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_order), (&PyUnicode_Type), 1, "order", 1))) __PYX_ERR(0, 987, __pyx_L1_error)
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd___init__(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self), __pyx_v_shape, __pyx_v_inembed, __pyx_v_istride, __pyx_v_idist, __pyx_v_idtype, __pyx_v_onembed, __pyx_v_ostride, __pyx_v_odist, __pyx_v_odtype, __pyx_v_batch, __pyx_v_edtype, __pyx_v_order, __pyx_v_last_axis, __pyx_v_last_size, __pyx_v_prealloc_plan);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = -1;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  goto __pyx_L7_cleaned_up;
  __pyx_L0:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __pyx_L7_cleaned_up:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static int __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd___init__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self, PyObject *__pyx_v_shape, PyObject *__pyx_v_inembed, PY_LONG_LONG __pyx_v_istride, PY_LONG_LONG __pyx_v_idist, PyObject *__pyx_v_idtype, PyObject *__pyx_v_onembed, PY_LONG_LONG __pyx_v_ostride, PY_LONG_LONG __pyx_v_odist, PyObject *__pyx_v_odtype, PY_LONG_LONG __pyx_v_batch, PyObject *__pyx_v_edtype, PyObject *__pyx_v_order, int __pyx_v_last_axis, PyObject *__pyx_v_last_size, intptr_t __pyx_v_prealloc_plan) {
  cufftHandle __pyx_v_plan;
  size_t __pyx_v_work_size;
  int __pyx_v_ndim;
  int __pyx_v_result;
  std::vector<PY_LONG_LONG>  __pyx_v_shape_arr;
  std::vector<PY_LONG_LONG>  __pyx_v_inembed_arr;
  std::vector<PY_LONG_LONG>  __pyx_v_onembed_arr;
  PY_LONG_LONG *__pyx_v_shape_ptr;
  PY_LONG_LONG *__pyx_v_inembed_ptr;
  PY_LONG_LONG *__pyx_v_onembed_ptr;
  PyObject *__pyx_v_to_cuda_dtype = NULL;
  int __pyx_v_itype;
  int __pyx_v_otype;
  int __pyx_v_etype;
  PY_LONG_LONG __pyx_v_length;
  PY_LONG_LONG __pyx_v_full;
  PyObject *__pyx_v_work_area = NULL;
  intptr_t __pyx_v_ptr;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  std::vector<PY_LONG_LONG>  __pyx_t_1;
  Py_ssize_t __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  size_t __pyx_t_7;
  int __pyx_t_8;
  PyObject *(*__pyx_t_9)(PyObject *);
  PY_LONG_LONG __pyx_t_10;
  PY_LONG_LONG __pyx_t_11;
  PyObject *__pyx_t_12 = NULL;
  PyObject *__pyx_t_13 = NULL;
  PyObject *__pyx_t_14 = NULL;
  PyObject *__pyx_t_15 = NULL;
  PyObject *__pyx_t_16 = NULL;
  PyObject *__pyx_t_17 = NULL;
  PyObject *__pyx_t_18 = NULL;
  intptr_t __pyx_t_19;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__init__", 0);

  /* "cupy/cuda/cufft.pyx":995
 *         cdef size_t work_size
 *         cdef int ndim, result
 *         cdef vector.vector[long long int] shape_arr = shape             # <<<<<<<<<<<<<<
 *         cdef vector.vector[long long int] inembed_arr
 *         cdef vector.vector[long long int] onembed_arr
*/
  __pyx_t_1 = __pyx_convert_vector_from_py_PY_LONG_LONG(__pyx_v_shape); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 995, __pyx_L1_error)
  __pyx_v_shape_arr = __PYX_STD_MOVE_IF_SUPPORTED(__pyx_t_1);

  /* "cupy/cuda/cufft.pyx":998
 *         cdef vector.vector[long long int] inembed_arr
 *         cdef vector.vector[long long int] onembed_arr
 *         cdef long long int* shape_ptr = shape_arr.data()             # <<<<<<<<<<<<<<
 *         cdef long long int* inembed_ptr
 *         cdef long long int* onembed_ptr
*/
  __pyx_v_shape_ptr = __pyx_v_shape_arr.data();

  /* "cupy/cuda/cufft.pyx":1002
 *         cdef long long int* onembed_ptr
 * 
 *         self.handle = <intptr_t>0             # <<<<<<<<<<<<<<
 *         ndim = len(shape)
 * 
*/
  __pyx_v_self->handle = ((intptr_t)0);

  /* "cupy/cuda/cufft.pyx":1003
 * 
 *         self.handle = <intptr_t>0
 *         ndim = len(shape)             # <<<<<<<<<<<<<<
 * 
 *         if inembed is None:
*/
  __pyx_t_2 = PyObject_Length(__pyx_v_shape); if (unlikely(__pyx_t_2 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1003, __pyx_L1_error)
  __pyx_v_ndim = __pyx_t_2;

  /* "cupy/cuda/cufft.pyx":1005
 *         ndim = len(shape)
 * 
 *         if inembed is None:             # <<<<<<<<<<<<<<
 *             inembed_ptr = NULL  # ignore istride and use default strides
 *         else:
*/
  __pyx_t_3 = (__pyx_v_inembed == Py_None);
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":1006
 * 
 *         if inembed is None:
 *             inembed_ptr = NULL  # ignore istride and use default strides             # <<<<<<<<<<<<<<
 *         else:
 *             inembed_arr = inembed
*/
    __pyx_v_inembed_ptr = NULL;

    /* "cupy/cuda/cufft.pyx":1005
 *         ndim = len(shape)
 * 
 *         if inembed is None:             # <<<<<<<<<<<<<<
 *             inembed_ptr = NULL  # ignore istride and use default strides
 *         else:
*/
    goto __pyx_L3;
  }

  /* "cupy/cuda/cufft.pyx":1008
 *             inembed_ptr = NULL  # ignore istride and use default strides
 *         else:
 *             inembed_arr = inembed             # <<<<<<<<<<<<<<
 *             inembed_ptr = inembed_arr.data()
 * 
*/
  /*else*/ {
    __pyx_t_1 = __pyx_convert_vector_from_py_PY_LONG_LONG(__pyx_v_inembed); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1008, __pyx_L1_error)
    __pyx_v_inembed_arr = __PYX_STD_MOVE_IF_SUPPORTED(__pyx_t_1);

    /* "cupy/cuda/cufft.pyx":1009
 *         else:
 *             inembed_arr = inembed
 *             inembed_ptr = inembed_arr.data()             # <<<<<<<<<<<<<<
 * 
 *         if onembed is None:
*/
    __pyx_v_inembed_ptr = __pyx_v_inembed_arr.data();
  }
  __pyx_L3:;

  /* "cupy/cuda/cufft.pyx":1011
 *             inembed_ptr = inembed_arr.data()
 * 
 *         if onembed is None:             # <<<<<<<<<<<<<<
 *             onembed_ptr = NULL  # ignore ostride and use default strides
 *         else:
*/
  __pyx_t_3 = (__pyx_v_onembed == Py_None);
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":1012
 * 
 *         if onembed is None:
 *             onembed_ptr = NULL  # ignore ostride and use default strides             # <<<<<<<<<<<<<<
 *         else:
 *             onembed_arr = onembed
*/
    __pyx_v_onembed_ptr = NULL;

    /* "cupy/cuda/cufft.pyx":1011
 *             inembed_ptr = inembed_arr.data()
 * 
 *         if onembed is None:             # <<<<<<<<<<<<<<
 *             onembed_ptr = NULL  # ignore ostride and use default strides
 *         else:
*/
    goto __pyx_L4;
  }

  /* "cupy/cuda/cufft.pyx":1014
 *             onembed_ptr = NULL  # ignore ostride and use default strides
 *         else:
 *             onembed_arr = onembed             # <<<<<<<<<<<<<<
 *             onembed_ptr = onembed_arr.data()
 * 
*/
  /*else*/ {
    __pyx_t_1 = __pyx_convert_vector_from_py_PY_LONG_LONG(__pyx_v_onembed); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1014, __pyx_L1_error)
    __pyx_v_onembed_arr = __PYX_STD_MOVE_IF_SUPPORTED(__pyx_t_1);

    /* "cupy/cuda/cufft.pyx":1015
 *         else:
 *             onembed_arr = onembed
 *             onembed_ptr = onembed_arr.data()             # <<<<<<<<<<<<<<
 * 
 *         if prealloc_plan:
*/
    __pyx_v_onembed_ptr = __pyx_v_onembed_arr.data();
  }
  __pyx_L4:;

  /* "cupy/cuda/cufft.pyx":1017
 *             onembed_ptr = onembed_arr.data()
 * 
 *         if prealloc_plan:             # <<<<<<<<<<<<<<
 *             plan = <Handle>(prealloc_plan)
 *         else:
*/
  __pyx_t_3 = (__pyx_v_prealloc_plan != 0);
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":1018
 * 
 *         if prealloc_plan:
 *             plan = <Handle>(prealloc_plan)             # <<<<<<<<<<<<<<
 *         else:
 *             with nogil:
*/
    __pyx_v_plan = ((cufftHandle)__pyx_v_prealloc_plan);

    /* "cupy/cuda/cufft.pyx":1017
 *             onembed_ptr = onembed_arr.data()
 * 
 *         if prealloc_plan:             # <<<<<<<<<<<<<<
 *             plan = <Handle>(prealloc_plan)
 *         else:
*/
    goto __pyx_L5;
  }

  /* "cupy/cuda/cufft.pyx":1020
 *             plan = <Handle>(prealloc_plan)
 *         else:
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftCreate(&plan)
 *                 if result == 0:
*/
  /*else*/ {
    {
        PyThreadState *_save;
        _save = NULL;
        Py_UNBLOCK_THREADS
        __Pyx_FastGIL_Remember();
        /*try:*/ {

          /* "cupy/cuda/cufft.pyx":1021
 *         else:
 *             with nogil:
 *                 result = cufftCreate(&plan)             # <<<<<<<<<<<<<<
 *                 if result == 0:
 *                     result = cufftSetAutoAllocation(plan, 0)
*/
          __pyx_v_result = cufftCreate((&__pyx_v_plan));

          /* "cupy/cuda/cufft.pyx":1022
 *             with nogil:
 *                 result = cufftCreate(&plan)
 *                 if result == 0:             # <<<<<<<<<<<<<<
 *                     result = cufftSetAutoAllocation(plan, 0)
 *             check_result(result)
*/
          __pyx_t_3 = (__pyx_v_result == 0);
          if (__pyx_t_3) {

            /* "cupy/cuda/cufft.pyx":1023
 *                 result = cufftCreate(&plan)
 *                 if result == 0:
 *                     result = cufftSetAutoAllocation(plan, 0)             # <<<<<<<<<<<<<<
 *             check_result(result)
 * 
*/
            __pyx_v_result = cufftSetAutoAllocation(__pyx_v_plan, 0);

            /* "cupy/cuda/cufft.pyx":1022
 *             with nogil:
 *                 result = cufftCreate(&plan)
 *                 if result == 0:             # <<<<<<<<<<<<<<
 *                     result = cufftSetAutoAllocation(plan, 0)
 *             check_result(result)
*/
          }
        }

        /* "cupy/cuda/cufft.pyx":1020
 *             plan = <Handle>(prealloc_plan)
 *         else:
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftCreate(&plan)
 *                 if result == 0:
*/
        /*finally:*/ {
          /*normal exit:*/{
            __Pyx_FastGIL_Forget();
            Py_BLOCK_THREADS
            goto __pyx_L8;
          }
          __pyx_L8:;
        }
    }

    /* "cupy/cuda/cufft.pyx":1024
 *                 if result == 0:
 *                     result = cufftSetAutoAllocation(plan, 0)
 *             check_result(result)             # <<<<<<<<<<<<<<
 * 
 *         self.handle = <intptr_t>plan
*/
    __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1024, __pyx_L1_error)
  }
  __pyx_L5:;

  /* "cupy/cuda/cufft.pyx":1026
 *             check_result(result)
 * 
 *         self.handle = <intptr_t>plan             # <<<<<<<<<<<<<<
 *         self.gpus = None  # TODO(leofang): support multi-GPU plans
 * 
*/
  __pyx_v_self->handle = ((intptr_t)__pyx_v_plan);

  /* "cupy/cuda/cufft.pyx":1027
 * 
 *         self.handle = <intptr_t>plan
 *         self.gpus = None  # TODO(leofang): support multi-GPU plans             # <<<<<<<<<<<<<<
 * 
 *         # determine input/output/execution types here; note that we don't
*/
  __Pyx_INCREF(Py_None);
  __Pyx_GIVEREF(Py_None);
  __Pyx_GOTREF(__pyx_v_self->gpus);
  __Pyx_DECREF(__pyx_v_self->gpus);
  __pyx_v_self->gpus = ((PyObject*)Py_None);

  /* "cupy/cuda/cufft.pyx":1031
 *         # determine input/output/execution types here; note that we don't
 *         # cimport to_cuda_dtype due to circular dependency
 *         from cupy._core._dtype import to_cuda_dtype             # <<<<<<<<<<<<<<
 *         cdef int itype = to_cuda_dtype(idtype, True)
 *         cdef int otype = to_cuda_dtype(odtype, True)
*/
  __pyx_t_4 = PyList_New(1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1031, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(__pyx_mstate_global->__pyx_n_u_to_cuda_dtype);
  __Pyx_GIVEREF(__pyx_mstate_global->__pyx_n_u_to_cuda_dtype);
  if (__Pyx_PyList_SET_ITEM(__pyx_t_4, 0, __pyx_mstate_global->__pyx_n_u_to_cuda_dtype) != (0)) __PYX_ERR(0, 1031, __pyx_L1_error);
  __pyx_t_5 = __Pyx_Import(__pyx_mstate_global->__pyx_n_u_cupy__core__dtype, __pyx_t_4, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1031, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = __Pyx_ImportFrom(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_to_cuda_dtype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1031, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_INCREF(__pyx_t_4);
  __pyx_v_to_cuda_dtype = __pyx_t_4;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "cupy/cuda/cufft.pyx":1032
 *         # cimport to_cuda_dtype due to circular dependency
 *         from cupy._core._dtype import to_cuda_dtype
 *         cdef int itype = to_cuda_dtype(idtype, True)             # <<<<<<<<<<<<<<
 *         cdef int otype = to_cuda_dtype(odtype, True)
 *         cdef int etype = to_cuda_dtype(edtype, True)
*/
  __pyx_t_4 = NULL;
  __Pyx_INCREF(__pyx_v_to_cuda_dtype);
  __pyx_t_6 = __pyx_v_to_cuda_dtype; 
  __pyx_t_7 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_6);
    assert(__pyx_t_4);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_6);
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_6, __pyx__function);
    __pyx_t_7 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[3] = {__pyx_t_4, __pyx_v_idtype, Py_True};
    __pyx_t_5 = __Pyx_PyObject_FastCall(__pyx_t_6, __pyx_callargs+__pyx_t_7, (3-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1032, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
  }
  __pyx_t_8 = __Pyx_PyLong_As_int(__pyx_t_5); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1032, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_itype = __pyx_t_8;

  /* "cupy/cuda/cufft.pyx":1033
 *         from cupy._core._dtype import to_cuda_dtype
 *         cdef int itype = to_cuda_dtype(idtype, True)
 *         cdef int otype = to_cuda_dtype(odtype, True)             # <<<<<<<<<<<<<<
 *         cdef int etype = to_cuda_dtype(edtype, True)
 * 
*/
  __pyx_t_6 = NULL;
  __Pyx_INCREF(__pyx_v_to_cuda_dtype);
  __pyx_t_4 = __pyx_v_to_cuda_dtype; 
  __pyx_t_7 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_4))) {
    __pyx_t_6 = PyMethod_GET_SELF(__pyx_t_4);
    assert(__pyx_t_6);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_4);
    __Pyx_INCREF(__pyx_t_6);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_4, __pyx__function);
    __pyx_t_7 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[3] = {__pyx_t_6, __pyx_v_odtype, Py_True};
    __pyx_t_5 = __Pyx_PyObject_FastCall(__pyx_t_4, __pyx_callargs+__pyx_t_7, (3-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1033, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
  }
  __pyx_t_8 = __Pyx_PyLong_As_int(__pyx_t_5); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1033, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_otype = __pyx_t_8;

  /* "cupy/cuda/cufft.pyx":1034
 *         cdef int itype = to_cuda_dtype(idtype, True)
 *         cdef int otype = to_cuda_dtype(odtype, True)
 *         cdef int etype = to_cuda_dtype(edtype, True)             # <<<<<<<<<<<<<<
 * 
 *         cdef long long int length
*/
  __pyx_t_4 = NULL;
  __Pyx_INCREF(__pyx_v_to_cuda_dtype);
  __pyx_t_6 = __pyx_v_to_cuda_dtype; 
  __pyx_t_7 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_6);
    assert(__pyx_t_4);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_6);
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_6, __pyx__function);
    __pyx_t_7 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[3] = {__pyx_t_4, __pyx_v_edtype, Py_True};
    __pyx_t_5 = __Pyx_PyObject_FastCall(__pyx_t_6, __pyx_callargs+__pyx_t_7, (3-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1034, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
  }
  __pyx_t_8 = __Pyx_PyLong_As_int(__pyx_t_5); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1034, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_etype = __pyx_t_8;

  /* "cupy/cuda/cufft.pyx":1037
 * 
 *         cdef long long int length
 *         cdef long long int full = 1             # <<<<<<<<<<<<<<
 *         for length in shape:
 *             full *= length
*/
  __pyx_v_full = 1;

  /* "cupy/cuda/cufft.pyx":1038
 *         cdef long long int length
 *         cdef long long int full = 1
 *         for length in shape:             # <<<<<<<<<<<<<<
 *             full *= length
 *         length = last_size if last_size is not None else shape[-1]
*/
  if (likely(PyList_CheckExact(__pyx_v_shape)) || PyTuple_CheckExact(__pyx_v_shape)) {
    __pyx_t_5 = __pyx_v_shape; __Pyx_INCREF(__pyx_t_5);
    __pyx_t_2 = 0;
    __pyx_t_9 = NULL;
  } else {
    __pyx_t_2 = -1; __pyx_t_5 = PyObject_GetIter(__pyx_v_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1038, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_9 = (CYTHON_COMPILING_IN_LIMITED_API) ? PyIter_Next : __Pyx_PyObject_GetIterNextFunc(__pyx_t_5); if (unlikely(!__pyx_t_9)) __PYX_ERR(0, 1038, __pyx_L1_error)
  }
  for (;;) {
    if (likely(!__pyx_t_9)) {
      if (likely(PyList_CheckExact(__pyx_t_5))) {
        {
          Py_ssize_t __pyx_temp = __Pyx_PyList_GET_SIZE(__pyx_t_5);
          #if !CYTHON_ASSUME_SAFE_SIZE
          if (unlikely((__pyx_temp < 0))) __PYX_ERR(0, 1038, __pyx_L1_error)
          #endif
          if (__pyx_t_2 >= __pyx_temp) break;
        }
        __pyx_t_6 = __Pyx_PyList_GetItemRef(__pyx_t_5, __pyx_t_2);
        ++__pyx_t_2;
      } else {
        {
          Py_ssize_t __pyx_temp = __Pyx_PyTuple_GET_SIZE(__pyx_t_5);
          #if !CYTHON_ASSUME_SAFE_SIZE
          if (unlikely((__pyx_temp < 0))) __PYX_ERR(0, 1038, __pyx_L1_error)
          #endif
          if (__pyx_t_2 >= __pyx_temp) break;
        }
        #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        __pyx_t_6 = __Pyx_NewRef(PyTuple_GET_ITEM(__pyx_t_5, __pyx_t_2));
        #else
        __pyx_t_6 = __Pyx_PySequence_ITEM(__pyx_t_5, __pyx_t_2);
        #endif
        ++__pyx_t_2;
      }
      if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1038, __pyx_L1_error)
    } else {
      __pyx_t_6 = __pyx_t_9(__pyx_t_5);
      if (unlikely(!__pyx_t_6)) {
        PyObject* exc_type = PyErr_Occurred();
        if (exc_type) {
          if (unlikely(!__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration))) __PYX_ERR(0, 1038, __pyx_L1_error)
          PyErr_Clear();
        }
        break;
      }
    }
    __Pyx_GOTREF(__pyx_t_6);
    __pyx_t_10 = __Pyx_PyLong_As_PY_LONG_LONG(__pyx_t_6); if (unlikely((__pyx_t_10 == (PY_LONG_LONG)-1) && PyErr_Occurred())) __PYX_ERR(0, 1038, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_v_length = __pyx_t_10;

    /* "cupy/cuda/cufft.pyx":1039
 *         cdef long long int full = 1
 *         for length in shape:
 *             full *= length             # <<<<<<<<<<<<<<
 *         length = last_size if last_size is not None else shape[-1]
 *         try:
*/
    __pyx_v_full = (__pyx_v_full * __pyx_v_length);

    /* "cupy/cuda/cufft.pyx":1038
 *         cdef long long int length
 *         cdef long long int full = 1
 *         for length in shape:             # <<<<<<<<<<<<<<
 *             full *= length
 *         length = last_size if last_size is not None else shape[-1]
*/
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "cupy/cuda/cufft.pyx":1040
 *         for length in shape:
 *             full *= length
 *         length = last_size if last_size is not None else shape[-1]             # <<<<<<<<<<<<<<
 *         try:
 *             self._sanity_checks(itype, otype, etype, length, full)
*/
  __pyx_t_3 = (__pyx_v_last_size != Py_None);
  if (__pyx_t_3) {
    __pyx_t_11 = __Pyx_PyLong_As_PY_LONG_LONG(__pyx_v_last_size); if (unlikely((__pyx_t_11 == (PY_LONG_LONG)-1) && PyErr_Occurred())) __PYX_ERR(0, 1040, __pyx_L1_error)
    __pyx_t_10 = __pyx_t_11;
  } else {
    __pyx_t_5 = __Pyx_GetItemInt(__pyx_v_shape, -1L, long, 1, __Pyx_PyLong_From_long, 0, 1, 1, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1040, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_11 = __Pyx_PyLong_As_PY_LONG_LONG(__pyx_t_5); if (unlikely((__pyx_t_11 == (PY_LONG_LONG)-1) && PyErr_Occurred())) __PYX_ERR(0, 1040, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_10 = __pyx_t_11;
  }
  __pyx_v_length = __pyx_t_10;

  /* "cupy/cuda/cufft.pyx":1041
 *             full *= length
 *         length = last_size if last_size is not None else shape[-1]
 *         try:             # <<<<<<<<<<<<<<
 *             self._sanity_checks(itype, otype, etype, length, full)
 *         except AssertionError:
*/
  {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    __Pyx_ExceptionSave(&__pyx_t_12, &__pyx_t_13, &__pyx_t_14);
    __Pyx_XGOTREF(__pyx_t_12);
    __Pyx_XGOTREF(__pyx_t_13);
    __Pyx_XGOTREF(__pyx_t_14);
    /*try:*/ {

      /* "cupy/cuda/cufft.pyx":1042
 *         length = last_size if last_size is not None else shape[-1]
 *         try:
 *             self._sanity_checks(itype, otype, etype, length, full)             # <<<<<<<<<<<<<<
 *         except AssertionError:
 *             raise ValueError('input/output/execution types mismatch')
*/
      __pyx_t_6 = ((PyObject *)__pyx_v_self);
      __Pyx_INCREF(__pyx_t_6);
      __pyx_t_4 = __Pyx_PyLong_From_int(__pyx_v_itype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1042, __pyx_L13_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_15 = __Pyx_PyLong_From_int(__pyx_v_otype); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 1042, __pyx_L13_error)
      __Pyx_GOTREF(__pyx_t_15);
      __pyx_t_16 = __Pyx_PyLong_From_int(__pyx_v_etype); if (unlikely(!__pyx_t_16)) __PYX_ERR(0, 1042, __pyx_L13_error)
      __Pyx_GOTREF(__pyx_t_16);
      __pyx_t_17 = __Pyx_PyLong_From_PY_LONG_LONG(__pyx_v_length); if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 1042, __pyx_L13_error)
      __Pyx_GOTREF(__pyx_t_17);
      __pyx_t_18 = __Pyx_PyLong_From_PY_LONG_LONG(__pyx_v_full); if (unlikely(!__pyx_t_18)) __PYX_ERR(0, 1042, __pyx_L13_error)
      __Pyx_GOTREF(__pyx_t_18);
      __pyx_t_7 = 0;
      {
        PyObject *__pyx_callargs[6] = {__pyx_t_6, __pyx_t_4, __pyx_t_15, __pyx_t_16, __pyx_t_17, __pyx_t_18};
        __pyx_t_5 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_sanity_checks, __pyx_callargs+__pyx_t_7, (6-__pyx_t_7) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
        __Pyx_DECREF(__pyx_t_16); __pyx_t_16 = 0;
        __Pyx_DECREF(__pyx_t_17); __pyx_t_17 = 0;
        __Pyx_DECREF(__pyx_t_18); __pyx_t_18 = 0;
        if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1042, __pyx_L13_error)
        __Pyx_GOTREF(__pyx_t_5);
      }
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

      /* "cupy/cuda/cufft.pyx":1041
 *             full *= length
 *         length = last_size if last_size is not None else shape[-1]
 *         try:             # <<<<<<<<<<<<<<
 *             self._sanity_checks(itype, otype, etype, length, full)
 *         except AssertionError:
*/
    }
    __Pyx_XDECREF(__pyx_t_12); __pyx_t_12 = 0;
    __Pyx_XDECREF(__pyx_t_13); __pyx_t_13 = 0;
    __Pyx_XDECREF(__pyx_t_14); __pyx_t_14 = 0;
    goto __pyx_L18_try_end;
    __pyx_L13_error:;
    __Pyx_XDECREF(__pyx_t_15); __pyx_t_15 = 0;
    __Pyx_XDECREF(__pyx_t_16); __pyx_t_16 = 0;
    __Pyx_XDECREF(__pyx_t_17); __pyx_t_17 = 0;
    __Pyx_XDECREF(__pyx_t_18); __pyx_t_18 = 0;
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;

    /* "cupy/cuda/cufft.pyx":1043
 *         try:
 *             self._sanity_checks(itype, otype, etype, length, full)
 *         except AssertionError:             # <<<<<<<<<<<<<<
 *             raise ValueError('input/output/execution types mismatch')
 * 
*/
    __pyx_t_8 = __Pyx_PyErr_ExceptionMatches(__pyx_builtin_AssertionError);
    if (__pyx_t_8) {
      __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
      if (__Pyx_GetException(&__pyx_t_5, &__pyx_t_18, &__pyx_t_17) < 0) __PYX_ERR(0, 1043, __pyx_L15_except_error)
      __Pyx_XGOTREF(__pyx_t_5);
      __Pyx_XGOTREF(__pyx_t_18);
      __Pyx_XGOTREF(__pyx_t_17);

      /* "cupy/cuda/cufft.pyx":1044
 *             self._sanity_checks(itype, otype, etype, length, full)
 *         except AssertionError:
 *             raise ValueError('input/output/execution types mismatch')             # <<<<<<<<<<<<<<
 * 
 *         if batch == 0:
*/
      __pyx_t_15 = NULL;
      __Pyx_INCREF(__pyx_builtin_ValueError);
      __pyx_t_4 = __pyx_builtin_ValueError; 
      __pyx_t_7 = 1;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_15, __pyx_mstate_global->__pyx_kp_u_input_output_execution_types_mis};
        __pyx_t_16 = __Pyx_PyObject_FastCall(__pyx_t_4, __pyx_callargs+__pyx_t_7, (2-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_15); __pyx_t_15 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        if (unlikely(!__pyx_t_16)) __PYX_ERR(0, 1044, __pyx_L15_except_error)
        __Pyx_GOTREF(__pyx_t_16);
      }
      __Pyx_Raise(__pyx_t_16, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_16); __pyx_t_16 = 0;
      __PYX_ERR(0, 1044, __pyx_L15_except_error)
    }
    goto __pyx_L15_except_error;

    /* "cupy/cuda/cufft.pyx":1041
 *             full *= length
 *         length = last_size if last_size is not None else shape[-1]
 *         try:             # <<<<<<<<<<<<<<
 *             self._sanity_checks(itype, otype, etype, length, full)
 *         except AssertionError:
*/
    __pyx_L15_except_error:;
    __Pyx_XGIVEREF(__pyx_t_12);
    __Pyx_XGIVEREF(__pyx_t_13);
    __Pyx_XGIVEREF(__pyx_t_14);
    __Pyx_ExceptionReset(__pyx_t_12, __pyx_t_13, __pyx_t_14);
    goto __pyx_L1_error;
    __pyx_L18_try_end:;
  }

  /* "cupy/cuda/cufft.pyx":1046
 *             raise ValueError('input/output/execution types mismatch')
 * 
 *         if batch == 0:             # <<<<<<<<<<<<<<
 *             work_size = 0
 *         else:
*/
  __pyx_t_3 = (__pyx_v_batch == 0);
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":1047
 * 
 *         if batch == 0:
 *             work_size = 0             # <<<<<<<<<<<<<<
 *         else:
 *             with nogil:
*/
    __pyx_v_work_size = 0;

    /* "cupy/cuda/cufft.pyx":1046
 *             raise ValueError('input/output/execution types mismatch')
 * 
 *         if batch == 0:             # <<<<<<<<<<<<<<
 *             work_size = 0
 *         else:
*/
    goto __pyx_L21;
  }

  /* "cupy/cuda/cufft.pyx":1049
 *             work_size = 0
 *         else:
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftXtMakePlanMany(
 *                     plan, ndim, shape_ptr,
*/
  /*else*/ {
    {
        PyThreadState *_save;
        _save = NULL;
        Py_UNBLOCK_THREADS
        __Pyx_FastGIL_Remember();
        /*try:*/ {

          /* "cupy/cuda/cufft.pyx":1050
 *         else:
 *             with nogil:
 *                 result = cufftXtMakePlanMany(             # <<<<<<<<<<<<<<
 *                     plan, ndim, shape_ptr,
 *                     inembed_ptr, istride, idist, <DataType>itype,
*/
          __pyx_v_result = cufftXtMakePlanMany(__pyx_v_plan, __pyx_v_ndim, __pyx_v_shape_ptr, __pyx_v_inembed_ptr, __pyx_v_istride, __pyx_v_idist, ((cudaDataType)__pyx_v_itype), __pyx_v_onembed_ptr, __pyx_v_ostride, __pyx_v_odist, ((cudaDataType)__pyx_v_otype), __pyx_v_batch, (&__pyx_v_work_size), ((cudaDataType)__pyx_v_etype));
        }

        /* "cupy/cuda/cufft.pyx":1049
 *             work_size = 0
 *         else:
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftXtMakePlanMany(
 *                     plan, ndim, shape_ptr,
*/
        /*finally:*/ {
          /*normal exit:*/{
            __Pyx_FastGIL_Forget();
            Py_BLOCK_THREADS
            goto __pyx_L24;
          }
          __pyx_L24:;
        }
    }

    /* "cupy/cuda/cufft.pyx":1057
 * 
 *             # cufftMakePlanMany could use a large amount of memory
 *             if result == 2:             # <<<<<<<<<<<<<<
 *                 cupy.get_default_memory_pool().free_all_blocks()
 *                 with nogil:
*/
    __pyx_t_3 = (__pyx_v_result == 2);
    if (__pyx_t_3) {

      /* "cupy/cuda/cufft.pyx":1058
 *             # cufftMakePlanMany could use a large amount of memory
 *             if result == 2:
 *                 cupy.get_default_memory_pool().free_all_blocks()             # <<<<<<<<<<<<<<
 *                 with nogil:
 *                     result = cufftXtMakePlanMany(
*/
      __pyx_t_16 = NULL;
      __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_cupy); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1058, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __pyx_t_15 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_get_default_memory_pool); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 1058, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_15);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __pyx_t_7 = 1;
      #if CYTHON_UNPACK_METHODS
      if (unlikely(PyMethod_Check(__pyx_t_15))) {
        __pyx_t_16 = PyMethod_GET_SELF(__pyx_t_15);
        assert(__pyx_t_16);
        PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_15);
        __Pyx_INCREF(__pyx_t_16);
        __Pyx_INCREF(__pyx__function);
        __Pyx_DECREF_SET(__pyx_t_15, __pyx__function);
        __pyx_t_7 = 0;
      }
      #endif
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_16, NULL};
        __pyx_t_5 = __Pyx_PyObject_FastCall(__pyx_t_15, __pyx_callargs+__pyx_t_7, (1-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_16); __pyx_t_16 = 0;
        __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
        if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1058, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_5);
      }
      __pyx_t_18 = __pyx_t_5;
      __Pyx_INCREF(__pyx_t_18);
      __pyx_t_7 = 0;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_18, NULL};
        __pyx_t_17 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_free_all_blocks, __pyx_callargs+__pyx_t_7, (1-__pyx_t_7) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_18); __pyx_t_18 = 0;
        __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
        if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 1058, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_17);
      }
      __Pyx_DECREF(__pyx_t_17); __pyx_t_17 = 0;

      /* "cupy/cuda/cufft.pyx":1059
 *             if result == 2:
 *                 cupy.get_default_memory_pool().free_all_blocks()
 *                 with nogil:             # <<<<<<<<<<<<<<
 *                     result = cufftXtMakePlanMany(
 *                         plan, ndim, shape_ptr,
*/
      {
          PyThreadState *_save;
          _save = NULL;
          Py_UNBLOCK_THREADS
          __Pyx_FastGIL_Remember();
          /*try:*/ {

            /* "cupy/cuda/cufft.pyx":1060
 *                 cupy.get_default_memory_pool().free_all_blocks()
 *                 with nogil:
 *                     result = cufftXtMakePlanMany(             # <<<<<<<<<<<<<<
 *                         plan, ndim, shape_ptr,
 *                         inembed_ptr, istride, idist, <DataType>itype,
*/
            __pyx_v_result = cufftXtMakePlanMany(__pyx_v_plan, __pyx_v_ndim, __pyx_v_shape_ptr, __pyx_v_inembed_ptr, __pyx_v_istride, __pyx_v_idist, ((cudaDataType)__pyx_v_itype), __pyx_v_onembed_ptr, __pyx_v_ostride, __pyx_v_odist, ((cudaDataType)__pyx_v_otype), __pyx_v_batch, (&__pyx_v_work_size), ((cudaDataType)__pyx_v_etype));
          }

          /* "cupy/cuda/cufft.pyx":1059
 *             if result == 2:
 *                 cupy.get_default_memory_pool().free_all_blocks()
 *                 with nogil:             # <<<<<<<<<<<<<<
 *                     result = cufftXtMakePlanMany(
 *                         plan, ndim, shape_ptr,
*/
          /*finally:*/ {
            /*normal exit:*/{
              __Pyx_FastGIL_Forget();
              Py_BLOCK_THREADS
              goto __pyx_L28;
            }
            __pyx_L28:;
          }
      }

      /* "cupy/cuda/cufft.pyx":1057
 * 
 *             # cufftMakePlanMany could use a large amount of memory
 *             if result == 2:             # <<<<<<<<<<<<<<
 *                 cupy.get_default_memory_pool().free_all_blocks()
 *                 with nogil:
*/
    }

    /* "cupy/cuda/cufft.pyx":1065
 *                         onembed_ptr, ostride, odist, <DataType>otype,
 *                         batch, &work_size, <DataType>etype)
 *             check_result(result)             # <<<<<<<<<<<<<<
 * 
 *         work_area = memory.alloc(work_size)
*/
    __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1065, __pyx_L1_error)
  }
  __pyx_L21:;

  /* "cupy/cuda/cufft.pyx":1067
 *             check_result(result)
 * 
 *         work_area = memory.alloc(work_size)             # <<<<<<<<<<<<<<
 *         cdef intptr_t ptr = <intptr_t>(work_area.ptr)
 *         with nogil:
*/
  __pyx_t_5 = NULL;
  __Pyx_GetModuleGlobalName(__pyx_t_18, __pyx_mstate_global->__pyx_n_u_memory); if (unlikely(!__pyx_t_18)) __PYX_ERR(0, 1067, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_18);
  __pyx_t_15 = __Pyx_PyObject_GetAttrStr(__pyx_t_18, __pyx_mstate_global->__pyx_n_u_alloc); if (unlikely(!__pyx_t_15)) __PYX_ERR(0, 1067, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_15);
  __Pyx_DECREF(__pyx_t_18); __pyx_t_18 = 0;
  __pyx_t_18 = __Pyx_PyLong_FromSize_t(__pyx_v_work_size); if (unlikely(!__pyx_t_18)) __PYX_ERR(0, 1067, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_18);
  __pyx_t_7 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_15))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_15);
    assert(__pyx_t_5);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_15);
    __Pyx_INCREF(__pyx_t_5);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_15, __pyx__function);
    __pyx_t_7 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_5, __pyx_t_18};
    __pyx_t_17 = __Pyx_PyObject_FastCall(__pyx_t_15, __pyx_callargs+__pyx_t_7, (2-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_18); __pyx_t_18 = 0;
    __Pyx_DECREF(__pyx_t_15); __pyx_t_15 = 0;
    if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 1067, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_17);
  }
  __pyx_v_work_area = __pyx_t_17;
  __pyx_t_17 = 0;

  /* "cupy/cuda/cufft.pyx":1068
 * 
 *         work_area = memory.alloc(work_size)
 *         cdef intptr_t ptr = <intptr_t>(work_area.ptr)             # <<<<<<<<<<<<<<
 *         with nogil:
 *             result = cufftSetWorkArea(plan, <void*>(ptr))
*/
  __pyx_t_17 = __Pyx_PyObject_GetAttrStr(__pyx_v_work_area, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 1068, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_17);
  __pyx_t_19 = PyLong_AsSsize_t(__pyx_t_17); if (unlikely((__pyx_t_19 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1068, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_17); __pyx_t_17 = 0;
  __pyx_v_ptr = ((intptr_t)__pyx_t_19);

  /* "cupy/cuda/cufft.pyx":1069
 *         work_area = memory.alloc(work_size)
 *         cdef intptr_t ptr = <intptr_t>(work_area.ptr)
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftSetWorkArea(plan, <void*>(ptr))
 *         check_result(result)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":1070
 *         cdef intptr_t ptr = <intptr_t>(work_area.ptr)
 *         with nogil:
 *             result = cufftSetWorkArea(plan, <void*>(ptr))             # <<<<<<<<<<<<<<
 *         check_result(result)
 * 
*/
        __pyx_v_result = cufftSetWorkArea(__pyx_v_plan, ((void *)__pyx_v_ptr));
      }

      /* "cupy/cuda/cufft.pyx":1069
 *         work_area = memory.alloc(work_size)
 *         cdef intptr_t ptr = <intptr_t>(work_area.ptr)
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftSetWorkArea(plan, <void*>(ptr))
 *         check_result(result)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L31;
        }
        __pyx_L31:;
      }
  }

  /* "cupy/cuda/cufft.pyx":1071
 *         with nogil:
 *             result = cufftSetWorkArea(plan, <void*>(ptr))
 *         check_result(result)             # <<<<<<<<<<<<<<
 * 
 *         self.shape = tuple(shape)
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1071, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1073
 *         check_result(result)
 * 
 *         self.shape = tuple(shape)             # <<<<<<<<<<<<<<
 *         self.itype = itype
 *         self.otype = otype
*/
  __pyx_t_17 = __Pyx_PySequence_Tuple(__pyx_v_shape); if (unlikely(!__pyx_t_17)) __PYX_ERR(0, 1073, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_17);
  __Pyx_GIVEREF(__pyx_t_17);
  __Pyx_GOTREF(__pyx_v_self->shape);
  __Pyx_DECREF(__pyx_v_self->shape);
  __pyx_v_self->shape = ((PyObject*)__pyx_t_17);
  __pyx_t_17 = 0;

  /* "cupy/cuda/cufft.pyx":1074
 * 
 *         self.shape = tuple(shape)
 *         self.itype = itype             # <<<<<<<<<<<<<<
 *         self.otype = otype
 *         self.etype = etype
*/
  __pyx_v_self->itype = __pyx_v_itype;

  /* "cupy/cuda/cufft.pyx":1075
 *         self.shape = tuple(shape)
 *         self.itype = itype
 *         self.otype = otype             # <<<<<<<<<<<<<<
 *         self.etype = etype
 *         self.work_area = work_area
*/
  __pyx_v_self->otype = __pyx_v_otype;

  /* "cupy/cuda/cufft.pyx":1076
 *         self.itype = itype
 *         self.otype = otype
 *         self.etype = etype             # <<<<<<<<<<<<<<
 *         self.work_area = work_area
 *         self.order = order  # either 'C' or 'F'
*/
  __pyx_v_self->etype = __pyx_v_etype;

  /* "cupy/cuda/cufft.pyx":1077
 *         self.otype = otype
 *         self.etype = etype
 *         self.work_area = work_area             # <<<<<<<<<<<<<<
 *         self.order = order  # either 'C' or 'F'
 *         self.last_axis = last_axis  # ignored for C2C
*/
  __Pyx_INCREF(__pyx_v_work_area);
  __Pyx_GIVEREF(__pyx_v_work_area);
  __Pyx_GOTREF(__pyx_v_self->work_area);
  __Pyx_DECREF(__pyx_v_self->work_area);
  __pyx_v_self->work_area = __pyx_v_work_area;

  /* "cupy/cuda/cufft.pyx":1078
 *         self.etype = etype
 *         self.work_area = work_area
 *         self.order = order  # either 'C' or 'F'             # <<<<<<<<<<<<<<
 *         self.last_axis = last_axis  # ignored for C2C
 *         self.last_size = last_size  # = None (and ignored) for C2C
*/
  __Pyx_INCREF(__pyx_v_order);
  __Pyx_GIVEREF(__pyx_v_order);
  __Pyx_GOTREF(__pyx_v_self->order);
  __Pyx_DECREF(__pyx_v_self->order);
  __pyx_v_self->order = __pyx_v_order;

  /* "cupy/cuda/cufft.pyx":1079
 *         self.work_area = work_area
 *         self.order = order  # either 'C' or 'F'
 *         self.last_axis = last_axis  # ignored for C2C             # <<<<<<<<<<<<<<
 *         self.last_size = last_size  # = None (and ignored) for C2C
 * 
*/
  __pyx_v_self->last_axis = __pyx_v_last_axis;

  /* "cupy/cuda/cufft.pyx":1080
 *         self.order = order  # either 'C' or 'F'
 *         self.last_axis = last_axis  # ignored for C2C
 *         self.last_size = last_size  # = None (and ignored) for C2C             # <<<<<<<<<<<<<<
 * 
 *     def __dealloc__(self):
*/
  __Pyx_INCREF(__pyx_v_last_size);
  __Pyx_GIVEREF(__pyx_v_last_size);
  __Pyx_GOTREF(__pyx_v_self->last_size);
  __Pyx_DECREF(__pyx_v_self->last_size);
  __pyx_v_self->last_size = __pyx_v_last_size;

  /* "cupy/cuda/cufft.pyx":983
 * # TODO(leofang): support cufftXtSetGPUs?
 * cdef class XtPlanNd:
 *     def __init__(self, shape,             # <<<<<<<<<<<<<<
 *                  inembed, long long int istride, long long int idist, idtype,
 *                  onembed, long long int ostride, long long int odist, odtype,
*/

  /* function exit code */
  __pyx_r = 0;
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_15);
  __Pyx_XDECREF(__pyx_t_16);
  __Pyx_XDECREF(__pyx_t_17);
  __Pyx_XDECREF(__pyx_t_18);
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.__init__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_to_cuda_dtype);
  __Pyx_XDECREF(__pyx_v_work_area);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1082
 *         self.last_size = last_size  # = None (and ignored) for C2C
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         cdef Handle plan = <Handle>self.handle
 *         cdef int result
*/

/* Python wrapper */
static void __pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_3__dealloc__(PyObject *__pyx_v_self); /*proto*/
static void __pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_3__dealloc__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__dealloc__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_2__dealloc__(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
}

static void __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_2__dealloc__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self) {
  cufftHandle __pyx_v_plan;
  int __pyx_v_result;
  int __pyx_t_1;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;

  /* "cupy/cuda/cufft.pyx":1083
 * 
 *     def __dealloc__(self):
 *         cdef Handle plan = <Handle>self.handle             # <<<<<<<<<<<<<<
 *         cdef int result
 * 
*/
  __pyx_v_plan = ((cufftHandle)__pyx_v_self->handle);

  /* "cupy/cuda/cufft.pyx":1086
 *         cdef int result
 * 
 *         if plan != <Handle>0:             # <<<<<<<<<<<<<<
 *             with nogil:
 *                 result = cufftDestroy(plan)
*/
  __pyx_t_1 = (__pyx_v_plan != ((cufftHandle)0));
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":1087
 * 
 *         if plan != <Handle>0:
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftDestroy(plan)
 *             check_result(result)
*/
    {
        PyThreadState *_save;
        _save = NULL;
        Py_UNBLOCK_THREADS
        __Pyx_FastGIL_Remember();
        /*try:*/ {

          /* "cupy/cuda/cufft.pyx":1088
 *         if plan != <Handle>0:
 *             with nogil:
 *                 result = cufftDestroy(plan)             # <<<<<<<<<<<<<<
 *             check_result(result)
 *             self.handle = <intptr_t>0
*/
          __pyx_v_result = cufftDestroy(__pyx_v_plan);
        }

        /* "cupy/cuda/cufft.pyx":1087
 * 
 *         if plan != <Handle>0:
 *             with nogil:             # <<<<<<<<<<<<<<
 *                 result = cufftDestroy(plan)
 *             check_result(result)
*/
        /*finally:*/ {
          /*normal exit:*/{
            __Pyx_FastGIL_Forget();
            Py_BLOCK_THREADS
            goto __pyx_L6;
          }
          __pyx_L6:;
        }
    }

    /* "cupy/cuda/cufft.pyx":1089
 *             with nogil:
 *                 result = cufftDestroy(plan)
 *             check_result(result)             # <<<<<<<<<<<<<<
 *             self.handle = <intptr_t>0
 * 
*/
    __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1089, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":1090
 *                 result = cufftDestroy(plan)
 *             check_result(result)
 *             self.handle = <intptr_t>0             # <<<<<<<<<<<<<<
 * 
 *     def __enter__(self):
*/
    __pyx_v_self->handle = ((intptr_t)0);

    /* "cupy/cuda/cufft.pyx":1086
 *         cdef int result
 * 
 *         if plan != <Handle>0:             # <<<<<<<<<<<<<<
 *             with nogil:
 *                 result = cufftDestroy(plan)
*/
  }

  /* "cupy/cuda/cufft.pyx":1082
 *         self.last_size = last_size  # = None (and ignored) for C2C
 * 
 *     def __dealloc__(self):             # <<<<<<<<<<<<<<
 *         cdef Handle plan = <Handle>self.handle
 *         cdef int result
*/

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_WriteUnraisable("cupy.cuda.cufft.XtPlanNd.__dealloc__", __pyx_clineno, __pyx_lineno, __pyx_filename, 1, 0);
  __pyx_L0:;
}

/* "cupy/cuda/cufft.pyx":1092
 *             self.handle = <intptr_t>0
 * 
 *     def __enter__(self):             # <<<<<<<<<<<<<<
 *         _thread_local._current_plan = self
 *         return self
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5__enter__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_8XtPlanNd_4__enter__, "XtPlanNd.__enter__(self)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5__enter__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__enter__ (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  if (unlikely(__pyx_nargs > 0)) { __Pyx_RaiseArgtupleInvalid("__enter__", 1, 0, 0, __pyx_nargs); return NULL; }
  const Py_ssize_t __pyx_kwds_len = unlikely(__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
  if (unlikely(__pyx_kwds_len < 0)) return NULL;
  if (unlikely(__pyx_kwds_len > 0)) {__Pyx_RejectKeywords("__enter__", __pyx_kwds); return NULL;}
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_4__enter__(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_4__enter__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__enter__", 0);

  /* "cupy/cuda/cufft.pyx":1093
 * 
 *     def __enter__(self):
 *         _thread_local._current_plan = self             # <<<<<<<<<<<<<<
 *         return self
 * 
*/
  if (__Pyx_PyObject_SetAttrStr(__pyx_v_4cupy_4cuda_5cufft__thread_local, __pyx_mstate_global->__pyx_n_u_current_plan, ((PyObject *)__pyx_v_self)) < (0)) __PYX_ERR(0, 1093, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1094
 *     def __enter__(self):
 *         _thread_local._current_plan = self
 *         return self             # <<<<<<<<<<<<<<
 * 
 *     def __exit__(self, exc_type, exc_value, traceback):
*/
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF((PyObject *)__pyx_v_self);
  __pyx_r = ((PyObject *)__pyx_v_self);
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":1092
 *             self.handle = <intptr_t>0
 * 
 *     def __enter__(self):             # <<<<<<<<<<<<<<
 *         _thread_local._current_plan = self
 *         return self
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.__enter__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1096
 *         return self
 * 
 *     def __exit__(self, exc_type, exc_value, traceback):             # <<<<<<<<<<<<<<
 *         _thread_local._current_plan = None
 * 
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_7__exit__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_8XtPlanNd_6__exit__, "XtPlanNd.__exit__(self, exc_type, exc_value, traceback)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_7__exit__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  CYTHON_UNUSED PyObject *__pyx_v_exc_type = 0;
  CYTHON_UNUSED PyObject *__pyx_v_exc_value = 0;
  CYTHON_UNUSED PyObject *__pyx_v_traceback = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__exit__ (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_exc_type,&__pyx_mstate_global->__pyx_n_u_exc_value,&__pyx_mstate_global->__pyx_n_u_traceback,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1096, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1096, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1096, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1096, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "__exit__", 0) < (0)) __PYX_ERR(0, 1096, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("__exit__", 1, 3, 3, i); __PYX_ERR(0, 1096, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1096, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1096, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1096, __pyx_L3_error)
    }
    __pyx_v_exc_type = values[0];
    __pyx_v_exc_value = values[1];
    __pyx_v_traceback = values[2];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__exit__", 1, 3, 3, __pyx_nargs); __PYX_ERR(0, 1096, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.__exit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_6__exit__(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self), __pyx_v_exc_type, __pyx_v_exc_value, __pyx_v_traceback);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_6__exit__(CYTHON_UNUSED struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self, CYTHON_UNUSED PyObject *__pyx_v_exc_type, CYTHON_UNUSED PyObject *__pyx_v_exc_value, CYTHON_UNUSED PyObject *__pyx_v_traceback) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__exit__", 0);

  /* "cupy/cuda/cufft.pyx":1097
 * 
 *     def __exit__(self, exc_type, exc_value, traceback):
 *         _thread_local._current_plan = None             # <<<<<<<<<<<<<<
 * 
 *     def fft(self, a, out, direction):
*/
  if (__Pyx_PyObject_SetAttrStr(__pyx_v_4cupy_4cuda_5cufft__thread_local, __pyx_mstate_global->__pyx_n_u_current_plan, Py_None) < (0)) __PYX_ERR(0, 1097, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1096
 *         return self
 * 
 *     def __exit__(self, exc_type, exc_value, traceback):             # <<<<<<<<<<<<<<
 *         _thread_local._current_plan = None
 * 
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.__exit__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1099
 *         _thread_local._current_plan = None
 * 
 *     def fft(self, a, out, direction):             # <<<<<<<<<<<<<<
 *         cdef intptr_t plan = self.handle
 *         cdef intptr_t s = stream.get_current_stream().ptr
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_9fft(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_8XtPlanNd_8fft, "XtPlanNd.fft(self, a, out, direction)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_9fft(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_a = 0;
  PyObject *__pyx_v_out = 0;
  PyObject *__pyx_v_direction = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("fft (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_a,&__pyx_mstate_global->__pyx_n_u_out,&__pyx_mstate_global->__pyx_n_u_direction,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1099, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1099, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1099, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1099, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "fft", 0) < (0)) __PYX_ERR(0, 1099, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("fft", 1, 3, 3, i); __PYX_ERR(0, 1099, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1099, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1099, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1099, __pyx_L3_error)
    }
    __pyx_v_a = values[0];
    __pyx_v_out = values[1];
    __pyx_v_direction = values[2];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("fft", 1, 3, 3, __pyx_nargs); __PYX_ERR(0, 1099, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.fft", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_8fft(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self), __pyx_v_a, __pyx_v_out, __pyx_v_direction);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_8fft(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_out, PyObject *__pyx_v_direction) {
  intptr_t __pyx_v_plan;
  intptr_t __pyx_v_s;
  int __pyx_v_result;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  intptr_t __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  size_t __pyx_t_6;
  intptr_t __pyx_t_7;
  int __pyx_t_8;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("fft", 0);

  /* "cupy/cuda/cufft.pyx":1100
 * 
 *     def fft(self, a, out, direction):
 *         cdef intptr_t plan = self.handle             # <<<<<<<<<<<<<<
 *         cdef intptr_t s = stream.get_current_stream().ptr
 *         cdef int result
*/
  __pyx_t_1 = __pyx_v_self->handle;
  __pyx_v_plan = __pyx_t_1;

  /* "cupy/cuda/cufft.pyx":1101
 *     def fft(self, a, out, direction):
 *         cdef intptr_t plan = self.handle
 *         cdef intptr_t s = stream.get_current_stream().ptr             # <<<<<<<<<<<<<<
 *         cdef int result
 * 
*/
  __pyx_t_3 = NULL;
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_stream); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1101, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_get_current_stream); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1101, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_6 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_3 = PyMethod_GET_SELF(__pyx_t_5);
    assert(__pyx_t_3);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_5);
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_5, __pyx__function);
    __pyx_t_6 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, NULL};
    __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_5, __pyx_callargs+__pyx_t_6, (1-__pyx_t_6) | (__pyx_t_6*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1101, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
  }
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1101, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_1 = PyLong_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_1 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1101, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_s = __pyx_t_1;

  /* "cupy/cuda/cufft.pyx":1104
 *         cdef int result
 * 
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftSetStream(<Handle>plan, <Stream>s)
 *         check_result(result)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":1105
 * 
 *         with nogil:
 *             result = cufftSetStream(<Handle>plan, <Stream>s)             # <<<<<<<<<<<<<<
 *         check_result(result)
 *         XtExec(plan, a.data.ptr, out.data.ptr, direction)
*/
        __pyx_v_result = cufftSetStream(((cufftHandle)__pyx_v_plan), ((cudaStream_t)__pyx_v_s));
      }

      /* "cupy/cuda/cufft.pyx":1104
 *         cdef int result
 * 
 *         with nogil:             # <<<<<<<<<<<<<<
 *             result = cufftSetStream(<Handle>plan, <Stream>s)
 *         check_result(result)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "cupy/cuda/cufft.pyx":1106
 *         with nogil:
 *             result = cufftSetStream(<Handle>plan, <Stream>s)
 *         check_result(result)             # <<<<<<<<<<<<<<
 *         XtExec(plan, a.data.ptr, out.data.ptr, direction)
 * 
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1106, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1107
 *             result = cufftSetStream(<Handle>plan, <Stream>s)
 *         check_result(result)
 *         XtExec(plan, a.data.ptr, out.data.ptr, direction)             # <<<<<<<<<<<<<<
 * 
 *     def _sanity_checks(self, int itype, int otype, int etype,
*/
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1107, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1107, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_1 = PyLong_AsSsize_t(__pyx_t_2); if (unlikely((__pyx_t_1 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1107, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_out, __pyx_mstate_global->__pyx_n_u_data); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1107, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_ptr); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1107, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_7 = PyLong_AsSsize_t(__pyx_t_5); if (unlikely((__pyx_t_7 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1107, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_8 = __Pyx_PyLong_As_int(__pyx_v_direction); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1107, __pyx_L1_error)
  __pyx_t_5 = __pyx_f_4cupy_4cuda_5cufft_XtExec(__pyx_v_plan, __pyx_t_1, __pyx_t_7, __pyx_t_8, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1107, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;

  /* "cupy/cuda/cufft.pyx":1099
 *         _thread_local._current_plan = None
 * 
 *     def fft(self, a, out, direction):             # <<<<<<<<<<<<<<
 *         cdef intptr_t plan = self.handle
 *         cdef intptr_t s = stream.get_current_stream().ptr
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.fft", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1109
 *         XtExec(plan, a.data.ptr, out.data.ptr, direction)
 * 
 *     def _sanity_checks(self, int itype, int otype, int etype,             # <<<<<<<<<<<<<<
 *                        long long int last_size, long long int full_size):
 *         # not every possible type combination is legit
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_11_sanity_checks(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_8XtPlanNd_10_sanity_checks, "XtPlanNd._sanity_checks(self, int itype, int otype, int etype, long long last_size, long long full_size)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_11_sanity_checks(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  int __pyx_v_itype;
  int __pyx_v_otype;
  int __pyx_v_etype;
  PY_LONG_LONG __pyx_v_last_size;
  PY_LONG_LONG __pyx_v_full_size;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[5] = {0,0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_sanity_checks (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_itype,&__pyx_mstate_global->__pyx_n_u_otype,&__pyx_mstate_global->__pyx_n_u_etype,&__pyx_mstate_global->__pyx_n_u_last_size,&__pyx_mstate_global->__pyx_n_u_full_size,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1109, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  5:
        values[4] = __Pyx_ArgRef_FASTCALL(__pyx_args, 4);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[4])) __PYX_ERR(0, 1109, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  4:
        values[3] = __Pyx_ArgRef_FASTCALL(__pyx_args, 3);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 1109, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1109, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1109, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1109, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "_sanity_checks", 0) < (0)) __PYX_ERR(0, 1109, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 5; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("_sanity_checks", 1, 5, 5, i); __PYX_ERR(0, 1109, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 5)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1109, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1109, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1109, __pyx_L3_error)
      values[3] = __Pyx_ArgRef_FASTCALL(__pyx_args, 3);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 1109, __pyx_L3_error)
      values[4] = __Pyx_ArgRef_FASTCALL(__pyx_args, 4);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[4])) __PYX_ERR(0, 1109, __pyx_L3_error)
    }
    __pyx_v_itype = __Pyx_PyLong_As_int(values[0]); if (unlikely((__pyx_v_itype == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1109, __pyx_L3_error)
    __pyx_v_otype = __Pyx_PyLong_As_int(values[1]); if (unlikely((__pyx_v_otype == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1109, __pyx_L3_error)
    __pyx_v_etype = __Pyx_PyLong_As_int(values[2]); if (unlikely((__pyx_v_etype == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1109, __pyx_L3_error)
    __pyx_v_last_size = __Pyx_PyLong_As_PY_LONG_LONG(values[3]); if (unlikely((__pyx_v_last_size == (PY_LONG_LONG)-1) && PyErr_Occurred())) __PYX_ERR(0, 1110, __pyx_L3_error)
    __pyx_v_full_size = __Pyx_PyLong_As_PY_LONG_LONG(values[4]); if (unlikely((__pyx_v_full_size == (PY_LONG_LONG)-1) && PyErr_Occurred())) __PYX_ERR(0, 1110, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_sanity_checks", 1, 5, 5, __pyx_nargs); __PYX_ERR(0, 1109, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd._sanity_checks", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_10_sanity_checks(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self), __pyx_v_itype, __pyx_v_otype, __pyx_v_etype, __pyx_v_last_size, __pyx_v_full_size);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_10_sanity_checks(CYTHON_UNUSED struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self, int __pyx_v_itype, int __pyx_v_otype, int __pyx_v_etype, PY_LONG_LONG __pyx_v_last_size, PY_LONG_LONG __pyx_v_full_size) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  int __pyx_t_5;
  PyObject *__pyx_t_6 = NULL;
  size_t __pyx_t_7;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_sanity_checks", 0);

  /* "cupy/cuda/cufft.pyx":1114
 *         # TODO(leofang): support bf16?
 *         # C2C
 *         if itype == runtime.CUDA_C_16F and otype == runtime.CUDA_C_16F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_16F
 *         elif itype == runtime.CUDA_C_32F and otype == runtime.CUDA_C_32F:
*/
  __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_v_itype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_CUDA_C_16F); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_2, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1114, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1114, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_5) {
  } else {
    __pyx_t_1 = __pyx_t_5;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyLong_From_int(__pyx_v_otype); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_CUDA_C_16F); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1114, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = PyObject_RichCompare(__pyx_t_3, __pyx_t_2, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1114, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1114, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_1 = __pyx_t_5;
  __pyx_L4_bool_binop_done:;
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":1115
 *         # C2C
 *         if itype == runtime.CUDA_C_16F and otype == runtime.CUDA_C_16F:
 *             assert etype == runtime.CUDA_C_16F             # <<<<<<<<<<<<<<
 *         elif itype == runtime.CUDA_C_32F and otype == runtime.CUDA_C_32F:
 *             assert etype == runtime.CUDA_C_32F
*/
    #ifndef CYTHON_WITHOUT_ASSERTIONS
    if (unlikely(__pyx_assertions_enabled())) {
      __pyx_t_4 = __Pyx_PyLong_From_int(__pyx_v_etype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1115, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1115, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_CUDA_C_16F); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1115, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyObject_RichCompare(__pyx_t_4, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1115, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 1115, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (unlikely(!__pyx_t_1)) {
        __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
        __PYX_ERR(0, 1115, __pyx_L1_error)
      }
    }
    #else
    if ((1)); else __PYX_ERR(0, 1115, __pyx_L1_error)
    #endif

    /* "cupy/cuda/cufft.pyx":1114
 *         # TODO(leofang): support bf16?
 *         # C2C
 *         if itype == runtime.CUDA_C_16F and otype == runtime.CUDA_C_16F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_16F
 *         elif itype == runtime.CUDA_C_32F and otype == runtime.CUDA_C_32F:
*/
    goto __pyx_L3;
  }

  /* "cupy/cuda/cufft.pyx":1116
 *         if itype == runtime.CUDA_C_16F and otype == runtime.CUDA_C_16F:
 *             assert etype == runtime.CUDA_C_16F
 *         elif itype == runtime.CUDA_C_32F and otype == runtime.CUDA_C_32F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_32F
 *         elif itype == runtime.CUDA_C_64F and otype == runtime.CUDA_C_64F:
*/
  __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_v_itype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1116, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1116, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_CUDA_C_32F); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1116, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_2, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1116, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1116, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_5) {
  } else {
    __pyx_t_1 = __pyx_t_5;
    goto __pyx_L6_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyLong_From_int(__pyx_v_otype); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1116, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1116, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_CUDA_C_32F); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1116, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = PyObject_RichCompare(__pyx_t_3, __pyx_t_2, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1116, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1116, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_1 = __pyx_t_5;
  __pyx_L6_bool_binop_done:;
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":1117
 *             assert etype == runtime.CUDA_C_16F
 *         elif itype == runtime.CUDA_C_32F and otype == runtime.CUDA_C_32F:
 *             assert etype == runtime.CUDA_C_32F             # <<<<<<<<<<<<<<
 *         elif itype == runtime.CUDA_C_64F and otype == runtime.CUDA_C_64F:
 *             assert etype == runtime.CUDA_C_64F
*/
    #ifndef CYTHON_WITHOUT_ASSERTIONS
    if (unlikely(__pyx_assertions_enabled())) {
      __pyx_t_4 = __Pyx_PyLong_From_int(__pyx_v_etype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1117, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1117, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_CUDA_C_32F); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1117, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyObject_RichCompare(__pyx_t_4, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1117, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 1117, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (unlikely(!__pyx_t_1)) {
        __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
        __PYX_ERR(0, 1117, __pyx_L1_error)
      }
    }
    #else
    if ((1)); else __PYX_ERR(0, 1117, __pyx_L1_error)
    #endif

    /* "cupy/cuda/cufft.pyx":1116
 *         if itype == runtime.CUDA_C_16F and otype == runtime.CUDA_C_16F:
 *             assert etype == runtime.CUDA_C_16F
 *         elif itype == runtime.CUDA_C_32F and otype == runtime.CUDA_C_32F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_32F
 *         elif itype == runtime.CUDA_C_64F and otype == runtime.CUDA_C_64F:
*/
    goto __pyx_L3;
  }

  /* "cupy/cuda/cufft.pyx":1118
 *         elif itype == runtime.CUDA_C_32F and otype == runtime.CUDA_C_32F:
 *             assert etype == runtime.CUDA_C_32F
 *         elif itype == runtime.CUDA_C_64F and otype == runtime.CUDA_C_64F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_64F
 *         # C2R
*/
  __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_v_itype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1118, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1118, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_CUDA_C_64F); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1118, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_2, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1118, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1118, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_5) {
  } else {
    __pyx_t_1 = __pyx_t_5;
    goto __pyx_L8_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyLong_From_int(__pyx_v_otype); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1118, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1118, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_CUDA_C_64F); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1118, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = PyObject_RichCompare(__pyx_t_3, __pyx_t_2, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1118, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1118, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_1 = __pyx_t_5;
  __pyx_L8_bool_binop_done:;
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":1119
 *             assert etype == runtime.CUDA_C_32F
 *         elif itype == runtime.CUDA_C_64F and otype == runtime.CUDA_C_64F:
 *             assert etype == runtime.CUDA_C_64F             # <<<<<<<<<<<<<<
 *         # C2R
 *         elif itype == runtime.CUDA_C_16F and otype == runtime.CUDA_R_16F:
*/
    #ifndef CYTHON_WITHOUT_ASSERTIONS
    if (unlikely(__pyx_assertions_enabled())) {
      __pyx_t_4 = __Pyx_PyLong_From_int(__pyx_v_etype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1119, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1119, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_CUDA_C_64F); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1119, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyObject_RichCompare(__pyx_t_4, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1119, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 1119, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (unlikely(!__pyx_t_1)) {
        __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
        __PYX_ERR(0, 1119, __pyx_L1_error)
      }
    }
    #else
    if ((1)); else __PYX_ERR(0, 1119, __pyx_L1_error)
    #endif

    /* "cupy/cuda/cufft.pyx":1118
 *         elif itype == runtime.CUDA_C_32F and otype == runtime.CUDA_C_32F:
 *             assert etype == runtime.CUDA_C_32F
 *         elif itype == runtime.CUDA_C_64F and otype == runtime.CUDA_C_64F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_64F
 *         # C2R
*/
    goto __pyx_L3;
  }

  /* "cupy/cuda/cufft.pyx":1121
 *             assert etype == runtime.CUDA_C_64F
 *         # C2R
 *         elif itype == runtime.CUDA_C_16F and otype == runtime.CUDA_R_16F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_16F
 *         elif itype == runtime.CUDA_C_32F and otype == runtime.CUDA_R_32F:
*/
  __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_v_itype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1121, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1121, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_CUDA_C_16F); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1121, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_2, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1121, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1121, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_5) {
  } else {
    __pyx_t_1 = __pyx_t_5;
    goto __pyx_L10_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyLong_From_int(__pyx_v_otype); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1121, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1121, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_CUDA_R_16F); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1121, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = PyObject_RichCompare(__pyx_t_3, __pyx_t_2, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1121, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1121, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_1 = __pyx_t_5;
  __pyx_L10_bool_binop_done:;
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":1122
 *         # C2R
 *         elif itype == runtime.CUDA_C_16F and otype == runtime.CUDA_R_16F:
 *             assert etype == runtime.CUDA_C_16F             # <<<<<<<<<<<<<<
 *         elif itype == runtime.CUDA_C_32F and otype == runtime.CUDA_R_32F:
 *             assert etype == runtime.CUDA_C_32F
*/
    #ifndef CYTHON_WITHOUT_ASSERTIONS
    if (unlikely(__pyx_assertions_enabled())) {
      __pyx_t_4 = __Pyx_PyLong_From_int(__pyx_v_etype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1122, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1122, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_CUDA_C_16F); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1122, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyObject_RichCompare(__pyx_t_4, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1122, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 1122, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (unlikely(!__pyx_t_1)) {
        __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
        __PYX_ERR(0, 1122, __pyx_L1_error)
      }
    }
    #else
    if ((1)); else __PYX_ERR(0, 1122, __pyx_L1_error)
    #endif

    /* "cupy/cuda/cufft.pyx":1121
 *             assert etype == runtime.CUDA_C_64F
 *         # C2R
 *         elif itype == runtime.CUDA_C_16F and otype == runtime.CUDA_R_16F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_16F
 *         elif itype == runtime.CUDA_C_32F and otype == runtime.CUDA_R_32F:
*/
    goto __pyx_L3;
  }

  /* "cupy/cuda/cufft.pyx":1123
 *         elif itype == runtime.CUDA_C_16F and otype == runtime.CUDA_R_16F:
 *             assert etype == runtime.CUDA_C_16F
 *         elif itype == runtime.CUDA_C_32F and otype == runtime.CUDA_R_32F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_32F
 *         elif itype == runtime.CUDA_C_64F and otype == runtime.CUDA_R_64F:
*/
  __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_v_itype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1123, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1123, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_CUDA_C_32F); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1123, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_2, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1123, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1123, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_5) {
  } else {
    __pyx_t_1 = __pyx_t_5;
    goto __pyx_L12_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyLong_From_int(__pyx_v_otype); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1123, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1123, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_CUDA_R_32F); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1123, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = PyObject_RichCompare(__pyx_t_3, __pyx_t_2, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1123, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1123, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_1 = __pyx_t_5;
  __pyx_L12_bool_binop_done:;
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":1124
 *             assert etype == runtime.CUDA_C_16F
 *         elif itype == runtime.CUDA_C_32F and otype == runtime.CUDA_R_32F:
 *             assert etype == runtime.CUDA_C_32F             # <<<<<<<<<<<<<<
 *         elif itype == runtime.CUDA_C_64F and otype == runtime.CUDA_R_64F:
 *             assert etype == runtime.CUDA_C_64F
*/
    #ifndef CYTHON_WITHOUT_ASSERTIONS
    if (unlikely(__pyx_assertions_enabled())) {
      __pyx_t_4 = __Pyx_PyLong_From_int(__pyx_v_etype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1124, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1124, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_CUDA_C_32F); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1124, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyObject_RichCompare(__pyx_t_4, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1124, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 1124, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (unlikely(!__pyx_t_1)) {
        __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
        __PYX_ERR(0, 1124, __pyx_L1_error)
      }
    }
    #else
    if ((1)); else __PYX_ERR(0, 1124, __pyx_L1_error)
    #endif

    /* "cupy/cuda/cufft.pyx":1123
 *         elif itype == runtime.CUDA_C_16F and otype == runtime.CUDA_R_16F:
 *             assert etype == runtime.CUDA_C_16F
 *         elif itype == runtime.CUDA_C_32F and otype == runtime.CUDA_R_32F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_32F
 *         elif itype == runtime.CUDA_C_64F and otype == runtime.CUDA_R_64F:
*/
    goto __pyx_L3;
  }

  /* "cupy/cuda/cufft.pyx":1125
 *         elif itype == runtime.CUDA_C_32F and otype == runtime.CUDA_R_32F:
 *             assert etype == runtime.CUDA_C_32F
 *         elif itype == runtime.CUDA_C_64F and otype == runtime.CUDA_R_64F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_64F
 *         # R2C
*/
  __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_v_itype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_CUDA_C_64F); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_2, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1125, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1125, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_5) {
  } else {
    __pyx_t_1 = __pyx_t_5;
    goto __pyx_L14_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyLong_From_int(__pyx_v_otype); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_CUDA_R_64F); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = PyObject_RichCompare(__pyx_t_3, __pyx_t_2, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1125, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1125, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_1 = __pyx_t_5;
  __pyx_L14_bool_binop_done:;
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":1126
 *             assert etype == runtime.CUDA_C_32F
 *         elif itype == runtime.CUDA_C_64F and otype == runtime.CUDA_R_64F:
 *             assert etype == runtime.CUDA_C_64F             # <<<<<<<<<<<<<<
 *         # R2C
 *         elif itype == runtime.CUDA_R_16F and otype == runtime.CUDA_C_16F:
*/
    #ifndef CYTHON_WITHOUT_ASSERTIONS
    if (unlikely(__pyx_assertions_enabled())) {
      __pyx_t_4 = __Pyx_PyLong_From_int(__pyx_v_etype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1126, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1126, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_CUDA_C_64F); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1126, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyObject_RichCompare(__pyx_t_4, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1126, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 1126, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (unlikely(!__pyx_t_1)) {
        __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
        __PYX_ERR(0, 1126, __pyx_L1_error)
      }
    }
    #else
    if ((1)); else __PYX_ERR(0, 1126, __pyx_L1_error)
    #endif

    /* "cupy/cuda/cufft.pyx":1125
 *         elif itype == runtime.CUDA_C_32F and otype == runtime.CUDA_R_32F:
 *             assert etype == runtime.CUDA_C_32F
 *         elif itype == runtime.CUDA_C_64F and otype == runtime.CUDA_R_64F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_64F
 *         # R2C
*/
    goto __pyx_L3;
  }

  /* "cupy/cuda/cufft.pyx":1128
 *             assert etype == runtime.CUDA_C_64F
 *         # R2C
 *         elif itype == runtime.CUDA_R_16F and otype == runtime.CUDA_C_16F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_16F
 *         elif itype == runtime.CUDA_R_32F and otype == runtime.CUDA_C_32F:
*/
  __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_v_itype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1128, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1128, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_CUDA_R_16F); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1128, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_2, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1128, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1128, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_5) {
  } else {
    __pyx_t_1 = __pyx_t_5;
    goto __pyx_L16_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyLong_From_int(__pyx_v_otype); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1128, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1128, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_CUDA_C_16F); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1128, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = PyObject_RichCompare(__pyx_t_3, __pyx_t_2, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1128, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1128, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_1 = __pyx_t_5;
  __pyx_L16_bool_binop_done:;
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":1129
 *         # R2C
 *         elif itype == runtime.CUDA_R_16F and otype == runtime.CUDA_C_16F:
 *             assert etype == runtime.CUDA_C_16F             # <<<<<<<<<<<<<<
 *         elif itype == runtime.CUDA_R_32F and otype == runtime.CUDA_C_32F:
 *             assert etype == runtime.CUDA_C_32F
*/
    #ifndef CYTHON_WITHOUT_ASSERTIONS
    if (unlikely(__pyx_assertions_enabled())) {
      __pyx_t_4 = __Pyx_PyLong_From_int(__pyx_v_etype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1129, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1129, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_CUDA_C_16F); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1129, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyObject_RichCompare(__pyx_t_4, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1129, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 1129, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (unlikely(!__pyx_t_1)) {
        __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
        __PYX_ERR(0, 1129, __pyx_L1_error)
      }
    }
    #else
    if ((1)); else __PYX_ERR(0, 1129, __pyx_L1_error)
    #endif

    /* "cupy/cuda/cufft.pyx":1128
 *             assert etype == runtime.CUDA_C_64F
 *         # R2C
 *         elif itype == runtime.CUDA_R_16F and otype == runtime.CUDA_C_16F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_16F
 *         elif itype == runtime.CUDA_R_32F and otype == runtime.CUDA_C_32F:
*/
    goto __pyx_L3;
  }

  /* "cupy/cuda/cufft.pyx":1130
 *         elif itype == runtime.CUDA_R_16F and otype == runtime.CUDA_C_16F:
 *             assert etype == runtime.CUDA_C_16F
 *         elif itype == runtime.CUDA_R_32F and otype == runtime.CUDA_C_32F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_32F
 *         elif itype == runtime.CUDA_R_64F and otype == runtime.CUDA_C_64F:
*/
  __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_v_itype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1130, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1130, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_CUDA_R_32F); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1130, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_2, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1130, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1130, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_5) {
  } else {
    __pyx_t_1 = __pyx_t_5;
    goto __pyx_L18_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyLong_From_int(__pyx_v_otype); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1130, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1130, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_CUDA_C_32F); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1130, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = PyObject_RichCompare(__pyx_t_3, __pyx_t_2, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1130, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1130, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_1 = __pyx_t_5;
  __pyx_L18_bool_binop_done:;
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":1131
 *             assert etype == runtime.CUDA_C_16F
 *         elif itype == runtime.CUDA_R_32F and otype == runtime.CUDA_C_32F:
 *             assert etype == runtime.CUDA_C_32F             # <<<<<<<<<<<<<<
 *         elif itype == runtime.CUDA_R_64F and otype == runtime.CUDA_C_64F:
 *             assert etype == runtime.CUDA_C_64F
*/
    #ifndef CYTHON_WITHOUT_ASSERTIONS
    if (unlikely(__pyx_assertions_enabled())) {
      __pyx_t_4 = __Pyx_PyLong_From_int(__pyx_v_etype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1131, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1131, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_CUDA_C_32F); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1131, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyObject_RichCompare(__pyx_t_4, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1131, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 1131, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (unlikely(!__pyx_t_1)) {
        __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
        __PYX_ERR(0, 1131, __pyx_L1_error)
      }
    }
    #else
    if ((1)); else __PYX_ERR(0, 1131, __pyx_L1_error)
    #endif

    /* "cupy/cuda/cufft.pyx":1130
 *         elif itype == runtime.CUDA_R_16F and otype == runtime.CUDA_C_16F:
 *             assert etype == runtime.CUDA_C_16F
 *         elif itype == runtime.CUDA_R_32F and otype == runtime.CUDA_C_32F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_32F
 *         elif itype == runtime.CUDA_R_64F and otype == runtime.CUDA_C_64F:
*/
    goto __pyx_L3;
  }

  /* "cupy/cuda/cufft.pyx":1132
 *         elif itype == runtime.CUDA_R_32F and otype == runtime.CUDA_C_32F:
 *             assert etype == runtime.CUDA_C_32F
 *         elif itype == runtime.CUDA_R_64F and otype == runtime.CUDA_C_64F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_64F
 *         else:
*/
  __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_v_itype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1132, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1132, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_CUDA_R_64F); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1132, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_2, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1132, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1132, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_5) {
  } else {
    __pyx_t_1 = __pyx_t_5;
    goto __pyx_L20_bool_binop_done;
  }
  __pyx_t_3 = __Pyx_PyLong_From_int(__pyx_v_otype); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1132, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1132, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_CUDA_C_64F); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1132, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = PyObject_RichCompare(__pyx_t_3, __pyx_t_2, Py_EQ); __Pyx_XGOTREF(__pyx_t_4); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1132, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_t_4); if (unlikely((__pyx_t_5 < 0))) __PYX_ERR(0, 1132, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_1 = __pyx_t_5;
  __pyx_L20_bool_binop_done:;
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":1133
 *             assert etype == runtime.CUDA_C_32F
 *         elif itype == runtime.CUDA_R_64F and otype == runtime.CUDA_C_64F:
 *             assert etype == runtime.CUDA_C_64F             # <<<<<<<<<<<<<<
 *         else:
 *             assert False
*/
    #ifndef CYTHON_WITHOUT_ASSERTIONS
    if (unlikely(__pyx_assertions_enabled())) {
      __pyx_t_4 = __Pyx_PyLong_From_int(__pyx_v_etype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1133, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_4);
      __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1133, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_2);
      __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_CUDA_C_64F); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1133, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __pyx_t_2 = PyObject_RichCompare(__pyx_t_4, __pyx_t_3, Py_EQ); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1133, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 1133, __pyx_L1_error)
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (unlikely(!__pyx_t_1)) {
        __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
        __PYX_ERR(0, 1133, __pyx_L1_error)
      }
    }
    #else
    if ((1)); else __PYX_ERR(0, 1133, __pyx_L1_error)
    #endif

    /* "cupy/cuda/cufft.pyx":1132
 *         elif itype == runtime.CUDA_R_32F and otype == runtime.CUDA_C_32F:
 *             assert etype == runtime.CUDA_C_32F
 *         elif itype == runtime.CUDA_R_64F and otype == runtime.CUDA_C_64F:             # <<<<<<<<<<<<<<
 *             assert etype == runtime.CUDA_C_64F
 *         else:
*/
    goto __pyx_L3;
  }

  /* "cupy/cuda/cufft.pyx":1135
 *             assert etype == runtime.CUDA_C_64F
 *         else:
 *             assert False             # <<<<<<<<<<<<<<
 * 
 *         # check fp16 runtime constraints
*/
  /*else*/ {
    #ifndef CYTHON_WITHOUT_ASSERTIONS
    if (unlikely(__pyx_assertions_enabled())) {
      if (unlikely(!0)) {
        __Pyx_Raise(__pyx_builtin_AssertionError, 0, 0, 0);
        __PYX_ERR(0, 1135, __pyx_L1_error)
      }
    }
    #else
    if ((1)); else __PYX_ERR(0, 1135, __pyx_L1_error)
    #endif
  }
  __pyx_L3:;

  /* "cupy/cuda/cufft.pyx":1139
 *         # check fp16 runtime constraints
 *         # https://docs.nvidia.com/cuda/cufft/index.html#half-precision-transforms
 *         if etype == runtime.CUDA_C_16F:             # <<<<<<<<<<<<<<
 *             if int(device.get_compute_capability()) < 53:
 *                 raise RuntimeError("this device doesn't support complex32 FFT")
*/
  __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_v_etype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1139, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GetModuleGlobalName(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1139, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_CUDA_C_16F); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1139, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyObject_RichCompare(__pyx_t_2, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1139, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 1139, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_1) {

    /* "cupy/cuda/cufft.pyx":1140
 *         # https://docs.nvidia.com/cuda/cufft/index.html#half-precision-transforms
 *         if etype == runtime.CUDA_C_16F:
 *             if int(device.get_compute_capability()) < 53:             # <<<<<<<<<<<<<<
 *                 raise RuntimeError("this device doesn't support complex32 FFT")
 *             if (last_size & (last_size - 1)) != 0:
*/
    __pyx_t_4 = NULL;
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1140, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_get_compute_capability); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1140, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_7 = 1;
    #if CYTHON_UNPACK_METHODS
    if (unlikely(PyMethod_Check(__pyx_t_6))) {
      __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_6);
      assert(__pyx_t_4);
      PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(__pyx__function);
      __Pyx_DECREF_SET(__pyx_t_6, __pyx__function);
      __pyx_t_7 = 0;
    }
    #endif
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_4, NULL};
      __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_6, __pyx_callargs+__pyx_t_7, (1-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1140, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
    }
    __pyx_t_6 = __Pyx_PyNumber_Int(__pyx_t_3); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1140, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = PyObject_RichCompare(__pyx_t_6, __pyx_mstate_global->__pyx_int_53, Py_LT); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1140, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 1140, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(__pyx_t_1)) {

      /* "cupy/cuda/cufft.pyx":1141
 *         if etype == runtime.CUDA_C_16F:
 *             if int(device.get_compute_capability()) < 53:
 *                 raise RuntimeError("this device doesn't support complex32 FFT")             # <<<<<<<<<<<<<<
 *             if (last_size & (last_size - 1)) != 0:
 *                 raise ValueError('size must be power of 2')
*/
      __pyx_t_6 = NULL;
      __Pyx_INCREF(__pyx_builtin_RuntimeError);
      __pyx_t_4 = __pyx_builtin_RuntimeError; 
      __pyx_t_7 = 1;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_6, __pyx_mstate_global->__pyx_kp_u_this_device_doesn_t_support_comp};
        __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_4, __pyx_callargs+__pyx_t_7, (2-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_6); __pyx_t_6 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1141, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
      }
      __Pyx_Raise(__pyx_t_3, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __PYX_ERR(0, 1141, __pyx_L1_error)

      /* "cupy/cuda/cufft.pyx":1140
 *         # https://docs.nvidia.com/cuda/cufft/index.html#half-precision-transforms
 *         if etype == runtime.CUDA_C_16F:
 *             if int(device.get_compute_capability()) < 53:             # <<<<<<<<<<<<<<
 *                 raise RuntimeError("this device doesn't support complex32 FFT")
 *             if (last_size & (last_size - 1)) != 0:
*/
    }

    /* "cupy/cuda/cufft.pyx":1142
 *             if int(device.get_compute_capability()) < 53:
 *                 raise RuntimeError("this device doesn't support complex32 FFT")
 *             if (last_size & (last_size - 1)) != 0:             # <<<<<<<<<<<<<<
 *                 raise ValueError('size must be power of 2')
 *             if full_size > 4000000000:
*/
    __pyx_t_1 = ((__pyx_v_last_size & (__pyx_v_last_size - 1)) != 0);
    if (unlikely(__pyx_t_1)) {

      /* "cupy/cuda/cufft.pyx":1143
 *                 raise RuntimeError("this device doesn't support complex32 FFT")
 *             if (last_size & (last_size - 1)) != 0:
 *                 raise ValueError('size must be power of 2')             # <<<<<<<<<<<<<<
 *             if full_size > 4000000000:
 *                 raise ValueError('input array too large')
*/
      __pyx_t_4 = NULL;
      __Pyx_INCREF(__pyx_builtin_ValueError);
      __pyx_t_6 = __pyx_builtin_ValueError; 
      __pyx_t_7 = 1;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_4, __pyx_mstate_global->__pyx_kp_u_size_must_be_power_of_2};
        __pyx_t_3 = __Pyx_PyObject_FastCall(__pyx_t_6, __pyx_callargs+__pyx_t_7, (2-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
        __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
        if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1143, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_3);
      }
      __Pyx_Raise(__pyx_t_3, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
      __PYX_ERR(0, 1143, __pyx_L1_error)

      /* "cupy/cuda/cufft.pyx":1142
 *             if int(device.get_compute_capability()) < 53:
 *                 raise RuntimeError("this device doesn't support complex32 FFT")
 *             if (last_size & (last_size - 1)) != 0:             # <<<<<<<<<<<<<<
 *                 raise ValueError('size must be power of 2')
 *             if full_size > 4000000000:
*/
    }

    /* "cupy/cuda/cufft.pyx":1144
 *             if (last_size & (last_size - 1)) != 0:
 *                 raise ValueError('size must be power of 2')
 *             if full_size > 4000000000:             # <<<<<<<<<<<<<<
 *                 raise ValueError('input array too large')
 *             # TODO(leofang): check if multi-GPU is requested
*/
    __pyx_t_3 = __Pyx_PyLong_From_PY_LONG_LONG(__pyx_v_full_size); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1144, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_6 = PyObject_RichCompare(__pyx_t_3, __pyx_mstate_global->__pyx_int_4000000000, Py_GT); __Pyx_XGOTREF(__pyx_t_6); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1144, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_1 = __Pyx_PyObject_IsTrue(__pyx_t_6); if (unlikely((__pyx_t_1 < 0))) __PYX_ERR(0, 1144, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    if (unlikely(__pyx_t_1)) {

      /* "cupy/cuda/cufft.pyx":1145
 *                 raise ValueError('size must be power of 2')
 *             if full_size > 4000000000:
 *                 raise ValueError('input array too large')             # <<<<<<<<<<<<<<
 *             # TODO(leofang): check if multi-GPU is requested
 *         # TODO(leofang): also check for bf16?
*/
      __pyx_t_3 = NULL;
      __Pyx_INCREF(__pyx_builtin_ValueError);
      __pyx_t_4 = __pyx_builtin_ValueError; 
      __pyx_t_7 = 1;
      {
        PyObject *__pyx_callargs[2] = {__pyx_t_3, __pyx_mstate_global->__pyx_kp_u_input_array_too_large};
        __pyx_t_6 = __Pyx_PyObject_FastCall(__pyx_t_4, __pyx_callargs+__pyx_t_7, (2-__pyx_t_7) | (__pyx_t_7*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
        __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
        __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
        if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 1145, __pyx_L1_error)
        __Pyx_GOTREF(__pyx_t_6);
      }
      __Pyx_Raise(__pyx_t_6, 0, 0, 0);
      __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
      __PYX_ERR(0, 1145, __pyx_L1_error)

      /* "cupy/cuda/cufft.pyx":1144
 *             if (last_size & (last_size - 1)) != 0:
 *                 raise ValueError('size must be power of 2')
 *             if full_size > 4000000000:             # <<<<<<<<<<<<<<
 *                 raise ValueError('input array too large')
 *             # TODO(leofang): check if multi-GPU is requested
*/
    }

    /* "cupy/cuda/cufft.pyx":1139
 *         # check fp16 runtime constraints
 *         # https://docs.nvidia.com/cuda/cufft/index.html#half-precision-transforms
 *         if etype == runtime.CUDA_C_16F:             # <<<<<<<<<<<<<<
 *             if int(device.get_compute_capability()) < 53:
 *                 raise RuntimeError("this device doesn't support complex32 FFT")
*/
  }

  /* "cupy/cuda/cufft.pyx":1109
 *         XtExec(plan, a.data.ptr, out.data.ptr, direction)
 * 
 *     def _sanity_checks(self, int itype, int otype, int etype,             # <<<<<<<<<<<<<<
 *                        long long int last_size, long long int full_size):
 *         # not every possible type combination is legit
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd._sanity_checks", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1150
 *         # https://docs.nvidia.com/cuda/cufft/index.html#bfloat16-precision-transforms
 * 
 *     def _output_dtype_and_shape(self, a):             # <<<<<<<<<<<<<<
 *         shape = list(a.shape)
 *         if self.itype != self.otype:  # R2C or C2R
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_13_output_dtype_and_shape(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_8XtPlanNd_12_output_dtype_and_shape, "XtPlanNd._output_dtype_and_shape(self, a)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_13_output_dtype_and_shape(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_a = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[1] = {0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("_output_dtype_and_shape (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_a,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1150, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1150, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "_output_dtype_and_shape", 0) < (0)) __PYX_ERR(0, 1150, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 1; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("_output_dtype_and_shape", 1, 1, 1, i); __PYX_ERR(0, 1150, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 1)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1150, __pyx_L3_error)
    }
    __pyx_v_a = values[0];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("_output_dtype_and_shape", 1, 1, 1, __pyx_nargs); __PYX_ERR(0, 1150, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd._output_dtype_and_shape", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_12_output_dtype_and_shape(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self), __pyx_v_a);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_12_output_dtype_and_shape(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self, PyObject *__pyx_v_a) {
  PyObject *__pyx_v_shape = NULL;
  PyObject *__pyx_v_dtype = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  size_t __pyx_t_5;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("_output_dtype_and_shape", 0);

  /* "cupy/cuda/cufft.pyx":1151
 * 
 *     def _output_dtype_and_shape(self, a):
 *         shape = list(a.shape)             # <<<<<<<<<<<<<<
 *         if self.itype != self.otype:  # R2C or C2R
 *             shape[self.last_axis] = self.last_size
*/
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_a, __pyx_mstate_global->__pyx_n_u_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1151, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PySequence_ListKeepNew(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1151, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_shape = ((PyObject*)__pyx_t_2);
  __pyx_t_2 = 0;

  /* "cupy/cuda/cufft.pyx":1152
 *     def _output_dtype_and_shape(self, a):
 *         shape = list(a.shape)
 *         if self.itype != self.otype:  # R2C or C2R             # <<<<<<<<<<<<<<
 *             shape[self.last_axis] = self.last_size
 *         if self.otype == runtime.CUDA_C_16F:
*/
  __pyx_t_3 = (__pyx_v_self->itype != __pyx_v_self->otype);
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":1153
 *         shape = list(a.shape)
 *         if self.itype != self.otype:  # R2C or C2R
 *             shape[self.last_axis] = self.last_size             # <<<<<<<<<<<<<<
 *         if self.otype == runtime.CUDA_C_16F:
 *             # dtype = numpy.complex32
*/
    __pyx_t_2 = __pyx_v_self->last_size;
    __Pyx_INCREF(__pyx_t_2);
    if (unlikely((__Pyx_SetItemInt(__pyx_v_shape, __pyx_v_self->last_axis, __pyx_t_2, int, 1, __Pyx_PyLong_From_int, 1, 1, 1, 1) < 0))) __PYX_ERR(0, 1153, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

    /* "cupy/cuda/cufft.pyx":1152
 *     def _output_dtype_and_shape(self, a):
 *         shape = list(a.shape)
 *         if self.itype != self.otype:  # R2C or C2R             # <<<<<<<<<<<<<<
 *             shape[self.last_axis] = self.last_size
 *         if self.otype == runtime.CUDA_C_16F:
*/
  }

  /* "cupy/cuda/cufft.pyx":1154
 *         if self.itype != self.otype:  # R2C or C2R
 *             shape[self.last_axis] = self.last_size
 *         if self.otype == runtime.CUDA_C_16F:             # <<<<<<<<<<<<<<
 *             # dtype = numpy.complex32
 *             raise NotImplementedError('complex32 is not supported yet, please '
*/
  __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_v_self->otype); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1154, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GetModuleGlobalName(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1154, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_mstate_global->__pyx_n_u_CUDA_C_16F); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1154, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyObject_RichCompare(__pyx_t_2, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1154, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely((__pyx_t_3 < 0))) __PYX_ERR(0, 1154, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (unlikely(__pyx_t_3)) {

    /* "cupy/cuda/cufft.pyx":1156
 *         if self.otype == runtime.CUDA_C_16F:
 *             # dtype = numpy.complex32
 *             raise NotImplementedError('complex32 is not supported yet, please '             # <<<<<<<<<<<<<<
 *                                       'allocate the output array manually')
 *         elif self.otype == runtime.CUDA_C_32F:
*/
    __pyx_t_4 = NULL;
    __Pyx_INCREF(__pyx_builtin_NotImplementedError);
    __pyx_t_2 = __pyx_builtin_NotImplementedError; 
    __pyx_t_5 = 1;
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_4, __pyx_mstate_global->__pyx_kp_u_complex32_is_not_supported_yet_p};
      __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_2, __pyx_callargs+__pyx_t_5, (2-__pyx_t_5) | (__pyx_t_5*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1156, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 1156, __pyx_L1_error)

    /* "cupy/cuda/cufft.pyx":1154
 *         if self.itype != self.otype:  # R2C or C2R
 *             shape[self.last_axis] = self.last_size
 *         if self.otype == runtime.CUDA_C_16F:             # <<<<<<<<<<<<<<
 *             # dtype = numpy.complex32
 *             raise NotImplementedError('complex32 is not supported yet, please '
*/
  }

  /* "cupy/cuda/cufft.pyx":1158
 *             raise NotImplementedError('complex32 is not supported yet, please '
 *                                       'allocate the output array manually')
 *         elif self.otype == runtime.CUDA_C_32F:             # <<<<<<<<<<<<<<
 *             dtype = numpy.complex64
 *         elif self.otype == runtime.CUDA_C_64F:
*/
  __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_self->otype); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1158, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1158, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_CUDA_C_32F); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1158, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1158, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_3 < 0))) __PYX_ERR(0, 1158, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":1159
 *                                       'allocate the output array manually')
 *         elif self.otype == runtime.CUDA_C_32F:
 *             dtype = numpy.complex64             # <<<<<<<<<<<<<<
 *         elif self.otype == runtime.CUDA_C_64F:
 *             dtype = numpy.complex128
*/
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1159, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_complex64); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1159, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_dtype = __pyx_t_4;
    __pyx_t_4 = 0;

    /* "cupy/cuda/cufft.pyx":1158
 *             raise NotImplementedError('complex32 is not supported yet, please '
 *                                       'allocate the output array manually')
 *         elif self.otype == runtime.CUDA_C_32F:             # <<<<<<<<<<<<<<
 *             dtype = numpy.complex64
 *         elif self.otype == runtime.CUDA_C_64F:
*/
    goto __pyx_L4;
  }

  /* "cupy/cuda/cufft.pyx":1160
 *         elif self.otype == runtime.CUDA_C_32F:
 *             dtype = numpy.complex64
 *         elif self.otype == runtime.CUDA_C_64F:             # <<<<<<<<<<<<<<
 *             dtype = numpy.complex128
 *         elif self.otype == runtime.CUDA_R_16F:
*/
  __pyx_t_4 = __Pyx_PyLong_From_int(__pyx_v_self->otype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1160, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1160, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_CUDA_C_64F); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1160, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_4, __pyx_t_1, Py_EQ); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1160, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_3 < 0))) __PYX_ERR(0, 1160, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":1161
 *             dtype = numpy.complex64
 *         elif self.otype == runtime.CUDA_C_64F:
 *             dtype = numpy.complex128             # <<<<<<<<<<<<<<
 *         elif self.otype == runtime.CUDA_R_16F:
 *             dtype = numpy.float16
*/
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1161, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_complex128); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1161, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_dtype = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":1160
 *         elif self.otype == runtime.CUDA_C_32F:
 *             dtype = numpy.complex64
 *         elif self.otype == runtime.CUDA_C_64F:             # <<<<<<<<<<<<<<
 *             dtype = numpy.complex128
 *         elif self.otype == runtime.CUDA_R_16F:
*/
    goto __pyx_L4;
  }

  /* "cupy/cuda/cufft.pyx":1162
 *         elif self.otype == runtime.CUDA_C_64F:
 *             dtype = numpy.complex128
 *         elif self.otype == runtime.CUDA_R_16F:             # <<<<<<<<<<<<<<
 *             dtype = numpy.float16
 *         elif self.otype == runtime.CUDA_R_32F:
*/
  __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_self->otype); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1162, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1162, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_CUDA_R_16F); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1162, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1162, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_3 < 0))) __PYX_ERR(0, 1162, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":1163
 *             dtype = numpy.complex128
 *         elif self.otype == runtime.CUDA_R_16F:
 *             dtype = numpy.float16             # <<<<<<<<<<<<<<
 *         elif self.otype == runtime.CUDA_R_32F:
 *             dtype = numpy.float32
*/
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1163, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_float16); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1163, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_dtype = __pyx_t_4;
    __pyx_t_4 = 0;

    /* "cupy/cuda/cufft.pyx":1162
 *         elif self.otype == runtime.CUDA_C_64F:
 *             dtype = numpy.complex128
 *         elif self.otype == runtime.CUDA_R_16F:             # <<<<<<<<<<<<<<
 *             dtype = numpy.float16
 *         elif self.otype == runtime.CUDA_R_32F:
*/
    goto __pyx_L4;
  }

  /* "cupy/cuda/cufft.pyx":1164
 *         elif self.otype == runtime.CUDA_R_16F:
 *             dtype = numpy.float16
 *         elif self.otype == runtime.CUDA_R_32F:             # <<<<<<<<<<<<<<
 *             dtype = numpy.float32
 *         elif self.otype == runtime.CUDA_R_64F:
*/
  __pyx_t_4 = __Pyx_PyLong_From_int(__pyx_v_self->otype); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1164, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1164, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_CUDA_R_32F); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1164, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_4, __pyx_t_1, Py_EQ); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1164, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_3 < 0))) __PYX_ERR(0, 1164, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":1165
 *             dtype = numpy.float16
 *         elif self.otype == runtime.CUDA_R_32F:
 *             dtype = numpy.float32             # <<<<<<<<<<<<<<
 *         elif self.otype == runtime.CUDA_R_64F:
 *             dtype = numpy.float64
*/
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1165, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_float32); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1165, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_dtype = __pyx_t_1;
    __pyx_t_1 = 0;

    /* "cupy/cuda/cufft.pyx":1164
 *         elif self.otype == runtime.CUDA_R_16F:
 *             dtype = numpy.float16
 *         elif self.otype == runtime.CUDA_R_32F:             # <<<<<<<<<<<<<<
 *             dtype = numpy.float32
 *         elif self.otype == runtime.CUDA_R_64F:
*/
    goto __pyx_L4;
  }

  /* "cupy/cuda/cufft.pyx":1166
 *         elif self.otype == runtime.CUDA_R_32F:
 *             dtype = numpy.float32
 *         elif self.otype == runtime.CUDA_R_64F:             # <<<<<<<<<<<<<<
 *             dtype = numpy.float64
 *         return tuple(shape), dtype
*/
  __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_self->otype); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1166, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1166, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_CUDA_R_64F); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1166, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyObject_RichCompare(__pyx_t_1, __pyx_t_4, Py_EQ); __Pyx_XGOTREF(__pyx_t_2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1166, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_3 = __Pyx_PyObject_IsTrue(__pyx_t_2); if (unlikely((__pyx_t_3 < 0))) __PYX_ERR(0, 1166, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  if (__pyx_t_3) {

    /* "cupy/cuda/cufft.pyx":1167
 *             dtype = numpy.float32
 *         elif self.otype == runtime.CUDA_R_64F:
 *             dtype = numpy.float64             # <<<<<<<<<<<<<<
 *         return tuple(shape), dtype
 * 
*/
    __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_numpy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1167, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_float64); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1167, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_v_dtype = __pyx_t_4;
    __pyx_t_4 = 0;

    /* "cupy/cuda/cufft.pyx":1166
 *         elif self.otype == runtime.CUDA_R_32F:
 *             dtype = numpy.float32
 *         elif self.otype == runtime.CUDA_R_64F:             # <<<<<<<<<<<<<<
 *             dtype = numpy.float64
 *         return tuple(shape), dtype
*/
  }
  __pyx_L4:;

  /* "cupy/cuda/cufft.pyx":1168
 *         elif self.otype == runtime.CUDA_R_64F:
 *             dtype = numpy.float64
 *         return tuple(shape), dtype             # <<<<<<<<<<<<<<
 * 
 *     def get_output_array(self, a, order='C'):
*/
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_4 = PyList_AsTuple(__pyx_v_shape); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1168, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (unlikely(!__pyx_v_dtype)) { __Pyx_RaiseUnboundLocalError("dtype"); __PYX_ERR(0, 1168, __pyx_L1_error) }
  __pyx_t_2 = PyTuple_New(2); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1168, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_4);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_2, 0, __pyx_t_4) != (0)) __PYX_ERR(0, 1168, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_dtype);
  __Pyx_GIVEREF(__pyx_v_dtype);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_2, 1, __pyx_v_dtype) != (0)) __PYX_ERR(0, 1168, __pyx_L1_error);
  __pyx_t_4 = 0;
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":1150
 *         # https://docs.nvidia.com/cuda/cufft/index.html#bfloat16-precision-transforms
 * 
 *     def _output_dtype_and_shape(self, a):             # <<<<<<<<<<<<<<
 *         shape = list(a.shape)
 *         if self.itype != self.otype:  # R2C or C2R
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd._output_dtype_and_shape", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XDECREF(__pyx_v_dtype);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1170
 *         return tuple(shape), dtype
 * 
 *     def get_output_array(self, a, order='C'):             # <<<<<<<<<<<<<<
 *         shape, dtype = self._output_dtype_and_shape(a)
 *         return cupy.empty(shape, dtype, order=order)
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_15get_output_array(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_8XtPlanNd_14get_output_array, "XtPlanNd.get_output_array(self, a, order='C')");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_15get_output_array(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v_a = 0;
  PyObject *__pyx_v_order = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[2] = {0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("get_output_array (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_a,&__pyx_mstate_global->__pyx_n_u_order,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1170, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1170, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1170, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "get_output_array", 0) < (0)) __PYX_ERR(0, 1170, __pyx_L3_error)
      if (!values[1]) values[1] = __Pyx_NewRef(((PyObject *)__pyx_mstate_global->__pyx_n_u_C));
      for (Py_ssize_t i = __pyx_nargs; i < 1; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("get_output_array", 0, 1, 2, i); __PYX_ERR(0, 1170, __pyx_L3_error) }
      }
    } else {
      switch (__pyx_nargs) {
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1170, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1170, __pyx_L3_error)
        break;
        default: goto __pyx_L5_argtuple_error;
      }
      if (!values[1]) values[1] = __Pyx_NewRef(((PyObject *)__pyx_mstate_global->__pyx_n_u_C));
    }
    __pyx_v_a = values[0];
    __pyx_v_order = values[1];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("get_output_array", 0, 1, 2, __pyx_nargs); __PYX_ERR(0, 1170, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.get_output_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_14get_output_array(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self), __pyx_v_a, __pyx_v_order);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_14get_output_array(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self, PyObject *__pyx_v_a, PyObject *__pyx_v_order) {
  PyObject *__pyx_v_shape = NULL;
  PyObject *__pyx_v_dtype = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  size_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *(*__pyx_t_6)(PyObject *);
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("get_output_array", 0);

  /* "cupy/cuda/cufft.pyx":1171
 * 
 *     def get_output_array(self, a, order='C'):
 *         shape, dtype = self._output_dtype_and_shape(a)             # <<<<<<<<<<<<<<
 *         return cupy.empty(shape, dtype, order=order)
 * 
*/
  __pyx_t_2 = ((PyObject *)__pyx_v_self);
  __Pyx_INCREF(__pyx_t_2);
  __pyx_t_3 = 0;
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_v_a};
    __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_output_dtype_and_shape, __pyx_callargs+__pyx_t_3, (2-__pyx_t_3) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1171, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    Py_ssize_t size = __Pyx_PySequence_SIZE(sequence);
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 1171, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0);
      __Pyx_INCREF(__pyx_t_2);
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 1);
      __Pyx_INCREF(__pyx_t_4);
    } else {
      __pyx_t_2 = __Pyx_PyList_GetItemRef(sequence, 0);
      if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1171, __pyx_L1_error)
      __Pyx_XGOTREF(__pyx_t_2);
      __pyx_t_4 = __Pyx_PyList_GetItemRef(sequence, 1);
      if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1171, __pyx_L1_error)
      __Pyx_XGOTREF(__pyx_t_4);
    }
    #else
    __pyx_t_2 = __Pyx_PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1171, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_4 = __Pyx_PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 1171, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_5 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1171, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_6 = (CYTHON_COMPILING_IN_LIMITED_API) ? PyIter_Next : __Pyx_PyObject_GetIterNextFunc(__pyx_t_5);
    index = 0; __pyx_t_2 = __pyx_t_6(__pyx_t_5); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 1; __pyx_t_4 = __pyx_t_6(__pyx_t_5); if (unlikely(!__pyx_t_4)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_4);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_6(__pyx_t_5), 2) < (0)) __PYX_ERR(0, 1171, __pyx_L1_error)
    __pyx_t_6 = NULL;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_6 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 1171, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_shape = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_dtype = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "cupy/cuda/cufft.pyx":1172
 *     def get_output_array(self, a, order='C'):
 *         shape, dtype = self._output_dtype_and_shape(a)
 *         return cupy.empty(shape, dtype, order=order)             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_4 = NULL;
  __Pyx_GetModuleGlobalName(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_cupy); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1172, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_empty); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 1172, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = 1;
  #if CYTHON_UNPACK_METHODS
  if (unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    assert(__pyx_t_4);
    PyObject* __pyx__function = PyMethod_GET_FUNCTION(__pyx_t_5);
    __Pyx_INCREF(__pyx_t_4);
    __Pyx_INCREF(__pyx__function);
    __Pyx_DECREF_SET(__pyx_t_5, __pyx__function);
    __pyx_t_3 = 0;
  }
  #endif
  {
    PyObject *__pyx_callargs[3 + ((CYTHON_VECTORCALL) ? 1 : 0)] = {__pyx_t_4, __pyx_v_shape, __pyx_v_dtype};
    __pyx_t_2 = __Pyx_MakeVectorcallBuilderKwds(1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1172, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    if (__Pyx_VectorcallBuilder_AddArg(__pyx_mstate_global->__pyx_n_u_order, __pyx_v_order, __pyx_t_2, __pyx_callargs+3, 0) < (0)) __PYX_ERR(0, 1172, __pyx_L1_error)
    __pyx_t_1 = __Pyx_Object_Vectorcall_CallFromBuilder(__pyx_t_5, __pyx_callargs+__pyx_t_3, (3-__pyx_t_3) | (__pyx_t_3*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET), __pyx_t_2);
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1172, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":1170
 *         return tuple(shape), dtype
 * 
 *     def get_output_array(self, a, order='C'):             # <<<<<<<<<<<<<<
 *         shape, dtype = self._output_dtype_and_shape(a)
 *         return cupy.empty(shape, dtype, order=order)
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.get_output_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_shape);
  __Pyx_XDECREF(__pyx_v_dtype);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":92
 * cdef class XtPlanNd:
 *     cdef:
 *         readonly intptr_t handle             # <<<<<<<<<<<<<<
 *         readonly object work_area  # memory.MemoryPointer
 *         readonly tuple shape
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_6handle_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_6handle_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_6handle___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_6handle___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = PyLong_FromSsize_t(__pyx_v_self->handle); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 92, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.handle.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":93
 *     cdef:
 *         readonly intptr_t handle
 *         readonly object work_area  # memory.MemoryPointer             # <<<<<<<<<<<<<<
 *         readonly tuple shape
 *         readonly int itype
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_9work_area_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_9work_area_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_9work_area___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_9work_area___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->work_area);
  __pyx_r = __pyx_v_self->work_area;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":94
 *         readonly intptr_t handle
 *         readonly object work_area  # memory.MemoryPointer
 *         readonly tuple shape             # <<<<<<<<<<<<<<
 *         readonly int itype
 *         readonly int otype
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5shape_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5shape_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_5shape___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_5shape___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->shape);
  __pyx_r = __pyx_v_self->shape;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":95
 *         readonly object work_area  # memory.MemoryPointer
 *         readonly tuple shape
 *         readonly int itype             # <<<<<<<<<<<<<<
 *         readonly int otype
 *         readonly int etype
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5itype_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5itype_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_5itype___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_5itype___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_self->itype); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.itype.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":96
 *         readonly tuple shape
 *         readonly int itype
 *         readonly int otype             # <<<<<<<<<<<<<<
 *         readonly int etype
 *         readonly str order
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5otype_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5otype_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_5otype___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_5otype___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_self->otype); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 96, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.otype.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":97
 *         readonly int itype
 *         readonly int otype
 *         readonly int etype             # <<<<<<<<<<<<<<
 *         readonly str order
 *         readonly int last_axis
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5etype_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5etype_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_5etype___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_5etype___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_self->etype); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 97, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.etype.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":98
 *         readonly int otype
 *         readonly int etype
 *         readonly str order             # <<<<<<<<<<<<<<
 *         readonly int last_axis
 *         readonly object last_size
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5order_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5order_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_5order___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_5order___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->order);
  __pyx_r = __pyx_v_self->order;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":99
 *         readonly int etype
 *         readonly str order
 *         readonly int last_axis             # <<<<<<<<<<<<<<
 *         readonly object last_size
 * 
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_9last_axis_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_9last_axis_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_9last_axis___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_9last_axis___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_self->last_axis); if (unlikely(!__pyx_t_1)) __PYX_ERR(2, 99, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.last_axis.__get__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":100
 *         readonly str order
 *         readonly int last_axis
 *         readonly object last_size             # <<<<<<<<<<<<<<
 * 
 *         # TODO(leofang): support multi-GPU transforms
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_9last_size_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_9last_size_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_9last_size___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_9last_size___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->last_size);
  __pyx_r = __pyx_v_self->last_size;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pxd":103
 * 
 *         # TODO(leofang): support multi-GPU transforms
 *         readonly list gpus             # <<<<<<<<<<<<<<
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_4gpus_1__get__(PyObject *__pyx_v_self); /*proto*/
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_4gpus_1__get__(PyObject *__pyx_v_self) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__ (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_4gpus___get__(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_4gpus___get__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__get__", 0);
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_self->gpus);
  __pyx_r = __pyx_v_self->gpus;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":1
 * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
 *     cdef tuple state
 *     cdef object _dict
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_17__reduce_cython__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_8XtPlanNd_16__reduce_cython__, "XtPlanNd.__reduce_cython__(self)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_17__reduce_cython__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__reduce_cython__ (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  if (unlikely(__pyx_nargs > 0)) { __Pyx_RaiseArgtupleInvalid("__reduce_cython__", 1, 0, 0, __pyx_nargs); return NULL; }
  const Py_ssize_t __pyx_kwds_len = unlikely(__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
  if (unlikely(__pyx_kwds_len < 0)) return NULL;
  if (unlikely(__pyx_kwds_len > 0)) {__Pyx_RejectKeywords("__reduce_cython__", __pyx_kwds); return NULL;}
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_16__reduce_cython__(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_16__reduce_cython__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self) {
  PyObject *__pyx_v_state = 0;
  PyObject *__pyx_v__dict = 0;
  int __pyx_v_use_setstate;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  int __pyx_t_7;
  int __pyx_t_8;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__reduce_cython__", 0);

  /* "(tree fragment)":5
 *     cdef object _dict
 *     cdef bint use_setstate
 *     state = (self.etype, self.gpus, self.handle, self.itype, self.last_axis, self.last_size, self.order, self.otype, self.shape, self.work_area)             # <<<<<<<<<<<<<<
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:
*/
  __pyx_t_1 = __Pyx_PyLong_From_int(__pyx_v_self->etype); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = PyLong_FromSsize_t(__pyx_v_self->handle); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyLong_From_int(__pyx_v_self->itype); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_4 = __Pyx_PyLong_From_int(__pyx_v_self->last_axis); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyLong_From_int(__pyx_v_self->otype); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = PyTuple_New(10); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 5, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_GIVEREF(__pyx_t_1);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_1) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->gpus);
  __Pyx_GIVEREF(__pyx_v_self->gpus);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_v_self->gpus) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_2);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_t_2) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_3);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 3, __pyx_t_3) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_4);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 4, __pyx_t_4) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->last_size);
  __Pyx_GIVEREF(__pyx_v_self->last_size);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 5, __pyx_v_self->last_size) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->order);
  __Pyx_GIVEREF(__pyx_v_self->order);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 6, __pyx_v_self->order) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_GIVEREF(__pyx_t_5);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 7, __pyx_t_5) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->shape);
  __Pyx_GIVEREF(__pyx_v_self->shape);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 8, __pyx_v_self->shape) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __Pyx_INCREF(__pyx_v_self->work_area);
  __Pyx_GIVEREF(__pyx_v_self->work_area);
  if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 9, __pyx_v_self->work_area) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
  __pyx_t_1 = 0;
  __pyx_t_2 = 0;
  __pyx_t_3 = 0;
  __pyx_t_4 = 0;
  __pyx_t_5 = 0;
  __pyx_v_state = ((PyObject*)__pyx_t_6);
  __pyx_t_6 = 0;

  /* "(tree fragment)":6
 *     cdef bint use_setstate
 *     state = (self.etype, self.gpus, self.handle, self.itype, self.last_axis, self.last_size, self.order, self.otype, self.shape, self.work_area)
 *     _dict = getattr(self, '__dict__', None)             # <<<<<<<<<<<<<<
 *     if _dict is not None:
 *         state += (_dict,)
*/
  __pyx_t_6 = __Pyx_GetAttr3(((PyObject *)__pyx_v_self), __pyx_mstate_global->__pyx_n_u_dict, Py_None); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 6, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __pyx_v__dict = __pyx_t_6;
  __pyx_t_6 = 0;

  /* "(tree fragment)":7
 *     state = (self.etype, self.gpus, self.handle, self.itype, self.last_axis, self.last_size, self.order, self.otype, self.shape, self.work_area)
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:             # <<<<<<<<<<<<<<
 *         state += (_dict,)
 *         use_setstate = True
*/
  __pyx_t_7 = (__pyx_v__dict != Py_None);
  if (__pyx_t_7) {

    /* "(tree fragment)":8
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:
 *         state += (_dict,)             # <<<<<<<<<<<<<<
 *         use_setstate = True
 *     else:
*/
    __pyx_t_6 = PyTuple_New(1); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 8, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_INCREF(__pyx_v__dict);
    __Pyx_GIVEREF(__pyx_v__dict);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_v__dict) != (0)) __PYX_ERR(1, 8, __pyx_L1_error);
    __pyx_t_5 = PyNumber_InPlaceAdd(__pyx_v_state, __pyx_t_6); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 8, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
    __Pyx_DECREF_SET(__pyx_v_state, ((PyObject*)__pyx_t_5));
    __pyx_t_5 = 0;

    /* "(tree fragment)":9
 *     if _dict is not None:
 *         state += (_dict,)
 *         use_setstate = True             # <<<<<<<<<<<<<<
 *     else:
 *         use_setstate = self.gpus is not None or self.last_size is not None or self.order is not None or self.shape is not None or self.work_area is not None
*/
    __pyx_v_use_setstate = 1;

    /* "(tree fragment)":7
 *     state = (self.etype, self.gpus, self.handle, self.itype, self.last_axis, self.last_size, self.order, self.otype, self.shape, self.work_area)
 *     _dict = getattr(self, '__dict__', None)
 *     if _dict is not None:             # <<<<<<<<<<<<<<
 *         state += (_dict,)
 *         use_setstate = True
*/
    goto __pyx_L3;
  }

  /* "(tree fragment)":11
 *         use_setstate = True
 *     else:
 *         use_setstate = self.gpus is not None or self.last_size is not None or self.order is not None or self.shape is not None or self.work_area is not None             # <<<<<<<<<<<<<<
 *     if use_setstate:
 *         return __pyx_unpickle_XtPlanNd, (type(self), 0x19c6497, None), state
*/
  /*else*/ {
    __pyx_t_8 = (__pyx_v_self->gpus != ((PyObject*)Py_None));
    if (!__pyx_t_8) {
    } else {
      __pyx_t_7 = __pyx_t_8;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_8 = (__pyx_v_self->last_size != Py_None);
    if (!__pyx_t_8) {
    } else {
      __pyx_t_7 = __pyx_t_8;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_8 = (__pyx_v_self->order != ((PyObject*)Py_None));
    if (!__pyx_t_8) {
    } else {
      __pyx_t_7 = __pyx_t_8;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_8 = (__pyx_v_self->shape != ((PyObject*)Py_None));
    if (!__pyx_t_8) {
    } else {
      __pyx_t_7 = __pyx_t_8;
      goto __pyx_L4_bool_binop_done;
    }
    __pyx_t_8 = (__pyx_v_self->work_area != Py_None);
    __pyx_t_7 = __pyx_t_8;
    __pyx_L4_bool_binop_done:;
    __pyx_v_use_setstate = __pyx_t_7;
  }
  __pyx_L3:;

  /* "(tree fragment)":12
 *     else:
 *         use_setstate = self.gpus is not None or self.last_size is not None or self.order is not None or self.shape is not None or self.work_area is not None
 *     if use_setstate:             # <<<<<<<<<<<<<<
 *         return __pyx_unpickle_XtPlanNd, (type(self), 0x19c6497, None), state
 *     else:
*/
  if (__pyx_v_use_setstate) {

    /* "(tree fragment)":13
 *         use_setstate = self.gpus is not None or self.last_size is not None or self.order is not None or self.shape is not None or self.work_area is not None
 *     if use_setstate:
 *         return __pyx_unpickle_XtPlanNd, (type(self), 0x19c6497, None), state             # <<<<<<<<<<<<<<
 *     else:
 *         return __pyx_unpickle_XtPlanNd, (type(self), 0x19c6497, state)
*/
    __Pyx_XDECREF(__pyx_r);
    __Pyx_GetModuleGlobalName(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_pyx_unpickle_XtPlanNd); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 13, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __pyx_t_6 = PyTuple_New(3); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 13, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_INCREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    __Pyx_GIVEREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 0, ((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self)))) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __Pyx_INCREF(__pyx_mstate_global->__pyx_int_27026583);
    __Pyx_GIVEREF(__pyx_mstate_global->__pyx_int_27026583);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_mstate_global->__pyx_int_27026583) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __Pyx_INCREF(Py_None);
    __Pyx_GIVEREF(Py_None);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 2, Py_None) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __pyx_t_4 = PyTuple_New(3); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 13, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_5);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 0, __pyx_t_5) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_6);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 1, __pyx_t_6) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __Pyx_INCREF(__pyx_v_state);
    __Pyx_GIVEREF(__pyx_v_state);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_4, 2, __pyx_v_state) != (0)) __PYX_ERR(1, 13, __pyx_L1_error);
    __pyx_t_5 = 0;
    __pyx_t_6 = 0;
    __pyx_r = __pyx_t_4;
    __pyx_t_4 = 0;
    goto __pyx_L0;

    /* "(tree fragment)":12
 *     else:
 *         use_setstate = self.gpus is not None or self.last_size is not None or self.order is not None or self.shape is not None or self.work_area is not None
 *     if use_setstate:             # <<<<<<<<<<<<<<
 *         return __pyx_unpickle_XtPlanNd, (type(self), 0x19c6497, None), state
 *     else:
*/
  }

  /* "(tree fragment)":15
 *         return __pyx_unpickle_XtPlanNd, (type(self), 0x19c6497, None), state
 *     else:
 *         return __pyx_unpickle_XtPlanNd, (type(self), 0x19c6497, state)             # <<<<<<<<<<<<<<
 * def __setstate_cython__(self, __pyx_state):
 *     __pyx_unpickle_XtPlanNd__set_state(self, __pyx_state)
*/
  /*else*/ {
    __Pyx_XDECREF(__pyx_r);
    __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_pyx_unpickle_XtPlanNd); if (unlikely(!__pyx_t_4)) __PYX_ERR(1, 15, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __pyx_t_6 = PyTuple_New(3); if (unlikely(!__pyx_t_6)) __PYX_ERR(1, 15, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    __Pyx_INCREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    __Pyx_GIVEREF(((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self))));
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 0, ((PyObject *)Py_TYPE(((PyObject *)__pyx_v_self)))) != (0)) __PYX_ERR(1, 15, __pyx_L1_error);
    __Pyx_INCREF(__pyx_mstate_global->__pyx_int_27026583);
    __Pyx_GIVEREF(__pyx_mstate_global->__pyx_int_27026583);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 1, __pyx_mstate_global->__pyx_int_27026583) != (0)) __PYX_ERR(1, 15, __pyx_L1_error);
    __Pyx_INCREF(__pyx_v_state);
    __Pyx_GIVEREF(__pyx_v_state);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_6, 2, __pyx_v_state) != (0)) __PYX_ERR(1, 15, __pyx_L1_error);
    __pyx_t_5 = PyTuple_New(2); if (unlikely(!__pyx_t_5)) __PYX_ERR(1, 15, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_GIVEREF(__pyx_t_4);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_4) != (0)) __PYX_ERR(1, 15, __pyx_L1_error);
    __Pyx_GIVEREF(__pyx_t_6);
    if (__Pyx_PyTuple_SET_ITEM(__pyx_t_5, 1, __pyx_t_6) != (0)) __PYX_ERR(1, 15, __pyx_L1_error);
    __pyx_t_4 = 0;
    __pyx_t_6 = 0;
    __pyx_r = __pyx_t_5;
    __pyx_t_5 = 0;
    goto __pyx_L0;
  }

  /* "(tree fragment)":1
 * def __reduce_cython__(self):             # <<<<<<<<<<<<<<
 *     cdef tuple state
 *     cdef object _dict
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.__reduce_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_state);
  __Pyx_XDECREF(__pyx_v__dict);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":16
 *     else:
 *         return __pyx_unpickle_XtPlanNd, (type(self), 0x19c6497, state)
 * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_unpickle_XtPlanNd__set_state(self, __pyx_state)
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_19__setstate_cython__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_8XtPlanNd_18__setstate_cython__, "XtPlanNd.__setstate_cython__(self, __pyx_state)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_19__setstate_cython__(PyObject *__pyx_v_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v___pyx_state = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[1] = {0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__setstate_cython__ (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_pyx_state,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(1, 16, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(1, 16, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "__setstate_cython__", 0) < (0)) __PYX_ERR(1, 16, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 1; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("__setstate_cython__", 1, 1, 1, i); __PYX_ERR(1, 16, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 1)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(1, 16, __pyx_L3_error)
    }
    __pyx_v___pyx_state = values[0];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__setstate_cython__", 1, 1, 1, __pyx_nargs); __PYX_ERR(1, 16, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.__setstate_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_18__setstate_cython__(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v_self), __pyx_v___pyx_state);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8XtPlanNd_18__setstate_cython__(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v_self, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__setstate_cython__", 0);

  /* "(tree fragment)":17
 *         return __pyx_unpickle_XtPlanNd, (type(self), 0x19c6497, state)
 * def __setstate_cython__(self, __pyx_state):
 *     __pyx_unpickle_XtPlanNd__set_state(self, __pyx_state)             # <<<<<<<<<<<<<<
*/
  if (!(likely(PyTuple_CheckExact(__pyx_v___pyx_state))||((__pyx_v___pyx_state) == Py_None) || __Pyx_RaiseUnexpectedTypeError("tuple", __pyx_v___pyx_state))) __PYX_ERR(1, 17, __pyx_L1_error)
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft___pyx_unpickle_XtPlanNd__set_state(__pyx_v_self, ((PyObject*)__pyx_v___pyx_state)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 17, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "(tree fragment)":16
 *     else:
 *         return __pyx_unpickle_XtPlanNd, (type(self), 0x19c6497, state)
 * def __setstate_cython__(self, __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_unpickle_XtPlanNd__set_state(self, __pyx_state)
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.XtPlanNd.__setstate_cython__", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1175
 * 
 * 
 * cpdef execC2C(intptr_t plan, intptr_t idata, intptr_t odata, int direction):             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan
 *     cdef int result
*/

static PyObject *__pyx_pw_4cupy_4cuda_5cufft_7execC2C(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_execC2C(intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, int __pyx_v_direction, CYTHON_UNUSED int __pyx_skip_dispatch) {
  cufftHandle __pyx_v_h;
  int __pyx_v_result;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("execC2C", 0);

  /* "cupy/cuda/cufft.pyx":1176
 * 
 * cpdef execC2C(intptr_t plan, intptr_t idata, intptr_t odata, int direction):
 *     cdef Handle h = <Handle>plan             # <<<<<<<<<<<<<<
 *     cdef int result
 * 
*/
  __pyx_v_h = ((cufftHandle)__pyx_v_plan);

  /* "cupy/cuda/cufft.pyx":1179
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftExecC2C(h, <Complex*>idata, <Complex*>odata,
 *                               direction)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":1180
 * 
 *     with nogil:
 *         result = cufftExecC2C(h, <Complex*>idata, <Complex*>odata,             # <<<<<<<<<<<<<<
 *                               direction)
 *     check_result(result)
*/
        __pyx_v_result = cufftExecC2C(__pyx_v_h, ((cufftComplex *)__pyx_v_idata), ((cufftComplex *)__pyx_v_odata), __pyx_v_direction);
      }

      /* "cupy/cuda/cufft.pyx":1179
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftExecC2C(h, <Complex*>idata, <Complex*>odata,
 *                               direction)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "cupy/cuda/cufft.pyx":1182
 *         result = cufftExecC2C(h, <Complex*>idata, <Complex*>odata,
 *                               direction)
 *     check_result(result)             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1182, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1175
 * 
 * 
 * cpdef execC2C(intptr_t plan, intptr_t idata, intptr_t odata, int direction):             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan
 *     cdef int result
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.execC2C", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_7execC2C(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_6execC2C, "execC2C(intptr_t plan, intptr_t idata, intptr_t odata, int direction)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_7execC2C(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  intptr_t __pyx_v_plan;
  intptr_t __pyx_v_idata;
  intptr_t __pyx_v_odata;
  int __pyx_v_direction;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[4] = {0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("execC2C (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_plan,&__pyx_mstate_global->__pyx_n_u_idata,&__pyx_mstate_global->__pyx_n_u_odata,&__pyx_mstate_global->__pyx_n_u_direction,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1175, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  4:
        values[3] = __Pyx_ArgRef_FASTCALL(__pyx_args, 3);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 1175, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1175, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1175, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1175, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "execC2C", 0) < (0)) __PYX_ERR(0, 1175, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 4; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("execC2C", 1, 4, 4, i); __PYX_ERR(0, 1175, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 4)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1175, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1175, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1175, __pyx_L3_error)
      values[3] = __Pyx_ArgRef_FASTCALL(__pyx_args, 3);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 1175, __pyx_L3_error)
    }
    __pyx_v_plan = PyLong_AsSsize_t(values[0]); if (unlikely((__pyx_v_plan == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1175, __pyx_L3_error)
    __pyx_v_idata = PyLong_AsSsize_t(values[1]); if (unlikely((__pyx_v_idata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1175, __pyx_L3_error)
    __pyx_v_odata = PyLong_AsSsize_t(values[2]); if (unlikely((__pyx_v_odata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1175, __pyx_L3_error)
    __pyx_v_direction = __Pyx_PyLong_As_int(values[3]); if (unlikely((__pyx_v_direction == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1175, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("execC2C", 1, 4, 4, __pyx_nargs); __PYX_ERR(0, 1175, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.execC2C", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_6execC2C(__pyx_self, __pyx_v_plan, __pyx_v_idata, __pyx_v_odata, __pyx_v_direction);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_6execC2C(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, int __pyx_v_direction) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("execC2C", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_execC2C(__pyx_v_plan, __pyx_v_idata, __pyx_v_odata, __pyx_v_direction, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1175, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.execC2C", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1185
 * 
 * 
 * cpdef execR2C(intptr_t plan, intptr_t idata, intptr_t odata):             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan
 *     cdef int result
*/

static PyObject *__pyx_pw_4cupy_4cuda_5cufft_9execR2C(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_execR2C(intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, CYTHON_UNUSED int __pyx_skip_dispatch) {
  cufftHandle __pyx_v_h;
  int __pyx_v_result;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("execR2C", 0);

  /* "cupy/cuda/cufft.pyx":1186
 * 
 * cpdef execR2C(intptr_t plan, intptr_t idata, intptr_t odata):
 *     cdef Handle h = <Handle>plan             # <<<<<<<<<<<<<<
 *     cdef int result
 * 
*/
  __pyx_v_h = ((cufftHandle)__pyx_v_plan);

  /* "cupy/cuda/cufft.pyx":1189
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftExecR2C(h, <Float*>idata, <Complex*>odata)
 *     check_result(result)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":1190
 * 
 *     with nogil:
 *         result = cufftExecR2C(h, <Float*>idata, <Complex*>odata)             # <<<<<<<<<<<<<<
 *     check_result(result)
 * 
*/
        __pyx_v_result = cufftExecR2C(__pyx_v_h, ((cufftReal *)__pyx_v_idata), ((cufftComplex *)__pyx_v_odata));
      }

      /* "cupy/cuda/cufft.pyx":1189
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftExecR2C(h, <Float*>idata, <Complex*>odata)
 *     check_result(result)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "cupy/cuda/cufft.pyx":1191
 *     with nogil:
 *         result = cufftExecR2C(h, <Float*>idata, <Complex*>odata)
 *     check_result(result)             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1191, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1185
 * 
 * 
 * cpdef execR2C(intptr_t plan, intptr_t idata, intptr_t odata):             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan
 *     cdef int result
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.execR2C", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_9execR2C(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_8execR2C, "execR2C(intptr_t plan, intptr_t idata, intptr_t odata)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_9execR2C(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  intptr_t __pyx_v_plan;
  intptr_t __pyx_v_idata;
  intptr_t __pyx_v_odata;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("execR2C (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_plan,&__pyx_mstate_global->__pyx_n_u_idata,&__pyx_mstate_global->__pyx_n_u_odata,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1185, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1185, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1185, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1185, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "execR2C", 0) < (0)) __PYX_ERR(0, 1185, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("execR2C", 1, 3, 3, i); __PYX_ERR(0, 1185, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1185, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1185, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1185, __pyx_L3_error)
    }
    __pyx_v_plan = PyLong_AsSsize_t(values[0]); if (unlikely((__pyx_v_plan == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1185, __pyx_L3_error)
    __pyx_v_idata = PyLong_AsSsize_t(values[1]); if (unlikely((__pyx_v_idata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1185, __pyx_L3_error)
    __pyx_v_odata = PyLong_AsSsize_t(values[2]); if (unlikely((__pyx_v_odata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1185, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("execR2C", 1, 3, 3, __pyx_nargs); __PYX_ERR(0, 1185, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.execR2C", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_8execR2C(__pyx_self, __pyx_v_plan, __pyx_v_idata, __pyx_v_odata);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_8execR2C(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("execR2C", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_execR2C(__pyx_v_plan, __pyx_v_idata, __pyx_v_odata, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1185, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.execR2C", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1194
 * 
 * 
 * cpdef execC2R(intptr_t plan, intptr_t idata, intptr_t odata):             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan
 *     cdef int result
*/

static PyObject *__pyx_pw_4cupy_4cuda_5cufft_11execC2R(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_execC2R(intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, CYTHON_UNUSED int __pyx_skip_dispatch) {
  cufftHandle __pyx_v_h;
  int __pyx_v_result;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("execC2R", 0);

  /* "cupy/cuda/cufft.pyx":1195
 * 
 * cpdef execC2R(intptr_t plan, intptr_t idata, intptr_t odata):
 *     cdef Handle h = <Handle>plan             # <<<<<<<<<<<<<<
 *     cdef int result
 * 
*/
  __pyx_v_h = ((cufftHandle)__pyx_v_plan);

  /* "cupy/cuda/cufft.pyx":1198
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftExecC2R(h, <Complex*>idata, <Float*>odata)
 *     check_result(result)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":1199
 * 
 *     with nogil:
 *         result = cufftExecC2R(h, <Complex*>idata, <Float*>odata)             # <<<<<<<<<<<<<<
 *     check_result(result)
 * 
*/
        __pyx_v_result = cufftExecC2R(__pyx_v_h, ((cufftComplex *)__pyx_v_idata), ((cufftReal *)__pyx_v_odata));
      }

      /* "cupy/cuda/cufft.pyx":1198
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftExecC2R(h, <Complex*>idata, <Float*>odata)
 *     check_result(result)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "cupy/cuda/cufft.pyx":1200
 *     with nogil:
 *         result = cufftExecC2R(h, <Complex*>idata, <Float*>odata)
 *     check_result(result)             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1200, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1194
 * 
 * 
 * cpdef execC2R(intptr_t plan, intptr_t idata, intptr_t odata):             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan
 *     cdef int result
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.execC2R", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_11execC2R(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_10execC2R, "execC2R(intptr_t plan, intptr_t idata, intptr_t odata)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_11execC2R(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  intptr_t __pyx_v_plan;
  intptr_t __pyx_v_idata;
  intptr_t __pyx_v_odata;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("execC2R (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_plan,&__pyx_mstate_global->__pyx_n_u_idata,&__pyx_mstate_global->__pyx_n_u_odata,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1194, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1194, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1194, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1194, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "execC2R", 0) < (0)) __PYX_ERR(0, 1194, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("execC2R", 1, 3, 3, i); __PYX_ERR(0, 1194, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1194, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1194, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1194, __pyx_L3_error)
    }
    __pyx_v_plan = PyLong_AsSsize_t(values[0]); if (unlikely((__pyx_v_plan == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1194, __pyx_L3_error)
    __pyx_v_idata = PyLong_AsSsize_t(values[1]); if (unlikely((__pyx_v_idata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1194, __pyx_L3_error)
    __pyx_v_odata = PyLong_AsSsize_t(values[2]); if (unlikely((__pyx_v_odata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1194, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("execC2R", 1, 3, 3, __pyx_nargs); __PYX_ERR(0, 1194, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.execC2R", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_10execC2R(__pyx_self, __pyx_v_plan, __pyx_v_idata, __pyx_v_odata);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_10execC2R(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("execC2R", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_execC2R(__pyx_v_plan, __pyx_v_idata, __pyx_v_odata, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1194, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.execC2R", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1203
 * 
 * 
 * cpdef execZ2Z(intptr_t plan, intptr_t idata, intptr_t odata, int direction):             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan
 *     cdef int result
*/

static PyObject *__pyx_pw_4cupy_4cuda_5cufft_13execZ2Z(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_execZ2Z(intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, int __pyx_v_direction, CYTHON_UNUSED int __pyx_skip_dispatch) {
  cufftHandle __pyx_v_h;
  int __pyx_v_result;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("execZ2Z", 0);

  /* "cupy/cuda/cufft.pyx":1204
 * 
 * cpdef execZ2Z(intptr_t plan, intptr_t idata, intptr_t odata, int direction):
 *     cdef Handle h = <Handle>plan             # <<<<<<<<<<<<<<
 *     cdef int result
 * 
*/
  __pyx_v_h = ((cufftHandle)__pyx_v_plan);

  /* "cupy/cuda/cufft.pyx":1207
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftExecZ2Z(h, <DoubleComplex*>idata,
 *                               <DoubleComplex*>odata, direction)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":1208
 * 
 *     with nogil:
 *         result = cufftExecZ2Z(h, <DoubleComplex*>idata,             # <<<<<<<<<<<<<<
 *                               <DoubleComplex*>odata, direction)
 *     check_result(result)
*/
        __pyx_v_result = cufftExecZ2Z(__pyx_v_h, ((cufftDoubleComplex *)__pyx_v_idata), ((cufftDoubleComplex *)__pyx_v_odata), __pyx_v_direction);
      }

      /* "cupy/cuda/cufft.pyx":1207
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftExecZ2Z(h, <DoubleComplex*>idata,
 *                               <DoubleComplex*>odata, direction)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "cupy/cuda/cufft.pyx":1210
 *         result = cufftExecZ2Z(h, <DoubleComplex*>idata,
 *                               <DoubleComplex*>odata, direction)
 *     check_result(result)             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1210, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1203
 * 
 * 
 * cpdef execZ2Z(intptr_t plan, intptr_t idata, intptr_t odata, int direction):             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan
 *     cdef int result
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.execZ2Z", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_13execZ2Z(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_12execZ2Z, "execZ2Z(intptr_t plan, intptr_t idata, intptr_t odata, int direction)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_13execZ2Z(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  intptr_t __pyx_v_plan;
  intptr_t __pyx_v_idata;
  intptr_t __pyx_v_odata;
  int __pyx_v_direction;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[4] = {0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("execZ2Z (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_plan,&__pyx_mstate_global->__pyx_n_u_idata,&__pyx_mstate_global->__pyx_n_u_odata,&__pyx_mstate_global->__pyx_n_u_direction,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1203, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  4:
        values[3] = __Pyx_ArgRef_FASTCALL(__pyx_args, 3);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 1203, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1203, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1203, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1203, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "execZ2Z", 0) < (0)) __PYX_ERR(0, 1203, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 4; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("execZ2Z", 1, 4, 4, i); __PYX_ERR(0, 1203, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 4)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1203, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1203, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1203, __pyx_L3_error)
      values[3] = __Pyx_ArgRef_FASTCALL(__pyx_args, 3);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 1203, __pyx_L3_error)
    }
    __pyx_v_plan = PyLong_AsSsize_t(values[0]); if (unlikely((__pyx_v_plan == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1203, __pyx_L3_error)
    __pyx_v_idata = PyLong_AsSsize_t(values[1]); if (unlikely((__pyx_v_idata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1203, __pyx_L3_error)
    __pyx_v_odata = PyLong_AsSsize_t(values[2]); if (unlikely((__pyx_v_odata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1203, __pyx_L3_error)
    __pyx_v_direction = __Pyx_PyLong_As_int(values[3]); if (unlikely((__pyx_v_direction == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1203, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("execZ2Z", 1, 4, 4, __pyx_nargs); __PYX_ERR(0, 1203, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.execZ2Z", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_12execZ2Z(__pyx_self, __pyx_v_plan, __pyx_v_idata, __pyx_v_odata, __pyx_v_direction);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_12execZ2Z(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, int __pyx_v_direction) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("execZ2Z", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_execZ2Z(__pyx_v_plan, __pyx_v_idata, __pyx_v_odata, __pyx_v_direction, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1203, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.execZ2Z", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1213
 * 
 * 
 * cpdef execD2Z(intptr_t plan, intptr_t idata, intptr_t odata):             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan
 *     cdef int result
*/

static PyObject *__pyx_pw_4cupy_4cuda_5cufft_15execD2Z(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_execD2Z(intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, CYTHON_UNUSED int __pyx_skip_dispatch) {
  cufftHandle __pyx_v_h;
  int __pyx_v_result;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("execD2Z", 0);

  /* "cupy/cuda/cufft.pyx":1214
 * 
 * cpdef execD2Z(intptr_t plan, intptr_t idata, intptr_t odata):
 *     cdef Handle h = <Handle>plan             # <<<<<<<<<<<<<<
 *     cdef int result
 * 
*/
  __pyx_v_h = ((cufftHandle)__pyx_v_plan);

  /* "cupy/cuda/cufft.pyx":1217
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftExecD2Z(h, <Double*>idata, <DoubleComplex*>odata)
 *     check_result(result)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":1218
 * 
 *     with nogil:
 *         result = cufftExecD2Z(h, <Double*>idata, <DoubleComplex*>odata)             # <<<<<<<<<<<<<<
 *     check_result(result)
 * 
*/
        __pyx_v_result = cufftExecD2Z(__pyx_v_h, ((cufftDoubleReal *)__pyx_v_idata), ((cufftDoubleComplex *)__pyx_v_odata));
      }

      /* "cupy/cuda/cufft.pyx":1217
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftExecD2Z(h, <Double*>idata, <DoubleComplex*>odata)
 *     check_result(result)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "cupy/cuda/cufft.pyx":1219
 *     with nogil:
 *         result = cufftExecD2Z(h, <Double*>idata, <DoubleComplex*>odata)
 *     check_result(result)             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1219, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1213
 * 
 * 
 * cpdef execD2Z(intptr_t plan, intptr_t idata, intptr_t odata):             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan
 *     cdef int result
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.execD2Z", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_15execD2Z(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_14execD2Z, "execD2Z(intptr_t plan, intptr_t idata, intptr_t odata)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_15execD2Z(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  intptr_t __pyx_v_plan;
  intptr_t __pyx_v_idata;
  intptr_t __pyx_v_odata;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("execD2Z (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_plan,&__pyx_mstate_global->__pyx_n_u_idata,&__pyx_mstate_global->__pyx_n_u_odata,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1213, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1213, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1213, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1213, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "execD2Z", 0) < (0)) __PYX_ERR(0, 1213, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("execD2Z", 1, 3, 3, i); __PYX_ERR(0, 1213, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1213, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1213, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1213, __pyx_L3_error)
    }
    __pyx_v_plan = PyLong_AsSsize_t(values[0]); if (unlikely((__pyx_v_plan == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1213, __pyx_L3_error)
    __pyx_v_idata = PyLong_AsSsize_t(values[1]); if (unlikely((__pyx_v_idata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1213, __pyx_L3_error)
    __pyx_v_odata = PyLong_AsSsize_t(values[2]); if (unlikely((__pyx_v_odata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1213, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("execD2Z", 1, 3, 3, __pyx_nargs); __PYX_ERR(0, 1213, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.execD2Z", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_14execD2Z(__pyx_self, __pyx_v_plan, __pyx_v_idata, __pyx_v_odata);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_14execD2Z(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("execD2Z", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_execD2Z(__pyx_v_plan, __pyx_v_idata, __pyx_v_odata, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1213, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.execD2Z", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1222
 * 
 * 
 * cpdef execZ2D(intptr_t plan, intptr_t idata, intptr_t odata):             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan
 *     cdef int result
*/

static PyObject *__pyx_pw_4cupy_4cuda_5cufft_17execZ2D(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_execZ2D(intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, CYTHON_UNUSED int __pyx_skip_dispatch) {
  cufftHandle __pyx_v_h;
  int __pyx_v_result;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("execZ2D", 0);

  /* "cupy/cuda/cufft.pyx":1223
 * 
 * cpdef execZ2D(intptr_t plan, intptr_t idata, intptr_t odata):
 *     cdef Handle h = <Handle>plan             # <<<<<<<<<<<<<<
 *     cdef int result
 * 
*/
  __pyx_v_h = ((cufftHandle)__pyx_v_plan);

  /* "cupy/cuda/cufft.pyx":1226
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftExecZ2D(h, <DoubleComplex*>idata, <Double*>odata)
 *     check_result(result)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":1227
 * 
 *     with nogil:
 *         result = cufftExecZ2D(h, <DoubleComplex*>idata, <Double*>odata)             # <<<<<<<<<<<<<<
 *     check_result(result)
 * 
*/
        __pyx_v_result = cufftExecZ2D(__pyx_v_h, ((cufftDoubleComplex *)__pyx_v_idata), ((cufftDoubleReal *)__pyx_v_odata));
      }

      /* "cupy/cuda/cufft.pyx":1226
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftExecZ2D(h, <DoubleComplex*>idata, <Double*>odata)
 *     check_result(result)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "cupy/cuda/cufft.pyx":1228
 *     with nogil:
 *         result = cufftExecZ2D(h, <DoubleComplex*>idata, <Double*>odata)
 *     check_result(result)             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1228, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1222
 * 
 * 
 * cpdef execZ2D(intptr_t plan, intptr_t idata, intptr_t odata):             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan
 *     cdef int result
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.execZ2D", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_17execZ2D(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_16execZ2D, "execZ2D(intptr_t plan, intptr_t idata, intptr_t odata)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_17execZ2D(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  intptr_t __pyx_v_plan;
  intptr_t __pyx_v_idata;
  intptr_t __pyx_v_odata;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("execZ2D (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_plan,&__pyx_mstate_global->__pyx_n_u_idata,&__pyx_mstate_global->__pyx_n_u_odata,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1222, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1222, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1222, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1222, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "execZ2D", 0) < (0)) __PYX_ERR(0, 1222, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("execZ2D", 1, 3, 3, i); __PYX_ERR(0, 1222, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1222, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1222, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1222, __pyx_L3_error)
    }
    __pyx_v_plan = PyLong_AsSsize_t(values[0]); if (unlikely((__pyx_v_plan == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1222, __pyx_L3_error)
    __pyx_v_idata = PyLong_AsSsize_t(values[1]); if (unlikely((__pyx_v_idata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1222, __pyx_L3_error)
    __pyx_v_odata = PyLong_AsSsize_t(values[2]); if (unlikely((__pyx_v_odata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1222, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("execZ2D", 1, 3, 3, __pyx_nargs); __PYX_ERR(0, 1222, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.execZ2D", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_16execZ2D(__pyx_self, __pyx_v_plan, __pyx_v_idata, __pyx_v_odata);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_16execZ2D(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("execZ2D", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_execZ2D(__pyx_v_plan, __pyx_v_idata, __pyx_v_odata, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1222, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.execZ2D", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1231
 * 
 * 
 * cpdef multi_gpu_execC2C(intptr_t plan, intptr_t idata, intptr_t odata,             # <<<<<<<<<<<<<<
 *                         int direction):
 *     cdef Handle h = <Handle>plan
*/

static PyObject *__pyx_pw_4cupy_4cuda_5cufft_19multi_gpu_execC2C(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_multi_gpu_execC2C(intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, int __pyx_v_direction, CYTHON_UNUSED int __pyx_skip_dispatch) {
  cufftHandle __pyx_v_h;
  int __pyx_v_result;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("multi_gpu_execC2C", 0);

  /* "cupy/cuda/cufft.pyx":1233
 * cpdef multi_gpu_execC2C(intptr_t plan, intptr_t idata, intptr_t odata,
 *                         int direction):
 *     cdef Handle h = <Handle>plan             # <<<<<<<<<<<<<<
 *     cdef int result
 * 
*/
  __pyx_v_h = ((cufftHandle)__pyx_v_plan);

  /* "cupy/cuda/cufft.pyx":1236
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftXtExecDescriptorC2C(h, <XtArray*>idata,
 *                                           <XtArray*>odata, direction)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":1237
 * 
 *     with nogil:
 *         result = cufftXtExecDescriptorC2C(h, <XtArray*>idata,             # <<<<<<<<<<<<<<
 *                                           <XtArray*>odata, direction)
 *     check_result(result)
*/
        __pyx_v_result = cufftXtExecDescriptorC2C(__pyx_v_h, ((cudaLibXtDesc *)__pyx_v_idata), ((cudaLibXtDesc *)__pyx_v_odata), __pyx_v_direction);
      }

      /* "cupy/cuda/cufft.pyx":1236
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftXtExecDescriptorC2C(h, <XtArray*>idata,
 *                                           <XtArray*>odata, direction)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "cupy/cuda/cufft.pyx":1239
 *         result = cufftXtExecDescriptorC2C(h, <XtArray*>idata,
 *                                           <XtArray*>odata, direction)
 *     check_result(result)             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1239, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1231
 * 
 * 
 * cpdef multi_gpu_execC2C(intptr_t plan, intptr_t idata, intptr_t odata,             # <<<<<<<<<<<<<<
 *                         int direction):
 *     cdef Handle h = <Handle>plan
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.multi_gpu_execC2C", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_19multi_gpu_execC2C(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_18multi_gpu_execC2C, "multi_gpu_execC2C(intptr_t plan, intptr_t idata, intptr_t odata, int direction)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_19multi_gpu_execC2C(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  intptr_t __pyx_v_plan;
  intptr_t __pyx_v_idata;
  intptr_t __pyx_v_odata;
  int __pyx_v_direction;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[4] = {0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("multi_gpu_execC2C (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_plan,&__pyx_mstate_global->__pyx_n_u_idata,&__pyx_mstate_global->__pyx_n_u_odata,&__pyx_mstate_global->__pyx_n_u_direction,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1231, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  4:
        values[3] = __Pyx_ArgRef_FASTCALL(__pyx_args, 3);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 1231, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1231, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1231, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1231, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "multi_gpu_execC2C", 0) < (0)) __PYX_ERR(0, 1231, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 4; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("multi_gpu_execC2C", 1, 4, 4, i); __PYX_ERR(0, 1231, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 4)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1231, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1231, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1231, __pyx_L3_error)
      values[3] = __Pyx_ArgRef_FASTCALL(__pyx_args, 3);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 1231, __pyx_L3_error)
    }
    __pyx_v_plan = PyLong_AsSsize_t(values[0]); if (unlikely((__pyx_v_plan == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1231, __pyx_L3_error)
    __pyx_v_idata = PyLong_AsSsize_t(values[1]); if (unlikely((__pyx_v_idata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1231, __pyx_L3_error)
    __pyx_v_odata = PyLong_AsSsize_t(values[2]); if (unlikely((__pyx_v_odata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1231, __pyx_L3_error)
    __pyx_v_direction = __Pyx_PyLong_As_int(values[3]); if (unlikely((__pyx_v_direction == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1232, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("multi_gpu_execC2C", 1, 4, 4, __pyx_nargs); __PYX_ERR(0, 1231, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.multi_gpu_execC2C", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_18multi_gpu_execC2C(__pyx_self, __pyx_v_plan, __pyx_v_idata, __pyx_v_odata, __pyx_v_direction);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_18multi_gpu_execC2C(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, int __pyx_v_direction) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("multi_gpu_execC2C", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_multi_gpu_execC2C(__pyx_v_plan, __pyx_v_idata, __pyx_v_odata, __pyx_v_direction, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1231, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.multi_gpu_execC2C", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1242
 * 
 * 
 * cpdef multi_gpu_execZ2Z(intptr_t plan, intptr_t idata, intptr_t odata,             # <<<<<<<<<<<<<<
 *                         int direction):
 *     cdef Handle h = <Handle>plan
*/

static PyObject *__pyx_pw_4cupy_4cuda_5cufft_21multi_gpu_execZ2Z(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_multi_gpu_execZ2Z(intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, int __pyx_v_direction, CYTHON_UNUSED int __pyx_skip_dispatch) {
  cufftHandle __pyx_v_h;
  int __pyx_v_result;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("multi_gpu_execZ2Z", 0);

  /* "cupy/cuda/cufft.pyx":1244
 * cpdef multi_gpu_execZ2Z(intptr_t plan, intptr_t idata, intptr_t odata,
 *                         int direction):
 *     cdef Handle h = <Handle>plan             # <<<<<<<<<<<<<<
 *     cdef int result
 * 
*/
  __pyx_v_h = ((cufftHandle)__pyx_v_plan);

  /* "cupy/cuda/cufft.pyx":1247
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftXtExecDescriptorZ2Z(h, <XtArray*>idata,
 *                                           <XtArray*>odata, direction)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":1248
 * 
 *     with nogil:
 *         result = cufftXtExecDescriptorZ2Z(h, <XtArray*>idata,             # <<<<<<<<<<<<<<
 *                                           <XtArray*>odata, direction)
 *     check_result(result)
*/
        __pyx_v_result = cufftXtExecDescriptorZ2Z(__pyx_v_h, ((cudaLibXtDesc *)__pyx_v_idata), ((cudaLibXtDesc *)__pyx_v_odata), __pyx_v_direction);
      }

      /* "cupy/cuda/cufft.pyx":1247
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftXtExecDescriptorZ2Z(h, <XtArray*>idata,
 *                                           <XtArray*>odata, direction)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "cupy/cuda/cufft.pyx":1250
 *         result = cufftXtExecDescriptorZ2Z(h, <XtArray*>idata,
 *                                           <XtArray*>odata, direction)
 *     check_result(result)             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1250, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1242
 * 
 * 
 * cpdef multi_gpu_execZ2Z(intptr_t plan, intptr_t idata, intptr_t odata,             # <<<<<<<<<<<<<<
 *                         int direction):
 *     cdef Handle h = <Handle>plan
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.multi_gpu_execZ2Z", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_21multi_gpu_execZ2Z(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_20multi_gpu_execZ2Z, "multi_gpu_execZ2Z(intptr_t plan, intptr_t idata, intptr_t odata, int direction)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_21multi_gpu_execZ2Z(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  intptr_t __pyx_v_plan;
  intptr_t __pyx_v_idata;
  intptr_t __pyx_v_odata;
  int __pyx_v_direction;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[4] = {0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("multi_gpu_execZ2Z (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_plan,&__pyx_mstate_global->__pyx_n_u_idata,&__pyx_mstate_global->__pyx_n_u_odata,&__pyx_mstate_global->__pyx_n_u_direction,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1242, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  4:
        values[3] = __Pyx_ArgRef_FASTCALL(__pyx_args, 3);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 1242, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1242, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1242, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1242, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "multi_gpu_execZ2Z", 0) < (0)) __PYX_ERR(0, 1242, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 4; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("multi_gpu_execZ2Z", 1, 4, 4, i); __PYX_ERR(0, 1242, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 4)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1242, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1242, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1242, __pyx_L3_error)
      values[3] = __Pyx_ArgRef_FASTCALL(__pyx_args, 3);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 1242, __pyx_L3_error)
    }
    __pyx_v_plan = PyLong_AsSsize_t(values[0]); if (unlikely((__pyx_v_plan == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1242, __pyx_L3_error)
    __pyx_v_idata = PyLong_AsSsize_t(values[1]); if (unlikely((__pyx_v_idata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1242, __pyx_L3_error)
    __pyx_v_odata = PyLong_AsSsize_t(values[2]); if (unlikely((__pyx_v_odata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1242, __pyx_L3_error)
    __pyx_v_direction = __Pyx_PyLong_As_int(values[3]); if (unlikely((__pyx_v_direction == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1243, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("multi_gpu_execZ2Z", 1, 4, 4, __pyx_nargs); __PYX_ERR(0, 1242, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.multi_gpu_execZ2Z", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_20multi_gpu_execZ2Z(__pyx_self, __pyx_v_plan, __pyx_v_idata, __pyx_v_odata, __pyx_v_direction);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_20multi_gpu_execZ2Z(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, int __pyx_v_direction) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("multi_gpu_execZ2Z", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_multi_gpu_execZ2Z(__pyx_v_plan, __pyx_v_idata, __pyx_v_odata, __pyx_v_direction, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1242, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.multi_gpu_execZ2Z", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1253
 * 
 * 
 * cpdef XtExec(intptr_t plan, intptr_t idata, intptr_t odata, int direction):             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan
 *     cdef int result
*/

static PyObject *__pyx_pw_4cupy_4cuda_5cufft_23XtExec(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
static PyObject *__pyx_f_4cupy_4cuda_5cufft_XtExec(intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, int __pyx_v_direction, CYTHON_UNUSED int __pyx_skip_dispatch) {
  cufftHandle __pyx_v_h;
  int __pyx_v_result;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("XtExec", 0);

  /* "cupy/cuda/cufft.pyx":1254
 * 
 * cpdef XtExec(intptr_t plan, intptr_t idata, intptr_t odata, int direction):
 *     cdef Handle h = <Handle>plan             # <<<<<<<<<<<<<<
 *     cdef int result
 * 
*/
  __pyx_v_h = ((cufftHandle)__pyx_v_plan);

  /* "cupy/cuda/cufft.pyx":1257
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftXtExec(h, <void*>idata, <void*>odata, direction)
 *     check_result(result)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":1258
 * 
 *     with nogil:
 *         result = cufftXtExec(h, <void*>idata, <void*>odata, direction)             # <<<<<<<<<<<<<<
 *     check_result(result)
 * 
*/
        __pyx_v_result = cufftXtExec(__pyx_v_h, ((void *)__pyx_v_idata), ((void *)__pyx_v_odata), __pyx_v_direction);
      }

      /* "cupy/cuda/cufft.pyx":1257
 *     cdef int result
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftXtExec(h, <void*>idata, <void*>odata, direction)
 *     check_result(result)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "cupy/cuda/cufft.pyx":1259
 *     with nogil:
 *         result = cufftXtExec(h, <void*>idata, <void*>odata, direction)
 *     check_result(result)             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1259, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1253
 * 
 * 
 * cpdef XtExec(intptr_t plan, intptr_t idata, intptr_t odata, int direction):             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan
 *     cdef int result
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.XtExec", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_23XtExec(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_22XtExec, "XtExec(intptr_t plan, intptr_t idata, intptr_t odata, int direction)");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_23XtExec(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  intptr_t __pyx_v_plan;
  intptr_t __pyx_v_idata;
  intptr_t __pyx_v_odata;
  int __pyx_v_direction;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[4] = {0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("XtExec (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_plan,&__pyx_mstate_global->__pyx_n_u_idata,&__pyx_mstate_global->__pyx_n_u_odata,&__pyx_mstate_global->__pyx_n_u_direction,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1253, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  4:
        values[3] = __Pyx_ArgRef_FASTCALL(__pyx_args, 3);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 1253, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1253, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1253, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1253, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "XtExec", 0) < (0)) __PYX_ERR(0, 1253, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 4; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("XtExec", 1, 4, 4, i); __PYX_ERR(0, 1253, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 4)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1253, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1253, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1253, __pyx_L3_error)
      values[3] = __Pyx_ArgRef_FASTCALL(__pyx_args, 3);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 1253, __pyx_L3_error)
    }
    __pyx_v_plan = PyLong_AsSsize_t(values[0]); if (unlikely((__pyx_v_plan == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1253, __pyx_L3_error)
    __pyx_v_idata = PyLong_AsSsize_t(values[1]); if (unlikely((__pyx_v_idata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1253, __pyx_L3_error)
    __pyx_v_odata = PyLong_AsSsize_t(values[2]); if (unlikely((__pyx_v_odata == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1253, __pyx_L3_error)
    __pyx_v_direction = __Pyx_PyLong_As_int(values[3]); if (unlikely((__pyx_v_direction == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1253, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("XtExec", 1, 4, 4, __pyx_nargs); __PYX_ERR(0, 1253, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.XtExec", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_22XtExec(__pyx_self, __pyx_v_plan, __pyx_v_idata, __pyx_v_odata, __pyx_v_direction);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_22XtExec(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, intptr_t __pyx_v_idata, intptr_t __pyx_v_odata, int __pyx_v_direction) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("XtExec", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_XtExec(__pyx_v_plan, __pyx_v_idata, __pyx_v_odata, __pyx_v_direction, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1253, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.XtExec", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1262
 * 
 * 
 * cpdef intptr_t setCallback(             # <<<<<<<<<<<<<<
 *         intptr_t plan, int cb_type, bint is_load,
 *         intptr_t aux_arr=0) except?-1:
*/

static PyObject *__pyx_pw_4cupy_4cuda_5cufft_25setCallback(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
static intptr_t __pyx_f_4cupy_4cuda_5cufft_setCallback(intptr_t __pyx_v_plan, CYTHON_UNUSED int __pyx_v_cb_type, CYTHON_UNUSED int __pyx_v_is_load, CYTHON_UNUSED int __pyx_skip_dispatch, struct __pyx_opt_args_4cupy_4cuda_5cufft_setCallback *__pyx_optional_args) {
  CYTHON_UNUSED cufftHandle __pyx_v_h;
  intptr_t __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  size_t __pyx_t_4;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("setCallback", 0);
  if (__pyx_optional_args) {
  }

  /* "cupy/cuda/cufft.pyx":1265
 *         intptr_t plan, int cb_type, bint is_load,
 *         intptr_t aux_arr=0) except?-1:
 *     cdef Handle h = <Handle>plan  # no-cython-lint             # <<<<<<<<<<<<<<
 *     cdef int result  # no-cython-lint
 *     cdef void** callerInfo  # no-cython-lint
*/
  __pyx_v_h = ((cufftHandle)__pyx_v_plan);

  /* "cupy/cuda/cufft.pyx":1279
 *         check_result(result)
 *     ELSE:
 *         raise RuntimeError('cuFFT is dynamically linked and thus does not '             # <<<<<<<<<<<<<<
 *                            'support callback')
 * 
*/
  __pyx_t_2 = NULL;
  __Pyx_INCREF(__pyx_builtin_RuntimeError);
  __pyx_t_3 = __pyx_builtin_RuntimeError; 
  __pyx_t_4 = 1;
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_2, __pyx_mstate_global->__pyx_kp_u_cuFFT_is_dynamically_linked_and};
    __pyx_t_1 = __Pyx_PyObject_FastCall(__pyx_t_3, __pyx_callargs+__pyx_t_4, (2-__pyx_t_4) | (__pyx_t_4*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1279, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  __Pyx_Raise(__pyx_t_1, 0, 0, 0);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __PYX_ERR(0, 1279, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1262
 * 
 * 
 * cpdef intptr_t setCallback(             # <<<<<<<<<<<<<<
 *         intptr_t plan, int cb_type, bint is_load,
 *         intptr_t aux_arr=0) except?-1:
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("cupy.cuda.cufft.setCallback", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_25setCallback(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_24setCallback, "setCallback(intptr_t plan, int cb_type, bool is_load, intptr_t aux_arr=0) -> intptr_t");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_25setCallback(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  intptr_t __pyx_v_plan;
  int __pyx_v_cb_type;
  int __pyx_v_is_load;
  intptr_t __pyx_v_aux_arr;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[4] = {0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("setCallback (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_plan,&__pyx_mstate_global->__pyx_n_u_cb_type,&__pyx_mstate_global->__pyx_n_u_is_load,&__pyx_mstate_global->__pyx_n_u_aux_arr,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1262, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  4:
        values[3] = __Pyx_ArgRef_FASTCALL(__pyx_args, 3);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 1262, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1262, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1262, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1262, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "setCallback", 0) < (0)) __PYX_ERR(0, 1262, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("setCallback", 0, 3, 4, i); __PYX_ERR(0, 1262, __pyx_L3_error) }
      }
    } else {
      switch (__pyx_nargs) {
        case  4:
        values[3] = __Pyx_ArgRef_FASTCALL(__pyx_args, 3);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 1262, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1262, __pyx_L3_error)
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1262, __pyx_L3_error)
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1262, __pyx_L3_error)
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_plan = PyLong_AsSsize_t(values[0]); if (unlikely((__pyx_v_plan == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1263, __pyx_L3_error)
    __pyx_v_cb_type = __Pyx_PyLong_As_int(values[1]); if (unlikely((__pyx_v_cb_type == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1263, __pyx_L3_error)
    __pyx_v_is_load = __Pyx_PyObject_IsTrue(values[2]); if (unlikely((__pyx_v_is_load == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1263, __pyx_L3_error)
    if (values[3]) {
      __pyx_v_aux_arr = PyLong_AsSsize_t(values[3]); if (unlikely((__pyx_v_aux_arr == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1264, __pyx_L3_error)
    } else {
      __pyx_v_aux_arr = ((intptr_t)0);
    }
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("setCallback", 0, 3, 4, __pyx_nargs); __PYX_ERR(0, 1262, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.setCallback", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_24setCallback(__pyx_self, __pyx_v_plan, __pyx_v_cb_type, __pyx_v_is_load, __pyx_v_aux_arr);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_24setCallback(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, int __pyx_v_cb_type, int __pyx_v_is_load, intptr_t __pyx_v_aux_arr) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  intptr_t __pyx_t_1;
  struct __pyx_opt_args_4cupy_4cuda_5cufft_setCallback __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("setCallback", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_2.__pyx_n = 1;
  __pyx_t_2.aux_arr = __pyx_v_aux_arr;
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_setCallback(__pyx_v_plan, __pyx_v_cb_type, __pyx_v_is_load, 1, &__pyx_t_2); if (unlikely(__pyx_t_1 == ((intptr_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1262, __pyx_L1_error)
  __pyx_t_3 = PyLong_FromSsize_t(__pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 1262, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_r = __pyx_t_3;
  __pyx_t_3 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("cupy.cuda.cufft.setCallback", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1283
 * 
 * 
 * cpdef intptr_t create() except?-1:             # <<<<<<<<<<<<<<
 *     cdef Handle plan
 *     with nogil:
*/

static PyObject *__pyx_pw_4cupy_4cuda_5cufft_27create(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
static intptr_t __pyx_f_4cupy_4cuda_5cufft_create(CYTHON_UNUSED int __pyx_skip_dispatch) {
  cufftHandle __pyx_v_plan;
  cufftResult_t __pyx_v_result;
  intptr_t __pyx_r;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;

  /* "cupy/cuda/cufft.pyx":1285
 * cpdef intptr_t create() except?-1:
 *     cdef Handle plan
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftCreate(&plan)
 *     check_result(result)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":1286
 *     cdef Handle plan
 *     with nogil:
 *         result = cufftCreate(&plan)             # <<<<<<<<<<<<<<
 *     check_result(result)
 *     return <intptr_t>plan
*/
        __pyx_v_result = cufftCreate((&__pyx_v_plan));
      }

      /* "cupy/cuda/cufft.pyx":1285
 * cpdef intptr_t create() except?-1:
 *     cdef Handle plan
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftCreate(&plan)
 *     check_result(result)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "cupy/cuda/cufft.pyx":1287
 *     with nogil:
 *         result = cufftCreate(&plan)
 *     check_result(result)             # <<<<<<<<<<<<<<
 *     return <intptr_t>plan
 * 
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1287, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1288
 *         result = cufftCreate(&plan)
 *     check_result(result)
 *     return <intptr_t>plan             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_r = ((intptr_t)__pyx_v_plan);
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":1283
 * 
 * 
 * cpdef intptr_t create() except?-1:             # <<<<<<<<<<<<<<
 *     cdef Handle plan
 *     with nogil:
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.create", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_27create(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_26create, "create() -> intptr_t");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_27create(PyObject *__pyx_self, CYTHON_UNUSED PyObject *unused) {
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("create (wrapper)", 0);
  __pyx_kwvalues = __Pyx_KwValues_VARARGS(__pyx_args, __pyx_nargs);
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_26create(__pyx_self);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_26create(CYTHON_UNUSED PyObject *__pyx_self) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  intptr_t __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("create", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_create(1); if (unlikely(__pyx_t_1 == ((intptr_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 1283, __pyx_L1_error)
  __pyx_t_2 = PyLong_FromSsize_t(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1283, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("cupy.cuda.cufft.create", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1291
 * 
 * 
 * cpdef int setAutoAllocation(intptr_t plan, int autoAllocate) except?-1:             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan
 *     with nogil:
*/

static PyObject *__pyx_pw_4cupy_4cuda_5cufft_29setAutoAllocation(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
static int __pyx_f_4cupy_4cuda_5cufft_setAutoAllocation(intptr_t __pyx_v_plan, int __pyx_v_autoAllocate, CYTHON_UNUSED int __pyx_skip_dispatch) {
  cufftHandle __pyx_v_h;
  cufftResult_t __pyx_v_result;
  int __pyx_r;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;

  /* "cupy/cuda/cufft.pyx":1292
 * 
 * cpdef int setAutoAllocation(intptr_t plan, int autoAllocate) except?-1:
 *     cdef Handle h = <Handle>plan             # <<<<<<<<<<<<<<
 *     with nogil:
 *         result = cufftSetAutoAllocation(h, autoAllocate)
*/
  __pyx_v_h = ((cufftHandle)__pyx_v_plan);

  /* "cupy/cuda/cufft.pyx":1293
 * cpdef int setAutoAllocation(intptr_t plan, int autoAllocate) except?-1:
 *     cdef Handle h = <Handle>plan
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftSetAutoAllocation(h, autoAllocate)
 *     check_result(result)
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":1294
 *     cdef Handle h = <Handle>plan
 *     with nogil:
 *         result = cufftSetAutoAllocation(h, autoAllocate)             # <<<<<<<<<<<<<<
 *     check_result(result)
 *     return 0
*/
        __pyx_v_result = cufftSetAutoAllocation(__pyx_v_h, __pyx_v_autoAllocate);
      }

      /* "cupy/cuda/cufft.pyx":1293
 * cpdef int setAutoAllocation(intptr_t plan, int autoAllocate) except?-1:
 *     cdef Handle h = <Handle>plan
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = cufftSetAutoAllocation(h, autoAllocate)
 *     check_result(result)
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "cupy/cuda/cufft.pyx":1295
 *     with nogil:
 *         result = cufftSetAutoAllocation(h, autoAllocate)
 *     check_result(result)             # <<<<<<<<<<<<<<
 *     return 0
 * 
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1295, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1296
 *         result = cufftSetAutoAllocation(h, autoAllocate)
 *     check_result(result)
 *     return 0             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_r = 0;
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":1291
 * 
 * 
 * cpdef int setAutoAllocation(intptr_t plan, int autoAllocate) except?-1:             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan
 *     with nogil:
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_AddTraceback("cupy.cuda.cufft.setAutoAllocation", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_29setAutoAllocation(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_28setAutoAllocation, "setAutoAllocation(intptr_t plan, int autoAllocate) -> int");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_29setAutoAllocation(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  intptr_t __pyx_v_plan;
  int __pyx_v_autoAllocate;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[2] = {0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("setAutoAllocation (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_plan,&__pyx_mstate_global->__pyx_n_u_autoAllocate,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1291, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1291, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1291, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "setAutoAllocation", 0) < (0)) __PYX_ERR(0, 1291, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 2; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("setAutoAllocation", 1, 2, 2, i); __PYX_ERR(0, 1291, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 2)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1291, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1291, __pyx_L3_error)
    }
    __pyx_v_plan = PyLong_AsSsize_t(values[0]); if (unlikely((__pyx_v_plan == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1291, __pyx_L3_error)
    __pyx_v_autoAllocate = __Pyx_PyLong_As_int(values[1]); if (unlikely((__pyx_v_autoAllocate == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1291, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("setAutoAllocation", 1, 2, 2, __pyx_nargs); __PYX_ERR(0, 1291, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.setAutoAllocation", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_28setAutoAllocation(__pyx_self, __pyx_v_plan, __pyx_v_autoAllocate);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_28setAutoAllocation(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, int __pyx_v_autoAllocate) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("setAutoAllocation", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_setAutoAllocation(__pyx_v_plan, __pyx_v_autoAllocate, 1); if (unlikely(__pyx_t_1 == ((int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1291, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1291, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("cupy.cuda.cufft.setAutoAllocation", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "cupy/cuda/cufft.pyx":1299
 * 
 * 
 * cpdef int setJITCallback(             # <<<<<<<<<<<<<<
 *         intptr_t plan, str callback_name, bytes callback, int callback_type,
 *         intptr_t caller_info) except?-1:
*/

static PyObject *__pyx_pw_4cupy_4cuda_5cufft_31setJITCallback(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
static int __pyx_f_4cupy_4cuda_5cufft_setJITCallback(intptr_t __pyx_v_plan, PyObject *__pyx_v_callback_name, PyObject *__pyx_v_callback, int __pyx_v_callback_type, intptr_t __pyx_v_caller_info, CYTHON_UNUSED int __pyx_skip_dispatch) {
  cufftHandle __pyx_v_h;
  PyObject *__pyx_v_callback_name_data = 0;
  char *__pyx_v_callback_name_ptr;
  char *__pyx_v_callback_ptr;
  size_t __pyx_v_callback_size;
  void *__pyx_v_caller_info_ptr;
  cufftResult_t __pyx_v_result;
  int __pyx_r;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  char *__pyx_t_2;
  Py_ssize_t __pyx_t_3;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("setJITCallback", 0);

  /* "cupy/cuda/cufft.pyx":1302
 *         intptr_t plan, str callback_name, bytes callback, int callback_type,
 *         intptr_t caller_info) except?-1:
 *     initialize()             # <<<<<<<<<<<<<<
 *     cdef Handle h = <Handle>plan  # no-cython-lint
 *     cdef bytes callback_name_data = callback_name.encode()
*/
  __pyx_f_4cupy_4cuda_5cufft_initialize(); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1302, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1303
 *         intptr_t caller_info) except?-1:
 *     initialize()
 *     cdef Handle h = <Handle>plan  # no-cython-lint             # <<<<<<<<<<<<<<
 *     cdef bytes callback_name_data = callback_name.encode()
 *     cdef char* callback_name_ptr = callback_name_data
*/
  __pyx_v_h = ((cufftHandle)__pyx_v_plan);

  /* "cupy/cuda/cufft.pyx":1304
 *     initialize()
 *     cdef Handle h = <Handle>plan  # no-cython-lint
 *     cdef bytes callback_name_data = callback_name.encode()             # <<<<<<<<<<<<<<
 *     cdef char* callback_name_ptr = callback_name_data
 *     cdef char* callback_ptr = callback
*/
  if (unlikely(__pyx_v_callback_name == Py_None)) {
    PyErr_Format(PyExc_AttributeError, "'NoneType' object has no attribute '%.30s'", "encode");
    __PYX_ERR(0, 1304, __pyx_L1_error)
  }
  __pyx_t_1 = PyUnicode_AsEncodedString(__pyx_v_callback_name, NULL, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1304, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_callback_name_data = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "cupy/cuda/cufft.pyx":1305
 *     cdef Handle h = <Handle>plan  # no-cython-lint
 *     cdef bytes callback_name_data = callback_name.encode()
 *     cdef char* callback_name_ptr = callback_name_data             # <<<<<<<<<<<<<<
 *     cdef char* callback_ptr = callback
 *     cdef size_t callback_size = len(callback)
*/
  __pyx_t_2 = __Pyx_PyBytes_AsWritableString(__pyx_v_callback_name_data); if (unlikely((!__pyx_t_2) && PyErr_Occurred())) __PYX_ERR(0, 1305, __pyx_L1_error)
  __pyx_v_callback_name_ptr = __pyx_t_2;

  /* "cupy/cuda/cufft.pyx":1306
 *     cdef bytes callback_name_data = callback_name.encode()
 *     cdef char* callback_name_ptr = callback_name_data
 *     cdef char* callback_ptr = callback             # <<<<<<<<<<<<<<
 *     cdef size_t callback_size = len(callback)
 *     cdef void* caller_info_ptr = <void*>(caller_info)
*/
  if (unlikely(__pyx_v_callback == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "expected bytes, NoneType found");
    __PYX_ERR(0, 1306, __pyx_L1_error)
  }
  __pyx_t_2 = __Pyx_PyBytes_AsWritableString(__pyx_v_callback); if (unlikely((!__pyx_t_2) && PyErr_Occurred())) __PYX_ERR(0, 1306, __pyx_L1_error)
  __pyx_v_callback_ptr = __pyx_t_2;

  /* "cupy/cuda/cufft.pyx":1307
 *     cdef char* callback_name_ptr = callback_name_data
 *     cdef char* callback_ptr = callback
 *     cdef size_t callback_size = len(callback)             # <<<<<<<<<<<<<<
 *     cdef void* caller_info_ptr = <void*>(caller_info)
 * 
*/
  if (unlikely(__pyx_v_callback == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(0, 1307, __pyx_L1_error)
  }
  __pyx_t_3 = __Pyx_PyBytes_GET_SIZE(__pyx_v_callback); if (unlikely(__pyx_t_3 == ((Py_ssize_t)-1))) __PYX_ERR(0, 1307, __pyx_L1_error)
  __pyx_v_callback_size = __pyx_t_3;

  /* "cupy/cuda/cufft.pyx":1308
 *     cdef char* callback_ptr = callback
 *     cdef size_t callback_size = len(callback)
 *     cdef void* caller_info_ptr = <void*>(caller_info)             # <<<<<<<<<<<<<<
 * 
 *     with nogil:
*/
  __pyx_v_caller_info_ptr = ((void *)__pyx_v_caller_info);

  /* "cupy/cuda/cufft.pyx":1310
 *     cdef void* caller_info_ptr = <void*>(caller_info)
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = _cufftXtSetJITCallback(
 *             h, callback_name_ptr, callback_ptr, callback_size,
*/
  {
      PyThreadState *_save;
      _save = NULL;
      Py_UNBLOCK_THREADS
      __Pyx_FastGIL_Remember();
      /*try:*/ {

        /* "cupy/cuda/cufft.pyx":1311
 * 
 *     with nogil:
 *         result = _cufftXtSetJITCallback(             # <<<<<<<<<<<<<<
 *             h, callback_name_ptr, callback_ptr, callback_size,
 *             <callbackType>callback_type, &caller_info_ptr)
*/
        __pyx_v_result = __pyx_v_4cupy_4cuda_5cufft__cufftXtSetJITCallback(__pyx_v_h, __pyx_v_callback_name_ptr, __pyx_v_callback_ptr, __pyx_v_callback_size, ((cufftXtCallbackType)__pyx_v_callback_type), (&__pyx_v_caller_info_ptr));
      }

      /* "cupy/cuda/cufft.pyx":1310
 *     cdef void* caller_info_ptr = <void*>(caller_info)
 * 
 *     with nogil:             # <<<<<<<<<<<<<<
 *         result = _cufftXtSetJITCallback(
 *             h, callback_name_ptr, callback_ptr, callback_size,
*/
      /*finally:*/ {
        /*normal exit:*/{
          __Pyx_FastGIL_Forget();
          Py_BLOCK_THREADS
          goto __pyx_L5;
        }
        __pyx_L5:;
      }
  }

  /* "cupy/cuda/cufft.pyx":1314
 *             h, callback_name_ptr, callback_ptr, callback_size,
 *             <callbackType>callback_type, &caller_info_ptr)
 *     check_result(result)             # <<<<<<<<<<<<<<
 *     return 0
*/
  __pyx_f_4cupy_4cuda_5cufft_check_result(__pyx_v_result, 0); if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1314, __pyx_L1_error)

  /* "cupy/cuda/cufft.pyx":1315
 *             <callbackType>callback_type, &caller_info_ptr)
 *     check_result(result)
 *     return 0             # <<<<<<<<<<<<<<
*/
  __pyx_r = 0;
  goto __pyx_L0;

  /* "cupy/cuda/cufft.pyx":1299
 * 
 * 
 * cpdef int setJITCallback(             # <<<<<<<<<<<<<<
 *         intptr_t plan, str callback_name, bytes callback, int callback_type,
 *         intptr_t caller_info) except?-1:
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("cupy.cuda.cufft.setJITCallback", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = -1;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_callback_name_data);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_31setJITCallback(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_30setJITCallback, "setJITCallback(intptr_t plan, str callback_name, bytes callback, int callback_type, intptr_t caller_info) -> int");
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_31setJITCallback(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  intptr_t __pyx_v_plan;
  PyObject *__pyx_v_callback_name = 0;
  PyObject *__pyx_v_callback = 0;
  int __pyx_v_callback_type;
  intptr_t __pyx_v_caller_info;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[5] = {0,0,0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("setJITCallback (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_plan,&__pyx_mstate_global->__pyx_n_u_callback_name,&__pyx_mstate_global->__pyx_n_u_callback,&__pyx_mstate_global->__pyx_n_u_callback_type,&__pyx_mstate_global->__pyx_n_u_caller_info,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(0, 1299, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  5:
        values[4] = __Pyx_ArgRef_FASTCALL(__pyx_args, 4);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[4])) __PYX_ERR(0, 1299, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  4:
        values[3] = __Pyx_ArgRef_FASTCALL(__pyx_args, 3);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 1299, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1299, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1299, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1299, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "setJITCallback", 0) < (0)) __PYX_ERR(0, 1299, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 5; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("setJITCallback", 1, 5, 5, i); __PYX_ERR(0, 1299, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 5)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(0, 1299, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(0, 1299, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(0, 1299, __pyx_L3_error)
      values[3] = __Pyx_ArgRef_FASTCALL(__pyx_args, 3);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[3])) __PYX_ERR(0, 1299, __pyx_L3_error)
      values[4] = __Pyx_ArgRef_FASTCALL(__pyx_args, 4);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[4])) __PYX_ERR(0, 1299, __pyx_L3_error)
    }
    __pyx_v_plan = PyLong_AsSsize_t(values[0]); if (unlikely((__pyx_v_plan == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1300, __pyx_L3_error)
    __pyx_v_callback_name = ((PyObject*)values[1]);
    __pyx_v_callback = ((PyObject*)values[2]);
    __pyx_v_callback_type = __Pyx_PyLong_As_int(values[3]); if (unlikely((__pyx_v_callback_type == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1300, __pyx_L3_error)
    __pyx_v_caller_info = PyLong_AsSsize_t(values[4]); if (unlikely((__pyx_v_caller_info == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 1301, __pyx_L3_error)
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("setJITCallback", 1, 5, 5, __pyx_nargs); __PYX_ERR(0, 1299, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.setJITCallback", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_callback_name), (&PyUnicode_Type), 1, "callback_name", 1))) __PYX_ERR(0, 1300, __pyx_L1_error)
  if (unlikely(!__Pyx_ArgTypeTest(((PyObject *)__pyx_v_callback), (&PyBytes_Type), 1, "callback", 1))) __PYX_ERR(0, 1300, __pyx_L1_error)
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_30setJITCallback(__pyx_self, __pyx_v_plan, __pyx_v_callback_name, __pyx_v_callback, __pyx_v_callback_type, __pyx_v_caller_info);

  /* function exit code */
  goto __pyx_L0;
  __pyx_L1_error:;
  __pyx_r = NULL;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  goto __pyx_L7_cleaned_up;
  __pyx_L0:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __pyx_L7_cleaned_up:;
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_30setJITCallback(CYTHON_UNUSED PyObject *__pyx_self, intptr_t __pyx_v_plan, PyObject *__pyx_v_callback_name, PyObject *__pyx_v_callback, int __pyx_v_callback_type, intptr_t __pyx_v_caller_info) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  int __pyx_t_1;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("setJITCallback", 0);
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft_setJITCallback(__pyx_v_plan, __pyx_v_callback_name, __pyx_v_callback, __pyx_v_callback_type, __pyx_v_caller_info, 1); if (unlikely(__pyx_t_1 == ((int)-1) && PyErr_Occurred())) __PYX_ERR(0, 1299, __pyx_L1_error)
  __pyx_t_2 = __Pyx_PyLong_From_int(__pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1299, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_r = __pyx_t_2;
  __pyx_t_2 = 0;
  goto __pyx_L0;

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("cupy.cuda.cufft.setJITCallback", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":1
 * def __pyx_unpickle_Plan1d(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
 *     cdef object __pyx_PickleError
 *     cdef object __pyx_result
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_33__pyx_unpickle_Plan1d(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_32__pyx_unpickle_Plan1d, "__pyx_unpickle_Plan1d(__pyx_type, long __pyx_checksum, __pyx_state)");
static PyMethodDef __pyx_mdef_4cupy_4cuda_5cufft_33__pyx_unpickle_Plan1d = {"__pyx_unpickle_Plan1d", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_33__pyx_unpickle_Plan1d, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_32__pyx_unpickle_Plan1d};
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_33__pyx_unpickle_Plan1d(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v___pyx_type = 0;
  long __pyx_v___pyx_checksum;
  PyObject *__pyx_v___pyx_state = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__pyx_unpickle_Plan1d (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_pyx_type,&__pyx_mstate_global->__pyx_n_u_pyx_checksum,&__pyx_mstate_global->__pyx_n_u_pyx_state,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(1, 1, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(1, 1, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(1, 1, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(1, 1, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "__pyx_unpickle_Plan1d", 0) < (0)) __PYX_ERR(1, 1, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("__pyx_unpickle_Plan1d", 1, 3, 3, i); __PYX_ERR(1, 1, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(1, 1, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(1, 1, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(1, 1, __pyx_L3_error)
    }
    __pyx_v___pyx_type = values[0];
    __pyx_v___pyx_checksum = __Pyx_PyLong_As_long(values[1]); if (unlikely((__pyx_v___pyx_checksum == (long)-1) && PyErr_Occurred())) __PYX_ERR(1, 1, __pyx_L3_error)
    __pyx_v___pyx_state = values[2];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__pyx_unpickle_Plan1d", 1, 3, 3, __pyx_nargs); __PYX_ERR(1, 1, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.__pyx_unpickle_Plan1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_32__pyx_unpickle_Plan1d(__pyx_self, __pyx_v___pyx_type, __pyx_v___pyx_checksum, __pyx_v___pyx_state);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_32__pyx_unpickle_Plan1d(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v___pyx_type, long __pyx_v___pyx_checksum, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_v___pyx_PickleError = 0;
  PyObject *__pyx_v___pyx_result = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  size_t __pyx_t_4;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__pyx_unpickle_Plan1d", 0);

  /* "(tree fragment)":4
 *     cdef object __pyx_PickleError
 *     cdef object __pyx_result
 *     if __pyx_checksum not in (0xbdeb9ba, 0x989b82b, 0xf5e4dcb):             # <<<<<<<<<<<<<<
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0xbdeb9ba, 0x989b82b, 0xf5e4dcb) = (batch, batch_share, fft_type, gather_events, gather_streams, gpus, handle, nx, scatter_events, scatter_streams, work_area, xtArr, xtArr_buffer))" % __pyx_checksum
*/
  __pyx_t_1 = __Pyx_PyLong_From_long(__pyx_v___pyx_checksum); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 4, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = (__Pyx_PySequence_ContainsTF(__pyx_t_1, __pyx_mstate_global->__pyx_tuple[0], Py_NE)); if (unlikely((__pyx_t_2 < 0))) __PYX_ERR(1, 4, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (__pyx_t_2) {

    /* "(tree fragment)":5
 *     cdef object __pyx_result
 *     if __pyx_checksum not in (0xbdeb9ba, 0x989b82b, 0xf5e4dcb):
 *         from pickle import PickleError as __pyx_PickleError             # <<<<<<<<<<<<<<
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0xbdeb9ba, 0x989b82b, 0xf5e4dcb) = (batch, batch_share, fft_type, gather_events, gather_streams, gpus, handle, nx, scatter_events, scatter_streams, work_area, xtArr, xtArr_buffer))" % __pyx_checksum
 *     __pyx_result = Plan1d.__new__(__pyx_type)
*/
    __pyx_t_1 = PyList_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 5, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_mstate_global->__pyx_n_u_PickleError);
    __Pyx_GIVEREF(__pyx_mstate_global->__pyx_n_u_PickleError);
    if (__Pyx_PyList_SET_ITEM(__pyx_t_1, 0, __pyx_mstate_global->__pyx_n_u_PickleError) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
    __pyx_t_3 = __Pyx_Import(__pyx_mstate_global->__pyx_n_u_pickle, __pyx_t_1, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_ImportFrom(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_PickleError); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 5, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_1);
    __pyx_v___pyx_PickleError = __pyx_t_1;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "(tree fragment)":6
 *     if __pyx_checksum not in (0xbdeb9ba, 0x989b82b, 0xf5e4dcb):
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0xbdeb9ba, 0x989b82b, 0xf5e4dcb) = (batch, batch_share, fft_type, gather_events, gather_streams, gpus, handle, nx, scatter_events, scatter_streams, work_area, xtArr, xtArr_buffer))" % __pyx_checksum             # <<<<<<<<<<<<<<
 *     __pyx_result = Plan1d.__new__(__pyx_type)
 *     if __pyx_state is not None:
*/
    __pyx_t_3 = __Pyx_PyLong_From_long(__pyx_v___pyx_checksum); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 6, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_1 = PyUnicode_Format(__pyx_mstate_global->__pyx_kp_u_Incompatible_checksums_0x_x_vs_0, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 6, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_Raise(__pyx_v___pyx_PickleError, __pyx_t_1, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(1, 6, __pyx_L1_error)

    /* "(tree fragment)":4
 *     cdef object __pyx_PickleError
 *     cdef object __pyx_result
 *     if __pyx_checksum not in (0xbdeb9ba, 0x989b82b, 0xf5e4dcb):             # <<<<<<<<<<<<<<
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0xbdeb9ba, 0x989b82b, 0xf5e4dcb) = (batch, batch_share, fft_type, gather_events, gather_streams, gpus, handle, nx, scatter_events, scatter_streams, work_area, xtArr, xtArr_buffer))" % __pyx_checksum
*/
  }

  /* "(tree fragment)":7
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0xbdeb9ba, 0x989b82b, 0xf5e4dcb) = (batch, batch_share, fft_type, gather_events, gather_streams, gpus, handle, nx, scatter_events, scatter_streams, work_area, xtArr, xtArr_buffer))" % __pyx_checksum
 *     __pyx_result = Plan1d.__new__(__pyx_type)             # <<<<<<<<<<<<<<
 *     if __pyx_state is not None:
 *         __pyx_unpickle_Plan1d__set_state(<Plan1d> __pyx_result, __pyx_state)
*/
  __pyx_t_3 = ((PyObject *)__pyx_mstate_global->__pyx_ptype_4cupy_4cuda_5cufft_Plan1d);
  __Pyx_INCREF(__pyx_t_3);
  __pyx_t_4 = 0;
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, __pyx_v___pyx_type};
    __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_new, __pyx_callargs+__pyx_t_4, (2-__pyx_t_4) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 7, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  __pyx_v___pyx_result = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "(tree fragment)":8
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0xbdeb9ba, 0x989b82b, 0xf5e4dcb) = (batch, batch_share, fft_type, gather_events, gather_streams, gpus, handle, nx, scatter_events, scatter_streams, work_area, xtArr, xtArr_buffer))" % __pyx_checksum
 *     __pyx_result = Plan1d.__new__(__pyx_type)
 *     if __pyx_state is not None:             # <<<<<<<<<<<<<<
 *         __pyx_unpickle_Plan1d__set_state(<Plan1d> __pyx_result, __pyx_state)
 *     return __pyx_result
*/
  __pyx_t_2 = (__pyx_v___pyx_state != Py_None);
  if (__pyx_t_2) {

    /* "(tree fragment)":9
 *     __pyx_result = Plan1d.__new__(__pyx_type)
 *     if __pyx_state is not None:
 *         __pyx_unpickle_Plan1d__set_state(<Plan1d> __pyx_result, __pyx_state)             # <<<<<<<<<<<<<<
 *     return __pyx_result
 * cdef __pyx_unpickle_Plan1d__set_state(Plan1d __pyx_result, tuple __pyx_state):
*/
    if (!(likely(PyTuple_CheckExact(__pyx_v___pyx_state))||((__pyx_v___pyx_state) == Py_None) || __Pyx_RaiseUnexpectedTypeError("tuple", __pyx_v___pyx_state))) __PYX_ERR(1, 9, __pyx_L1_error)
    __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft___pyx_unpickle_Plan1d__set_state(((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)__pyx_v___pyx_result), ((PyObject*)__pyx_v___pyx_state)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 9, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "(tree fragment)":8
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0xbdeb9ba, 0x989b82b, 0xf5e4dcb) = (batch, batch_share, fft_type, gather_events, gather_streams, gpus, handle, nx, scatter_events, scatter_streams, work_area, xtArr, xtArr_buffer))" % __pyx_checksum
 *     __pyx_result = Plan1d.__new__(__pyx_type)
 *     if __pyx_state is not None:             # <<<<<<<<<<<<<<
 *         __pyx_unpickle_Plan1d__set_state(<Plan1d> __pyx_result, __pyx_state)
 *     return __pyx_result
*/
  }

  /* "(tree fragment)":10
 *     if __pyx_state is not None:
 *         __pyx_unpickle_Plan1d__set_state(<Plan1d> __pyx_result, __pyx_state)
 *     return __pyx_result             # <<<<<<<<<<<<<<
 * cdef __pyx_unpickle_Plan1d__set_state(Plan1d __pyx_result, tuple __pyx_state):
 *     __pyx_result.batch = __pyx_state[0]; __pyx_result.batch_share = __pyx_state[1]; __pyx_result.fft_type = __pyx_state[2]; __pyx_result.gather_events = __pyx_state[3]; __pyx_result.gather_streams = __pyx_state[4]; __pyx_result.gpus = __pyx_state[5]; __pyx_result.handle = __pyx_state[6]; __pyx_result.nx = __pyx_state[7]; __pyx_result.scatter_events = __pyx_state[8]; __pyx_result.scatter_streams = __pyx_state[9]; __pyx_result.work_area = __pyx_state[10]; __pyx_result.xtArr = __pyx_state[11]; __pyx_result.xtArr_buffer = __pyx_state[12]
*/
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v___pyx_result);
  __pyx_r = __pyx_v___pyx_result;
  goto __pyx_L0;

  /* "(tree fragment)":1
 * def __pyx_unpickle_Plan1d(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
 *     cdef object __pyx_PickleError
 *     cdef object __pyx_result
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("cupy.cuda.cufft.__pyx_unpickle_Plan1d", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v___pyx_PickleError);
  __Pyx_XDECREF(__pyx_v___pyx_result);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":11
 *         __pyx_unpickle_Plan1d__set_state(<Plan1d> __pyx_result, __pyx_state)
 *     return __pyx_result
 * cdef __pyx_unpickle_Plan1d__set_state(Plan1d __pyx_result, tuple __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_result.batch = __pyx_state[0]; __pyx_result.batch_share = __pyx_state[1]; __pyx_result.fft_type = __pyx_state[2]; __pyx_result.gather_events = __pyx_state[3]; __pyx_result.gather_streams = __pyx_state[4]; __pyx_result.gpus = __pyx_state[5]; __pyx_result.handle = __pyx_state[6]; __pyx_result.nx = __pyx_state[7]; __pyx_result.scatter_events = __pyx_state[8]; __pyx_result.scatter_streams = __pyx_state[9]; __pyx_result.work_area = __pyx_state[10]; __pyx_result.xtArr = __pyx_state[11]; __pyx_result.xtArr_buffer = __pyx_state[12]
 *     if len(__pyx_state) > 13 and hasattr(__pyx_result, '__dict__'):
*/

static PyObject *__pyx_f_4cupy_4cuda_5cufft___pyx_unpickle_Plan1d__set_state(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *__pyx_v___pyx_result, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  cufftType_t __pyx_t_3;
  intptr_t __pyx_t_4;
  int __pyx_t_5;
  Py_ssize_t __pyx_t_6;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  size_t __pyx_t_11;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__pyx_unpickle_Plan1d__set_state", 0);

  /* "(tree fragment)":12
 *     return __pyx_result
 * cdef __pyx_unpickle_Plan1d__set_state(Plan1d __pyx_result, tuple __pyx_state):
 *     __pyx_result.batch = __pyx_state[0]; __pyx_result.batch_share = __pyx_state[1]; __pyx_result.fft_type = __pyx_state[2]; __pyx_result.gather_events = __pyx_state[3]; __pyx_result.gather_streams = __pyx_state[4]; __pyx_result.gpus = __pyx_state[5]; __pyx_result.handle = __pyx_state[6]; __pyx_result.nx = __pyx_state[7]; __pyx_result.scatter_events = __pyx_state[8]; __pyx_result.scatter_streams = __pyx_state[9]; __pyx_result.work_area = __pyx_state[10]; __pyx_result.xtArr = __pyx_state[11]; __pyx_result.xtArr_buffer = __pyx_state[12]             # <<<<<<<<<<<<<<
 *     if len(__pyx_state) > 13 and hasattr(__pyx_result, '__dict__'):
 *         __pyx_result.__dict__.update(__pyx_state[13])
*/
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 0, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyLong_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->batch = __pyx_t_2;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 1, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(PyList_CheckExact(__pyx_t_1))||((__pyx_t_1) == Py_None) || __Pyx_RaiseUnexpectedTypeError("list", __pyx_t_1))) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->batch_share);
  __Pyx_DECREF(__pyx_v___pyx_result->batch_share);
  __pyx_v___pyx_result->batch_share = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 2, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = ((cufftType_t)__Pyx_PyLong_As_cufftType_t(__pyx_t_1)); if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->fft_type = __pyx_t_3;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 3, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(PyList_CheckExact(__pyx_t_1))||((__pyx_t_1) == Py_None) || __Pyx_RaiseUnexpectedTypeError("list", __pyx_t_1))) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->gather_events);
  __Pyx_DECREF(__pyx_v___pyx_result->gather_events);
  __pyx_v___pyx_result->gather_events = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 4, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(PyList_CheckExact(__pyx_t_1))||((__pyx_t_1) == Py_None) || __Pyx_RaiseUnexpectedTypeError("list", __pyx_t_1))) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->gather_streams);
  __Pyx_DECREF(__pyx_v___pyx_result->gather_streams);
  __pyx_v___pyx_result->gather_streams = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 5, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(PyList_CheckExact(__pyx_t_1))||((__pyx_t_1) == Py_None) || __Pyx_RaiseUnexpectedTypeError("list", __pyx_t_1))) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->gpus);
  __Pyx_DECREF(__pyx_v___pyx_result->gpus);
  __pyx_v___pyx_result->gpus = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 6, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = PyLong_AsSsize_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->handle = __pyx_t_4;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 7, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyLong_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->nx = __pyx_t_2;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 8, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(PyDict_CheckExact(__pyx_t_1))||((__pyx_t_1) == Py_None) || __Pyx_RaiseUnexpectedTypeError("dict", __pyx_t_1))) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->scatter_events);
  __Pyx_DECREF(__pyx_v___pyx_result->scatter_events);
  __pyx_v___pyx_result->scatter_events = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 9, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(PyDict_CheckExact(__pyx_t_1))||((__pyx_t_1) == Py_None) || __Pyx_RaiseUnexpectedTypeError("dict", __pyx_t_1))) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->scatter_streams);
  __Pyx_DECREF(__pyx_v___pyx_result->scatter_streams);
  __pyx_v___pyx_result->scatter_streams = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 10, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->work_area);
  __Pyx_DECREF(__pyx_v___pyx_result->work_area);
  __pyx_v___pyx_result->work_area = __pyx_t_1;
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 11, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = PyLong_AsSsize_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->xtArr = __pyx_t_4;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 12, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(PyList_CheckExact(__pyx_t_1))||((__pyx_t_1) == Py_None) || __Pyx_RaiseUnexpectedTypeError("list", __pyx_t_1))) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->xtArr_buffer);
  __Pyx_DECREF(__pyx_v___pyx_result->xtArr_buffer);
  __pyx_v___pyx_result->xtArr_buffer = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;

  /* "(tree fragment)":13
 * cdef __pyx_unpickle_Plan1d__set_state(Plan1d __pyx_result, tuple __pyx_state):
 *     __pyx_result.batch = __pyx_state[0]; __pyx_result.batch_share = __pyx_state[1]; __pyx_result.fft_type = __pyx_state[2]; __pyx_result.gather_events = __pyx_state[3]; __pyx_result.gather_streams = __pyx_state[4]; __pyx_result.gpus = __pyx_state[5]; __pyx_result.handle = __pyx_state[6]; __pyx_result.nx = __pyx_state[7]; __pyx_result.scatter_events = __pyx_state[8]; __pyx_result.scatter_streams = __pyx_state[9]; __pyx_result.work_area = __pyx_state[10]; __pyx_result.xtArr = __pyx_state[11]; __pyx_result.xtArr_buffer = __pyx_state[12]
 *     if len(__pyx_state) > 13 and hasattr(__pyx_result, '__dict__'):             # <<<<<<<<<<<<<<
 *         __pyx_result.__dict__.update(__pyx_state[13])
*/
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(1, 13, __pyx_L1_error)
  }
  __pyx_t_6 = __Pyx_PyTuple_GET_SIZE(__pyx_v___pyx_state); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(1, 13, __pyx_L1_error)
  __pyx_t_7 = (__pyx_t_6 > 13);
  if (__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_7 = __Pyx_HasAttr(((PyObject *)__pyx_v___pyx_result), __pyx_mstate_global->__pyx_n_u_dict); if (unlikely(__pyx_t_7 == ((int)-1))) __PYX_ERR(1, 13, __pyx_L1_error)
  __pyx_t_5 = __pyx_t_7;
  __pyx_L4_bool_binop_done:;
  if (__pyx_t_5) {

    /* "(tree fragment)":14
 *     __pyx_result.batch = __pyx_state[0]; __pyx_result.batch_share = __pyx_state[1]; __pyx_result.fft_type = __pyx_state[2]; __pyx_result.gather_events = __pyx_state[3]; __pyx_result.gather_streams = __pyx_state[4]; __pyx_result.gpus = __pyx_state[5]; __pyx_result.handle = __pyx_state[6]; __pyx_result.nx = __pyx_state[7]; __pyx_result.scatter_events = __pyx_state[8]; __pyx_result.scatter_streams = __pyx_state[9]; __pyx_result.work_area = __pyx_state[10]; __pyx_result.xtArr = __pyx_state[11]; __pyx_result.xtArr_buffer = __pyx_state[12]
 *     if len(__pyx_state) > 13 and hasattr(__pyx_result, '__dict__'):
 *         __pyx_result.__dict__.update(__pyx_state[13])             # <<<<<<<<<<<<<<
*/
    __pyx_t_9 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v___pyx_result), __pyx_mstate_global->__pyx_n_u_dict); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 14, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __pyx_t_8 = __pyx_t_9;
    __Pyx_INCREF(__pyx_t_8);
    if (unlikely(__pyx_v___pyx_state == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
      __PYX_ERR(1, 14, __pyx_L1_error)
    }
    __pyx_t_10 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 13, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 14, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_11 = 0;
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_8, __pyx_t_10};
      __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_update, __pyx_callargs+__pyx_t_11, (2-__pyx_t_11) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 14, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "(tree fragment)":13
 * cdef __pyx_unpickle_Plan1d__set_state(Plan1d __pyx_result, tuple __pyx_state):
 *     __pyx_result.batch = __pyx_state[0]; __pyx_result.batch_share = __pyx_state[1]; __pyx_result.fft_type = __pyx_state[2]; __pyx_result.gather_events = __pyx_state[3]; __pyx_result.gather_streams = __pyx_state[4]; __pyx_result.gpus = __pyx_state[5]; __pyx_result.handle = __pyx_state[6]; __pyx_result.nx = __pyx_state[7]; __pyx_result.scatter_events = __pyx_state[8]; __pyx_result.scatter_streams = __pyx_state[9]; __pyx_result.work_area = __pyx_state[10]; __pyx_result.xtArr = __pyx_state[11]; __pyx_result.xtArr_buffer = __pyx_state[12]
 *     if len(__pyx_state) > 13 and hasattr(__pyx_result, '__dict__'):             # <<<<<<<<<<<<<<
 *         __pyx_result.__dict__.update(__pyx_state[13])
*/
  }

  /* "(tree fragment)":11
 *         __pyx_unpickle_Plan1d__set_state(<Plan1d> __pyx_result, __pyx_state)
 *     return __pyx_result
 * cdef __pyx_unpickle_Plan1d__set_state(Plan1d __pyx_result, tuple __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_result.batch = __pyx_state[0]; __pyx_result.batch_share = __pyx_state[1]; __pyx_result.fft_type = __pyx_state[2]; __pyx_result.gather_events = __pyx_state[3]; __pyx_result.gather_streams = __pyx_state[4]; __pyx_result.gpus = __pyx_state[5]; __pyx_result.handle = __pyx_state[6]; __pyx_result.nx = __pyx_state[7]; __pyx_result.scatter_events = __pyx_state[8]; __pyx_result.scatter_streams = __pyx_state[9]; __pyx_result.work_area = __pyx_state[10]; __pyx_result.xtArr = __pyx_state[11]; __pyx_result.xtArr_buffer = __pyx_state[12]
 *     if len(__pyx_state) > 13 and hasattr(__pyx_result, '__dict__'):
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("cupy.cuda.cufft.__pyx_unpickle_Plan1d__set_state", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":1
 * def __pyx_unpickle_PlanNd(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
 *     cdef object __pyx_PickleError
 *     cdef object __pyx_result
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_35__pyx_unpickle_PlanNd(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_34__pyx_unpickle_PlanNd, "__pyx_unpickle_PlanNd(__pyx_type, long __pyx_checksum, __pyx_state)");
static PyMethodDef __pyx_mdef_4cupy_4cuda_5cufft_35__pyx_unpickle_PlanNd = {"__pyx_unpickle_PlanNd", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_35__pyx_unpickle_PlanNd, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_34__pyx_unpickle_PlanNd};
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_35__pyx_unpickle_PlanNd(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v___pyx_type = 0;
  long __pyx_v___pyx_checksum;
  PyObject *__pyx_v___pyx_state = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__pyx_unpickle_PlanNd (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_pyx_type,&__pyx_mstate_global->__pyx_n_u_pyx_checksum,&__pyx_mstate_global->__pyx_n_u_pyx_state,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(1, 1, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(1, 1, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(1, 1, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(1, 1, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "__pyx_unpickle_PlanNd", 0) < (0)) __PYX_ERR(1, 1, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("__pyx_unpickle_PlanNd", 1, 3, 3, i); __PYX_ERR(1, 1, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(1, 1, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(1, 1, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(1, 1, __pyx_L3_error)
    }
    __pyx_v___pyx_type = values[0];
    __pyx_v___pyx_checksum = __Pyx_PyLong_As_long(values[1]); if (unlikely((__pyx_v___pyx_checksum == (long)-1) && PyErr_Occurred())) __PYX_ERR(1, 1, __pyx_L3_error)
    __pyx_v___pyx_state = values[2];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__pyx_unpickle_PlanNd", 1, 3, 3, __pyx_nargs); __PYX_ERR(1, 1, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.__pyx_unpickle_PlanNd", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_34__pyx_unpickle_PlanNd(__pyx_self, __pyx_v___pyx_type, __pyx_v___pyx_checksum, __pyx_v___pyx_state);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_34__pyx_unpickle_PlanNd(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v___pyx_type, long __pyx_v___pyx_checksum, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_v___pyx_PickleError = 0;
  PyObject *__pyx_v___pyx_result = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  size_t __pyx_t_4;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__pyx_unpickle_PlanNd", 0);

  /* "(tree fragment)":4
 *     cdef object __pyx_PickleError
 *     cdef object __pyx_result
 *     if __pyx_checksum not in (0xc57f9e5, 0x9bf2b45, 0x12c7fc7):             # <<<<<<<<<<<<<<
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0xc57f9e5, 0x9bf2b45, 0x12c7fc7) = (fft_type, gpus, handle, last_axis, last_size, order, shape, work_area))" % __pyx_checksum
*/
  __pyx_t_1 = __Pyx_PyLong_From_long(__pyx_v___pyx_checksum); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 4, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = (__Pyx_PySequence_ContainsTF(__pyx_t_1, __pyx_mstate_global->__pyx_tuple[1], Py_NE)); if (unlikely((__pyx_t_2 < 0))) __PYX_ERR(1, 4, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (__pyx_t_2) {

    /* "(tree fragment)":5
 *     cdef object __pyx_result
 *     if __pyx_checksum not in (0xc57f9e5, 0x9bf2b45, 0x12c7fc7):
 *         from pickle import PickleError as __pyx_PickleError             # <<<<<<<<<<<<<<
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0xc57f9e5, 0x9bf2b45, 0x12c7fc7) = (fft_type, gpus, handle, last_axis, last_size, order, shape, work_area))" % __pyx_checksum
 *     __pyx_result = PlanNd.__new__(__pyx_type)
*/
    __pyx_t_1 = PyList_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 5, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_mstate_global->__pyx_n_u_PickleError);
    __Pyx_GIVEREF(__pyx_mstate_global->__pyx_n_u_PickleError);
    if (__Pyx_PyList_SET_ITEM(__pyx_t_1, 0, __pyx_mstate_global->__pyx_n_u_PickleError) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
    __pyx_t_3 = __Pyx_Import(__pyx_mstate_global->__pyx_n_u_pickle, __pyx_t_1, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_ImportFrom(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_PickleError); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 5, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_1);
    __pyx_v___pyx_PickleError = __pyx_t_1;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "(tree fragment)":6
 *     if __pyx_checksum not in (0xc57f9e5, 0x9bf2b45, 0x12c7fc7):
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0xc57f9e5, 0x9bf2b45, 0x12c7fc7) = (fft_type, gpus, handle, last_axis, last_size, order, shape, work_area))" % __pyx_checksum             # <<<<<<<<<<<<<<
 *     __pyx_result = PlanNd.__new__(__pyx_type)
 *     if __pyx_state is not None:
*/
    __pyx_t_3 = __Pyx_PyLong_From_long(__pyx_v___pyx_checksum); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 6, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_1 = PyUnicode_Format(__pyx_mstate_global->__pyx_kp_u_Incompatible_checksums_0x_x_vs_0_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 6, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_Raise(__pyx_v___pyx_PickleError, __pyx_t_1, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(1, 6, __pyx_L1_error)

    /* "(tree fragment)":4
 *     cdef object __pyx_PickleError
 *     cdef object __pyx_result
 *     if __pyx_checksum not in (0xc57f9e5, 0x9bf2b45, 0x12c7fc7):             # <<<<<<<<<<<<<<
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0xc57f9e5, 0x9bf2b45, 0x12c7fc7) = (fft_type, gpus, handle, last_axis, last_size, order, shape, work_area))" % __pyx_checksum
*/
  }

  /* "(tree fragment)":7
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0xc57f9e5, 0x9bf2b45, 0x12c7fc7) = (fft_type, gpus, handle, last_axis, last_size, order, shape, work_area))" % __pyx_checksum
 *     __pyx_result = PlanNd.__new__(__pyx_type)             # <<<<<<<<<<<<<<
 *     if __pyx_state is not None:
 *         __pyx_unpickle_PlanNd__set_state(<PlanNd> __pyx_result, __pyx_state)
*/
  __pyx_t_3 = ((PyObject *)__pyx_mstate_global->__pyx_ptype_4cupy_4cuda_5cufft_PlanNd);
  __Pyx_INCREF(__pyx_t_3);
  __pyx_t_4 = 0;
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, __pyx_v___pyx_type};
    __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_new, __pyx_callargs+__pyx_t_4, (2-__pyx_t_4) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 7, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  __pyx_v___pyx_result = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "(tree fragment)":8
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0xc57f9e5, 0x9bf2b45, 0x12c7fc7) = (fft_type, gpus, handle, last_axis, last_size, order, shape, work_area))" % __pyx_checksum
 *     __pyx_result = PlanNd.__new__(__pyx_type)
 *     if __pyx_state is not None:             # <<<<<<<<<<<<<<
 *         __pyx_unpickle_PlanNd__set_state(<PlanNd> __pyx_result, __pyx_state)
 *     return __pyx_result
*/
  __pyx_t_2 = (__pyx_v___pyx_state != Py_None);
  if (__pyx_t_2) {

    /* "(tree fragment)":9
 *     __pyx_result = PlanNd.__new__(__pyx_type)
 *     if __pyx_state is not None:
 *         __pyx_unpickle_PlanNd__set_state(<PlanNd> __pyx_result, __pyx_state)             # <<<<<<<<<<<<<<
 *     return __pyx_result
 * cdef __pyx_unpickle_PlanNd__set_state(PlanNd __pyx_result, tuple __pyx_state):
*/
    if (!(likely(PyTuple_CheckExact(__pyx_v___pyx_state))||((__pyx_v___pyx_state) == Py_None) || __Pyx_RaiseUnexpectedTypeError("tuple", __pyx_v___pyx_state))) __PYX_ERR(1, 9, __pyx_L1_error)
    __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft___pyx_unpickle_PlanNd__set_state(((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)__pyx_v___pyx_result), ((PyObject*)__pyx_v___pyx_state)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 9, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "(tree fragment)":8
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0xc57f9e5, 0x9bf2b45, 0x12c7fc7) = (fft_type, gpus, handle, last_axis, last_size, order, shape, work_area))" % __pyx_checksum
 *     __pyx_result = PlanNd.__new__(__pyx_type)
 *     if __pyx_state is not None:             # <<<<<<<<<<<<<<
 *         __pyx_unpickle_PlanNd__set_state(<PlanNd> __pyx_result, __pyx_state)
 *     return __pyx_result
*/
  }

  /* "(tree fragment)":10
 *     if __pyx_state is not None:
 *         __pyx_unpickle_PlanNd__set_state(<PlanNd> __pyx_result, __pyx_state)
 *     return __pyx_result             # <<<<<<<<<<<<<<
 * cdef __pyx_unpickle_PlanNd__set_state(PlanNd __pyx_result, tuple __pyx_state):
 *     __pyx_result.fft_type = __pyx_state[0]; __pyx_result.gpus = __pyx_state[1]; __pyx_result.handle = __pyx_state[2]; __pyx_result.last_axis = __pyx_state[3]; __pyx_result.last_size = __pyx_state[4]; __pyx_result.order = __pyx_state[5]; __pyx_result.shape = __pyx_state[6]; __pyx_result.work_area = __pyx_state[7]
*/
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v___pyx_result);
  __pyx_r = __pyx_v___pyx_result;
  goto __pyx_L0;

  /* "(tree fragment)":1
 * def __pyx_unpickle_PlanNd(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
 *     cdef object __pyx_PickleError
 *     cdef object __pyx_result
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("cupy.cuda.cufft.__pyx_unpickle_PlanNd", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v___pyx_PickleError);
  __Pyx_XDECREF(__pyx_v___pyx_result);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":11
 *         __pyx_unpickle_PlanNd__set_state(<PlanNd> __pyx_result, __pyx_state)
 *     return __pyx_result
 * cdef __pyx_unpickle_PlanNd__set_state(PlanNd __pyx_result, tuple __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_result.fft_type = __pyx_state[0]; __pyx_result.gpus = __pyx_state[1]; __pyx_result.handle = __pyx_state[2]; __pyx_result.last_axis = __pyx_state[3]; __pyx_result.last_size = __pyx_state[4]; __pyx_result.order = __pyx_state[5]; __pyx_result.shape = __pyx_state[6]; __pyx_result.work_area = __pyx_state[7]
 *     if len(__pyx_state) > 8 and hasattr(__pyx_result, '__dict__'):
*/

static PyObject *__pyx_f_4cupy_4cuda_5cufft___pyx_unpickle_PlanNd__set_state(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *__pyx_v___pyx_result, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  cufftType_t __pyx_t_2;
  intptr_t __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  Py_ssize_t __pyx_t_6;
  int __pyx_t_7;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  PyObject *__pyx_t_10 = NULL;
  size_t __pyx_t_11;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__pyx_unpickle_PlanNd__set_state", 0);

  /* "(tree fragment)":12
 *     return __pyx_result
 * cdef __pyx_unpickle_PlanNd__set_state(PlanNd __pyx_result, tuple __pyx_state):
 *     __pyx_result.fft_type = __pyx_state[0]; __pyx_result.gpus = __pyx_state[1]; __pyx_result.handle = __pyx_state[2]; __pyx_result.last_axis = __pyx_state[3]; __pyx_result.last_size = __pyx_state[4]; __pyx_result.order = __pyx_state[5]; __pyx_result.shape = __pyx_state[6]; __pyx_result.work_area = __pyx_state[7]             # <<<<<<<<<<<<<<
 *     if len(__pyx_state) > 8 and hasattr(__pyx_result, '__dict__'):
 *         __pyx_result.__dict__.update(__pyx_state[8])
*/
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 0, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = ((cufftType_t)__Pyx_PyLong_As_cufftType_t(__pyx_t_1)); if (unlikely(PyErr_Occurred())) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->fft_type = __pyx_t_2;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 1, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(PyList_CheckExact(__pyx_t_1))||((__pyx_t_1) == Py_None) || __Pyx_RaiseUnexpectedTypeError("list", __pyx_t_1))) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->gpus);
  __Pyx_DECREF(__pyx_v___pyx_result->gpus);
  __pyx_v___pyx_result->gpus = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 2, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = PyLong_AsSsize_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->handle = __pyx_t_3;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 3, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyLong_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->last_axis = __pyx_t_4;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 4, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->last_size);
  __Pyx_DECREF(__pyx_v___pyx_result->last_size);
  __pyx_v___pyx_result->last_size = __pyx_t_1;
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 5, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(PyUnicode_CheckExact(__pyx_t_1))||((__pyx_t_1) == Py_None) || __Pyx_RaiseUnexpectedTypeError("str", __pyx_t_1))) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->order);
  __Pyx_DECREF(__pyx_v___pyx_result->order);
  __pyx_v___pyx_result->order = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 6, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(PyTuple_CheckExact(__pyx_t_1))||((__pyx_t_1) == Py_None) || __Pyx_RaiseUnexpectedTypeError("tuple", __pyx_t_1))) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->shape);
  __Pyx_DECREF(__pyx_v___pyx_result->shape);
  __pyx_v___pyx_result->shape = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 7, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->work_area);
  __Pyx_DECREF(__pyx_v___pyx_result->work_area);
  __pyx_v___pyx_result->work_area = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "(tree fragment)":13
 * cdef __pyx_unpickle_PlanNd__set_state(PlanNd __pyx_result, tuple __pyx_state):
 *     __pyx_result.fft_type = __pyx_state[0]; __pyx_result.gpus = __pyx_state[1]; __pyx_result.handle = __pyx_state[2]; __pyx_result.last_axis = __pyx_state[3]; __pyx_result.last_size = __pyx_state[4]; __pyx_result.order = __pyx_state[5]; __pyx_result.shape = __pyx_state[6]; __pyx_result.work_area = __pyx_state[7]
 *     if len(__pyx_state) > 8 and hasattr(__pyx_result, '__dict__'):             # <<<<<<<<<<<<<<
 *         __pyx_result.__dict__.update(__pyx_state[8])
*/
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(1, 13, __pyx_L1_error)
  }
  __pyx_t_6 = __Pyx_PyTuple_GET_SIZE(__pyx_v___pyx_state); if (unlikely(__pyx_t_6 == ((Py_ssize_t)-1))) __PYX_ERR(1, 13, __pyx_L1_error)
  __pyx_t_7 = (__pyx_t_6 > 8);
  if (__pyx_t_7) {
  } else {
    __pyx_t_5 = __pyx_t_7;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_7 = __Pyx_HasAttr(((PyObject *)__pyx_v___pyx_result), __pyx_mstate_global->__pyx_n_u_dict); if (unlikely(__pyx_t_7 == ((int)-1))) __PYX_ERR(1, 13, __pyx_L1_error)
  __pyx_t_5 = __pyx_t_7;
  __pyx_L4_bool_binop_done:;
  if (__pyx_t_5) {

    /* "(tree fragment)":14
 *     __pyx_result.fft_type = __pyx_state[0]; __pyx_result.gpus = __pyx_state[1]; __pyx_result.handle = __pyx_state[2]; __pyx_result.last_axis = __pyx_state[3]; __pyx_result.last_size = __pyx_state[4]; __pyx_result.order = __pyx_state[5]; __pyx_result.shape = __pyx_state[6]; __pyx_result.work_area = __pyx_state[7]
 *     if len(__pyx_state) > 8 and hasattr(__pyx_result, '__dict__'):
 *         __pyx_result.__dict__.update(__pyx_state[8])             # <<<<<<<<<<<<<<
*/
    __pyx_t_9 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v___pyx_result), __pyx_mstate_global->__pyx_n_u_dict); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 14, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __pyx_t_8 = __pyx_t_9;
    __Pyx_INCREF(__pyx_t_8);
    if (unlikely(__pyx_v___pyx_state == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
      __PYX_ERR(1, 14, __pyx_L1_error)
    }
    __pyx_t_10 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 8, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_10)) __PYX_ERR(1, 14, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_10);
    __pyx_t_11 = 0;
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_8, __pyx_t_10};
      __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_update, __pyx_callargs+__pyx_t_11, (2-__pyx_t_11) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_8); __pyx_t_8 = 0;
      __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 14, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "(tree fragment)":13
 * cdef __pyx_unpickle_PlanNd__set_state(PlanNd __pyx_result, tuple __pyx_state):
 *     __pyx_result.fft_type = __pyx_state[0]; __pyx_result.gpus = __pyx_state[1]; __pyx_result.handle = __pyx_state[2]; __pyx_result.last_axis = __pyx_state[3]; __pyx_result.last_size = __pyx_state[4]; __pyx_result.order = __pyx_state[5]; __pyx_result.shape = __pyx_state[6]; __pyx_result.work_area = __pyx_state[7]
 *     if len(__pyx_state) > 8 and hasattr(__pyx_result, '__dict__'):             # <<<<<<<<<<<<<<
 *         __pyx_result.__dict__.update(__pyx_state[8])
*/
  }

  /* "(tree fragment)":11
 *         __pyx_unpickle_PlanNd__set_state(<PlanNd> __pyx_result, __pyx_state)
 *     return __pyx_result
 * cdef __pyx_unpickle_PlanNd__set_state(PlanNd __pyx_result, tuple __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_result.fft_type = __pyx_state[0]; __pyx_result.gpus = __pyx_state[1]; __pyx_result.handle = __pyx_state[2]; __pyx_result.last_axis = __pyx_state[3]; __pyx_result.last_size = __pyx_state[4]; __pyx_result.order = __pyx_state[5]; __pyx_result.shape = __pyx_state[6]; __pyx_result.work_area = __pyx_state[7]
 *     if len(__pyx_state) > 8 and hasattr(__pyx_result, '__dict__'):
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_AddTraceback("cupy.cuda.cufft.__pyx_unpickle_PlanNd__set_state", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":1
 * def __pyx_unpickle_XtPlanNd(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
 *     cdef object __pyx_PickleError
 *     cdef object __pyx_result
*/

/* Python wrapper */
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_37__pyx_unpickle_XtPlanNd(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
); /*proto*/
PyDoc_STRVAR(__pyx_doc_4cupy_4cuda_5cufft_36__pyx_unpickle_XtPlanNd, "__pyx_unpickle_XtPlanNd(__pyx_type, long __pyx_checksum, __pyx_state)");
static PyMethodDef __pyx_mdef_4cupy_4cuda_5cufft_37__pyx_unpickle_XtPlanNd = {"__pyx_unpickle_XtPlanNd", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_37__pyx_unpickle_XtPlanNd, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_36__pyx_unpickle_XtPlanNd};
static PyObject *__pyx_pw_4cupy_4cuda_5cufft_37__pyx_unpickle_XtPlanNd(PyObject *__pyx_self, 
#if CYTHON_METH_FASTCALL
PyObject *const *__pyx_args, Py_ssize_t __pyx_nargs, PyObject *__pyx_kwds
#else
PyObject *__pyx_args, PyObject *__pyx_kwds
#endif
) {
  PyObject *__pyx_v___pyx_type = 0;
  long __pyx_v___pyx_checksum;
  PyObject *__pyx_v___pyx_state = 0;
  #if !CYTHON_METH_FASTCALL
  CYTHON_UNUSED Py_ssize_t __pyx_nargs;
  #endif
  CYTHON_UNUSED PyObject *const *__pyx_kwvalues;
  PyObject* values[3] = {0,0,0};
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__pyx_unpickle_XtPlanNd (wrapper)", 0);
  #if !CYTHON_METH_FASTCALL
  #if CYTHON_ASSUME_SAFE_SIZE
  __pyx_nargs = PyTuple_GET_SIZE(__pyx_args);
  #else
  __pyx_nargs = PyTuple_Size(__pyx_args); if (unlikely(__pyx_nargs < 0)) return NULL;
  #endif
  #endif
  __pyx_kwvalues = __Pyx_KwValues_FASTCALL(__pyx_args, __pyx_nargs);
  {
    PyObject ** const __pyx_pyargnames[] = {&__pyx_mstate_global->__pyx_n_u_pyx_type,&__pyx_mstate_global->__pyx_n_u_pyx_checksum,&__pyx_mstate_global->__pyx_n_u_pyx_state,0};
    const Py_ssize_t __pyx_kwds_len = (__pyx_kwds) ? __Pyx_NumKwargs_FASTCALL(__pyx_kwds) : 0;
    if (unlikely(__pyx_kwds_len) < 0) __PYX_ERR(1, 1, __pyx_L3_error)
    if (__pyx_kwds_len > 0) {
      switch (__pyx_nargs) {
        case  3:
        values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(1, 1, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  2:
        values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(1, 1, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  1:
        values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
        if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(1, 1, __pyx_L3_error)
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      const Py_ssize_t kwd_pos_args = __pyx_nargs;
      if (__Pyx_ParseKeywords(__pyx_kwds, __pyx_kwvalues, __pyx_pyargnames, 0, values, kwd_pos_args, __pyx_kwds_len, "__pyx_unpickle_XtPlanNd", 0) < (0)) __PYX_ERR(1, 1, __pyx_L3_error)
      for (Py_ssize_t i = __pyx_nargs; i < 3; i++) {
        if (unlikely(!values[i])) { __Pyx_RaiseArgtupleInvalid("__pyx_unpickle_XtPlanNd", 1, 3, 3, i); __PYX_ERR(1, 1, __pyx_L3_error) }
      }
    } else if (unlikely(__pyx_nargs != 3)) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = __Pyx_ArgRef_FASTCALL(__pyx_args, 0);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[0])) __PYX_ERR(1, 1, __pyx_L3_error)
      values[1] = __Pyx_ArgRef_FASTCALL(__pyx_args, 1);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[1])) __PYX_ERR(1, 1, __pyx_L3_error)
      values[2] = __Pyx_ArgRef_FASTCALL(__pyx_args, 2);
      if (!CYTHON_ASSUME_SAFE_MACROS && unlikely(!values[2])) __PYX_ERR(1, 1, __pyx_L3_error)
    }
    __pyx_v___pyx_type = values[0];
    __pyx_v___pyx_checksum = __Pyx_PyLong_As_long(values[1]); if (unlikely((__pyx_v___pyx_checksum == (long)-1) && PyErr_Occurred())) __PYX_ERR(1, 1, __pyx_L3_error)
    __pyx_v___pyx_state = values[2];
  }
  goto __pyx_L6_skip;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("__pyx_unpickle_XtPlanNd", 1, 3, 3, __pyx_nargs); __PYX_ERR(1, 1, __pyx_L3_error)
  __pyx_L6_skip:;
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L3_error:;
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_AddTraceback("cupy.cuda.cufft.__pyx_unpickle_XtPlanNd", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_4cupy_4cuda_5cufft_36__pyx_unpickle_XtPlanNd(__pyx_self, __pyx_v___pyx_type, __pyx_v___pyx_checksum, __pyx_v___pyx_state);

  /* function exit code */
  for (Py_ssize_t __pyx_temp=0; __pyx_temp < (Py_ssize_t)(sizeof(values)/sizeof(values[0])); ++__pyx_temp) {
    Py_XDECREF(values[__pyx_temp]);
  }
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_4cupy_4cuda_5cufft_36__pyx_unpickle_XtPlanNd(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v___pyx_type, long __pyx_v___pyx_checksum, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_v___pyx_PickleError = 0;
  PyObject *__pyx_v___pyx_result = 0;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  PyObject *__pyx_t_3 = NULL;
  size_t __pyx_t_4;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__pyx_unpickle_XtPlanNd", 0);

  /* "(tree fragment)":4
 *     cdef object __pyx_PickleError
 *     cdef object __pyx_result
 *     if __pyx_checksum not in (0x19c6497, 0x054ffc9, 0x5c231b7):             # <<<<<<<<<<<<<<
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0x19c6497, 0x054ffc9, 0x5c231b7) = (etype, gpus, handle, itype, last_axis, last_size, order, otype, shape, work_area))" % __pyx_checksum
*/
  __pyx_t_1 = __Pyx_PyLong_From_long(__pyx_v___pyx_checksum); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 4, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = (__Pyx_PySequence_ContainsTF(__pyx_t_1, __pyx_mstate_global->__pyx_tuple[2], Py_NE)); if (unlikely((__pyx_t_2 < 0))) __PYX_ERR(1, 4, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (__pyx_t_2) {

    /* "(tree fragment)":5
 *     cdef object __pyx_result
 *     if __pyx_checksum not in (0x19c6497, 0x054ffc9, 0x5c231b7):
 *         from pickle import PickleError as __pyx_PickleError             # <<<<<<<<<<<<<<
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0x19c6497, 0x054ffc9, 0x5c231b7) = (etype, gpus, handle, itype, last_axis, last_size, order, otype, shape, work_area))" % __pyx_checksum
 *     __pyx_result = XtPlanNd.__new__(__pyx_type)
*/
    __pyx_t_1 = PyList_New(1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 5, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_mstate_global->__pyx_n_u_PickleError);
    __Pyx_GIVEREF(__pyx_mstate_global->__pyx_n_u_PickleError);
    if (__Pyx_PyList_SET_ITEM(__pyx_t_1, 0, __pyx_mstate_global->__pyx_n_u_PickleError) != (0)) __PYX_ERR(1, 5, __pyx_L1_error);
    __pyx_t_3 = __Pyx_Import(__pyx_mstate_global->__pyx_n_u_pickle, __pyx_t_1, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 5, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_ImportFrom(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_PickleError); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 5, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_INCREF(__pyx_t_1);
    __pyx_v___pyx_PickleError = __pyx_t_1;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

    /* "(tree fragment)":6
 *     if __pyx_checksum not in (0x19c6497, 0x054ffc9, 0x5c231b7):
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0x19c6497, 0x054ffc9, 0x5c231b7) = (etype, gpus, handle, itype, last_axis, last_size, order, otype, shape, work_area))" % __pyx_checksum             # <<<<<<<<<<<<<<
 *     __pyx_result = XtPlanNd.__new__(__pyx_type)
 *     if __pyx_state is not None:
*/
    __pyx_t_3 = __Pyx_PyLong_From_long(__pyx_v___pyx_checksum); if (unlikely(!__pyx_t_3)) __PYX_ERR(1, 6, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_1 = PyUnicode_Format(__pyx_mstate_global->__pyx_kp_u_Incompatible_checksums_0x_x_vs_0_3, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 6, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_Raise(__pyx_v___pyx_PickleError, __pyx_t_1, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(1, 6, __pyx_L1_error)

    /* "(tree fragment)":4
 *     cdef object __pyx_PickleError
 *     cdef object __pyx_result
 *     if __pyx_checksum not in (0x19c6497, 0x054ffc9, 0x5c231b7):             # <<<<<<<<<<<<<<
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0x19c6497, 0x054ffc9, 0x5c231b7) = (etype, gpus, handle, itype, last_axis, last_size, order, otype, shape, work_area))" % __pyx_checksum
*/
  }

  /* "(tree fragment)":7
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0x19c6497, 0x054ffc9, 0x5c231b7) = (etype, gpus, handle, itype, last_axis, last_size, order, otype, shape, work_area))" % __pyx_checksum
 *     __pyx_result = XtPlanNd.__new__(__pyx_type)             # <<<<<<<<<<<<<<
 *     if __pyx_state is not None:
 *         __pyx_unpickle_XtPlanNd__set_state(<XtPlanNd> __pyx_result, __pyx_state)
*/
  __pyx_t_3 = ((PyObject *)__pyx_mstate_global->__pyx_ptype_4cupy_4cuda_5cufft_XtPlanNd);
  __Pyx_INCREF(__pyx_t_3);
  __pyx_t_4 = 0;
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, __pyx_v___pyx_type};
    __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_new, __pyx_callargs+__pyx_t_4, (2-__pyx_t_4) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 7, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  }
  __pyx_v___pyx_result = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "(tree fragment)":8
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0x19c6497, 0x054ffc9, 0x5c231b7) = (etype, gpus, handle, itype, last_axis, last_size, order, otype, shape, work_area))" % __pyx_checksum
 *     __pyx_result = XtPlanNd.__new__(__pyx_type)
 *     if __pyx_state is not None:             # <<<<<<<<<<<<<<
 *         __pyx_unpickle_XtPlanNd__set_state(<XtPlanNd> __pyx_result, __pyx_state)
 *     return __pyx_result
*/
  __pyx_t_2 = (__pyx_v___pyx_state != Py_None);
  if (__pyx_t_2) {

    /* "(tree fragment)":9
 *     __pyx_result = XtPlanNd.__new__(__pyx_type)
 *     if __pyx_state is not None:
 *         __pyx_unpickle_XtPlanNd__set_state(<XtPlanNd> __pyx_result, __pyx_state)             # <<<<<<<<<<<<<<
 *     return __pyx_result
 * cdef __pyx_unpickle_XtPlanNd__set_state(XtPlanNd __pyx_result, tuple __pyx_state):
*/
    if (!(likely(PyTuple_CheckExact(__pyx_v___pyx_state))||((__pyx_v___pyx_state) == Py_None) || __Pyx_RaiseUnexpectedTypeError("tuple", __pyx_v___pyx_state))) __PYX_ERR(1, 9, __pyx_L1_error)
    __pyx_t_1 = __pyx_f_4cupy_4cuda_5cufft___pyx_unpickle_XtPlanNd__set_state(((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)__pyx_v___pyx_result), ((PyObject*)__pyx_v___pyx_state)); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 9, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "(tree fragment)":8
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0x19c6497, 0x054ffc9, 0x5c231b7) = (etype, gpus, handle, itype, last_axis, last_size, order, otype, shape, work_area))" % __pyx_checksum
 *     __pyx_result = XtPlanNd.__new__(__pyx_type)
 *     if __pyx_state is not None:             # <<<<<<<<<<<<<<
 *         __pyx_unpickle_XtPlanNd__set_state(<XtPlanNd> __pyx_result, __pyx_state)
 *     return __pyx_result
*/
  }

  /* "(tree fragment)":10
 *     if __pyx_state is not None:
 *         __pyx_unpickle_XtPlanNd__set_state(<XtPlanNd> __pyx_result, __pyx_state)
 *     return __pyx_result             # <<<<<<<<<<<<<<
 * cdef __pyx_unpickle_XtPlanNd__set_state(XtPlanNd __pyx_result, tuple __pyx_state):
 *     __pyx_result.etype = __pyx_state[0]; __pyx_result.gpus = __pyx_state[1]; __pyx_result.handle = __pyx_state[2]; __pyx_result.itype = __pyx_state[3]; __pyx_result.last_axis = __pyx_state[4]; __pyx_result.last_size = __pyx_state[5]; __pyx_result.order = __pyx_state[6]; __pyx_result.otype = __pyx_state[7]; __pyx_result.shape = __pyx_state[8]; __pyx_result.work_area = __pyx_state[9]
*/
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v___pyx_result);
  __pyx_r = __pyx_v___pyx_result;
  goto __pyx_L0;

  /* "(tree fragment)":1
 * def __pyx_unpickle_XtPlanNd(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
 *     cdef object __pyx_PickleError
 *     cdef object __pyx_result
*/

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("cupy.cuda.cufft.__pyx_unpickle_XtPlanNd", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v___pyx_PickleError);
  __Pyx_XDECREF(__pyx_v___pyx_result);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "(tree fragment)":11
 *         __pyx_unpickle_XtPlanNd__set_state(<XtPlanNd> __pyx_result, __pyx_state)
 *     return __pyx_result
 * cdef __pyx_unpickle_XtPlanNd__set_state(XtPlanNd __pyx_result, tuple __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_result.etype = __pyx_state[0]; __pyx_result.gpus = __pyx_state[1]; __pyx_result.handle = __pyx_state[2]; __pyx_result.itype = __pyx_state[3]; __pyx_result.last_axis = __pyx_state[4]; __pyx_result.last_size = __pyx_state[5]; __pyx_result.order = __pyx_state[6]; __pyx_result.otype = __pyx_state[7]; __pyx_result.shape = __pyx_state[8]; __pyx_result.work_area = __pyx_state[9]
 *     if len(__pyx_state) > 10 and hasattr(__pyx_result, '__dict__'):
*/

static PyObject *__pyx_f_4cupy_4cuda_5cufft___pyx_unpickle_XtPlanNd__set_state(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *__pyx_v___pyx_result, PyObject *__pyx_v___pyx_state) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  intptr_t __pyx_t_3;
  int __pyx_t_4;
  Py_ssize_t __pyx_t_5;
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  PyObject *__pyx_t_8 = NULL;
  PyObject *__pyx_t_9 = NULL;
  size_t __pyx_t_10;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__pyx_unpickle_XtPlanNd__set_state", 0);

  /* "(tree fragment)":12
 *     return __pyx_result
 * cdef __pyx_unpickle_XtPlanNd__set_state(XtPlanNd __pyx_result, tuple __pyx_state):
 *     __pyx_result.etype = __pyx_state[0]; __pyx_result.gpus = __pyx_state[1]; __pyx_result.handle = __pyx_state[2]; __pyx_result.itype = __pyx_state[3]; __pyx_result.last_axis = __pyx_state[4]; __pyx_result.last_size = __pyx_state[5]; __pyx_result.order = __pyx_state[6]; __pyx_result.otype = __pyx_state[7]; __pyx_result.shape = __pyx_state[8]; __pyx_result.work_area = __pyx_state[9]             # <<<<<<<<<<<<<<
 *     if len(__pyx_state) > 10 and hasattr(__pyx_result, '__dict__'):
 *         __pyx_result.__dict__.update(__pyx_state[10])
*/
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 0, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyLong_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->etype = __pyx_t_2;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 1, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(PyList_CheckExact(__pyx_t_1))||((__pyx_t_1) == Py_None) || __Pyx_RaiseUnexpectedTypeError("list", __pyx_t_1))) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->gpus);
  __Pyx_DECREF(__pyx_v___pyx_result->gpus);
  __pyx_v___pyx_result->gpus = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 2, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = PyLong_AsSsize_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((intptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->handle = __pyx_t_3;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 3, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyLong_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->itype = __pyx_t_2;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 4, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyLong_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->last_axis = __pyx_t_2;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 5, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->last_size);
  __Pyx_DECREF(__pyx_v___pyx_result->last_size);
  __pyx_v___pyx_result->last_size = __pyx_t_1;
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 6, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(PyUnicode_CheckExact(__pyx_t_1))||((__pyx_t_1) == Py_None) || __Pyx_RaiseUnexpectedTypeError("str", __pyx_t_1))) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->order);
  __Pyx_DECREF(__pyx_v___pyx_result->order);
  __pyx_v___pyx_result->order = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 7, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyLong_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v___pyx_result->otype = __pyx_t_2;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 8, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (!(likely(PyTuple_CheckExact(__pyx_t_1))||((__pyx_t_1) == Py_None) || __Pyx_RaiseUnexpectedTypeError("tuple", __pyx_t_1))) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->shape);
  __Pyx_DECREF(__pyx_v___pyx_result->shape);
  __pyx_v___pyx_result->shape = ((PyObject*)__pyx_t_1);
  __pyx_t_1 = 0;
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
    __PYX_ERR(1, 12, __pyx_L1_error)
  }
  __pyx_t_1 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 9, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_GIVEREF(__pyx_t_1);
  __Pyx_GOTREF(__pyx_v___pyx_result->work_area);
  __Pyx_DECREF(__pyx_v___pyx_result->work_area);
  __pyx_v___pyx_result->work_area = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "(tree fragment)":13
 * cdef __pyx_unpickle_XtPlanNd__set_state(XtPlanNd __pyx_result, tuple __pyx_state):
 *     __pyx_result.etype = __pyx_state[0]; __pyx_result.gpus = __pyx_state[1]; __pyx_result.handle = __pyx_state[2]; __pyx_result.itype = __pyx_state[3]; __pyx_result.last_axis = __pyx_state[4]; __pyx_result.last_size = __pyx_state[5]; __pyx_result.order = __pyx_state[6]; __pyx_result.otype = __pyx_state[7]; __pyx_result.shape = __pyx_state[8]; __pyx_result.work_area = __pyx_state[9]
 *     if len(__pyx_state) > 10 and hasattr(__pyx_result, '__dict__'):             # <<<<<<<<<<<<<<
 *         __pyx_result.__dict__.update(__pyx_state[10])
*/
  if (unlikely(__pyx_v___pyx_state == Py_None)) {
    PyErr_SetString(PyExc_TypeError, "object of type 'NoneType' has no len()");
    __PYX_ERR(1, 13, __pyx_L1_error)
  }
  __pyx_t_5 = __Pyx_PyTuple_GET_SIZE(__pyx_v___pyx_state); if (unlikely(__pyx_t_5 == ((Py_ssize_t)-1))) __PYX_ERR(1, 13, __pyx_L1_error)
  __pyx_t_6 = (__pyx_t_5 > 10);
  if (__pyx_t_6) {
  } else {
    __pyx_t_4 = __pyx_t_6;
    goto __pyx_L4_bool_binop_done;
  }
  __pyx_t_6 = __Pyx_HasAttr(((PyObject *)__pyx_v___pyx_result), __pyx_mstate_global->__pyx_n_u_dict); if (unlikely(__pyx_t_6 == ((int)-1))) __PYX_ERR(1, 13, __pyx_L1_error)
  __pyx_t_4 = __pyx_t_6;
  __pyx_L4_bool_binop_done:;
  if (__pyx_t_4) {

    /* "(tree fragment)":14
 *     __pyx_result.etype = __pyx_state[0]; __pyx_result.gpus = __pyx_state[1]; __pyx_result.handle = __pyx_state[2]; __pyx_result.itype = __pyx_state[3]; __pyx_result.last_axis = __pyx_state[4]; __pyx_result.last_size = __pyx_state[5]; __pyx_result.order = __pyx_state[6]; __pyx_result.otype = __pyx_state[7]; __pyx_result.shape = __pyx_state[8]; __pyx_result.work_area = __pyx_state[9]
 *     if len(__pyx_state) > 10 and hasattr(__pyx_result, '__dict__'):
 *         __pyx_result.__dict__.update(__pyx_state[10])             # <<<<<<<<<<<<<<
*/
    __pyx_t_8 = __Pyx_PyObject_GetAttrStr(((PyObject *)__pyx_v___pyx_result), __pyx_mstate_global->__pyx_n_u_dict); if (unlikely(!__pyx_t_8)) __PYX_ERR(1, 14, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_8);
    __pyx_t_7 = __pyx_t_8;
    __Pyx_INCREF(__pyx_t_7);
    if (unlikely(__pyx_v___pyx_state == Py_None)) {
      PyErr_SetString(PyExc_TypeError, "'NoneType' object is not subscriptable");
      __PYX_ERR(1, 14, __pyx_L1_error)
    }
    __pyx_t_9 = __Pyx_GetItemInt_Tuple(__pyx_v___pyx_state, 10, long, 1, __Pyx_PyLong_From_long, 0, 0, 1, 1); if (unlikely(!__pyx_t_9)) __PYX_ERR(1, 14, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_9);
    __pyx_t_10 = 0;
    {
      PyObject *__pyx_callargs[2] = {__pyx_t_7, __pyx_t_9};
      __pyx_t_1 = __Pyx_PyObject_FastCallMethod(__pyx_mstate_global->__pyx_n_u_update, __pyx_callargs+__pyx_t_10, (2-__pyx_t_10) | (1*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
      __Pyx_XDECREF(__pyx_t_7); __pyx_t_7 = 0;
      __Pyx_DECREF(__pyx_t_9); __pyx_t_9 = 0;
      __Pyx_DECREF(__pyx_t_8); __pyx_t_8 = 0;
      if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 14, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
    }
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

    /* "(tree fragment)":13
 * cdef __pyx_unpickle_XtPlanNd__set_state(XtPlanNd __pyx_result, tuple __pyx_state):
 *     __pyx_result.etype = __pyx_state[0]; __pyx_result.gpus = __pyx_state[1]; __pyx_result.handle = __pyx_state[2]; __pyx_result.itype = __pyx_state[3]; __pyx_result.last_axis = __pyx_state[4]; __pyx_result.last_size = __pyx_state[5]; __pyx_result.order = __pyx_state[6]; __pyx_result.otype = __pyx_state[7]; __pyx_result.shape = __pyx_state[8]; __pyx_result.work_area = __pyx_state[9]
 *     if len(__pyx_state) > 10 and hasattr(__pyx_result, '__dict__'):             # <<<<<<<<<<<<<<
 *         __pyx_result.__dict__.update(__pyx_state[10])
*/
  }

  /* "(tree fragment)":11
 *         __pyx_unpickle_XtPlanNd__set_state(<XtPlanNd> __pyx_result, __pyx_state)
 *     return __pyx_result
 * cdef __pyx_unpickle_XtPlanNd__set_state(XtPlanNd __pyx_result, tuple __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_result.etype = __pyx_state[0]; __pyx_result.gpus = __pyx_state[1]; __pyx_result.handle = __pyx_state[2]; __pyx_result.itype = __pyx_state[3]; __pyx_result.last_axis = __pyx_state[4]; __pyx_result.last_size = __pyx_state[5]; __pyx_result.order = __pyx_state[6]; __pyx_result.otype = __pyx_state[7]; __pyx_result.shape = __pyx_state[8]; __pyx_result.work_area = __pyx_state[9]
 *     if len(__pyx_state) > 10 and hasattr(__pyx_result, '__dict__'):
*/

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_XDECREF(__pyx_t_8);
  __Pyx_XDECREF(__pyx_t_9);
  __Pyx_AddTraceback("cupy.cuda.cufft.__pyx_unpickle_XtPlanNd__set_state", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}
/* #### Code section: module_exttypes ### */
static struct __pyx_vtabstruct_4cupy_4cuda_5cufft_Plan1d __pyx_vtable_4cupy_4cuda_5cufft_Plan1d;

static PyObject *__pyx_tp_new_4cupy_4cuda_5cufft_Plan1d(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *p;
  PyObject *o;
  #if CYTHON_COMPILING_IN_LIMITED_API
  allocfunc alloc_func = (allocfunc)PyType_GetSlot(t, Py_tp_alloc);
  o = alloc_func(t, 0);
  #else
  if (likely(!__Pyx_PyType_HasFeature(t, Py_TPFLAGS_IS_ABSTRACT))) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_mstate_global->__pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  #endif
  p = ((struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)o);
  p->__pyx_vtab = __pyx_vtabptr_4cupy_4cuda_5cufft_Plan1d;
  p->work_area = Py_None; Py_INCREF(Py_None);
  p->gpus = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->batch_share = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->gather_streams = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->gather_events = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->scatter_streams = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->scatter_events = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->xtArr_buffer = ((PyObject*)Py_None); Py_INCREF(Py_None);
  return o;
}

static void __pyx_tp_dealloc_4cupy_4cuda_5cufft_Plan1d(PyObject *o) {
  struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *p = (struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)o;
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely((PY_VERSION_HEX >= 0x03080000 || __Pyx_PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE)) && __Pyx_PyObject_GetSlot(o, tp_finalize, destructor)) && !__Pyx_PyObject_GC_IsFinalized(o)) {
    if (__Pyx_PyObject_GetSlot(o, tp_dealloc, destructor) == __pyx_tp_dealloc_4cupy_4cuda_5cufft_Plan1d) {
      if (PyObject_CallFinalizerFromDealloc(o)) return;
    }
  }
  #endif
  PyObject_GC_UnTrack(o);
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    __Pyx_SET_REFCNT(o, Py_REFCNT(o) + 1);
    __pyx_pw_4cupy_4cuda_5cufft_6Plan1d_5__dealloc__(o);
    __Pyx_SET_REFCNT(o, Py_REFCNT(o) - 1);
    PyErr_Restore(etype, eval, etb);
  }
  Py_CLEAR(p->work_area);
  Py_CLEAR(p->gpus);
  Py_CLEAR(p->batch_share);
  Py_CLEAR(p->gather_streams);
  Py_CLEAR(p->gather_events);
  Py_CLEAR(p->scatter_streams);
  Py_CLEAR(p->scatter_events);
  Py_CLEAR(p->xtArr_buffer);
  #if CYTHON_USE_TYPE_SLOTS
  (*Py_TYPE(o)->tp_free)(o);
  #else
  {
    freefunc tp_free = (freefunc)PyType_GetSlot(Py_TYPE(o), Py_tp_free);
    if (tp_free) tp_free(o);
  }
  #endif
}

static int __pyx_tp_traverse_4cupy_4cuda_5cufft_Plan1d(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *p = (struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)o;
  {
    e = __Pyx_call_type_traverse(o, 1, v, a);
    if (e) return e;
  }
  if (p->work_area) {
    e = (*v)(p->work_area, a); if (e) return e;
  }
  if (p->gpus) {
    e = (*v)(p->gpus, a); if (e) return e;
  }
  if (p->batch_share) {
    e = (*v)(p->batch_share, a); if (e) return e;
  }
  if (p->gather_streams) {
    e = (*v)(p->gather_streams, a); if (e) return e;
  }
  if (p->gather_events) {
    e = (*v)(p->gather_events, a); if (e) return e;
  }
  if (p->scatter_streams) {
    e = (*v)(p->scatter_streams, a); if (e) return e;
  }
  if (p->scatter_events) {
    e = (*v)(p->scatter_events, a); if (e) return e;
  }
  if (p->xtArr_buffer) {
    e = (*v)(p->xtArr_buffer, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_4cupy_4cuda_5cufft_Plan1d(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *p = (struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *)o;
  tmp = ((PyObject*)p->work_area);
  p->work_area = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->gpus);
  p->gpus = ((PyObject*)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->batch_share);
  p->batch_share = ((PyObject*)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->gather_streams);
  p->gather_streams = ((PyObject*)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->gather_events);
  p->gather_events = ((PyObject*)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->scatter_streams);
  p->scatter_streams = ((PyObject*)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->scatter_events);
  p->scatter_events = ((PyObject*)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->xtArr_buffer);
  p->xtArr_buffer = ((PyObject*)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_6Plan1d_handle(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_6Plan1d_6handle_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_6Plan1d_work_area(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_6Plan1d_9work_area_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_6Plan1d_nx(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_6Plan1d_2nx_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_6Plan1d_batch(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_6Plan1d_5batch_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_6Plan1d_fft_type(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_6Plan1d_8fft_type_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_6Plan1d_gpus(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_6Plan1d_4gpus_1__get__(o);
}

static PyMethodDef __pyx_methods_4cupy_4cuda_5cufft_Plan1d[] = {
  {"_multi_gpu_get_scatter_streams_events", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_3_multi_gpu_get_scatter_streams_events, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6Plan1d_2_multi_gpu_get_scatter_streams_events},
  {"__enter__", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_7__enter__, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6Plan1d_6__enter__},
  {"__exit__", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_9__exit__, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6Plan1d_8__exit__},
  {"fft", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_11fft, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6Plan1d_10fft},
  {"_single_gpu_fft", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_13_single_gpu_fft, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6Plan1d_12_single_gpu_fft},
  {"_multi_gpu_setup_buffer", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_15_multi_gpu_setup_buffer, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6Plan1d_14_multi_gpu_setup_buffer},
  {"_multi_gpu_memcpy", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_17_multi_gpu_memcpy, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6Plan1d_16_multi_gpu_memcpy},
  {"_multi_gpu_fft", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_19_multi_gpu_fft, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6Plan1d_18_multi_gpu_fft},
  {"_output_dtype_and_shape", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_21_output_dtype_and_shape, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6Plan1d_20_output_dtype_and_shape},
  {"get_output_array", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_23get_output_array, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6Plan1d_22get_output_array},
  {"check_output_array", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_25check_output_array, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6Plan1d_24check_output_array},
  {"__reduce_cython__", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_27__reduce_cython__, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6Plan1d_26__reduce_cython__},
  {"__setstate_cython__", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_29__setstate_cython__, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6Plan1d_28__setstate_cython__},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_4cupy_4cuda_5cufft_Plan1d[] = {
  {"handle", __pyx_getprop_4cupy_4cuda_5cufft_6Plan1d_handle, 0, 0, 0},
  {"work_area", __pyx_getprop_4cupy_4cuda_5cufft_6Plan1d_work_area, 0, 0, 0},
  {"nx", __pyx_getprop_4cupy_4cuda_5cufft_6Plan1d_nx, 0, 0, 0},
  {"batch", __pyx_getprop_4cupy_4cuda_5cufft_6Plan1d_batch, 0, 0, 0},
  {"fft_type", __pyx_getprop_4cupy_4cuda_5cufft_6Plan1d_fft_type, 0, 0, 0},
  {"gpus", __pyx_getprop_4cupy_4cuda_5cufft_6Plan1d_gpus, 0, 0, 0},
  {0, 0, 0, 0, 0}
};
#if CYTHON_USE_TYPE_SPECS
static PyType_Slot __pyx_type_4cupy_4cuda_5cufft_Plan1d_slots[] = {
  {Py_tp_dealloc, (void *)__pyx_tp_dealloc_4cupy_4cuda_5cufft_Plan1d},
  {Py_tp_doc, (void *)PyDoc_STR("Plan1d(int nx, int fft_type, int batch, devices=None, *, out=None, intptr_t prealloc_plan=0)")},
  {Py_tp_traverse, (void *)__pyx_tp_traverse_4cupy_4cuda_5cufft_Plan1d},
  {Py_tp_clear, (void *)__pyx_tp_clear_4cupy_4cuda_5cufft_Plan1d},
  {Py_tp_methods, (void *)__pyx_methods_4cupy_4cuda_5cufft_Plan1d},
  {Py_tp_getset, (void *)__pyx_getsets_4cupy_4cuda_5cufft_Plan1d},
  {Py_tp_init, (void *)__pyx_pw_4cupy_4cuda_5cufft_6Plan1d_1__init__},
  {Py_tp_new, (void *)__pyx_tp_new_4cupy_4cuda_5cufft_Plan1d},
  {0, 0},
};
static PyType_Spec __pyx_type_4cupy_4cuda_5cufft_Plan1d_spec = {
  "cupy.cuda.cufft.Plan1d",
  sizeof(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d),
  0,
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC,
  __pyx_type_4cupy_4cuda_5cufft_Plan1d_slots,
};
#else

static PyTypeObject __pyx_type_4cupy_4cuda_5cufft_Plan1d = {
  PyVarObject_HEAD_INIT(0, 0)
  "cupy.cuda.cufft.""Plan1d", /*tp_name*/
  sizeof(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_4cupy_4cuda_5cufft_Plan1d, /*tp_dealloc*/
  #if PY_VERSION_HEX < 0x030800b4
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4
  0, /*tp_vectorcall_offset*/
  #endif
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  0, /*tp_as_async*/
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  PyDoc_STR("Plan1d(int nx, int fft_type, int batch, devices=None, *, out=None, intptr_t prealloc_plan=0)"), /*tp_doc*/
  __pyx_tp_traverse_4cupy_4cuda_5cufft_Plan1d, /*tp_traverse*/
  __pyx_tp_clear_4cupy_4cuda_5cufft_Plan1d, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_4cupy_4cuda_5cufft_Plan1d, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_4cupy_4cuda_5cufft_Plan1d, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  #if !CYTHON_USE_TYPE_SPECS
  0, /*tp_dictoffset*/
  #endif
  __pyx_pw_4cupy_4cuda_5cufft_6Plan1d_1__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_4cupy_4cuda_5cufft_Plan1d, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if CYTHON_USE_TP_FINALIZE
  0, /*tp_finalize*/
  #else
  NULL, /*tp_finalize*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b1 && (!CYTHON_COMPILING_IN_PYPY || PYPY_VERSION_NUM >= 0x07030800)
  0, /*tp_vectorcall*/
  #endif
  #if __PYX_NEED_TP_PRINT_SLOT == 1
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030C0000
  0, /*tp_watched*/
  #endif
  #if PY_VERSION_HEX >= 0x030d00A4
  0, /*tp_versions_used*/
  #endif
  #if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX >= 0x03090000 && PY_VERSION_HEX < 0x030a0000
  0, /*tp_pypy_flags*/
  #endif
};
#endif

static PyObject *__pyx_tp_new_4cupy_4cuda_5cufft_PlanNd(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *p;
  PyObject *o;
  #if CYTHON_COMPILING_IN_LIMITED_API
  allocfunc alloc_func = (allocfunc)PyType_GetSlot(t, Py_tp_alloc);
  o = alloc_func(t, 0);
  #else
  if (likely(!__Pyx_PyType_HasFeature(t, Py_TPFLAGS_IS_ABSTRACT))) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_mstate_global->__pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  #endif
  p = ((struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)o);
  p->work_area = Py_None; Py_INCREF(Py_None);
  p->shape = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->order = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->last_size = Py_None; Py_INCREF(Py_None);
  p->gpus = ((PyObject*)Py_None); Py_INCREF(Py_None);
  return o;
}

static void __pyx_tp_dealloc_4cupy_4cuda_5cufft_PlanNd(PyObject *o) {
  struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *p = (struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)o;
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely((PY_VERSION_HEX >= 0x03080000 || __Pyx_PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE)) && __Pyx_PyObject_GetSlot(o, tp_finalize, destructor)) && !__Pyx_PyObject_GC_IsFinalized(o)) {
    if (__Pyx_PyObject_GetSlot(o, tp_dealloc, destructor) == __pyx_tp_dealloc_4cupy_4cuda_5cufft_PlanNd) {
      if (PyObject_CallFinalizerFromDealloc(o)) return;
    }
  }
  #endif
  PyObject_GC_UnTrack(o);
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    __Pyx_SET_REFCNT(o, Py_REFCNT(o) + 1);
    __pyx_pw_4cupy_4cuda_5cufft_6PlanNd_3__dealloc__(o);
    __Pyx_SET_REFCNT(o, Py_REFCNT(o) - 1);
    PyErr_Restore(etype, eval, etb);
  }
  Py_CLEAR(p->work_area);
  Py_CLEAR(p->shape);
  Py_CLEAR(p->order);
  Py_CLEAR(p->last_size);
  Py_CLEAR(p->gpus);
  #if CYTHON_USE_TYPE_SLOTS
  (*Py_TYPE(o)->tp_free)(o);
  #else
  {
    freefunc tp_free = (freefunc)PyType_GetSlot(Py_TYPE(o), Py_tp_free);
    if (tp_free) tp_free(o);
  }
  #endif
}

static int __pyx_tp_traverse_4cupy_4cuda_5cufft_PlanNd(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *p = (struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)o;
  {
    e = __Pyx_call_type_traverse(o, 1, v, a);
    if (e) return e;
  }
  if (p->work_area) {
    e = (*v)(p->work_area, a); if (e) return e;
  }
  if (p->shape) {
    e = (*v)(p->shape, a); if (e) return e;
  }
  if (p->last_size) {
    e = (*v)(p->last_size, a); if (e) return e;
  }
  if (p->gpus) {
    e = (*v)(p->gpus, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_4cupy_4cuda_5cufft_PlanNd(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *p = (struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd *)o;
  tmp = ((PyObject*)p->work_area);
  p->work_area = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->shape);
  p->shape = ((PyObject*)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->last_size);
  p->last_size = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->gpus);
  p->gpus = ((PyObject*)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_6PlanNd_handle(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_6PlanNd_6handle_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_6PlanNd_work_area(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_6PlanNd_9work_area_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_6PlanNd_shape(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_6PlanNd_5shape_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_6PlanNd_fft_type(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_6PlanNd_8fft_type_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_6PlanNd_order(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_6PlanNd_5order_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_6PlanNd_last_axis(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_6PlanNd_9last_axis_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_6PlanNd_last_size(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_6PlanNd_9last_size_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_6PlanNd_gpus(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_6PlanNd_4gpus_1__get__(o);
}

static PyMethodDef __pyx_methods_4cupy_4cuda_5cufft_PlanNd[] = {
  {"__enter__", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_5__enter__, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6PlanNd_4__enter__},
  {"__exit__", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_7__exit__, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6PlanNd_6__exit__},
  {"fft", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_9fft, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6PlanNd_8fft},
  {"_output_dtype_and_shape", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_11_output_dtype_and_shape, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6PlanNd_10_output_dtype_and_shape},
  {"get_output_array", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_13get_output_array, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6PlanNd_12get_output_array},
  {"check_output_array", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_15check_output_array, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6PlanNd_14check_output_array},
  {"__reduce_cython__", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_17__reduce_cython__, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6PlanNd_16__reduce_cython__},
  {"__setstate_cython__", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_19__setstate_cython__, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6PlanNd_18__setstate_cython__},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_4cupy_4cuda_5cufft_PlanNd[] = {
  {"handle", __pyx_getprop_4cupy_4cuda_5cufft_6PlanNd_handle, 0, 0, 0},
  {"work_area", __pyx_getprop_4cupy_4cuda_5cufft_6PlanNd_work_area, 0, 0, 0},
  {"shape", __pyx_getprop_4cupy_4cuda_5cufft_6PlanNd_shape, 0, 0, 0},
  {"fft_type", __pyx_getprop_4cupy_4cuda_5cufft_6PlanNd_fft_type, 0, 0, 0},
  {"order", __pyx_getprop_4cupy_4cuda_5cufft_6PlanNd_order, 0, 0, 0},
  {"last_axis", __pyx_getprop_4cupy_4cuda_5cufft_6PlanNd_last_axis, 0, 0, 0},
  {"last_size", __pyx_getprop_4cupy_4cuda_5cufft_6PlanNd_last_size, 0, 0, 0},
  {"gpus", __pyx_getprop_4cupy_4cuda_5cufft_6PlanNd_gpus, 0, 0, 0},
  {0, 0, 0, 0, 0}
};
#if CYTHON_USE_TYPE_SPECS
static PyType_Slot __pyx_type_4cupy_4cuda_5cufft_PlanNd_slots[] = {
  {Py_tp_dealloc, (void *)__pyx_tp_dealloc_4cupy_4cuda_5cufft_PlanNd},
  {Py_tp_doc, (void *)PyDoc_STR("PlanNd(shape, inembed, int istride, int idist, onembed, int ostride, int odist, int fft_type, int batch, str order, int last_axis, last_size, intptr_t prealloc_plan=0, *)")},
  {Py_tp_traverse, (void *)__pyx_tp_traverse_4cupy_4cuda_5cufft_PlanNd},
  {Py_tp_clear, (void *)__pyx_tp_clear_4cupy_4cuda_5cufft_PlanNd},
  {Py_tp_methods, (void *)__pyx_methods_4cupy_4cuda_5cufft_PlanNd},
  {Py_tp_getset, (void *)__pyx_getsets_4cupy_4cuda_5cufft_PlanNd},
  {Py_tp_init, (void *)__pyx_pw_4cupy_4cuda_5cufft_6PlanNd_1__init__},
  {Py_tp_new, (void *)__pyx_tp_new_4cupy_4cuda_5cufft_PlanNd},
  {0, 0},
};
static PyType_Spec __pyx_type_4cupy_4cuda_5cufft_PlanNd_spec = {
  "cupy.cuda.cufft.PlanNd",
  sizeof(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd),
  0,
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC,
  __pyx_type_4cupy_4cuda_5cufft_PlanNd_slots,
};
#else

static PyTypeObject __pyx_type_4cupy_4cuda_5cufft_PlanNd = {
  PyVarObject_HEAD_INIT(0, 0)
  "cupy.cuda.cufft.""PlanNd", /*tp_name*/
  sizeof(struct __pyx_obj_4cupy_4cuda_5cufft_PlanNd), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_4cupy_4cuda_5cufft_PlanNd, /*tp_dealloc*/
  #if PY_VERSION_HEX < 0x030800b4
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4
  0, /*tp_vectorcall_offset*/
  #endif
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  0, /*tp_as_async*/
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  PyDoc_STR("PlanNd(shape, inembed, int istride, int idist, onembed, int ostride, int odist, int fft_type, int batch, str order, int last_axis, last_size, intptr_t prealloc_plan=0, *)"), /*tp_doc*/
  __pyx_tp_traverse_4cupy_4cuda_5cufft_PlanNd, /*tp_traverse*/
  __pyx_tp_clear_4cupy_4cuda_5cufft_PlanNd, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_4cupy_4cuda_5cufft_PlanNd, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_4cupy_4cuda_5cufft_PlanNd, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  #if !CYTHON_USE_TYPE_SPECS
  0, /*tp_dictoffset*/
  #endif
  __pyx_pw_4cupy_4cuda_5cufft_6PlanNd_1__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_4cupy_4cuda_5cufft_PlanNd, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if CYTHON_USE_TP_FINALIZE
  0, /*tp_finalize*/
  #else
  NULL, /*tp_finalize*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b1 && (!CYTHON_COMPILING_IN_PYPY || PYPY_VERSION_NUM >= 0x07030800)
  0, /*tp_vectorcall*/
  #endif
  #if __PYX_NEED_TP_PRINT_SLOT == 1
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030C0000
  0, /*tp_watched*/
  #endif
  #if PY_VERSION_HEX >= 0x030d00A4
  0, /*tp_versions_used*/
  #endif
  #if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX >= 0x03090000 && PY_VERSION_HEX < 0x030a0000
  0, /*tp_pypy_flags*/
  #endif
};
#endif

static PyObject *__pyx_tp_new_4cupy_4cuda_5cufft_XtPlanNd(PyTypeObject *t, CYTHON_UNUSED PyObject *a, CYTHON_UNUSED PyObject *k) {
  struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *p;
  PyObject *o;
  #if CYTHON_COMPILING_IN_LIMITED_API
  allocfunc alloc_func = (allocfunc)PyType_GetSlot(t, Py_tp_alloc);
  o = alloc_func(t, 0);
  #else
  if (likely(!__Pyx_PyType_HasFeature(t, Py_TPFLAGS_IS_ABSTRACT))) {
    o = (*t->tp_alloc)(t, 0);
  } else {
    o = (PyObject *) PyBaseObject_Type.tp_new(t, __pyx_mstate_global->__pyx_empty_tuple, 0);
  }
  if (unlikely(!o)) return 0;
  #endif
  p = ((struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)o);
  p->work_area = Py_None; Py_INCREF(Py_None);
  p->shape = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->order = ((PyObject*)Py_None); Py_INCREF(Py_None);
  p->last_size = Py_None; Py_INCREF(Py_None);
  p->gpus = ((PyObject*)Py_None); Py_INCREF(Py_None);
  return o;
}

static void __pyx_tp_dealloc_4cupy_4cuda_5cufft_XtPlanNd(PyObject *o) {
  struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *p = (struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)o;
  #if CYTHON_USE_TP_FINALIZE
  if (unlikely((PY_VERSION_HEX >= 0x03080000 || __Pyx_PyType_HasFeature(Py_TYPE(o), Py_TPFLAGS_HAVE_FINALIZE)) && __Pyx_PyObject_GetSlot(o, tp_finalize, destructor)) && !__Pyx_PyObject_GC_IsFinalized(o)) {
    if (__Pyx_PyObject_GetSlot(o, tp_dealloc, destructor) == __pyx_tp_dealloc_4cupy_4cuda_5cufft_XtPlanNd) {
      if (PyObject_CallFinalizerFromDealloc(o)) return;
    }
  }
  #endif
  PyObject_GC_UnTrack(o);
  {
    PyObject *etype, *eval, *etb;
    PyErr_Fetch(&etype, &eval, &etb);
    __Pyx_SET_REFCNT(o, Py_REFCNT(o) + 1);
    __pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_3__dealloc__(o);
    __Pyx_SET_REFCNT(o, Py_REFCNT(o) - 1);
    PyErr_Restore(etype, eval, etb);
  }
  Py_CLEAR(p->work_area);
  Py_CLEAR(p->shape);
  Py_CLEAR(p->order);
  Py_CLEAR(p->last_size);
  Py_CLEAR(p->gpus);
  #if CYTHON_USE_TYPE_SLOTS
  (*Py_TYPE(o)->tp_free)(o);
  #else
  {
    freefunc tp_free = (freefunc)PyType_GetSlot(Py_TYPE(o), Py_tp_free);
    if (tp_free) tp_free(o);
  }
  #endif
}

static int __pyx_tp_traverse_4cupy_4cuda_5cufft_XtPlanNd(PyObject *o, visitproc v, void *a) {
  int e;
  struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *p = (struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)o;
  {
    e = __Pyx_call_type_traverse(o, 1, v, a);
    if (e) return e;
  }
  if (p->work_area) {
    e = (*v)(p->work_area, a); if (e) return e;
  }
  if (p->shape) {
    e = (*v)(p->shape, a); if (e) return e;
  }
  if (p->last_size) {
    e = (*v)(p->last_size, a); if (e) return e;
  }
  if (p->gpus) {
    e = (*v)(p->gpus, a); if (e) return e;
  }
  return 0;
}

static int __pyx_tp_clear_4cupy_4cuda_5cufft_XtPlanNd(PyObject *o) {
  PyObject* tmp;
  struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *p = (struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd *)o;
  tmp = ((PyObject*)p->work_area);
  p->work_area = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->shape);
  p->shape = ((PyObject*)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->last_size);
  p->last_size = Py_None; Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  tmp = ((PyObject*)p->gpus);
  p->gpus = ((PyObject*)Py_None); Py_INCREF(Py_None);
  Py_XDECREF(tmp);
  return 0;
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_handle(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_6handle_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_work_area(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_9work_area_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_shape(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5shape_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_itype(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5itype_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_otype(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5otype_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_etype(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5etype_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_order(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5order_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_last_axis(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_9last_axis_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_last_size(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_9last_size_1__get__(o);
}

static PyObject *__pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_gpus(PyObject *o, CYTHON_UNUSED void *x) {
  return __pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_4gpus_1__get__(o);
}

static PyMethodDef __pyx_methods_4cupy_4cuda_5cufft_XtPlanNd[] = {
  {"__enter__", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_5__enter__, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_8XtPlanNd_4__enter__},
  {"__exit__", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_7__exit__, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_8XtPlanNd_6__exit__},
  {"fft", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_9fft, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_8XtPlanNd_8fft},
  {"_sanity_checks", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_11_sanity_checks, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_8XtPlanNd_10_sanity_checks},
  {"_output_dtype_and_shape", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_13_output_dtype_and_shape, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_8XtPlanNd_12_output_dtype_and_shape},
  {"get_output_array", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_15get_output_array, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_8XtPlanNd_14get_output_array},
  {"__reduce_cython__", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_17__reduce_cython__, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_8XtPlanNd_16__reduce_cython__},
  {"__setstate_cython__", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_19__setstate_cython__, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_8XtPlanNd_18__setstate_cython__},
  {0, 0, 0, 0}
};

static struct PyGetSetDef __pyx_getsets_4cupy_4cuda_5cufft_XtPlanNd[] = {
  {"handle", __pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_handle, 0, 0, 0},
  {"work_area", __pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_work_area, 0, 0, 0},
  {"shape", __pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_shape, 0, 0, 0},
  {"itype", __pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_itype, 0, 0, 0},
  {"otype", __pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_otype, 0, 0, 0},
  {"etype", __pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_etype, 0, 0, 0},
  {"order", __pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_order, 0, 0, 0},
  {"last_axis", __pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_last_axis, 0, 0, 0},
  {"last_size", __pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_last_size, 0, 0, 0},
  {"gpus", __pyx_getprop_4cupy_4cuda_5cufft_8XtPlanNd_gpus, 0, 0, 0},
  {0, 0, 0, 0, 0}
};
#if CYTHON_USE_TYPE_SPECS
static PyType_Slot __pyx_type_4cupy_4cuda_5cufft_XtPlanNd_slots[] = {
  {Py_tp_dealloc, (void *)__pyx_tp_dealloc_4cupy_4cuda_5cufft_XtPlanNd},
  {Py_tp_doc, (void *)PyDoc_STR("XtPlanNd(shape, inembed, long long istride, long long idist, idtype, onembed, long long ostride, long long odist, odtype, long long batch, edtype, str order, *, int last_axis, last_size, intptr_t prealloc_plan=0)")},
  {Py_tp_traverse, (void *)__pyx_tp_traverse_4cupy_4cuda_5cufft_XtPlanNd},
  {Py_tp_clear, (void *)__pyx_tp_clear_4cupy_4cuda_5cufft_XtPlanNd},
  {Py_tp_methods, (void *)__pyx_methods_4cupy_4cuda_5cufft_XtPlanNd},
  {Py_tp_getset, (void *)__pyx_getsets_4cupy_4cuda_5cufft_XtPlanNd},
  {Py_tp_init, (void *)__pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_1__init__},
  {Py_tp_new, (void *)__pyx_tp_new_4cupy_4cuda_5cufft_XtPlanNd},
  {0, 0},
};
static PyType_Spec __pyx_type_4cupy_4cuda_5cufft_XtPlanNd_spec = {
  "cupy.cuda.cufft.XtPlanNd",
  sizeof(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd),
  0,
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC,
  __pyx_type_4cupy_4cuda_5cufft_XtPlanNd_slots,
};
#else

static PyTypeObject __pyx_type_4cupy_4cuda_5cufft_XtPlanNd = {
  PyVarObject_HEAD_INIT(0, 0)
  "cupy.cuda.cufft.""XtPlanNd", /*tp_name*/
  sizeof(struct __pyx_obj_4cupy_4cuda_5cufft_XtPlanNd), /*tp_basicsize*/
  0, /*tp_itemsize*/
  __pyx_tp_dealloc_4cupy_4cuda_5cufft_XtPlanNd, /*tp_dealloc*/
  #if PY_VERSION_HEX < 0x030800b4
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b4
  0, /*tp_vectorcall_offset*/
  #endif
  0, /*tp_getattr*/
  0, /*tp_setattr*/
  0, /*tp_as_async*/
  0, /*tp_repr*/
  0, /*tp_as_number*/
  0, /*tp_as_sequence*/
  0, /*tp_as_mapping*/
  0, /*tp_hash*/
  0, /*tp_call*/
  0, /*tp_str*/
  0, /*tp_getattro*/
  0, /*tp_setattro*/
  0, /*tp_as_buffer*/
  Py_TPFLAGS_DEFAULT|Py_TPFLAGS_HAVE_VERSION_TAG|Py_TPFLAGS_CHECKTYPES|Py_TPFLAGS_HAVE_NEWBUFFER|Py_TPFLAGS_BASETYPE|Py_TPFLAGS_HAVE_GC, /*tp_flags*/
  PyDoc_STR("XtPlanNd(shape, inembed, long long istride, long long idist, idtype, onembed, long long ostride, long long odist, odtype, long long batch, edtype, str order, *, int last_axis, last_size, intptr_t prealloc_plan=0)"), /*tp_doc*/
  __pyx_tp_traverse_4cupy_4cuda_5cufft_XtPlanNd, /*tp_traverse*/
  __pyx_tp_clear_4cupy_4cuda_5cufft_XtPlanNd, /*tp_clear*/
  0, /*tp_richcompare*/
  0, /*tp_weaklistoffset*/
  0, /*tp_iter*/
  0, /*tp_iternext*/
  __pyx_methods_4cupy_4cuda_5cufft_XtPlanNd, /*tp_methods*/
  0, /*tp_members*/
  __pyx_getsets_4cupy_4cuda_5cufft_XtPlanNd, /*tp_getset*/
  0, /*tp_base*/
  0, /*tp_dict*/
  0, /*tp_descr_get*/
  0, /*tp_descr_set*/
  #if !CYTHON_USE_TYPE_SPECS
  0, /*tp_dictoffset*/
  #endif
  __pyx_pw_4cupy_4cuda_5cufft_8XtPlanNd_1__init__, /*tp_init*/
  0, /*tp_alloc*/
  __pyx_tp_new_4cupy_4cuda_5cufft_XtPlanNd, /*tp_new*/
  0, /*tp_free*/
  0, /*tp_is_gc*/
  0, /*tp_bases*/
  0, /*tp_mro*/
  0, /*tp_cache*/
  0, /*tp_subclasses*/
  0, /*tp_weaklist*/
  0, /*tp_del*/
  0, /*tp_version_tag*/
  #if CYTHON_USE_TP_FINALIZE
  0, /*tp_finalize*/
  #else
  NULL, /*tp_finalize*/
  #endif
  #if PY_VERSION_HEX >= 0x030800b1 && (!CYTHON_COMPILING_IN_PYPY || PYPY_VERSION_NUM >= 0x07030800)
  0, /*tp_vectorcall*/
  #endif
  #if __PYX_NEED_TP_PRINT_SLOT == 1
  0, /*tp_print*/
  #endif
  #if PY_VERSION_HEX >= 0x030C0000
  0, /*tp_watched*/
  #endif
  #if PY_VERSION_HEX >= 0x030d00A4
  0, /*tp_versions_used*/
  #endif
  #if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX >= 0x03090000 && PY_VERSION_HEX < 0x030a0000
  0, /*tp_pypy_flags*/
  #endif
};
#endif

static PyMethodDef __pyx_methods[] = {
  {"get_current_plan", (PyCFunction)__pyx_pw_4cupy_4cuda_5cufft_1get_current_plan, METH_NOARGS, __pyx_doc_4cupy_4cuda_5cufft_get_current_plan},
  {"check_result", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_3check_result, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_2check_result},
  {"getVersion", (PyCFunction)__pyx_pw_4cupy_4cuda_5cufft_5getVersion, METH_NOARGS, __pyx_doc_4cupy_4cuda_5cufft_4getVersion},
  {"execC2C", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_7execC2C, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_6execC2C},
  {"execR2C", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_9execR2C, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_8execR2C},
  {"execC2R", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_11execC2R, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_10execC2R},
  {"execZ2Z", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_13execZ2Z, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_12execZ2Z},
  {"execD2Z", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_15execD2Z, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_14execD2Z},
  {"execZ2D", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_17execZ2D, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_16execZ2D},
  {"multi_gpu_execC2C", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_19multi_gpu_execC2C, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_18multi_gpu_execC2C},
  {"multi_gpu_execZ2Z", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_21multi_gpu_execZ2Z, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_20multi_gpu_execZ2Z},
  {"XtExec", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_23XtExec, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_22XtExec},
  {"setCallback", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_25setCallback, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_24setCallback},
  {"create", (PyCFunction)__pyx_pw_4cupy_4cuda_5cufft_27create, METH_NOARGS, __pyx_doc_4cupy_4cuda_5cufft_26create},
  {"setAutoAllocation", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_29setAutoAllocation, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_28setAutoAllocation},
  {"setJITCallback", (PyCFunction)(void(*)(void))(__Pyx_PyCFunction_FastCallWithKeywords)__pyx_pw_4cupy_4cuda_5cufft_31setJITCallback, __Pyx_METH_FASTCALL|METH_KEYWORDS, __pyx_doc_4cupy_4cuda_5cufft_30setJITCallback},
  {0, 0, 0, 0}
};
/* #### Code section: initfunc_declarations ### */
static CYTHON_SMALL_CODE int __Pyx_InitCachedBuiltins(__pyx_mstatetype *__pyx_mstate); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_InitCachedConstants(__pyx_mstatetype *__pyx_mstate); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_InitGlobals(void); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_InitConstants(__pyx_mstatetype *__pyx_mstate); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_global_init_code(__pyx_mstatetype *__pyx_mstate); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_variable_export_code(__pyx_mstatetype *__pyx_mstate); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_function_export_code(__pyx_mstatetype *__pyx_mstate); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_type_init_code(__pyx_mstatetype *__pyx_mstate); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_type_import_code(__pyx_mstatetype *__pyx_mstate); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_variable_import_code(__pyx_mstatetype *__pyx_mstate); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_modinit_function_import_code(__pyx_mstatetype *__pyx_mstate); /*proto*/
static CYTHON_SMALL_CODE int __Pyx_CreateCodeObjects(__pyx_mstatetype *__pyx_mstate); /*proto*/
/* #### Code section: init_module ### */

static int __Pyx_modinit_global_init_code(__pyx_mstatetype *__pyx_mstate) {
  __Pyx_RefNannyDeclarations
  CYTHON_UNUSED_VAR(__pyx_mstate);
  __Pyx_RefNannySetupContext("__Pyx_modinit_global_init_code", 0);
  /*--- Global init code ---*/
  __pyx_v_4cupy_4cuda_5cufft__L = ((struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink *)Py_None); Py_INCREF(Py_None);
  __pyx_v_4cupy_4cuda_5cufft__thread_local = Py_None; Py_INCREF(Py_None);
  __pyx_v_4cupy_4cuda_5cufft_RESULT = ((PyObject*)Py_None); Py_INCREF(Py_None);
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_variable_export_code(__pyx_mstatetype *__pyx_mstate) {
  __Pyx_RefNannyDeclarations
  CYTHON_UNUSED_VAR(__pyx_mstate);
  __Pyx_RefNannySetupContext("__Pyx_modinit_variable_export_code", 0);
  /*--- Variable export code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_function_export_code(__pyx_mstatetype *__pyx_mstate) {
  __Pyx_RefNannyDeclarations
  CYTHON_UNUSED_VAR(__pyx_mstate);
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__Pyx_modinit_function_export_code", 0);
  /*--- Function export code ---*/
  if (__Pyx_ExportFunction("get_current_plan", (void (*)(void))__pyx_f_4cupy_4cuda_5cufft_get_current_plan, "PyObject *(int __pyx_skip_dispatch)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_ExportFunction("getVersion", (void (*)(void))__pyx_f_4cupy_4cuda_5cufft_getVersion, "int (int __pyx_skip_dispatch)") < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_modinit_type_init_code(__pyx_mstatetype *__pyx_mstate) {
  __Pyx_RefNannyDeclarations
  CYTHON_UNUSED_VAR(__pyx_mstate);
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__Pyx_modinit_type_init_code", 0);
  /*--- Type init code ---*/
  __pyx_vtabptr_4cupy_4cuda_5cufft_Plan1d = &__pyx_vtable_4cupy_4cuda_5cufft_Plan1d;
  __pyx_vtable_4cupy_4cuda_5cufft_Plan1d._single_gpu_get_plan = (void (*)(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *, cufftHandle, int, int, int))__pyx_f_4cupy_4cuda_5cufft_6Plan1d__single_gpu_get_plan;
  __pyx_vtable_4cupy_4cuda_5cufft_Plan1d._multi_gpu_get_plan = (void (*)(struct __pyx_obj_4cupy_4cuda_5cufft_Plan1d *, cufftHandle, int, int, int, PyObject *, PyObject *))__pyx_f_4cupy_4cuda_5cufft_6Plan1d__multi_gpu_get_plan;
  #if CYTHON_USE_TYPE_SPECS
  __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_Plan1d = (PyTypeObject *) __Pyx_PyType_FromModuleAndSpec(__pyx_m, &__pyx_type_4cupy_4cuda_5cufft_Plan1d_spec, NULL); if (unlikely(!__pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_Plan1d)) __PYX_ERR(0, 338, __pyx_L1_error)
  if (__Pyx_fix_up_extension_type_from_spec(&__pyx_type_4cupy_4cuda_5cufft_Plan1d_spec, __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_Plan1d) < (0)) __PYX_ERR(0, 338, __pyx_L1_error)
  #else
  __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_Plan1d = &__pyx_type_4cupy_4cuda_5cufft_Plan1d;
  #endif
  #if !CYTHON_COMPILING_IN_LIMITED_API
  #endif
  #if !CYTHON_USE_TYPE_SPECS
  if (__Pyx_PyType_Ready(__pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_Plan1d) < (0)) __PYX_ERR(0, 338, __pyx_L1_error)
  #endif
  #if !CYTHON_COMPILING_IN_LIMITED_API
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_Plan1d->tp_dictoffset && __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_Plan1d->tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_Plan1d->tp_getattro = PyObject_GenericGetAttr;
  }
  #endif
  if (__Pyx_SetVtable(__pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_Plan1d, __pyx_vtabptr_4cupy_4cuda_5cufft_Plan1d) < (0)) __PYX_ERR(0, 338, __pyx_L1_error)
  if (__Pyx_MergeVtables(__pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_Plan1d) < (0)) __PYX_ERR(0, 338, __pyx_L1_error)
  if (PyObject_SetAttr(__pyx_m, __pyx_mstate_global->__pyx_n_u_Plan1d, (PyObject *) __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_Plan1d) < (0)) __PYX_ERR(0, 338, __pyx_L1_error)
  if (__Pyx_setup_reduce((PyObject *) __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_Plan1d) < (0)) __PYX_ERR(0, 338, __pyx_L1_error)
  #if CYTHON_USE_TYPE_SPECS
  __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_PlanNd = (PyTypeObject *) __Pyx_PyType_FromModuleAndSpec(__pyx_m, &__pyx_type_4cupy_4cuda_5cufft_PlanNd_spec, NULL); if (unlikely(!__pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_PlanNd)) __PYX_ERR(0, 808, __pyx_L1_error)
  if (__Pyx_fix_up_extension_type_from_spec(&__pyx_type_4cupy_4cuda_5cufft_PlanNd_spec, __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_PlanNd) < (0)) __PYX_ERR(0, 808, __pyx_L1_error)
  #else
  __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_PlanNd = &__pyx_type_4cupy_4cuda_5cufft_PlanNd;
  #endif
  #if !CYTHON_COMPILING_IN_LIMITED_API
  #endif
  #if !CYTHON_USE_TYPE_SPECS
  if (__Pyx_PyType_Ready(__pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_PlanNd) < (0)) __PYX_ERR(0, 808, __pyx_L1_error)
  #endif
  #if !CYTHON_COMPILING_IN_LIMITED_API
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_PlanNd->tp_dictoffset && __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_PlanNd->tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_PlanNd->tp_getattro = PyObject_GenericGetAttr;
  }
  #endif
  if (PyObject_SetAttr(__pyx_m, __pyx_mstate_global->__pyx_n_u_PlanNd, (PyObject *) __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_PlanNd) < (0)) __PYX_ERR(0, 808, __pyx_L1_error)
  if (__Pyx_setup_reduce((PyObject *) __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_PlanNd) < (0)) __PYX_ERR(0, 808, __pyx_L1_error)
  #if CYTHON_USE_TYPE_SPECS
  __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_XtPlanNd = (PyTypeObject *) __Pyx_PyType_FromModuleAndSpec(__pyx_m, &__pyx_type_4cupy_4cuda_5cufft_XtPlanNd_spec, NULL); if (unlikely(!__pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_XtPlanNd)) __PYX_ERR(0, 982, __pyx_L1_error)
  if (__Pyx_fix_up_extension_type_from_spec(&__pyx_type_4cupy_4cuda_5cufft_XtPlanNd_spec, __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_XtPlanNd) < (0)) __PYX_ERR(0, 982, __pyx_L1_error)
  #else
  __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_XtPlanNd = &__pyx_type_4cupy_4cuda_5cufft_XtPlanNd;
  #endif
  #if !CYTHON_COMPILING_IN_LIMITED_API
  #endif
  #if !CYTHON_USE_TYPE_SPECS
  if (__Pyx_PyType_Ready(__pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_XtPlanNd) < (0)) __PYX_ERR(0, 982, __pyx_L1_error)
  #endif
  #if !CYTHON_COMPILING_IN_LIMITED_API
  if ((CYTHON_USE_TYPE_SLOTS && CYTHON_USE_PYTYPE_LOOKUP) && likely(!__pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_XtPlanNd->tp_dictoffset && __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_XtPlanNd->tp_getattro == PyObject_GenericGetAttr)) {
    __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_XtPlanNd->tp_getattro = PyObject_GenericGetAttr;
  }
  #endif
  if (PyObject_SetAttr(__pyx_m, __pyx_mstate_global->__pyx_n_u_XtPlanNd, (PyObject *) __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_XtPlanNd) < (0)) __PYX_ERR(0, 982, __pyx_L1_error)
  if (__Pyx_setup_reduce((PyObject *) __pyx_mstate->__pyx_ptype_4cupy_4cuda_5cufft_XtPlanNd) < (0)) __PYX_ERR(0, 982, __pyx_L1_error)
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_modinit_type_import_code(__pyx_mstatetype *__pyx_mstate) {
  __Pyx_RefNannyDeclarations
  CYTHON_UNUSED_VAR(__pyx_mstate);
  PyObject *__pyx_t_1 = NULL;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannySetupContext("__Pyx_modinit_type_import_code", 0);
  /*--- Type import code ---*/
  __pyx_t_1 = PyImport_ImportModule("cupy_backends.cuda._softlink"); if (unlikely(!__pyx_t_1)) __PYX_ERR(3, 3, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_mstate->__pyx_ptype_13cupy_backends_4cuda_9_softlink_SoftLink = __Pyx_ImportType_3_1_6(__pyx_t_1, "cupy_backends.cuda._softlink", "SoftLink",
  #if defined(PYPY_VERSION_NUM) && PYPY_VERSION_NUM < 0x050B0000
  sizeof(struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink), __PYX_GET_STRUCT_ALIGNMENT_3_1_6(struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink),
  #elif CYTHON_COMPILING_IN_LIMITED_API
  sizeof(struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink), __PYX_GET_STRUCT_ALIGNMENT_3_1_6(struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink),
  #else
  sizeof(struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink), __PYX_GET_STRUCT_ALIGNMENT_3_1_6(struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink),
  #endif
  __Pyx_ImportType_CheckSize_Warn_3_1_6); if (!__pyx_mstate->__pyx_ptype_13cupy_backends_4cuda_9_softlink_SoftLink) __PYX_ERR(3, 3, __pyx_L1_error)
  __pyx_vtabptr_13cupy_backends_4cuda_9_softlink_SoftLink = (struct __pyx_vtabstruct_13cupy_backends_4cuda_9_softlink_SoftLink*)__Pyx_GetVtable(__pyx_mstate->__pyx_ptype_13cupy_backends_4cuda_9_softlink_SoftLink); if (unlikely(!__pyx_vtabptr_13cupy_backends_4cuda_9_softlink_SoftLink)) __PYX_ERR(3, 3, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_modinit_variable_import_code(__pyx_mstatetype *__pyx_mstate) {
  __Pyx_RefNannyDeclarations
  CYTHON_UNUSED_VAR(__pyx_mstate);
  __Pyx_RefNannySetupContext("__Pyx_modinit_variable_import_code", 0);
  /*--- Variable import code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

static int __Pyx_modinit_function_import_code(__pyx_mstatetype *__pyx_mstate) {
  __Pyx_RefNannyDeclarations
  CYTHON_UNUSED_VAR(__pyx_mstate);
  __Pyx_RefNannySetupContext("__Pyx_modinit_function_import_code", 0);
  /*--- Function import code ---*/
  __Pyx_RefNannyFinishContext();
  return 0;
}

#if CYTHON_PEP489_MULTI_PHASE_INIT
static PyObject* __pyx_pymod_create(PyObject *spec, PyModuleDef *def); /*proto*/
static int __pyx_pymod_exec_cufft(PyObject* module); /*proto*/
static PyModuleDef_Slot __pyx_moduledef_slots[] = {
  {Py_mod_create, (void*)__pyx_pymod_create},
  {Py_mod_exec, (void*)__pyx_pymod_exec_cufft},
  #if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
  {Py_mod_gil, Py_MOD_GIL_USED},
  #endif
  #if PY_VERSION_HEX >= 0x030C0000 && CYTHON_USE_MODULE_STATE
  {Py_mod_multiple_interpreters, Py_MOD_MULTIPLE_INTERPRETERS_NOT_SUPPORTED},
  #endif
  {0, NULL}
};
#endif

#ifdef __cplusplus
namespace {
  struct PyModuleDef __pyx_moduledef =
  #else
  static struct PyModuleDef __pyx_moduledef =
  #endif
  {
      PyModuleDef_HEAD_INIT,
      "cufft",
      0, /* m_doc */
    #if CYTHON_USE_MODULE_STATE
      sizeof(__pyx_mstatetype), /* m_size */
    #else
      (CYTHON_PEP489_MULTI_PHASE_INIT) ? 0 : -1, /* m_size */
    #endif
      __pyx_methods /* m_methods */,
    #if CYTHON_PEP489_MULTI_PHASE_INIT
      __pyx_moduledef_slots, /* m_slots */
    #else
      NULL, /* m_reload */
    #endif
    #if CYTHON_USE_MODULE_STATE
      __pyx_m_traverse, /* m_traverse */
      __pyx_m_clear, /* m_clear */
      NULL /* m_free */
    #else
      NULL, /* m_traverse */
      NULL, /* m_clear */
      NULL /* m_free */
    #endif
  };
  #ifdef __cplusplus
} /* anonymous namespace */
#endif

/* PyModInitFuncType */
#ifndef CYTHON_NO_PYINIT_EXPORT
  #define __Pyx_PyMODINIT_FUNC PyMODINIT_FUNC
#else
  #ifdef __cplusplus
  #define __Pyx_PyMODINIT_FUNC extern "C" PyObject *
  #else
  #define __Pyx_PyMODINIT_FUNC PyObject *
  #endif
#endif

__Pyx_PyMODINIT_FUNC PyInit_cufft(void) CYTHON_SMALL_CODE; /*proto*/
__Pyx_PyMODINIT_FUNC PyInit_cufft(void)
#if CYTHON_PEP489_MULTI_PHASE_INIT
{
  return PyModuleDef_Init(&__pyx_moduledef);
}
/* ModuleCreationPEP489 */
#if CYTHON_COMPILING_IN_LIMITED_API && __PYX_LIMITED_VERSION_HEX < 0x03090000
static PY_INT64_T __Pyx_GetCurrentInterpreterId(void) {
    {
        PyObject *module = PyImport_ImportModule("_interpreters"); // 3.13+ I think
        if (!module) {
            PyErr_Clear(); // just try the 3.8-3.12 version
            module = PyImport_ImportModule("_xxsubinterpreters");
            if (!module) goto bad;
        }
        PyObject *current = PyObject_CallMethod(module, "get_current", NULL);
        Py_DECREF(module);
        if (!current) goto bad;
        if (PyTuple_Check(current)) {
            PyObject *new_current = PySequence_GetItem(current, 0);
            Py_DECREF(current);
            current = new_current;
            if (!new_current) goto bad;
        }
        long long as_c_int = PyLong_AsLongLong(current);
        Py_DECREF(current);
        return as_c_int;
    }
  bad:
    PySys_WriteStderr("__Pyx_GetCurrentInterpreterId failed. Try setting the C define CYTHON_PEP489_MULTI_PHASE_INIT=0\n");
    return -1;
}
#endif
#if !CYTHON_USE_MODULE_STATE
static CYTHON_SMALL_CODE int __Pyx_check_single_interpreter(void) {
    static PY_INT64_T main_interpreter_id = -1;
#if CYTHON_COMPILING_IN_GRAAL
    PY_INT64_T current_id = PyInterpreterState_GetIDFromThreadState(PyThreadState_Get());
#elif CYTHON_COMPILING_IN_LIMITED_API && __PYX_LIMITED_VERSION_HEX >= 0x03090000
    PY_INT64_T current_id = PyInterpreterState_GetID(PyInterpreterState_Get());
#elif CYTHON_COMPILING_IN_LIMITED_API
    PY_INT64_T current_id = __Pyx_GetCurrentInterpreterId();
#else
    PY_INT64_T current_id = PyInterpreterState_GetID(PyThreadState_Get()->interp);
#endif
    if (unlikely(current_id == -1)) {
        return -1;
    }
    if (main_interpreter_id == -1) {
        main_interpreter_id = current_id;
        return 0;
    } else if (unlikely(main_interpreter_id != current_id)) {
        PyErr_SetString(
            PyExc_ImportError,
            "Interpreter change detected - this module can only be loaded into one interpreter per process.");
        return -1;
    }
    return 0;
}
#endif
static CYTHON_SMALL_CODE int __Pyx_copy_spec_to_module(PyObject *spec, PyObject *moddict, const char* from_name, const char* to_name, int allow_none)
{
    PyObject *value = PyObject_GetAttrString(spec, from_name);
    int result = 0;
    if (likely(value)) {
        if (allow_none || value != Py_None) {
            result = PyDict_SetItemString(moddict, to_name, value);
        }
        Py_DECREF(value);
    } else if (PyErr_ExceptionMatches(PyExc_AttributeError)) {
        PyErr_Clear();
    } else {
        result = -1;
    }
    return result;
}
static CYTHON_SMALL_CODE PyObject* __pyx_pymod_create(PyObject *spec, PyModuleDef *def) {
    PyObject *module = NULL, *moddict, *modname;
    CYTHON_UNUSED_VAR(def);
    #if !CYTHON_USE_MODULE_STATE
    if (__Pyx_check_single_interpreter())
        return NULL;
    #endif
    if (__pyx_m)
        return __Pyx_NewRef(__pyx_m);
    modname = PyObject_GetAttrString(spec, "name");
    if (unlikely(!modname)) goto bad;
    module = PyModule_NewObject(modname);
    Py_DECREF(modname);
    if (unlikely(!module)) goto bad;
    moddict = PyModule_GetDict(module);
    if (unlikely(!moddict)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "loader", "__loader__", 1) < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "origin", "__file__", 1) < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "parent", "__package__", 1) < 0)) goto bad;
    if (unlikely(__Pyx_copy_spec_to_module(spec, moddict, "submodule_search_locations", "__path__", 0) < 0)) goto bad;
    return module;
bad:
    Py_XDECREF(module);
    return NULL;
}


static CYTHON_SMALL_CODE int __pyx_pymod_exec_cufft(PyObject *__pyx_pyinit_module)
#endif
{
  int stringtab_initialized = 0;
  #if CYTHON_USE_MODULE_STATE
  int pystate_addmodule_run = 0;
  #endif
  __pyx_mstatetype *__pyx_mstate = NULL;
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  size_t __pyx_t_6;
  int __pyx_lineno = 0;
  const char *__pyx_filename = NULL;
  int __pyx_clineno = 0;
  __Pyx_RefNannyDeclarations
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  if (__pyx_m) {
    if (__pyx_m == __pyx_pyinit_module) return 0;
    PyErr_SetString(PyExc_RuntimeError, "Module 'cufft' has already been imported. Re-initialisation is not supported.");
    return -1;
  }
  #else
  if (__pyx_m) return __Pyx_NewRef(__pyx_m);
  #endif
  /*--- Module creation code ---*/
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  __pyx_t_1 = __pyx_pyinit_module;
  Py_INCREF(__pyx_t_1);
  #else
  __pyx_t_1 = PyModule_Create(&__pyx_moduledef); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #if CYTHON_USE_MODULE_STATE
  {
    int add_module_result = __Pyx_State_AddModule(__pyx_t_1, &__pyx_moduledef);
    __pyx_t_1 = 0; /* transfer ownership from __pyx_t_1 to "cufft" pseudovariable */
    if (unlikely((add_module_result < 0))) __PYX_ERR(0, 1, __pyx_L1_error)
    pystate_addmodule_run = 1;
  }
  #else
  __pyx_m = __pyx_t_1;
  #endif
  #if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
  PyUnstable_Module_SetGIL(__pyx_m, Py_MOD_GIL_USED);
  #endif
  __pyx_mstate = __pyx_mstate_global;
  CYTHON_UNUSED_VAR(__pyx_t_1);
  __pyx_mstate->__pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_mstate->__pyx_d)) __PYX_ERR(0, 1, __pyx_L1_error)
  Py_INCREF(__pyx_mstate->__pyx_d);
  __pyx_mstate->__pyx_b = __Pyx_PyImport_AddModuleRef(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_mstate->__pyx_b)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_cython_runtime = __Pyx_PyImport_AddModuleRef("cython_runtime"); if (unlikely(!__pyx_mstate->__pyx_cython_runtime)) __PYX_ERR(0, 1, __pyx_L1_error)
  if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_mstate->__pyx_b) < 0) __PYX_ERR(0, 1, __pyx_L1_error)
  /* ImportRefnannyAPI */
  #if CYTHON_REFNANNY
__Pyx_RefNanny = __Pyx_RefNannyImportAPI("refnanny");
if (!__Pyx_RefNanny) {
  PyErr_Clear();
  __Pyx_RefNanny = __Pyx_RefNannyImportAPI("Cython.Runtime.refnanny");
  if (!__Pyx_RefNanny)
      Py_FatalError("failed to import 'refnanny' module");
}
#endif

__Pyx_RefNannySetupContext("PyInit_cufft", 0);
  if (__Pyx_check_binary_version(__PYX_LIMITED_VERSION_HEX, __Pyx_get_runtime_version(), CYTHON_COMPILING_IN_LIMITED_API) < (0)) __PYX_ERR(0, 1, __pyx_L1_error)
  #ifdef __Pxy_PyFrame_Initialize_Offsets
  __Pxy_PyFrame_Initialize_Offsets();
  #endif
  __pyx_mstate->__pyx_empty_tuple = PyTuple_New(0); if (unlikely(!__pyx_mstate->__pyx_empty_tuple)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_empty_bytes = PyBytes_FromStringAndSize("", 0); if (unlikely(!__pyx_mstate->__pyx_empty_bytes)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_empty_unicode = PyUnicode_FromStringAndSize("", 0); if (unlikely(!__pyx_mstate->__pyx_empty_unicode)) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Initialize various global constants etc. ---*/
  if (__Pyx_InitConstants(__pyx_mstate) < (0)) __PYX_ERR(0, 1, __pyx_L1_error)
  stringtab_initialized = 1;
  if (__Pyx_InitGlobals() < (0)) __PYX_ERR(0, 1, __pyx_L1_error)
  #if 0 || defined(__Pyx_CyFunction_USED) || defined(__Pyx_FusedFunction_USED) || defined(__Pyx_Coroutine_USED) || defined(__Pyx_Generator_USED) || defined(__Pyx_AsyncGen_USED)
  if (__pyx_CommonTypesMetaclass_init(__pyx_m) < (0)) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_CyFunction_USED
  if (__pyx_CyFunction_init(__pyx_m) < (0)) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_FusedFunction_USED
  if (__pyx_FusedFunction_init(__pyx_m) < (0)) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Coroutine_USED
  if (__pyx_Coroutine_init(__pyx_m) < (0)) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Generator_USED
  if (__pyx_Generator_init(__pyx_m) < (0)) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_AsyncGen_USED
  if (__pyx_AsyncGen_init(__pyx_m) < (0)) __PYX_ERR(0, 1, __pyx_L1_error)
  #endif
  /*--- Library function declarations ---*/
  if (__pyx_module_is_main_cupy__cuda__cufft) {
    if (PyObject_SetAttr(__pyx_m, __pyx_mstate_global->__pyx_n_u_name, __pyx_mstate_global->__pyx_n_u_main) < (0)) __PYX_ERR(0, 1, __pyx_L1_error)
  }
  {
    PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) __PYX_ERR(0, 1, __pyx_L1_error)
    if (!PyDict_GetItemString(modules, "cupy.cuda.cufft")) {
      if (unlikely((PyDict_SetItemString(modules, "cupy.cuda.cufft", __pyx_m) < 0))) __PYX_ERR(0, 1, __pyx_L1_error)
    }
  }
  /*--- Builtin init code ---*/
  if (__Pyx_InitCachedBuiltins(__pyx_mstate) < (0)) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Constants init code ---*/
  if (__Pyx_InitCachedConstants(__pyx_mstate) < (0)) __PYX_ERR(0, 1, __pyx_L1_error)
  if (__Pyx_CreateCodeObjects(__pyx_mstate) < (0)) __PYX_ERR(0, 1, __pyx_L1_error)
  /*--- Global type/function init code ---*/
  (void)__Pyx_modinit_global_init_code(__pyx_mstate);
  (void)__Pyx_modinit_variable_export_code(__pyx_mstate);
  if (unlikely((__Pyx_modinit_function_export_code(__pyx_mstate) < 0))) __PYX_ERR(0, 1, __pyx_L1_error)
  if (unlikely((__Pyx_modinit_type_init_code(__pyx_mstate) < 0))) __PYX_ERR(0, 1, __pyx_L1_error)
  if (unlikely((__Pyx_modinit_type_import_code(__pyx_mstate) < 0))) __PYX_ERR(0, 1, __pyx_L1_error)
  (void)__Pyx_modinit_variable_import_code(__pyx_mstate);
  (void)__Pyx_modinit_function_import_code(__pyx_mstate);
  /*--- Execution code ---*/

  /* "cupy/cuda/cufft.pyx":8
 * from cupy_backends.cuda._softlink cimport SoftLink
 * 
 * import sys as _sys             # <<<<<<<<<<<<<<
 * import threading
 * 
*/
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_mstate_global->__pyx_n_u_sys_2, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 8, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_mstate_global->__pyx_d, __pyx_mstate_global->__pyx_n_u_sys, __pyx_t_2) < (0)) __PYX_ERR(0, 8, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "cupy/cuda/cufft.pyx":9
 * 
 * import sys as _sys
 * import threading             # <<<<<<<<<<<<<<
 * 
 * import numpy
*/
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_mstate_global->__pyx_n_u_threading, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 9, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_mstate_global->__pyx_d, __pyx_mstate_global->__pyx_n_u_threading, __pyx_t_2) < (0)) __PYX_ERR(0, 9, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "cupy/cuda/cufft.pyx":11
 * import threading
 * 
 * import numpy             # <<<<<<<<<<<<<<
 * 
 * import cupy
*/
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_mstate_global->__pyx_n_u_numpy, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 11, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_mstate_global->__pyx_d, __pyx_mstate_global->__pyx_n_u_numpy, __pyx_t_2) < (0)) __PYX_ERR(0, 11, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "cupy/cuda/cufft.pyx":13
 * import numpy
 * 
 * import cupy             # <<<<<<<<<<<<<<
 * from cupy.cuda import device
 * from cupy.cuda import memory
*/
  __pyx_t_2 = __Pyx_ImportDottedModule(__pyx_mstate_global->__pyx_n_u_cupy, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 13, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_mstate_global->__pyx_d, __pyx_mstate_global->__pyx_n_u_cupy, __pyx_t_2) < (0)) __PYX_ERR(0, 13, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "cupy/cuda/cufft.pyx":14
 * 
 * import cupy
 * from cupy.cuda import device             # <<<<<<<<<<<<<<
 * from cupy.cuda import memory
 * from cupy.cuda import runtime
*/
  __pyx_t_2 = __Pyx_PyList_Pack(1, __pyx_mstate_global->__pyx_n_u_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 14, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_Import(__pyx_mstate_global->__pyx_n_u_cupy_cuda, __pyx_t_2, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 14, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_ImportFrom(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_device); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 14, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_mstate_global->__pyx_d, __pyx_mstate_global->__pyx_n_u_device, __pyx_t_2) < (0)) __PYX_ERR(0, 14, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "cupy/cuda/cufft.pyx":15
 * import cupy
 * from cupy.cuda import device
 * from cupy.cuda import memory             # <<<<<<<<<<<<<<
 * from cupy.cuda import runtime
 * from cupy.cuda import stream
*/
  __pyx_t_3 = __Pyx_PyList_Pack(1, __pyx_mstate_global->__pyx_n_u_memory); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 15, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_Import(__pyx_mstate_global->__pyx_n_u_cupy_cuda, __pyx_t_3, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 15, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_ImportFrom(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_memory); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 15, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_mstate_global->__pyx_d, __pyx_mstate_global->__pyx_n_u_memory, __pyx_t_3) < (0)) __PYX_ERR(0, 15, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "cupy/cuda/cufft.pyx":16
 * from cupy.cuda import device
 * from cupy.cuda import memory
 * from cupy.cuda import runtime             # <<<<<<<<<<<<<<
 * from cupy.cuda import stream
 * 
*/
  __pyx_t_2 = __Pyx_PyList_Pack(1, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 16, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_Import(__pyx_mstate_global->__pyx_n_u_cupy_cuda, __pyx_t_2, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 16, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_ImportFrom(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_runtime); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 16, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_mstate_global->__pyx_d, __pyx_mstate_global->__pyx_n_u_runtime, __pyx_t_2) < (0)) __PYX_ERR(0, 16, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;

  /* "cupy/cuda/cufft.pyx":17
 * from cupy.cuda import memory
 * from cupy.cuda import runtime
 * from cupy.cuda import stream             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_t_3 = __Pyx_PyList_Pack(1, __pyx_mstate_global->__pyx_n_u_stream); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 17, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_Import(__pyx_mstate_global->__pyx_n_u_cupy_cuda, __pyx_t_3, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 17, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_ImportFrom(__pyx_t_2, __pyx_mstate_global->__pyx_n_u_stream); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 17, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_mstate_global->__pyx_d, __pyx_mstate_global->__pyx_n_u_stream, __pyx_t_3) < (0)) __PYX_ERR(0, 17, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "cupy/cuda/cufft.pyx":28
 * # ****************** SoftLink utilities ******************
 * 
 * cdef SoftLink _L = None             # <<<<<<<<<<<<<<
 * 
 * cdef inline void initialize() except *:
*/
  __Pyx_INCREF(Py_None);
  __Pyx_XGOTREF((PyObject *)__pyx_v_4cupy_4cuda_5cufft__L);
  __Pyx_DECREF_SET(__pyx_v_4cupy_4cuda_5cufft__L, ((struct __pyx_obj_13cupy_backends_4cuda_9_softlink_SoftLink *)Py_None));
  __Pyx_GIVEREF(Py_None);

  /* "cupy/cuda/cufft.pyx":81
 * 
 * 
 * cdef object _thread_local = threading.local()             # <<<<<<<<<<<<<<
 * 
 * 
*/
  __pyx_t_3 = NULL;
  __Pyx_GetModuleGlobalName(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_threading); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 81, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_mstate_global->__pyx_n_u_local); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 81, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_6 = 1;
  {
    PyObject *__pyx_callargs[2] = {__pyx_t_3, NULL};
    __pyx_t_2 = __Pyx_PyObject_FastCall(__pyx_t_5, __pyx_callargs+__pyx_t_6, (1-__pyx_t_6) | (__pyx_t_6*__Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET));
    __Pyx_XDECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 81, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
  }
  __Pyx_XGOTREF(__pyx_v_4cupy_4cuda_5cufft__thread_local);
  __Pyx_DECREF_SET(__pyx_v_4cupy_4cuda_5cufft__thread_local, __pyx_t_2);
  __Pyx_GIVEREF(__pyx_t_2);
  __pyx_t_2 = 0;

  /* "cupy/cuda/cufft.pyx":199
 * 
 * cdef dict RESULT = {
 *     0: 'CUFFT_SUCCESS',             # <<<<<<<<<<<<<<
 *     1: 'CUFFT_INVALID_PLAN',
 *     2: 'CUFFT_ALLOC_FAILED',
*/
  __pyx_t_2 = __Pyx_PyDict_NewPresized(17); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 199, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_0, __pyx_mstate_global->__pyx_n_u_CUFFT_SUCCESS) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_1, __pyx_mstate_global->__pyx_n_u_CUFFT_INVALID_PLAN) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_2, __pyx_mstate_global->__pyx_n_u_CUFFT_ALLOC_FAILED) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_3, __pyx_mstate_global->__pyx_n_u_CUFFT_INVALID_TYPE) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_4, __pyx_mstate_global->__pyx_n_u_CUFFT_INVALID_VALUE) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_5, __pyx_mstate_global->__pyx_n_u_CUFFT_INTERNAL_ERROR) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_6, __pyx_mstate_global->__pyx_n_u_CUFFT_EXEC_FAILED) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_7, __pyx_mstate_global->__pyx_n_u_CUFFT_SETUP_FAILED) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_8, __pyx_mstate_global->__pyx_n_u_CUFFT_INVALID_SIZE) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_9, __pyx_mstate_global->__pyx_n_u_CUFFT_UNALIGNED_DATA) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_10, __pyx_mstate_global->__pyx_n_u_CUFFT_INCOMPLETE_PARAMETER_LIST) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_11, __pyx_mstate_global->__pyx_n_u_CUFFT_INVALID_DEVICE) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_12, __pyx_mstate_global->__pyx_n_u_CUFFT_PARSE_ERROR) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_13, __pyx_mstate_global->__pyx_n_u_CUFFT_NO_WORKSPACE) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_14, __pyx_mstate_global->__pyx_n_u_CUFFT_NOT_IMPLEMENTED) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_15, __pyx_mstate_global->__pyx_n_u_CUFFT_LICENSE_ERROR) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  if (PyDict_SetItem(__pyx_t_2, __pyx_mstate_global->__pyx_int_16, __pyx_mstate_global->__pyx_n_u_CUFFT_NOT_SUPPORTED) < (0)) __PYX_ERR(0, 199, __pyx_L1_error)
  __Pyx_XGOTREF(__pyx_v_4cupy_4cuda_5cufft_RESULT);
  __Pyx_DECREF_SET(__pyx_v_4cupy_4cuda_5cufft_RESULT, ((PyObject*)__pyx_t_2));
  __Pyx_GIVEREF(__pyx_t_2);
  __pyx_t_2 = 0;

  /* "cupy/cuda/cufft.pyx":219
 * 
 * 
 * class CuFFTError(RuntimeError):             # <<<<<<<<<<<<<<
 * 
 *     def __init__(self, int result):
*/
  __pyx_t_2 = __Pyx_PEP560_update_bases(__pyx_mstate_global->__pyx_tuple[4]); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 219, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = __Pyx_CalculateMetaclass(NULL, __pyx_t_2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 219, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_3 = __Pyx_Py3MetaclassPrepare(__pyx_t_5, __pyx_t_2, __pyx_mstate_global->__pyx_n_u_CuFFTError, __pyx_mstate_global->__pyx_n_u_CuFFTError, (PyObject *) NULL, __pyx_mstate_global->__pyx_n_u_cupy_cuda_cufft, (PyObject *) NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 219, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (__pyx_t_2 != __pyx_mstate_global->__pyx_tuple[4]) {
    if (unlikely((PyDict_SetItemString(__pyx_t_3, "__orig_bases__", __pyx_mstate_global->__pyx_tuple[4]) < 0))) __PYX_ERR(0, 219, __pyx_L1_error)
  }

  /* "cupy/cuda/cufft.pyx":221
 * class CuFFTError(RuntimeError):
 * 
 *     def __init__(self, int result):             # <<<<<<<<<<<<<<
 *         self.result = result
 *         super(CuFFTError, self).__init__('%s' % (RESULT[result]))
*/
  __pyx_t_4 = __Pyx_CyFunction_New(&__pyx_mdef_4cupy_4cuda_5cufft_10CuFFTError_1__init__, 0, __pyx_mstate_global->__pyx_n_u_CuFFTError___init, NULL, __pyx_mstate_global->__pyx_n_u_cupy_cuda_cufft, __pyx_mstate_global->__pyx_d, ((PyObject *)__pyx_mstate_global->__pyx_codeobj_tab[0])); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 221, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (__Pyx_SetNameInClass(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_init, __pyx_t_4) < (0)) __PYX_ERR(0, 221, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "cupy/cuda/cufft.pyx":225
 *         super(CuFFTError, self).__init__('%s' % (RESULT[result]))
 * 
 *     def __reduce__(self):             # <<<<<<<<<<<<<<
 *         return (type(self), (self.result,))
 * 
*/
  __pyx_t_4 = __Pyx_CyFunction_New(&__pyx_mdef_4cupy_4cuda_5cufft_10CuFFTError_3__reduce__, 0, __pyx_mstate_global->__pyx_n_u_CuFFTError___reduce, NULL, __pyx_mstate_global->__pyx_n_u_cupy_cuda_cufft, __pyx_mstate_global->__pyx_d, ((PyObject *)__pyx_mstate_global->__pyx_codeobj_tab[1])); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 225, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (__Pyx_SetNameInClass(__pyx_t_3, __pyx_mstate_global->__pyx_n_u_reduce, __pyx_t_4) < (0)) __PYX_ERR(0, 225, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;

  /* "cupy/cuda/cufft.pyx":219
 * 
 * 
 * class CuFFTError(RuntimeError):             # <<<<<<<<<<<<<<
 * 
 *     def __init__(self, int result):
*/
  __pyx_t_4 = __Pyx_Py3ClassCreate(__pyx_t_5, __pyx_mstate_global->__pyx_n_u_CuFFTError, __pyx_t_2, __pyx_t_3, NULL, 0, 0); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 219, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  if (PyDict_SetItem(__pyx_mstate_global->__pyx_d, __pyx_mstate_global->__pyx_n_u_CuFFTError, __pyx_t_4) < (0)) __PYX_ERR(0, 219, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "(tree fragment)":1
 * def __pyx_unpickle_Plan1d(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
 *     cdef object __pyx_PickleError
 *     cdef object __pyx_result
*/
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_4cupy_4cuda_5cufft_33__pyx_unpickle_Plan1d, NULL, __pyx_mstate_global->__pyx_n_u_cupy_cuda_cufft); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_mstate_global->__pyx_d, __pyx_mstate_global->__pyx_n_u_pyx_unpickle_Plan1d, __pyx_t_2) < (0)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "(tree fragment)":11
 *         __pyx_unpickle_Plan1d__set_state(<Plan1d> __pyx_result, __pyx_state)
 *     return __pyx_result
 * cdef __pyx_unpickle_Plan1d__set_state(Plan1d __pyx_result, tuple __pyx_state):             # <<<<<<<<<<<<<<
 *     __pyx_result.batch = __pyx_state[0]; __pyx_result.batch_share = __pyx_state[1]; __pyx_result.fft_type = __pyx_state[2]; __pyx_result.gather_events = __pyx_state[3]; __pyx_result.gather_streams = __pyx_state[4]; __pyx_result.gpus = __pyx_state[5]; __pyx_result.handle = __pyx_state[6]; __pyx_result.nx = __pyx_state[7]; __pyx_result.scatter_events = __pyx_state[8]; __pyx_result.scatter_streams = __pyx_state[9]; __pyx_result.work_area = __pyx_state[10]; __pyx_result.xtArr = __pyx_state[11]; __pyx_result.xtArr_buffer = __pyx_state[12]
 *     if len(__pyx_state) > 13 and hasattr(__pyx_result, '__dict__'):
*/
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_4cupy_4cuda_5cufft_35__pyx_unpickle_PlanNd, NULL, __pyx_mstate_global->__pyx_n_u_cupy_cuda_cufft); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_mstate_global->__pyx_d, __pyx_mstate_global->__pyx_n_u_pyx_unpickle_PlanNd, __pyx_t_2) < (0)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "(tree fragment)":1
 * def __pyx_unpickle_XtPlanNd(__pyx_type, long __pyx_checksum, __pyx_state):             # <<<<<<<<<<<<<<
 *     cdef object __pyx_PickleError
 *     cdef object __pyx_result
*/
  __pyx_t_2 = PyCFunction_NewEx(&__pyx_mdef_4cupy_4cuda_5cufft_37__pyx_unpickle_XtPlanNd, NULL, __pyx_mstate_global->__pyx_n_u_cupy_cuda_cufft); if (unlikely(!__pyx_t_2)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_mstate_global->__pyx_d, __pyx_mstate_global->__pyx_n_u_pyx_unpickle_XtPlanNd, __pyx_t_2) < (0)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "cupy/cuda/cufft.pyx":1
 * cimport cython  # NOQA             # <<<<<<<<<<<<<<
 * from cpython.mem cimport PyMem_Malloc, PyMem_Free
 * from libc.string cimport memset as c_memset
*/
  __pyx_t_2 = __Pyx_PyDict_NewPresized(0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  if (PyDict_SetItem(__pyx_mstate_global->__pyx_d, __pyx_mstate_global->__pyx_n_u_test, __pyx_t_2) < (0)) __PYX_ERR(0, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /*--- Wrapped vars code ---*/
  {
    PyObject* wrapped = __Pyx_PyLong_From___pyx_anon_enum(__pyx_e_4cupy_4cuda_5cufft_CUFFT_C2C);
    if (unlikely(!wrapped)) __PYX_ERR(2, 28, __pyx_L1_error)
    if (PyObject_SetAttrString(__pyx_m, "CUFFT_C2C", wrapped) < 0) __PYX_ERR(2, 28, __pyx_L1_error);
  }
  {
    PyObject* wrapped = __Pyx_PyLong_From___pyx_anon_enum(__pyx_e_4cupy_4cuda_5cufft_CUFFT_C2R);
    if (unlikely(!wrapped)) __PYX_ERR(2, 30, __pyx_L1_error)
    if (PyObject_SetAttrString(__pyx_m, "CUFFT_C2R", wrapped) < 0) __PYX_ERR(2, 30, __pyx_L1_error);
  }
  {
    PyObject* wrapped = __Pyx_PyLong_From___pyx_anon_enum(__pyx_e_4cupy_4cuda_5cufft_CUFFT_CB_LD_COMPLEX);
    if (unlikely(!wrapped)) __PYX_ERR(2, 38, __pyx_L1_error)
    if (PyObject_SetAttrString(__pyx_m, "CUFFT_CB_LD_COMPLEX", wrapped) < 0) __PYX_ERR(2, 38, __pyx_L1_error);
  }
  {
    PyObject* wrapped = __Pyx_PyLong_From___pyx_anon_enum(__pyx_e_4cupy_4cuda_5cufft_CUFFT_CB_LD_COMPLEX_DOUBLE);
    if (unlikely(!wrapped)) __PYX_ERR(2, 39, __pyx_L1_error)
    if (PyObject_SetAttrString(__pyx_m, "CUFFT_CB_LD_COMPLEX_DOUBLE", wrapped) < 0) __PYX_ERR(2, 39, __pyx_L1_error);
  }
  {
    PyObject* wrapped = __Pyx_PyLong_From___pyx_anon_enum(__pyx_e_4cupy_4cuda_5cufft_CUFFT_CB_LD_REAL);
    if (unlikely(!wrapped)) __PYX_ERR(2, 40, __pyx_L1_error)
    if (PyObject_SetAttrString(__pyx_m, "CUFFT_CB_LD_REAL", wrapped) < 0) __PYX_ERR(2, 40, __pyx_L1_error);
  }
  {
    PyObject* wrapped = __Pyx_PyLong_From___pyx_anon_enum(__pyx_e_4cupy_4cuda_5cufft_CUFFT_CB_LD_REAL_DOUBLE);
    if (unlikely(!wrapped)) __PYX_ERR(2, 41, __pyx_L1_error)
    if (PyObject_SetAttrString(__pyx_m, "CUFFT_CB_LD_REAL_DOUBLE", wrapped) < 0) __PYX_ERR(2, 41, __pyx_L1_error);
  }
  {
    PyObject* wrapped = __Pyx_PyLong_From___pyx_anon_enum(__pyx_e_4cupy_4cuda_5cufft_CUFFT_CB_ST_COMPLEX);
    if (unlikely(!wrapped)) __PYX_ERR(2, 42, __pyx_L1_error)
    if (PyObject_SetAttrString(__pyx_m, "CUFFT_CB_ST_COMPLEX", wrapped) < 0) __PYX_ERR(2, 42, __pyx_L1_error);
  }
  {
    PyObject* wrapped = __Pyx_PyLong_From___pyx_anon_enum(__pyx_e_4cupy_4cuda_5cufft_CUFFT_CB_ST_COMPLEX_DOUBLE);
    if (unlikely(!wrapped)) __PYX_ERR(2, 43, __pyx_L1_error)
    if (PyObject_SetAttrString(__pyx_m, "CUFFT_CB_ST_COMPLEX_DOUBLE", wrapped) < 0) __PYX_ERR(2, 43, __pyx_L1_error);
  }
  {
    PyObject* wrapped = __Pyx_PyLong_From___pyx_anon_enum(__pyx_e_4cupy_4cuda_5cufft_CUFFT_CB_ST_REAL);
    if (unlikely(!wrapped)) __PYX_ERR(2, 44, __pyx_L1_error)
    if (PyObject_SetAttrString(__pyx_m, "CUFFT_CB_ST_REAL", wrapped) < 0) __PYX_ERR(2, 44, __pyx_L1_error);
  }
  {
    PyObject* wrapped = __Pyx_PyLong_From___pyx_anon_enum(__pyx_e_4cupy_4cuda_5cufft_CUFFT_CB_ST_REAL_DOUBLE);
    if (unlikely(!wrapped)) __PYX_ERR(2, 45, __pyx_L1_error)
    if (PyObject_SetAttrString(__pyx_m, "CUFFT_CB_ST_REAL_DOUBLE", wrapped) < 0) __PYX_ERR(2, 45, __pyx_L1_error);
  }
  {
    PyObject* wrapped = __Pyx_PyLong_From___pyx_anon_enum(__pyx_e_4cupy_4cuda_5cufft_CUFFT_D2Z);
    if (unlikely(!wrapped)) __PYX_ERR(2, 32, __pyx_L1_error)
    if (PyObject_SetAttrString(__pyx_m, "CUFFT_D2Z", wrapped) < 0) __PYX_ERR(2, 32, __pyx_L1_error);
  }
  {
    PyObject* wrapped = __Pyx_PyLong_From___pyx_anon_enum(__pyx_e_4cupy_4cuda_5cufft_CUFFT_FORWARD);
    if (unlikely(!wrapped)) __PYX_ERR(2, 35, __pyx_L1_error)
    if (PyObject_SetAttrString(__pyx_m, "CUFFT_FORWARD", wrapped) < 0) __PYX_ERR(2, 35, __pyx_L1_error);
  }
  {
    PyObject* wrapped = __Pyx_PyLong_From___pyx_anon_enum(__pyx_e_4cupy_4cuda_5cufft_CUFFT_INVERSE);
    if (unlikely(!wrapped)) __PYX_ERR(2, 36, __pyx_L1_error)
    if (PyObject_SetAttrString(__pyx_m, "CUFFT_INVERSE", wrapped) < 0) __PYX_ERR(2, 36, __pyx_L1_error);
  }
  {
    PyObject* wrapped = __Pyx_PyLong_From___pyx_anon_enum(__pyx_e_4cupy_4cuda_5cufft_CUFFT_R2C);
    if (unlikely(!wrapped)) __PYX_ERR(2, 29, __pyx_L1_error)
    if (PyObject_SetAttrString(__pyx_m, "CUFFT_R2C", wrapped) < 0) __PYX_ERR(2, 29, __pyx_L1_error);
  }
  {
    PyObject* wrapped = __Pyx_PyLong_From___pyx_anon_enum(__pyx_e_4cupy_4cuda_5cufft_CUFFT_Z2D);
    if (unlikely(!wrapped)) __PYX_ERR(2, 33, __pyx_L1_error)
    if (PyObject_SetAttrString(__pyx_m, "CUFFT_Z2D", wrapped) < 0) __PYX_ERR(2, 33, __pyx_L1_error);
  }
  {
    PyObject* wrapped = __Pyx_PyLong_From___pyx_anon_enum(__pyx_e_4cupy_4cuda_5cufft_CUFFT_Z2Z);
    if (unlikely(!wrapped)) __PYX_ERR(2, 31, __pyx_L1_error)
    if (PyObject_SetAttrString(__pyx_m, "CUFFT_Z2Z", wrapped) < 0) __PYX_ERR(2, 31, __pyx_L1_error);
  }

  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  if (__pyx_m) {
    if (__pyx_mstate->__pyx_d && stringtab_initialized) {
      __Pyx_AddTraceback("init cupy.cuda.cufft", __pyx_clineno, __pyx_lineno, __pyx_filename);
    }
    #if !CYTHON_USE_MODULE_STATE
    Py_CLEAR(__pyx_m);
    #else
    Py_DECREF(__pyx_m);
    if (pystate_addmodule_run) {
      PyObject *tp, *value, *tb;
      PyErr_Fetch(&tp, &value, &tb);
      PyState_RemoveModule(&__pyx_moduledef);
      PyErr_Restore(tp, value, tb);
    }
    #endif
  } else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_ImportError, "init cupy.cuda.cufft");
  }
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  #if CYTHON_PEP489_MULTI_PHASE_INIT
  return (__pyx_m != NULL) ? 0 : -1;
  #else
  return __pyx_m;
  #endif
}
/* #### Code section: pystring_table ### */

typedef struct {
    const char *s;
#if 213 <= 65535
    const unsigned short n;
#elif 213 / 2 < INT_MAX
    const unsigned int n;
#elif 213 / 2 < LONG_MAX
    const unsigned long n;
#else
    const Py_ssize_t n;
#endif
#if 1 <= 31
    const unsigned int encoding : 5;
#elif 1 <= 255
    const unsigned char encoding;
#elif 1 <= 65535
    const unsigned short encoding;
#else
    const Py_ssize_t encoding;
#endif
    const unsigned int is_unicode : 1;
    const unsigned int intern : 1;
} __Pyx_StringTabEntry;
static const char * const __pyx_string_tab_encodings[] = { 0 };
static const __Pyx_StringTabEntry __pyx_string_tab[] = {
  {__pyx_k_, sizeof(__pyx_k_), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_ */
  {__pyx_k_AssertionError, sizeof(__pyx_k_AssertionError), 0, 1, 1}, /* PyObject cname: __pyx_n_u_AssertionError */
  {__pyx_k_C, sizeof(__pyx_k_C), 0, 1, 1}, /* PyObject cname: __pyx_n_u_C */
  {__pyx_k_CUDA_C_16F, sizeof(__pyx_k_CUDA_C_16F), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUDA_C_16F */
  {__pyx_k_CUDA_C_32F, sizeof(__pyx_k_CUDA_C_32F), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUDA_C_32F */
  {__pyx_k_CUDA_C_64F, sizeof(__pyx_k_CUDA_C_64F), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUDA_C_64F */
  {__pyx_k_CUDA_R_16F, sizeof(__pyx_k_CUDA_R_16F), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUDA_R_16F */
  {__pyx_k_CUDA_R_32F, sizeof(__pyx_k_CUDA_R_32F), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUDA_R_32F */
  {__pyx_k_CUDA_R_64F, sizeof(__pyx_k_CUDA_R_64F), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUDA_R_64F */
  {__pyx_k_CUFFT_ALLOC_FAILED, sizeof(__pyx_k_CUFFT_ALLOC_FAILED), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_ALLOC_FAILED */
  {__pyx_k_CUFFT_EXEC_FAILED, sizeof(__pyx_k_CUFFT_EXEC_FAILED), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_EXEC_FAILED */
  {__pyx_k_CUFFT_INCOMPLETE_PARAMETER_LIST, sizeof(__pyx_k_CUFFT_INCOMPLETE_PARAMETER_LIST), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_INCOMPLETE_PARAMETER_LIST */
  {__pyx_k_CUFFT_INTERNAL_ERROR, sizeof(__pyx_k_CUFFT_INTERNAL_ERROR), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_INTERNAL_ERROR */
  {__pyx_k_CUFFT_INVALID_DEVICE, sizeof(__pyx_k_CUFFT_INVALID_DEVICE), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_INVALID_DEVICE */
  {__pyx_k_CUFFT_INVALID_PLAN, sizeof(__pyx_k_CUFFT_INVALID_PLAN), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_INVALID_PLAN */
  {__pyx_k_CUFFT_INVALID_SIZE, sizeof(__pyx_k_CUFFT_INVALID_SIZE), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_INVALID_SIZE */
  {__pyx_k_CUFFT_INVALID_TYPE, sizeof(__pyx_k_CUFFT_INVALID_TYPE), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_INVALID_TYPE */
  {__pyx_k_CUFFT_INVALID_VALUE, sizeof(__pyx_k_CUFFT_INVALID_VALUE), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_INVALID_VALUE */
  {__pyx_k_CUFFT_LICENSE_ERROR, sizeof(__pyx_k_CUFFT_LICENSE_ERROR), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_LICENSE_ERROR */
  {__pyx_k_CUFFT_NOT_IMPLEMENTED, sizeof(__pyx_k_CUFFT_NOT_IMPLEMENTED), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_NOT_IMPLEMENTED */
  {__pyx_k_CUFFT_NOT_SUPPORTED, sizeof(__pyx_k_CUFFT_NOT_SUPPORTED), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_NOT_SUPPORTED */
  {__pyx_k_CUFFT_NO_WORKSPACE, sizeof(__pyx_k_CUFFT_NO_WORKSPACE), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_NO_WORKSPACE */
  {__pyx_k_CUFFT_PARSE_ERROR, sizeof(__pyx_k_CUFFT_PARSE_ERROR), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_PARSE_ERROR */
  {__pyx_k_CUFFT_SETUP_FAILED, sizeof(__pyx_k_CUFFT_SETUP_FAILED), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_SETUP_FAILED */
  {__pyx_k_CUFFT_SUCCESS, sizeof(__pyx_k_CUFFT_SUCCESS), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_SUCCESS */
  {__pyx_k_CUFFT_UNALIGNED_DATA, sizeof(__pyx_k_CUFFT_UNALIGNED_DATA), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CUFFT_UNALIGNED_DATA */
  {__pyx_k_CuFFTError, sizeof(__pyx_k_CuFFTError), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CuFFTError */
  {__pyx_k_CuFFTError___init, sizeof(__pyx_k_CuFFTError___init), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CuFFTError___init */
  {__pyx_k_CuFFTError___reduce, sizeof(__pyx_k_CuFFTError___reduce), 0, 1, 1}, /* PyObject cname: __pyx_n_u_CuFFTError___reduce */
  {__pyx_k_Currently_for_multiple_GPUs_only, sizeof(__pyx_k_Currently_for_multiple_GPUs_only), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_Currently_for_multiple_GPUs_only */
  {__pyx_k_Event, sizeof(__pyx_k_Event), 0, 1, 1}, /* PyObject cname: __pyx_n_u_Event */
  {__pyx_k_For_GPUs_the_array_length_must_b, sizeof(__pyx_k_For_GPUs_the_array_length_must_b), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_For_GPUs_the_array_length_must_b */
  {__pyx_k_For_multi_GPU_FFT_with_batch_1_t, sizeof(__pyx_k_For_multi_GPU_FFT_with_batch_1_t), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_For_multi_GPU_FFT_with_batch_1_t */
  {__pyx_k_For_multi_GPU_FFT_with_batch_1_t_2, sizeof(__pyx_k_For_multi_GPU_FFT_with_batch_1_t_2), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_For_multi_GPU_FFT_with_batch_1_t_2 */
  {__pyx_k_Impossible_to_reach, sizeof(__pyx_k_Impossible_to_reach), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_Impossible_to_reach */
  {__pyx_k_Incompatible_checksums_0x_x_vs_0, sizeof(__pyx_k_Incompatible_checksums_0x_x_vs_0), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_Incompatible_checksums_0x_x_vs_0 */
  {__pyx_k_Incompatible_checksums_0x_x_vs_0_2, sizeof(__pyx_k_Incompatible_checksums_0x_x_vs_0_2), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_Incompatible_checksums_0x_x_vs_0_2 */
  {__pyx_k_Incompatible_checksums_0x_x_vs_0_3, sizeof(__pyx_k_Incompatible_checksums_0x_x_vs_0_3), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_Incompatible_checksums_0x_x_vs_0_3 */
  {__pyx_k_MemoryError, sizeof(__pyx_k_MemoryError), 0, 1, 1}, /* PyObject cname: __pyx_n_u_MemoryError */
  {__pyx_k_NotImplementedError, sizeof(__pyx_k_NotImplementedError), 0, 1, 1}, /* PyObject cname: __pyx_n_u_NotImplementedError */
  {__pyx_k_Note_that_Cython_is_deliberately, sizeof(__pyx_k_Note_that_Cython_is_deliberately), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_Note_that_Cython_is_deliberately */
  {__pyx_k_OWNDATA, sizeof(__pyx_k_OWNDATA), 0, 1, 1}, /* PyObject cname: __pyx_n_u_OWNDATA */
  {__pyx_k_PickleError, sizeof(__pyx_k_PickleError), 0, 1, 1}, /* PyObject cname: __pyx_n_u_PickleError */
  {__pyx_k_Plan1d, sizeof(__pyx_k_Plan1d), 0, 1, 1}, /* PyObject cname: __pyx_n_u_Plan1d */
  {__pyx_k_PlanNd, sizeof(__pyx_k_PlanNd), 0, 1, 1}, /* PyObject cname: __pyx_n_u_PlanNd */
  {__pyx_k_RuntimeError, sizeof(__pyx_k_RuntimeError), 0, 1, 1}, /* PyObject cname: __pyx_n_u_RuntimeError */
  {__pyx_k_Stream, sizeof(__pyx_k_Stream), 0, 1, 1}, /* PyObject cname: __pyx_n_u_Stream */
  {__pyx_k_User_managed_buffer_area_is_not, sizeof(__pyx_k_User_managed_buffer_area_is_not), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_User_managed_buffer_area_is_not */
  {__pyx_k_ValueError, sizeof(__pyx_k_ValueError), 0, 1, 1}, /* PyObject cname: __pyx_n_u_ValueError */
  {__pyx_k_XtPlanNd, sizeof(__pyx_k_XtPlanNd), 0, 1, 1}, /* PyObject cname: __pyx_n_u_XtPlanNd */
  {__pyx_k_XtSetJITCallback, sizeof(__pyx_k_XtSetJITCallback), 0, 1, 1}, /* PyObject cname: __pyx_n_u_XtSetJITCallback */
  {__pyx_k__2, sizeof(__pyx_k__2), 0, 1, 0}, /* PyObject cname: __pyx_kp_u__2 */
  {__pyx_k_a, sizeof(__pyx_k_a), 0, 1, 1}, /* PyObject cname: __pyx_n_u_a */
  {__pyx_k_action, sizeof(__pyx_k_action), 0, 1, 1}, /* PyObject cname: __pyx_n_u_action */
  {__pyx_k_add_note, sizeof(__pyx_k_add_note), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_add_note */
  {__pyx_k_alloc, sizeof(__pyx_k_alloc), 0, 1, 1}, /* PyObject cname: __pyx_n_u_alloc */
  {__pyx_k_asyncio_coroutines, sizeof(__pyx_k_asyncio_coroutines), 0, 1, 1}, /* PyObject cname: __pyx_n_u_asyncio_coroutines */
  {__pyx_k_autoAllocate, sizeof(__pyx_k_autoAllocate), 0, 1, 1}, /* PyObject cname: __pyx_n_u_autoAllocate */
  {__pyx_k_aux_arr, sizeof(__pyx_k_aux_arr), 0, 1, 1}, /* PyObject cname: __pyx_n_u_aux_arr */
  {__pyx_k_batch, sizeof(__pyx_k_batch), 0, 1, 1}, /* PyObject cname: __pyx_n_u_batch */
  {__pyx_k_c_contiguous, sizeof(__pyx_k_c_contiguous), 0, 1, 1}, /* PyObject cname: __pyx_n_u_c_contiguous */
  {__pyx_k_callback, sizeof(__pyx_k_callback), 0, 1, 1}, /* PyObject cname: __pyx_n_u_callback */
  {__pyx_k_callback_name, sizeof(__pyx_k_callback_name), 0, 1, 1}, /* PyObject cname: __pyx_n_u_callback_name */
  {__pyx_k_callback_type, sizeof(__pyx_k_callback_type), 0, 1, 1}, /* PyObject cname: __pyx_n_u_callback_type */
  {__pyx_k_caller_info, sizeof(__pyx_k_caller_info), 0, 1, 1}, /* PyObject cname: __pyx_n_u_caller_info */
  {__pyx_k_cb_type, sizeof(__pyx_k_cb_type), 0, 1, 1}, /* PyObject cname: __pyx_n_u_cb_type */
  {__pyx_k_char, sizeof(__pyx_k_char), 0, 1, 1}, /* PyObject cname: __pyx_n_u_char */
  {__pyx_k_class_getitem, sizeof(__pyx_k_class_getitem), 0, 1, 1}, /* PyObject cname: __pyx_n_u_class_getitem */
  {__pyx_k_cline_in_traceback, sizeof(__pyx_k_cline_in_traceback), 0, 1, 1}, /* PyObject cname: __pyx_n_u_cline_in_traceback */
  {__pyx_k_complex128, sizeof(__pyx_k_complex128), 0, 1, 1}, /* PyObject cname: __pyx_n_u_complex128 */
  {__pyx_k_complex32_is_not_supported_yet_p, sizeof(__pyx_k_complex32_is_not_supported_yet_p), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_complex32_is_not_supported_yet_p */
  {__pyx_k_complex64, sizeof(__pyx_k_complex64), 0, 1, 1}, /* PyObject cname: __pyx_n_u_complex64 */
  {__pyx_k_copy_from_device_async, sizeof(__pyx_k_copy_from_device_async), 0, 1, 1}, /* PyObject cname: __pyx_n_u_copy_from_device_async */
  {__pyx_k_ctypes, sizeof(__pyx_k_ctypes), 0, 1, 1}, /* PyObject cname: __pyx_n_u_ctypes */
  {__pyx_k_cuFFT_is_dynamically_linked_and, sizeof(__pyx_k_cuFFT_is_dynamically_linked_and), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_cuFFT_is_dynamically_linked_and */
  {__pyx_k_cufft, sizeof(__pyx_k_cufft), 0, 1, 1}, /* PyObject cname: __pyx_n_u_cufft */
  {__pyx_k_cufft64_11_dll, sizeof(__pyx_k_cufft64_11_dll), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_cufft64_11_dll */
  {__pyx_k_cufft64_12_dll, sizeof(__pyx_k_cufft64_12_dll), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_cufft64_12_dll */
  {__pyx_k_cufft_2, sizeof(__pyx_k_cufft_2), 0, 1, 1}, /* PyObject cname: __pyx_n_u_cufft_2 */
  {__pyx_k_cupy, sizeof(__pyx_k_cupy), 0, 1, 1}, /* PyObject cname: __pyx_n_u_cupy */
  {__pyx_k_cupy__core__dtype, sizeof(__pyx_k_cupy__core__dtype), 0, 1, 1}, /* PyObject cname: __pyx_n_u_cupy__core__dtype */
  {__pyx_k_cupy_cuda, sizeof(__pyx_k_cupy_cuda), 0, 1, 1}, /* PyObject cname: __pyx_n_u_cupy_cuda */
  {__pyx_k_cupy_cuda_cufft, sizeof(__pyx_k_cupy_cuda_cufft), 0, 1, 1}, /* PyObject cname: __pyx_n_u_cupy_cuda_cufft */
  {__pyx_k_cupy_cuda_cufft_pyx, sizeof(__pyx_k_cupy_cuda_cufft_pyx), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_cupy_cuda_cufft_pyx */
  {__pyx_k_curr_device, sizeof(__pyx_k_curr_device), 0, 1, 1}, /* PyObject cname: __pyx_n_u_curr_device */
  {__pyx_k_current_plan, sizeof(__pyx_k_current_plan), 0, 1, 1}, /* PyObject cname: __pyx_n_u_current_plan */
  {__pyx_k_data, sizeof(__pyx_k_data), 0, 1, 1}, /* PyObject cname: __pyx_n_u_data */
  {__pyx_k_device, sizeof(__pyx_k_device), 0, 1, 1}, /* PyObject cname: __pyx_n_u_device */
  {__pyx_k_device_id, sizeof(__pyx_k_device_id), 0, 1, 1}, /* PyObject cname: __pyx_n_u_device_id */
  {__pyx_k_devices, sizeof(__pyx_k_devices), 0, 1, 1}, /* PyObject cname: __pyx_n_u_devices */
  {__pyx_k_devices_should_be_an_int_or_an, sizeof(__pyx_k_devices_should_be_an_int_or_an), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_devices_should_be_an_int_or_an */
  {__pyx_k_dict, sizeof(__pyx_k_dict), 0, 1, 1}, /* PyObject cname: __pyx_n_u_dict */
  {__pyx_k_direction, sizeof(__pyx_k_direction), 0, 1, 1}, /* PyObject cname: __pyx_n_u_direction */
  {__pyx_k_disable, sizeof(__pyx_k_disable), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_disable */
  {__pyx_k_doc, sizeof(__pyx_k_doc), 0, 1, 1}, /* PyObject cname: __pyx_n_u_doc */
  {__pyx_k_dtype, sizeof(__pyx_k_dtype), 0, 1, 1}, /* PyObject cname: __pyx_n_u_dtype */
  {__pyx_k_edtype, sizeof(__pyx_k_edtype), 0, 1, 1}, /* PyObject cname: __pyx_n_u_edtype */
  {__pyx_k_empty, sizeof(__pyx_k_empty), 0, 1, 1}, /* PyObject cname: __pyx_n_u_empty */
  {__pyx_k_enable, sizeof(__pyx_k_enable), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_enable */
  {__pyx_k_enumerate, sizeof(__pyx_k_enumerate), 0, 1, 1}, /* PyObject cname: __pyx_n_u_enumerate */
  {__pyx_k_etype, sizeof(__pyx_k_etype), 0, 1, 1}, /* PyObject cname: __pyx_n_u_etype */
  {__pyx_k_exc_type, sizeof(__pyx_k_exc_type), 0, 1, 1}, /* PyObject cname: __pyx_n_u_exc_type */
  {__pyx_k_exc_value, sizeof(__pyx_k_exc_value), 0, 1, 1}, /* PyObject cname: __pyx_n_u_exc_value */
  {__pyx_k_f_contiguous, sizeof(__pyx_k_f_contiguous), 0, 1, 1}, /* PyObject cname: __pyx_n_u_f_contiguous */
  {__pyx_k_fft_type, sizeof(__pyx_k_fft_type), 0, 1, 1}, /* PyObject cname: __pyx_n_u_fft_type */
  {__pyx_k_flags, sizeof(__pyx_k_flags), 0, 1, 1}, /* PyObject cname: __pyx_n_u_flags */
  {__pyx_k_float16, sizeof(__pyx_k_float16), 0, 1, 1}, /* PyObject cname: __pyx_n_u_float16 */
  {__pyx_k_float32, sizeof(__pyx_k_float32), 0, 1, 1}, /* PyObject cname: __pyx_n_u_float32 */
  {__pyx_k_float64, sizeof(__pyx_k_float64), 0, 1, 1}, /* PyObject cname: __pyx_n_u_float64 */
  {__pyx_k_format, sizeof(__pyx_k_format), 0, 1, 1}, /* PyObject cname: __pyx_n_u_format */
  {__pyx_k_free_all_blocks, sizeof(__pyx_k_free_all_blocks), 0, 1, 1}, /* PyObject cname: __pyx_n_u_free_all_blocks */
  {__pyx_k_full_size, sizeof(__pyx_k_full_size), 0, 1, 1}, /* PyObject cname: __pyx_n_u_full_size */
  {__pyx_k_func, sizeof(__pyx_k_func), 0, 1, 1}, /* PyObject cname: __pyx_n_u_func */
  {__pyx_k_gather, sizeof(__pyx_k_gather), 0, 1, 1}, /* PyObject cname: __pyx_n_u_gather */
  {__pyx_k_gc, sizeof(__pyx_k_gc), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_gc */
  {__pyx_k_getDevice, sizeof(__pyx_k_getDevice), 0, 1, 1}, /* PyObject cname: __pyx_n_u_getDevice */
  {__pyx_k_get_compute_capability, sizeof(__pyx_k_get_compute_capability), 0, 1, 1}, /* PyObject cname: __pyx_n_u_get_compute_capability */
  {__pyx_k_get_current_stream, sizeof(__pyx_k_get_current_stream), 0, 1, 1}, /* PyObject cname: __pyx_n_u_get_current_stream */
  {__pyx_k_get_default_memory_pool, sizeof(__pyx_k_get_default_memory_pool), 0, 1, 1}, /* PyObject cname: __pyx_n_u_get_default_memory_pool */
  {__pyx_k_getstate, sizeof(__pyx_k_getstate), 0, 1, 1}, /* PyObject cname: __pyx_n_u_getstate */
  {__pyx_k_hipFFT_rocFFT_does_not_support_m, sizeof(__pyx_k_hipFFT_rocFFT_does_not_support_m), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_hipFFT_rocFFT_does_not_support_m */
  {__pyx_k_idata, sizeof(__pyx_k_idata), 0, 1, 1}, /* PyObject cname: __pyx_n_u_idata */
  {__pyx_k_idist, sizeof(__pyx_k_idist), 0, 1, 1}, /* PyObject cname: __pyx_n_u_idist */
  {__pyx_k_idtype, sizeof(__pyx_k_idtype), 0, 1, 1}, /* PyObject cname: __pyx_n_u_idtype */
  {__pyx_k_inembed, sizeof(__pyx_k_inembed), 0, 1, 1}, /* PyObject cname: __pyx_n_u_inembed */
  {__pyx_k_init, sizeof(__pyx_k_init), 0, 1, 1}, /* PyObject cname: __pyx_n_u_init */
  {__pyx_k_initializing, sizeof(__pyx_k_initializing), 0, 1, 1}, /* PyObject cname: __pyx_n_u_initializing */
  {__pyx_k_input_array_too_large, sizeof(__pyx_k_input_array_too_large), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_input_array_too_large */
  {__pyx_k_input_output_execution_types_mis, sizeof(__pyx_k_input_output_execution_types_mis), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_input_output_execution_types_mis */
  {__pyx_k_is_coroutine, sizeof(__pyx_k_is_coroutine), 0, 1, 1}, /* PyObject cname: __pyx_n_u_is_coroutine */
  {__pyx_k_is_hip, sizeof(__pyx_k_is_hip), 0, 1, 1}, /* PyObject cname: __pyx_n_u_is_hip */
  {__pyx_k_is_load, sizeof(__pyx_k_is_load), 0, 1, 1}, /* PyObject cname: __pyx_n_u_is_load */
  {__pyx_k_isenabled, sizeof(__pyx_k_isenabled), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_isenabled */
  {__pyx_k_istride, sizeof(__pyx_k_istride), 0, 1, 1}, /* PyObject cname: __pyx_n_u_istride */
  {__pyx_k_itemsize, sizeof(__pyx_k_itemsize), 0, 1, 1}, /* PyObject cname: __pyx_n_u_itemsize */
  {__pyx_k_itype, sizeof(__pyx_k_itype), 0, 1, 1}, /* PyObject cname: __pyx_n_u_itype */
  {__pyx_k_last_axis, sizeof(__pyx_k_last_axis), 0, 1, 1}, /* PyObject cname: __pyx_n_u_last_axis */
  {__pyx_k_last_size, sizeof(__pyx_k_last_size), 0, 1, 1}, /* PyObject cname: __pyx_n_u_last_size */
  {__pyx_k_libcufft_so_11, sizeof(__pyx_k_libcufft_so_11), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_libcufft_so_11 */
  {__pyx_k_libcufft_so_12, sizeof(__pyx_k_libcufft_so_12), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_libcufft_so_12 */
  {__pyx_k_linux, sizeof(__pyx_k_linux), 0, 1, 1}, /* PyObject cname: __pyx_n_u_linux */
  {__pyx_k_local, sizeof(__pyx_k_local), 0, 1, 1}, /* PyObject cname: __pyx_n_u_local */
  {__pyx_k_lower, sizeof(__pyx_k_lower), 0, 1, 1}, /* PyObject cname: __pyx_n_u_lower */
  {__pyx_k_main, sizeof(__pyx_k_main), 0, 1, 1}, /* PyObject cname: __pyx_n_u_main */
  {__pyx_k_mandatory, sizeof(__pyx_k_mandatory), 0, 1, 1}, /* PyObject cname: __pyx_n_u_mandatory */
  {__pyx_k_memory, sizeof(__pyx_k_memory), 0, 1, 1}, /* PyObject cname: __pyx_n_u_memory */
  {__pyx_k_metaclass, sizeof(__pyx_k_metaclass), 0, 1, 1}, /* PyObject cname: __pyx_n_u_metaclass */
  {__pyx_k_module, sizeof(__pyx_k_module), 0, 1, 1}, /* PyObject cname: __pyx_n_u_module */
  {__pyx_k_mro_entries, sizeof(__pyx_k_mro_entries), 0, 1, 1}, /* PyObject cname: __pyx_n_u_mro_entries */
  {__pyx_k_multi_gpu_fft, sizeof(__pyx_k_multi_gpu_fft), 0, 1, 1}, /* PyObject cname: __pyx_n_u_multi_gpu_fft */
  {__pyx_k_multi_gpu_get_scatter_streams_e, sizeof(__pyx_k_multi_gpu_get_scatter_streams_e), 0, 1, 1}, /* PyObject cname: __pyx_n_u_multi_gpu_get_scatter_streams_e */
  {__pyx_k_multi_gpu_memcpy, sizeof(__pyx_k_multi_gpu_memcpy), 0, 1, 1}, /* PyObject cname: __pyx_n_u_multi_gpu_memcpy */
  {__pyx_k_multi_gpu_setup_buffer, sizeof(__pyx_k_multi_gpu_setup_buffer), 0, 1, 1}, /* PyObject cname: __pyx_n_u_multi_gpu_setup_buffer */
  {__pyx_k_name, sizeof(__pyx_k_name), 0, 1, 1}, /* PyObject cname: __pyx_n_u_name */
  {__pyx_k_ndarray, sizeof(__pyx_k_ndarray), 0, 1, 1}, /* PyObject cname: __pyx_n_u_ndarray */
  {__pyx_k_ndim, sizeof(__pyx_k_ndim), 0, 1, 1}, /* PyObject cname: __pyx_n_u_ndim */
  {__pyx_k_new, sizeof(__pyx_k_new), 0, 1, 1}, /* PyObject cname: __pyx_n_u_new */
  {__pyx_k_numpy, sizeof(__pyx_k_numpy), 0, 1, 1}, /* PyObject cname: __pyx_n_u_numpy */
  {__pyx_k_nx, sizeof(__pyx_k_nx), 0, 1, 1}, /* PyObject cname: __pyx_n_u_nx */
  {__pyx_k_odata, sizeof(__pyx_k_odata), 0, 1, 1}, /* PyObject cname: __pyx_n_u_odata */
  {__pyx_k_odist, sizeof(__pyx_k_odist), 0, 1, 1}, /* PyObject cname: __pyx_n_u_odist */
  {__pyx_k_odtype, sizeof(__pyx_k_odtype), 0, 1, 1}, /* PyObject cname: __pyx_n_u_odtype */
  {__pyx_k_onembed, sizeof(__pyx_k_onembed), 0, 1, 1}, /* PyObject cname: __pyx_n_u_onembed */
  {__pyx_k_order, sizeof(__pyx_k_order), 0, 1, 1}, /* PyObject cname: __pyx_n_u_order */
  {__pyx_k_ostride, sizeof(__pyx_k_ostride), 0, 1, 1}, /* PyObject cname: __pyx_n_u_ostride */
  {__pyx_k_otype, sizeof(__pyx_k_otype), 0, 1, 1}, /* PyObject cname: __pyx_n_u_otype */
  {__pyx_k_out, sizeof(__pyx_k_out), 0, 1, 1}, /* PyObject cname: __pyx_n_u_out */
  {__pyx_k_out_dtype_mismatch_found_expecte, sizeof(__pyx_k_out_dtype_mismatch_found_expecte), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_out_dtype_mismatch_found_expecte */
  {__pyx_k_out_must_have_shape, sizeof(__pyx_k_out_must_have_shape), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_out_must_have_shape */
  {__pyx_k_output_contiguity_mismatch, sizeof(__pyx_k_output_contiguity_mismatch), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_output_contiguity_mismatch */
  {__pyx_k_output_dimension_mismatch, sizeof(__pyx_k_output_dimension_mismatch), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_output_dimension_mismatch */
  {__pyx_k_output_dtype_and_shape, sizeof(__pyx_k_output_dtype_and_shape), 0, 1, 1}, /* PyObject cname: __pyx_n_u_output_dtype_and_shape */
  {__pyx_k_output_dtype_is_unexpected, sizeof(__pyx_k_output_dtype_is_unexpected), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_output_dtype_is_unexpected */
  {__pyx_k_output_dtype_mismatch, sizeof(__pyx_k_output_dtype_mismatch), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_output_dtype_mismatch */
  {__pyx_k_output_shape_is_incorrecct, sizeof(__pyx_k_output_shape_is_incorrecct), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_output_shape_is_incorrecct */
  {__pyx_k_output_shape_mismatch, sizeof(__pyx_k_output_shape_mismatch), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_output_shape_mismatch */
  {__pyx_k_pickle, sizeof(__pyx_k_pickle), 0, 1, 1}, /* PyObject cname: __pyx_n_u_pickle */
  {__pyx_k_plan, sizeof(__pyx_k_plan), 0, 1, 1}, /* PyObject cname: __pyx_n_u_plan */
  {__pyx_k_platform, sizeof(__pyx_k_platform), 0, 1, 1}, /* PyObject cname: __pyx_n_u_platform */
  {__pyx_k_pop, sizeof(__pyx_k_pop), 0, 1, 1}, /* PyObject cname: __pyx_n_u_pop */
  {__pyx_k_prealloc_plan, sizeof(__pyx_k_prealloc_plan), 0, 1, 1}, /* PyObject cname: __pyx_n_u_prealloc_plan */
  {__pyx_k_prepare, sizeof(__pyx_k_prepare), 0, 1, 1}, /* PyObject cname: __pyx_n_u_prepare */
  {__pyx_k_ptr, sizeof(__pyx_k_ptr), 0, 1, 1}, /* PyObject cname: __pyx_n_u_ptr */
  {__pyx_k_pyx_checksum, sizeof(__pyx_k_pyx_checksum), 0, 1, 1}, /* PyObject cname: __pyx_n_u_pyx_checksum */
  {__pyx_k_pyx_state, sizeof(__pyx_k_pyx_state), 0, 1, 1}, /* PyObject cname: __pyx_n_u_pyx_state */
  {__pyx_k_pyx_type, sizeof(__pyx_k_pyx_type), 0, 1, 1}, /* PyObject cname: __pyx_n_u_pyx_type */
  {__pyx_k_pyx_unpickle_Plan1d, sizeof(__pyx_k_pyx_unpickle_Plan1d), 0, 1, 1}, /* PyObject cname: __pyx_n_u_pyx_unpickle_Plan1d */
  {__pyx_k_pyx_unpickle_PlanNd, sizeof(__pyx_k_pyx_unpickle_PlanNd), 0, 1, 1}, /* PyObject cname: __pyx_n_u_pyx_unpickle_PlanNd */
  {__pyx_k_pyx_unpickle_XtPlanNd, sizeof(__pyx_k_pyx_unpickle_XtPlanNd), 0, 1, 1}, /* PyObject cname: __pyx_n_u_pyx_unpickle_XtPlanNd */
  {__pyx_k_pyx_vtable, sizeof(__pyx_k_pyx_vtable), 0, 1, 1}, /* PyObject cname: __pyx_n_u_pyx_vtable */
  {__pyx_k_qualname, sizeof(__pyx_k_qualname), 0, 1, 1}, /* PyObject cname: __pyx_n_u_qualname */
  {__pyx_k_range, sizeof(__pyx_k_range), 0, 1, 1}, /* PyObject cname: __pyx_n_u_range */
  {__pyx_k_ravel, sizeof(__pyx_k_ravel), 0, 1, 1}, /* PyObject cname: __pyx_n_u_ravel */
  {__pyx_k_record, sizeof(__pyx_k_record), 0, 1, 1}, /* PyObject cname: __pyx_n_u_record */
  {__pyx_k_reduce, sizeof(__pyx_k_reduce), 0, 1, 1}, /* PyObject cname: __pyx_n_u_reduce */
  {__pyx_k_reduce_cython, sizeof(__pyx_k_reduce_cython), 0, 1, 1}, /* PyObject cname: __pyx_n_u_reduce_cython */
  {__pyx_k_reduce_ex, sizeof(__pyx_k_reduce_ex), 0, 1, 1}, /* PyObject cname: __pyx_n_u_reduce_ex */
  {__pyx_k_result, sizeof(__pyx_k_result), 0, 1, 1}, /* PyObject cname: __pyx_n_u_result */
  {__pyx_k_runtime, sizeof(__pyx_k_runtime), 0, 1, 1}, /* PyObject cname: __pyx_n_u_runtime */
  {__pyx_k_runtimeGetVersion, sizeof(__pyx_k_runtimeGetVersion), 0, 1, 1}, /* PyObject cname: __pyx_n_u_runtimeGetVersion */
  {__pyx_k_s, sizeof(__pyx_k_s), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_s */
  {__pyx_k_sanity_checks, sizeof(__pyx_k_sanity_checks), 0, 1, 1}, /* PyObject cname: __pyx_n_u_sanity_checks */
  {__pyx_k_scatter, sizeof(__pyx_k_scatter), 0, 1, 1}, /* PyObject cname: __pyx_n_u_scatter */
  {__pyx_k_self, sizeof(__pyx_k_self), 0, 1, 1}, /* PyObject cname: __pyx_n_u_self */
  {__pyx_k_setDevice, sizeof(__pyx_k_setDevice), 0, 1, 1}, /* PyObject cname: __pyx_n_u_setDevice */
  {__pyx_k_set_name, sizeof(__pyx_k_set_name), 0, 1, 1}, /* PyObject cname: __pyx_n_u_set_name */
  {__pyx_k_setstate, sizeof(__pyx_k_setstate), 0, 1, 1}, /* PyObject cname: __pyx_n_u_setstate */
  {__pyx_k_setstate_cython, sizeof(__pyx_k_setstate_cython), 0, 1, 1}, /* PyObject cname: __pyx_n_u_setstate_cython */
  {__pyx_k_shape, sizeof(__pyx_k_shape), 0, 1, 1}, /* PyObject cname: __pyx_n_u_shape */
  {__pyx_k_single_gpu_fft, sizeof(__pyx_k_single_gpu_fft), 0, 1, 1}, /* PyObject cname: __pyx_n_u_single_gpu_fft */
  {__pyx_k_size, sizeof(__pyx_k_size), 0, 1, 1}, /* PyObject cname: __pyx_n_u_size */
  {__pyx_k_size_must_be_power_of_2, sizeof(__pyx_k_size_must_be_power_of_2), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_size_must_be_power_of_2 */
  {__pyx_k_spec, sizeof(__pyx_k_spec), 0, 1, 1}, /* PyObject cname: __pyx_n_u_spec */
  {__pyx_k_stream, sizeof(__pyx_k_stream), 0, 1, 1}, /* PyObject cname: __pyx_n_u_stream */
  {__pyx_k_super, sizeof(__pyx_k_super), 0, 1, 1}, /* PyObject cname: __pyx_n_u_super */
  {__pyx_k_synchronize, sizeof(__pyx_k_synchronize), 0, 1, 1}, /* PyObject cname: __pyx_n_u_synchronize */
  {__pyx_k_sys, sizeof(__pyx_k_sys), 0, 1, 1}, /* PyObject cname: __pyx_n_u_sys */
  {__pyx_k_sys_2, sizeof(__pyx_k_sys_2), 0, 1, 1}, /* PyObject cname: __pyx_n_u_sys_2 */
  {__pyx_k_test, sizeof(__pyx_k_test), 0, 1, 1}, /* PyObject cname: __pyx_n_u_test */
  {__pyx_k_this_device_doesn_t_support_comp, sizeof(__pyx_k_this_device_doesn_t_support_comp), 0, 1, 0}, /* PyObject cname: __pyx_kp_u_this_device_doesn_t_support_comp */
  {__pyx_k_threading, sizeof(__pyx_k_threading), 0, 1, 1}, /* PyObject cname: __pyx_n_u_threading */
  {__pyx_k_to_cuda_dtype, sizeof(__pyx_k_to_cuda_dtype), 0, 1, 1}, /* PyObject cname: __pyx_n_u_to_cuda_dtype */
  {__pyx_k_traceback, sizeof(__pyx_k_traceback), 0, 1, 1}, /* PyObject cname: __pyx_n_u_traceback */
  {__pyx_k_update, sizeof(__pyx_k_update), 0, 1, 1}, /* PyObject cname: __pyx_n_u_update */
  {__pyx_k_upper, sizeof(__pyx_k_upper), 0, 1, 1}, /* PyObject cname: __pyx_n_u_upper */
  {__pyx_k_wait_event, sizeof(__pyx_k_wait_event), 0, 1, 1}, /* PyObject cname: __pyx_n_u_wait_event */
  {__pyx_k_zip, sizeof(__pyx_k_zip), 0, 1, 1}, /* PyObject cname: __pyx_n_u_zip */
  {0, 0, 0, 0, 0}
};
/* InitStrings.proto */
static int __Pyx_InitStrings(__Pyx_StringTabEntry const *t, PyObject **target, const char* const* encoding_names);

/* #### Code section: cached_builtins ### */

static int __Pyx_InitCachedBuiltins(__pyx_mstatetype *__pyx_mstate) {
  CYTHON_UNUSED_VAR(__pyx_mstate);
  __pyx_builtin_RuntimeError = __Pyx_GetBuiltinName(__pyx_mstate->__pyx_n_u_RuntimeError); if (!__pyx_builtin_RuntimeError) __PYX_ERR(0, 219, __pyx_L1_error)
  __pyx_builtin_NotImplementedError = __Pyx_GetBuiltinName(__pyx_mstate->__pyx_n_u_NotImplementedError); if (!__pyx_builtin_NotImplementedError) __PYX_ERR(0, 74, __pyx_L1_error)
  __pyx_builtin_super = __Pyx_GetBuiltinName(__pyx_mstate->__pyx_n_u_super); if (!__pyx_builtin_super) __PYX_ERR(0, 223, __pyx_L1_error)
  __pyx_builtin_AssertionError = __Pyx_GetBuiltinName(__pyx_mstate->__pyx_n_u_AssertionError); if (!__pyx_builtin_AssertionError) __PYX_ERR(0, 256, __pyx_L1_error)
  __pyx_builtin_range = __Pyx_GetBuiltinName(__pyx_mstate->__pyx_n_u_range); if (!__pyx_builtin_range) __PYX_ERR(0, 259, __pyx_L1_error)
  __pyx_builtin_enumerate = __Pyx_GetBuiltinName(__pyx_mstate->__pyx_n_u_enumerate); if (!__pyx_builtin_enumerate) __PYX_ERR(0, 309, __pyx_L1_error)
  __pyx_builtin_zip = __Pyx_GetBuiltinName(__pyx_mstate->__pyx_n_u_zip); if (!__pyx_builtin_zip) __PYX_ERR(0, 309, __pyx_L1_error)
  __pyx_builtin_ValueError = __Pyx_GetBuiltinName(__pyx_mstate->__pyx_n_u_ValueError); if (!__pyx_builtin_ValueError) __PYX_ERR(0, 384, __pyx_L1_error)
  __pyx_builtin_MemoryError = __Pyx_GetBuiltinName(__pyx_mstate->__pyx_n_u_MemoryError); if (!__pyx_builtin_MemoryError) __PYX_ERR(1, 82, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}
/* #### Code section: cached_constants ### */

static int __Pyx_InitCachedConstants(__pyx_mstatetype *__pyx_mstate) {
  __Pyx_RefNannyDeclarations
  CYTHON_UNUSED_VAR(__pyx_mstate);
  __Pyx_RefNannySetupContext("__Pyx_InitCachedConstants", 0);

  /* "(tree fragment)":4
 *     cdef object __pyx_PickleError
 *     cdef object __pyx_result
 *     if __pyx_checksum not in (0xbdeb9ba, 0x989b82b, 0xf5e4dcb):             # <<<<<<<<<<<<<<
 *         from pickle import PickleError as __pyx_PickleError
 *         raise __pyx_PickleError, "Incompatible checksums (0x%x vs (0xbdeb9ba, 0x989b82b, 0xf5e4dcb) = (batch, batch_share, fft_type, gather_events, gather_streams, gpus, handle, nx, scatter_events, scatter_streams, work_area, xtArr, xtArr_buffer))" % __pyx_checksum
*/
  __pyx_mstate_global->__pyx_tuple[0] = PyTuple_Pack(3, __pyx_mstate_global->__pyx_int_199145914, __pyx_mstate_global->__pyx_int_160020523, __pyx_mstate_global->__pyx_int_257838539); if (unlikely(!__pyx_mstate_global->__pyx_tuple[0])) __PYX_ERR(1, 4, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_mstate_global->__pyx_tuple[0]);
  __Pyx_GIVEREF(__pyx_mstate_global->__pyx_tuple[0]);
  __pyx_mstate_global->__pyx_tuple[1] = PyTuple_Pack(3, __pyx_mstate_global->__pyx_int_207092197, __pyx_mstate_global->__pyx_int_163523397, __pyx_mstate_global->__pyx_int_19693511); if (unlikely(!__pyx_mstate_global->__pyx_tuple[1])) __PYX_ERR(1, 4, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_mstate_global->__pyx_tuple[1]);
  __Pyx_GIVEREF(__pyx_mstate_global->__pyx_tuple[1]);
  __pyx_mstate_global->__pyx_tuple[2] = PyTuple_Pack(3, __pyx_mstate_global->__pyx_int_27026583, __pyx_mstate_global->__pyx_int_5570505, __pyx_mstate_global->__pyx_int_96612791); if (unlikely(!__pyx_mstate_global->__pyx_tuple[2])) __PYX_ERR(1, 4, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_mstate_global->__pyx_tuple[2]);
  __Pyx_GIVEREF(__pyx_mstate_global->__pyx_tuple[2]);

  /* "cupy/cuda/cufft.pyx":219
 * 
 * 
 * class CuFFTError(RuntimeError):             # <<<<<<<<<<<<<<
 * 
 *     def __init__(self, int result):
*/
  __pyx_mstate_global->__pyx_tuple[3] = PyTuple_Pack(1, __pyx_builtin_RuntimeError); if (unlikely(!__pyx_mstate_global->__pyx_tuple[3])) __PYX_ERR(0, 219, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_mstate_global->__pyx_tuple[3]);
  __Pyx_GIVEREF(__pyx_mstate_global->__pyx_tuple[3]);
  __pyx_mstate_global->__pyx_tuple[4] = PyTuple_Pack(1, __pyx_builtin_RuntimeError); if (unlikely(!__pyx_mstate_global->__pyx_tuple[4])) __PYX_ERR(0, 219, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_mstate_global->__pyx_tuple[4]);
  __Pyx_GIVEREF(__pyx_mstate_global->__pyx_tuple[4]);
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}
/* #### Code section: init_constants ### */

static int __Pyx_InitConstants(__pyx_mstatetype *__pyx_mstate) {
  CYTHON_UNUSED_VAR(__pyx_mstate);
  __pyx_mstate->__pyx_umethod_PyDict_Type_pop.type = (PyObject*)&PyDict_Type;
  __pyx_mstate->__pyx_umethod_PyDict_Type_pop.method_name = &__pyx_mstate->__pyx_n_u_pop;
  if (__Pyx_InitStrings(__pyx_string_tab, __pyx_mstate->__pyx_string_tab, __pyx_string_tab_encodings) < 0) __PYX_ERR(0, 1, __pyx_L1_error);
  __pyx_mstate->__pyx_int_0 = PyLong_FromLong(0); if (unlikely(!__pyx_mstate->__pyx_int_0)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_1 = PyLong_FromLong(1); if (unlikely(!__pyx_mstate->__pyx_int_1)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_2 = PyLong_FromLong(2); if (unlikely(!__pyx_mstate->__pyx_int_2)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_3 = PyLong_FromLong(3); if (unlikely(!__pyx_mstate->__pyx_int_3)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_4 = PyLong_FromLong(4); if (unlikely(!__pyx_mstate->__pyx_int_4)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_5 = PyLong_FromLong(5); if (unlikely(!__pyx_mstate->__pyx_int_5)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_6 = PyLong_FromLong(6); if (unlikely(!__pyx_mstate->__pyx_int_6)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_7 = PyLong_FromLong(7); if (unlikely(!__pyx_mstate->__pyx_int_7)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_8 = PyLong_FromLong(8); if (unlikely(!__pyx_mstate->__pyx_int_8)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_9 = PyLong_FromLong(9); if (unlikely(!__pyx_mstate->__pyx_int_9)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_10 = PyLong_FromLong(10); if (unlikely(!__pyx_mstate->__pyx_int_10)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_11 = PyLong_FromLong(11); if (unlikely(!__pyx_mstate->__pyx_int_11)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_12 = PyLong_FromLong(12); if (unlikely(!__pyx_mstate->__pyx_int_12)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_13 = PyLong_FromLong(13); if (unlikely(!__pyx_mstate->__pyx_int_13)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_14 = PyLong_FromLong(14); if (unlikely(!__pyx_mstate->__pyx_int_14)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_15 = PyLong_FromLong(15); if (unlikely(!__pyx_mstate->__pyx_int_15)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_16 = PyLong_FromLong(16); if (unlikely(!__pyx_mstate->__pyx_int_16)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_53 = PyLong_FromLong(53); if (unlikely(!__pyx_mstate->__pyx_int_53)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_5570505 = PyLong_FromLong(5570505L); if (unlikely(!__pyx_mstate->__pyx_int_5570505)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_19693511 = PyLong_FromLong(19693511L); if (unlikely(!__pyx_mstate->__pyx_int_19693511)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_27026583 = PyLong_FromLong(27026583L); if (unlikely(!__pyx_mstate->__pyx_int_27026583)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_96612791 = PyLong_FromLong(96612791L); if (unlikely(!__pyx_mstate->__pyx_int_96612791)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_160020523 = PyLong_FromLong(160020523L); if (unlikely(!__pyx_mstate->__pyx_int_160020523)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_163523397 = PyLong_FromLong(163523397L); if (unlikely(!__pyx_mstate->__pyx_int_163523397)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_199145914 = PyLong_FromLong(199145914L); if (unlikely(!__pyx_mstate->__pyx_int_199145914)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_207092197 = PyLong_FromLong(207092197L); if (unlikely(!__pyx_mstate->__pyx_int_207092197)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_257838539 = PyLong_FromLong(257838539L); if (unlikely(!__pyx_mstate->__pyx_int_257838539)) __PYX_ERR(0, 1, __pyx_L1_error)
  __pyx_mstate->__pyx_int_4000000000 = PyLong_FromString("4000000000", 0, 0); if (unlikely(!__pyx_mstate->__pyx_int_4000000000)) __PYX_ERR(0, 1, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}
/* #### Code section: init_codeobjects ### */
\
        typedef struct {
            unsigned int argcount : 2;
            unsigned int num_posonly_args : 1;
            unsigned int num_kwonly_args : 1;
            unsigned int nlocals : 2;
            unsigned int flags : 10;
            unsigned int first_line : 8;
            unsigned int line_table_length : 10;
        } __Pyx_PyCode_New_function_description;
/* NewCodeObj.proto */
static PyObject* __Pyx_PyCode_New(
        const __Pyx_PyCode_New_function_description descr,
        PyObject * const *varnames,
        PyObject *filename,
        PyObject *funcname,
        const char *line_table,
        PyObject *tuple_dedup_map
);


static int __Pyx_CreateCodeObjects(__pyx_mstatetype *__pyx_mstate) {
  PyObject* tuple_dedup_map = PyDict_New();
  if (unlikely(!tuple_dedup_map)) return -1;
  {
    const __Pyx_PyCode_New_function_description descr = {2, 0, 0, 2, (unsigned int)(CO_OPTIMIZED|CO_NEWLOCALS), 221, 32};
    PyObject* const varnames[] = {__pyx_mstate->__pyx_n_u_self, __pyx_mstate->__pyx_n_u_result};
    __pyx_mstate_global->__pyx_codeobj_tab[0] = __Pyx_PyCode_New(descr, varnames, __pyx_mstate->__pyx_kp_u_cupy_cuda_cufft_pyx, __pyx_mstate->__pyx_n_u_init, __pyx_k_A_Ja_Ql_y_c_q, tuple_dedup_map); if (unlikely(!__pyx_mstate_global->__pyx_codeobj_tab[0])) goto bad;
  }
  {
    const __Pyx_PyCode_New_function_description descr = {1, 0, 0, 1, (unsigned int)(CO_OPTIMIZED|CO_NEWLOCALS), 225, 15};
    PyObject* const varnames[] = {__pyx_mstate->__pyx_n_u_self};
    __pyx_mstate_global->__pyx_codeobj_tab[1] = __Pyx_PyCode_New(descr, varnames, __pyx_mstate->__pyx_kp_u_cupy_cuda_cufft_pyx, __pyx_mstate->__pyx_n_u_reduce, __pyx_k_A_AXT, tuple_dedup_map); if (unlikely(!__pyx_mstate_global->__pyx_codeobj_tab[1])) goto bad;
  }
  Py_DECREF(tuple_dedup_map);
  return 0;
  bad:
  Py_DECREF(tuple_dedup_map);
  return -1;
}
/* #### Code section: init_globals ### */

static int __Pyx_InitGlobals(void) {
  /* PythonCompatibility.init */
  if (likely(__Pyx_init_co_variables() == 0)); else

if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1, __pyx_L1_error)

  /* AssertionsEnabled.init */
  if (likely(__Pyx_init_assertions_enabled() == 0)); else

if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1, __pyx_L1_error)

  /* CachedMethodType.init */
  #if CYTHON_COMPILING_IN_LIMITED_API
{
    PyObject *typesModule=NULL;
    typesModule = PyImport_ImportModule("types");
    if (typesModule) {
        __pyx_mstate_global->__Pyx_CachedMethodType = PyObject_GetAttrString(typesModule, "MethodType");
        Py_DECREF(typesModule);
    }
} // error handling follows
#endif

if (unlikely(PyErr_Occurred())) __PYX_ERR(0, 1, __pyx_L1_error)

  return 0;
  __pyx_L1_error:;
  return -1;
}
/* #### Code section: cleanup_globals ### */
/* #### Code section: cleanup_module ### */
/* #### Code section: main_method ### */
/* #### Code section: utility_code_pragmas ### */
#ifdef _MSC_VER
#pragma warning( push )
/* Warning 4127: conditional expression is constant
 * Cython uses constant conditional expressions to allow in inline functions to be optimized at
 * compile-time, so this warning is not useful
 */
#pragma warning( disable : 4127 )
#endif



/* #### Code section: utility_code_def ### */

/* --- Runtime support code --- */
/* Refnanny */
#if CYTHON_REFNANNY
static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname) {
    PyObject *m = NULL, *p = NULL;
    void *r = NULL;
    m = PyImport_ImportModule(modname);
    if (!m) goto end;
    p = PyObject_GetAttrString(m, "RefNannyAPI");
    if (!p) goto end;
    r = PyLong_AsVoidPtr(p);
end:
    Py_XDECREF(p);
    Py_XDECREF(m);
    return (__Pyx_RefNannyAPIStruct *)r;
}
#endif

/* PyErrExceptionMatches */
#if CYTHON_FAST_THREAD_STATE
static int __Pyx_PyErr_ExceptionMatchesTuple(PyObject *exc_type, PyObject *tuple) {
    Py_ssize_t i, n;
    n = PyTuple_GET_SIZE(tuple);
    for (i=0; i<n; i++) {
        if (exc_type == PyTuple_GET_ITEM(tuple, i)) return 1;
    }
    for (i=0; i<n; i++) {
        if (__Pyx_PyErr_GivenExceptionMatches(exc_type, PyTuple_GET_ITEM(tuple, i))) return 1;
    }
    return 0;
}
static CYTHON_INLINE int __Pyx_PyErr_ExceptionMatchesInState(PyThreadState* tstate, PyObject* err) {
    int result;
    PyObject *exc_type;
#if PY_VERSION_HEX >= 0x030C00A6
    PyObject *current_exception = tstate->current_exception;
    if (unlikely(!current_exception)) return 0;
    exc_type = (PyObject*) Py_TYPE(current_exception);
    if (exc_type == err) return 1;
#else
    exc_type = tstate->curexc_type;
    if (exc_type == err) return 1;
    if (unlikely(!exc_type)) return 0;
#endif
    #if CYTHON_AVOID_BORROWED_REFS
    Py_INCREF(exc_type);
    #endif
    if (unlikely(PyTuple_Check(err))) {
        result = __Pyx_PyErr_ExceptionMatchesTuple(exc_type, err);
    } else {
        result = __Pyx_PyErr_GivenExceptionMatches(exc_type, err);
    }
    #if CYTHON_AVOID_BORROWED_REFS
    Py_DECREF(exc_type);
    #endif
    return result;
}
#endif

/* PyErrFetchRestore */
#if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
#if PY_VERSION_HEX >= 0x030C00A6
    PyObject *tmp_value;
    assert(type == NULL || (value != NULL && type == (PyObject*) Py_TYPE(value)));
    if (value) {
        #if CYTHON_COMPILING_IN_CPYTHON
        if (unlikely(((PyBaseExceptionObject*) value)->traceback != tb))
        #endif
            PyException_SetTraceback(value, tb);
    }
    tmp_value = tstate->current_exception;
    tstate->current_exception = value;
    Py_XDECREF(tmp_value);
    Py_XDECREF(type);
    Py_XDECREF(tb);
#else
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    tmp_type = tstate->curexc_type;
    tmp_value = tstate->curexc_value;
    tmp_tb = tstate->curexc_traceback;
    tstate->curexc_type = type;
    tstate->curexc_value = value;
    tstate->curexc_traceback = tb;
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
#endif
}
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
#if PY_VERSION_HEX >= 0x030C00A6
    PyObject* exc_value;
    exc_value = tstate->current_exception;
    tstate->current_exception = 0;
    *value = exc_value;
    *type = NULL;
    *tb = NULL;
    if (exc_value) {
        *type = (PyObject*) Py_TYPE(exc_value);
        Py_INCREF(*type);
        #if CYTHON_COMPILING_IN_CPYTHON
        *tb = ((PyBaseExceptionObject*) exc_value)->traceback;
        Py_XINCREF(*tb);
        #else
        *tb = PyException_GetTraceback(exc_value);
        #endif
    }
#else
    *type = tstate->curexc_type;
    *value = tstate->curexc_value;
    *tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
#endif
}
#endif

/* PyObjectGetAttrStr */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_getattro))
        return tp->tp_getattro(obj, attr_name);
    return PyObject_GetAttr(obj, attr_name);
}
#endif

/* PyObjectGetAttrStrNoError */
#if __PYX_LIMITED_VERSION_HEX < 0x030d0000
static void __Pyx_PyObject_GetAttrStr_ClearAttributeError(void) {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    if (likely(__Pyx_PyErr_ExceptionMatches(PyExc_AttributeError)))
        __Pyx_PyErr_Clear();
}
#endif
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStrNoError(PyObject* obj, PyObject* attr_name) {
    PyObject *result;
#if __PYX_LIMITED_VERSION_HEX >= 0x030d0000
    (void) PyObject_GetOptionalAttr(obj, attr_name, &result);
    return result;
#else
#if CYTHON_COMPILING_IN_CPYTHON && CYTHON_USE_TYPE_SLOTS
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_getattro == PyObject_GenericGetAttr)) {
        return _PyObject_GenericGetAttrWithDict(obj, attr_name, NULL, 1);
    }
#endif
    result = __Pyx_PyObject_GetAttrStr(obj, attr_name);
    if (unlikely(!result)) {
        __Pyx_PyObject_GetAttrStr_ClearAttributeError();
    }
    return result;
#endif
}

/* GetBuiltinName */
static PyObject *__Pyx_GetBuiltinName(PyObject *name) {
    PyObject* result = __Pyx_PyObject_GetAttrStrNoError(__pyx_mstate_global->__pyx_b, name);
    if (unlikely(!result) && !PyErr_Occurred()) {
        PyErr_Format(PyExc_NameError,
            "name '%U' is not defined", name);
    }
    return result;
}

/* PyDictVersioning */
#if CYTHON_USE_DICT_VERSIONS && CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PY_UINT64_T __Pyx_get_tp_dict_version(PyObject *obj) {
    PyObject *dict = Py_TYPE(obj)->tp_dict;
    return likely(dict) ? __PYX_GET_DICT_VERSION(dict) : 0;
}
static CYTHON_INLINE PY_UINT64_T __Pyx_get_object_dict_version(PyObject *obj) {
    PyObject **dictptr = NULL;
    Py_ssize_t offset = Py_TYPE(obj)->tp_dictoffset;
    if (offset) {
#if CYTHON_COMPILING_IN_CPYTHON
        dictptr = (likely(offset > 0)) ? (PyObject **) ((char *)obj + offset) : _PyObject_GetDictPtr(obj);
#else
        dictptr = _PyObject_GetDictPtr(obj);
#endif
    }
    return (dictptr && *dictptr) ? __PYX_GET_DICT_VERSION(*dictptr) : 0;
}
static CYTHON_INLINE int __Pyx_object_dict_version_matches(PyObject* obj, PY_UINT64_T tp_dict_version, PY_UINT64_T obj_dict_version) {
    PyObject *dict = Py_TYPE(obj)->tp_dict;
    if (unlikely(!dict) || unlikely(tp_dict_version != __PYX_GET_DICT_VERSION(dict)))
        return 0;
    return obj_dict_version == __Pyx_get_object_dict_version(obj);
}
#endif

/* GetModuleGlobalName */
#if CYTHON_USE_DICT_VERSIONS
static PyObject *__Pyx__GetModuleGlobalName(PyObject *name, PY_UINT64_T *dict_version, PyObject **dict_cached_value)
#else
static CYTHON_INLINE PyObject *__Pyx__GetModuleGlobalName(PyObject *name)
#endif
{
    PyObject *result;
#if CYTHON_COMPILING_IN_LIMITED_API
    if (unlikely(!__pyx_m)) {
        if (!PyErr_Occurred())
            PyErr_SetNone(PyExc_NameError);
        return NULL;
    }
    result = PyObject_GetAttr(__pyx_m, name);
    if (likely(result)) {
        return result;
    }
    PyErr_Clear();
#elif CYTHON_AVOID_BORROWED_REFS || CYTHON_AVOID_THREAD_UNSAFE_BORROWED_REFS
    if (unlikely(__Pyx_PyDict_GetItemRef(__pyx_mstate_global->__pyx_d, name, &result) == -1)) PyErr_Clear();
    __PYX_UPDATE_DICT_CACHE(__pyx_mstate_global->__pyx_d, result, *dict_cached_value, *dict_version)
    if (likely(result)) {
        return result;
    }
#else
    result = _PyDict_GetItem_KnownHash(__pyx_mstate_global->__pyx_d, name, ((PyASCIIObject *) name)->hash);
    __PYX_UPDATE_DICT_CACHE(__pyx_mstate_global->__pyx_d, result, *dict_cached_value, *dict_version)
    if (likely(result)) {
        return __Pyx_NewRef(result);
    }
    PyErr_Clear();
#endif
    return __Pyx_GetBuiltinName(name);
}

/* PyFunctionFastCall */
#if CYTHON_FAST_PYCALL && !CYTHON_VECTORCALL
static PyObject* __Pyx_PyFunction_FastCallNoKw(PyCodeObject *co, PyObject *const *args, Py_ssize_t na,
                                               PyObject *globals) {
    PyFrameObject *f;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    PyObject **fastlocals;
    Py_ssize_t i;
    PyObject *result;
    assert(globals != NULL);
    /* XXX Perhaps we should create a specialized
       PyFrame_New() that doesn't take locals, but does
       take builtins without sanity checking them.
       */
    assert(tstate != NULL);
    f = PyFrame_New(tstate, co, globals, NULL);
    if (f == NULL) {
        return NULL;
    }
    fastlocals = __Pyx_PyFrame_GetLocalsplus(f);
    for (i = 0; i < na; i++) {
        Py_INCREF(*args);
        fastlocals[i] = *args++;
    }
    result = PyEval_EvalFrameEx(f,0);
    ++tstate->recursion_depth;
    Py_DECREF(f);
    --tstate->recursion_depth;
    return result;
}
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject *const *args, Py_ssize_t nargs, PyObject *kwargs) {
    PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
    PyObject *globals = PyFunction_GET_GLOBALS(func);
    PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
    PyObject *closure;
    PyObject *kwdefs;
    PyObject *kwtuple, **k;
    PyObject **d;
    Py_ssize_t nd;
    Py_ssize_t nk;
    PyObject *result;
    assert(kwargs == NULL || PyDict_Check(kwargs));
    nk = kwargs ? PyDict_Size(kwargs) : 0;
    if (unlikely(Py_EnterRecursiveCall(" while calling a Python object"))) {
        return NULL;
    }
    if (
            co->co_kwonlyargcount == 0 &&
            likely(kwargs == NULL || nk == 0) &&
            co->co_flags == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE)) {
        if (argdefs == NULL && co->co_argcount == nargs) {
            result = __Pyx_PyFunction_FastCallNoKw(co, args, nargs, globals);
            goto done;
        }
        else if (nargs == 0 && argdefs != NULL
                 && co->co_argcount == Py_SIZE(argdefs)) {
            /* function called with no arguments, but all parameters have
               a default value: use default values as arguments .*/
            args = &PyTuple_GET_ITEM(argdefs, 0);
            result =__Pyx_PyFunction_FastCallNoKw(co, args, Py_SIZE(argdefs), globals);
            goto done;
        }
    }
    if (kwargs != NULL) {
        Py_ssize_t pos, i;
        kwtuple = PyTuple_New(2 * nk);
        if (kwtuple == NULL) {
            result = NULL;
            goto done;
        }
        k = &PyTuple_GET_ITEM(kwtuple, 0);
        pos = i = 0;
        while (PyDict_Next(kwargs, &pos, &k[i], &k[i+1])) {
            Py_INCREF(k[i]);
            Py_INCREF(k[i+1]);
            i += 2;
        }
        nk = i / 2;
    }
    else {
        kwtuple = NULL;
        k = NULL;
    }
    closure = PyFunction_GET_CLOSURE(func);
    kwdefs = PyFunction_GET_KW_DEFAULTS(func);
    if (argdefs != NULL) {
        d = &PyTuple_GET_ITEM(argdefs, 0);
        nd = Py_SIZE(argdefs);
    }
    else {
        d = NULL;
        nd = 0;
    }
    result = PyEval_EvalCodeEx((PyObject*)co, globals, (PyObject *)NULL,
                               args, (int)nargs,
                               k, (int)nk,
                               d, (int)nd, kwdefs, closure);
    Py_XDECREF(kwtuple);
done:
    Py_LeaveRecursiveCall();
    return result;
}
#endif

/* PyObjectCall */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    PyObject *result;
    ternaryfunc call = Py_TYPE(func)->tp_call;
    if (unlikely(!call))
        return PyObject_Call(func, arg, kw);
    if (unlikely(Py_EnterRecursiveCall(" while calling a Python object")))
        return NULL;
    result = (*call)(func, arg, kw);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectCallMethO */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg) {
    PyObject *self, *result;
    PyCFunction cfunc;
    cfunc = __Pyx_CyOrPyCFunction_GET_FUNCTION(func);
    self = __Pyx_CyOrPyCFunction_GET_SELF(func);
    if (unlikely(Py_EnterRecursiveCall(" while calling a Python object")))
        return NULL;
    result = cfunc(self, arg);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectFastCall */
#if PY_VERSION_HEX < 0x03090000 || CYTHON_COMPILING_IN_LIMITED_API
static PyObject* __Pyx_PyObject_FastCall_fallback(PyObject *func, PyObject * const*args, size_t nargs, PyObject *kwargs) {
    PyObject *argstuple;
    PyObject *result = 0;
    size_t i;
    argstuple = PyTuple_New((Py_ssize_t)nargs);
    if (unlikely(!argstuple)) return NULL;
    for (i = 0; i < nargs; i++) {
        Py_INCREF(args[i]);
        if (__Pyx_PyTuple_SET_ITEM(argstuple, (Py_ssize_t)i, args[i]) != (0)) goto bad;
    }
    result = __Pyx_PyObject_Call(func, argstuple, kwargs);
  bad:
    Py_DECREF(argstuple);
    return result;
}
#endif
#if CYTHON_VECTORCALL && !CYTHON_COMPILING_IN_LIMITED_API
  #if PY_VERSION_HEX < 0x03090000
    #define __Pyx_PyVectorcall_Function(callable) _PyVectorcall_Function(callable)
  #elif CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE vectorcallfunc __Pyx_PyVectorcall_Function(PyObject *callable) {
    PyTypeObject *tp = Py_TYPE(callable);
    #if defined(__Pyx_CyFunction_USED)
    if (__Pyx_CyFunction_CheckExact(callable)) {
        return __Pyx_CyFunction_func_vectorcall(callable);
    }
    #endif
    if (!PyType_HasFeature(tp, Py_TPFLAGS_HAVE_VECTORCALL)) {
        return NULL;
    }
    assert(PyCallable_Check(callable));
    Py_ssize_t offset = tp->tp_vectorcall_offset;
    assert(offset > 0);
    vectorcallfunc ptr;
    memcpy(&ptr, (char *) callable + offset, sizeof(ptr));
    return ptr;
}
  #else
    #define __Pyx_PyVectorcall_Function(callable) PyVectorcall_Function(callable)
  #endif
#endif
static CYTHON_INLINE PyObject* __Pyx_PyObject_FastCallDict(PyObject *func, PyObject *const *args, size_t _nargs, PyObject *kwargs) {
    Py_ssize_t nargs = __Pyx_PyVectorcall_NARGS(_nargs);
#if CYTHON_COMPILING_IN_CPYTHON
    if (nargs == 0 && kwargs == NULL) {
        if (__Pyx_CyOrPyCFunction_Check(func) && likely( __Pyx_CyOrPyCFunction_GET_FLAGS(func) & METH_NOARGS))
            return __Pyx_PyObject_CallMethO(func, NULL);
    }
    else if (nargs == 1 && kwargs == NULL) {
        if (__Pyx_CyOrPyCFunction_Check(func) && likely( __Pyx_CyOrPyCFunction_GET_FLAGS(func) & METH_O))
            return __Pyx_PyObject_CallMethO(func, args[0]);
    }
#endif
    #if PY_VERSION_HEX < 0x030800B1
    #if CYTHON_FAST_PYCCALL
    if (PyCFunction_Check(func)) {
        if (kwargs) {
            return _PyCFunction_FastCallDict(func, args, nargs, kwargs);
        } else {
            return _PyCFunction_FastCallKeywords(func, args, nargs, NULL);
        }
    }
    if (!kwargs && __Pyx_IS_TYPE(func, &PyMethodDescr_Type)) {
        return _PyMethodDescr_FastCallKeywords(func, args, nargs, NULL);
    }
    #endif
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs);
    }
    #endif
    #endif
    if (kwargs == NULL) {
        #if CYTHON_VECTORCALL && !CYTHON_COMPILING_IN_LIMITED_API
        vectorcallfunc f = __Pyx_PyVectorcall_Function(func);
        if (f) {
            return f(func, args, _nargs, NULL);
        }
        #elif defined(__Pyx_CyFunction_USED) && CYTHON_BACKPORT_VECTORCALL
        if (__Pyx_CyFunction_CheckExact(func)) {
            __pyx_vectorcallfunc f = __Pyx_CyFunction_func_vectorcall(func);
            if (f) return f(func, args, _nargs, NULL);
        }
        #elif CYTHON_COMPILING_IN_LIMITED_API && CYTHON_VECTORCALL
        return PyObject_Vectorcall(func, args, _nargs, NULL);
        #endif
    }
    if (nargs == 0) {
        return __Pyx_PyObject_Call(func, __pyx_mstate_global->__pyx_empty_tuple, kwargs);
    }
    #if PY_VERSION_HEX >= 0x03090000 && !CYTHON_COMPILING_IN_LIMITED_API
    return PyObject_VectorcallDict(func, args, (size_t)nargs, kwargs);
    #else
    return __Pyx_PyObject_FastCall_fallback(func, args, (size_t)nargs, kwargs);
    #endif
}

/* BytesEquals */
static CYTHON_INLINE int __Pyx_PyBytes_Equals(PyObject* s1, PyObject* s2, int equals) {
#if CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_LIMITED_API || CYTHON_COMPILING_IN_GRAAL ||\
        !(CYTHON_ASSUME_SAFE_SIZE && CYTHON_ASSUME_SAFE_MACROS)
    return PyObject_RichCompareBool(s1, s2, equals);
#else
    if (s1 == s2) {
        return (equals == Py_EQ);
    } else if (PyBytes_CheckExact(s1) & PyBytes_CheckExact(s2)) {
        const char *ps1, *ps2;
        Py_ssize_t length = PyBytes_GET_SIZE(s1);
        if (length != PyBytes_GET_SIZE(s2))
            return (equals == Py_NE);
        ps1 = PyBytes_AS_STRING(s1);
        ps2 = PyBytes_AS_STRING(s2);
        if (ps1[0] != ps2[0]) {
            return (equals == Py_NE);
        } else if (length == 1) {
            return (equals == Py_EQ);
        } else {
            int result;
#if CYTHON_USE_UNICODE_INTERNALS && (PY_VERSION_HEX < 0x030B0000)
            Py_hash_t hash1, hash2;
            hash1 = ((PyBytesObject*)s1)->ob_shash;
            hash2 = ((PyBytesObject*)s2)->ob_shash;
            if (hash1 != hash2 && hash1 != -1 && hash2 != -1) {
                return (equals == Py_NE);
            }
#endif
            result = memcmp(ps1, ps2, (size_t)length);
            return (equals == Py_EQ) ? (result == 0) : (result != 0);
        }
    } else if ((s1 == Py_None) & PyBytes_CheckExact(s2)) {
        return (equals == Py_NE);
    } else if ((s2 == Py_None) & PyBytes_CheckExact(s1)) {
        return (equals == Py_NE);
    } else {
        int result;
        PyObject* py_result = PyObject_RichCompare(s1, s2, equals);
        if (!py_result)
            return -1;
        result = __Pyx_PyObject_IsTrue(py_result);
        Py_DECREF(py_result);
        return result;
    }
#endif
}

/* UnicodeEquals */
static CYTHON_INLINE int __Pyx_PyUnicode_Equals(PyObject* s1, PyObject* s2, int equals) {
#if CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_LIMITED_API || CYTHON_COMPILING_IN_GRAAL
    return PyObject_RichCompareBool(s1, s2, equals);
#else
    int s1_is_unicode, s2_is_unicode;
    if (s1 == s2) {
        goto return_eq;
    }
    s1_is_unicode = PyUnicode_CheckExact(s1);
    s2_is_unicode = PyUnicode_CheckExact(s2);
    if (s1_is_unicode & s2_is_unicode) {
        Py_ssize_t length, length2;
        int kind;
        void *data1, *data2;
        #if !CYTHON_COMPILING_IN_LIMITED_API
        if (unlikely(__Pyx_PyUnicode_READY(s1) < 0) || unlikely(__Pyx_PyUnicode_READY(s2) < 0))
            return -1;
        #endif
        length = __Pyx_PyUnicode_GET_LENGTH(s1);
        #if !CYTHON_ASSUME_SAFE_SIZE
        if (unlikely(length < 0)) return -1;
        #endif
        length2 = __Pyx_PyUnicode_GET_LENGTH(s2);
        #if !CYTHON_ASSUME_SAFE_SIZE
        if (unlikely(length2 < 0)) return -1;
        #endif
        if (length != length2) {
            goto return_ne;
        }
#if CYTHON_USE_UNICODE_INTERNALS
        {
            Py_hash_t hash1, hash2;
            hash1 = ((PyASCIIObject*)s1)->hash;
            hash2 = ((PyASCIIObject*)s2)->hash;
            if (hash1 != hash2 && hash1 != -1 && hash2 != -1) {
                goto return_ne;
            }
        }
#endif
        kind = __Pyx_PyUnicode_KIND(s1);
        if (kind != __Pyx_PyUnicode_KIND(s2)) {
            goto return_ne;
        }
        data1 = __Pyx_PyUnicode_DATA(s1);
        data2 = __Pyx_PyUnicode_DATA(s2);
        if (__Pyx_PyUnicode_READ(kind, data1, 0) != __Pyx_PyUnicode_READ(kind, data2, 0)) {
            goto return_ne;
        } else if (length == 1) {
            goto return_eq;
        } else {
            int result = memcmp(data1, data2, (size_t)(length * kind));
            return (equals == Py_EQ) ? (result == 0) : (result != 0);
        }
    } else if ((s1 == Py_None) & s2_is_unicode) {
        goto return_ne;
    } else if ((s2 == Py_None) & s1_is_unicode) {
        goto return_ne;
    } else {
        int result;
        PyObject* py_result = PyObject_RichCompare(s1, s2, equals);
        if (!py_result)
            return -1;
        result = __Pyx_PyObject_IsTrue(py_result);
        Py_DECREF(py_result);
        return result;
    }
return_eq:
    return (equals == Py_EQ);
return_ne:
    return (equals == Py_NE);
#endif
}

/* RaiseException */
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause) {
    PyObject* owned_instance = NULL;
    if (tb == Py_None) {
        tb = 0;
    } else if (tb && !PyTraceBack_Check(tb)) {
        PyErr_SetString(PyExc_TypeError,
            "raise: arg 3 must be a traceback or None");
        goto bad;
    }
    if (value == Py_None)
        value = 0;
    if (PyExceptionInstance_Check(type)) {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto bad;
        }
        value = type;
        type = (PyObject*) Py_TYPE(value);
    } else if (PyExceptionClass_Check(type)) {
        PyObject *instance_class = NULL;
        if (value && PyExceptionInstance_Check(value)) {
            instance_class = (PyObject*) Py_TYPE(value);
            if (instance_class != type) {
                int is_subclass = PyObject_IsSubclass(instance_class, type);
                if (!is_subclass) {
                    instance_class = NULL;
                } else if (unlikely(is_subclass == -1)) {
                    goto bad;
                } else {
                    type = instance_class;
                }
            }
        }
        if (!instance_class) {
            PyObject *args;
            if (!value)
                args = PyTuple_New(0);
            else if (PyTuple_Check(value)) {
                Py_INCREF(value);
                args = value;
            } else
                args = PyTuple_Pack(1, value);
            if (!args)
                goto bad;
            owned_instance = PyObject_Call(type, args, NULL);
            Py_DECREF(args);
            if (!owned_instance)
                goto bad;
            value = owned_instance;
            if (!PyExceptionInstance_Check(value)) {
                PyErr_Format(PyExc_TypeError,
                             "calling %R should have returned an instance of "
                             "BaseException, not %R",
                             type, Py_TYPE(value));
                goto bad;
            }
        }
    } else {
        PyErr_SetString(PyExc_TypeError,
            "raise: exception class must be a subclass of BaseException");
        goto bad;
    }
    if (cause) {
        PyObject *fixed_cause;
        if (cause == Py_None) {
            fixed_cause = NULL;
        } else if (PyExceptionClass_Check(cause)) {
            fixed_cause = PyObject_CallObject(cause, NULL);
            if (fixed_cause == NULL)
                goto bad;
        } else if (PyExceptionInstance_Check(cause)) {
            fixed_cause = cause;
            Py_INCREF(fixed_cause);
        } else {
            PyErr_SetString(PyExc_TypeError,
                            "exception causes must derive from "
                            "BaseException");
            goto bad;
        }
        PyException_SetCause(value, fixed_cause);
    }
    PyErr_SetObject(type, value);
    if (tb) {
#if PY_VERSION_HEX >= 0x030C00A6
        PyException_SetTraceback(value, tb);
#elif CYTHON_FAST_THREAD_STATE
        PyThreadState *tstate = __Pyx_PyThreadState_Current;
        PyObject* tmp_tb = tstate->curexc_traceback;
        if (tb != tmp_tb) {
            Py_INCREF(tb);
            tstate->curexc_traceback = tb;
            Py_XDECREF(tmp_tb);
        }
#else
        PyObject *tmp_type, *tmp_value, *tmp_tb;
        PyErr_Fetch(&tmp_type, &tmp_value, &tmp_tb);
        Py_INCREF(tb);
        PyErr_Restore(tmp_type, tmp_value, tb);
        Py_XDECREF(tmp_tb);
#endif
    }
bad:
    Py_XDECREF(owned_instance);
    return;
}

/* PyObjectVectorCallKwBuilder */
#if CYTHON_VECTORCALL
static int __Pyx_VectorcallBuilder_AddArg(PyObject *key, PyObject *value, PyObject *builder, PyObject **args, int n) {
    (void)__Pyx_PyObject_FastCallDict;
    if (__Pyx_PyTuple_SET_ITEM(builder, n, key) != (0)) return -1;
    Py_INCREF(key);
    args[n] = value;
    return 0;
}
CYTHON_UNUSED static int __Pyx_VectorcallBuilder_AddArg_Check(PyObject *key, PyObject *value, PyObject *builder, PyObject **args, int n) {
    (void)__Pyx_VectorcallBuilder_AddArgStr;
    if (unlikely(!PyUnicode_Check(key))) {
        PyErr_SetString(PyExc_TypeError, "keywords must be strings");
        return -1;
    }
    return __Pyx_VectorcallBuilder_AddArg(key, value, builder, args, n);
}
static int __Pyx_VectorcallBuilder_AddArgStr(const char *key, PyObject *value, PyObject *builder, PyObject **args, int n) {
    PyObject *pyKey = PyUnicode_FromString(key);
    if (!pyKey) return -1;
    return __Pyx_VectorcallBuilder_AddArg(pyKey, value, builder, args, n);
}
#else // CYTHON_VECTORCALL
CYTHON_UNUSED static int __Pyx_VectorcallBuilder_AddArg_Check(PyObject *key, PyObject *value, PyObject *builder, CYTHON_UNUSED PyObject **args, CYTHON_UNUSED int n) {
    if (unlikely(!PyUnicode_Check(key))) {
        PyErr_SetString(PyExc_TypeError, "keywords must be strings");
        return -1;
    }
    return PyDict_SetItem(builder, key, value);
}
#endif

/* HasAttr */
#if __PYX_LIMITED_VERSION_HEX < 0x030d0000
static CYTHON_INLINE int __Pyx_HasAttr(PyObject *o, PyObject *n) {
    PyObject *r;
    if (unlikely(!PyUnicode_Check(n))) {
        PyErr_SetString(PyExc_TypeError,
                        "hasattr(): attribute name must be string");
        return -1;
    }
    r = __Pyx_PyObject_GetAttrStrNoError(o, n);
    if (!r) {
        return (unlikely(PyErr_Occurred())) ? -1 : 0;
    } else {
        Py_DECREF(r);
        return 1;
    }
}
#endif

/* PyObjectSetAttrStr */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE int __Pyx_PyObject_SetAttrStr(PyObject* obj, PyObject* attr_name, PyObject* value) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_setattro))
        return tp->tp_setattro(obj, attr_name, value);
    return PyObject_SetAttr(obj, attr_name, value);
}
#endif

/* TupleAndListFromArray */
#if !CYTHON_COMPILING_IN_CPYTHON && CYTHON_METH_FASTCALL
static CYTHON_INLINE PyObject *
__Pyx_PyTuple_FromArray(PyObject *const *src, Py_ssize_t n)
{
    PyObject *res;
    Py_ssize_t i;
    if (n <= 0) {
        return __Pyx_NewRef(__pyx_mstate_global->__pyx_empty_tuple);
    }
    res = PyTuple_New(n);
    if (unlikely(res == NULL)) return NULL;
    for (i = 0; i < n; i++) {
        if (unlikely(__Pyx_PyTuple_SET_ITEM(res, i, src[i]) < (0))) {
            Py_DECREF(res);
            return NULL;
        }
        Py_INCREF(src[i]);
    }
    return res;
}
#elif CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE void __Pyx_copy_object_array(PyObject *const *CYTHON_RESTRICT src, PyObject** CYTHON_RESTRICT dest, Py_ssize_t length) {
    PyObject *v;
    Py_ssize_t i;
    for (i = 0; i < length; i++) {
        v = dest[i] = src[i];
        Py_INCREF(v);
    }
}
static CYTHON_INLINE PyObject *
__Pyx_PyTuple_FromArray(PyObject *const *src, Py_ssize_t n)
{
    PyObject *res;
    if (n <= 0) {
        return __Pyx_NewRef(__pyx_mstate_global->__pyx_empty_tuple);
    }
    res = PyTuple_New(n);
    if (unlikely(res == NULL)) return NULL;
    __Pyx_copy_object_array(src, ((PyTupleObject*)res)->ob_item, n);
    return res;
}
static CYTHON_INLINE PyObject *
__Pyx_PyList_FromArray(PyObject *const *src, Py_ssize_t n)
{
    PyObject *res;
    if (n <= 0) {
        return PyList_New(0);
    }
    res = PyList_New(n);
    if (unlikely(res == NULL)) return NULL;
    __Pyx_copy_object_array(src, ((PyListObject*)res)->ob_item, n);
    return res;
}
#endif

/* fastcall */
#if CYTHON_METH_FASTCALL
static CYTHON_INLINE PyObject * __Pyx_GetKwValue_FASTCALL(PyObject *kwnames, PyObject *const *kwvalues, PyObject *s)
{
    Py_ssize_t i, n = __Pyx_PyTuple_GET_SIZE(kwnames);
    #if !CYTHON_ASSUME_SAFE_SIZE
    if (unlikely(n == -1)) return NULL;
    #endif
    for (i = 0; i < n; i++)
    {
        PyObject *namei = __Pyx_PyTuple_GET_ITEM(kwnames, i);
        #if !CYTHON_ASSUME_SAFE_MACROS
        if (unlikely(!namei)) return NULL;
        #endif
        if (s == namei) return kwvalues[i];
    }
    for (i = 0; i < n; i++)
    {
        PyObject *namei = __Pyx_PyTuple_GET_ITEM(kwnames, i);
        #if !CYTHON_ASSUME_SAFE_MACROS
        if (unlikely(!namei)) return NULL;
        #endif
        int eq = __Pyx_PyUnicode_Equals(s, namei, Py_EQ);
        if (unlikely(eq != 0)) {
            if (unlikely(eq < 0)) return NULL;
            return kwvalues[i];
        }
    }
    return NULL;
}
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030d0000 || CYTHON_COMPILING_IN_LIMITED_API
CYTHON_UNUSED static PyObject *__Pyx_KwargsAsDict_FASTCALL(PyObject *kwnames, PyObject *const *kwvalues) {
    Py_ssize_t i, nkwargs;
    PyObject *dict;
#if !CYTHON_ASSUME_SAFE_SIZE
    nkwargs = PyTuple_Size(kwnames);
    if (unlikely(nkwargs < 0)) return NULL;
#else
    nkwargs = PyTuple_GET_SIZE(kwnames);
#endif
    dict = PyDict_New();
    if (unlikely(!dict))
        return NULL;
    for (i=0; i<nkwargs; i++) {
#if !CYTHON_ASSUME_SAFE_MACROS
        PyObject *key = PyTuple_GetItem(kwnames, i);
        if (!key) goto bad;
#else
        PyObject *key = PyTuple_GET_ITEM(kwnames, i);
#endif
        if (unlikely(PyDict_SetItem(dict, key, kwvalues[i]) < 0))
            goto bad;
    }
    return dict;
bad:
    Py_DECREF(dict);
    return NULL;
}
#endif
#endif

/* RaiseDoubleKeywords */
static void __Pyx_RaiseDoubleKeywordsError(
    const char* func_name,
    PyObject* kw_name)
{
    PyErr_Format(PyExc_TypeError,
        "%s() got multiple values for keyword argument '%U'", func_name, kw_name);
}

/* UnpackUnboundCMethod */
#if CYTHON_COMPILING_IN_LIMITED_API && __PYX_LIMITED_VERSION_HEX < 0x030C0000
static PyObject *__Pyx_SelflessCall(PyObject *method, PyObject *args, PyObject *kwargs) {
    PyObject *result;
    PyObject *selfless_args = PyTuple_GetSlice(args, 1, PyTuple_Size(args));
    if (unlikely(!selfless_args)) return NULL;
    result = PyObject_Call(method, selfless_args, kwargs);
    Py_DECREF(selfless_args);
    return result;
}
#elif CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x03090000
static PyObject *__Pyx_SelflessCall(PyObject *method, PyObject **args, Py_ssize_t nargs, PyObject *kwnames) {
        return _PyObject_Vectorcall
            (method, args ? args+1 : NULL, nargs ? nargs-1 : 0, kwnames);
}
#else
static PyObject *__Pyx_SelflessCall(PyObject *method, PyObject *const *args, Py_ssize_t nargs, PyObject *kwnames) {
    return
#if PY_VERSION_HEX < 0x03090000
    _PyObject_Vectorcall
#else
    PyObject_Vectorcall
#endif
        (method, args ? args+1 : NULL, nargs ? (size_t) nargs-1 : 0, kwnames);
}
#endif
static PyMethodDef __Pyx_UnboundCMethod_Def = {
     "CythonUnboundCMethod",
     __PYX_REINTERPRET_FUNCION(PyCFunction, __Pyx_SelflessCall),
#if CYTHON_COMPILING_IN_LIMITED_API && __PYX_LIMITED_VERSION_HEX < 0x030C0000
     METH_VARARGS | METH_KEYWORDS,
#else
     METH_FASTCALL | METH_KEYWORDS,
#endif
     NULL
};
static int __Pyx_TryUnpackUnboundCMethod(__Pyx_CachedCFunction* target) {
    PyObject *method, *result=NULL;
    method = __Pyx_PyObject_GetAttrStr(target->type, *target->method_name);
    if (unlikely(!method))
        return -1;
    result = method;
#if CYTHON_COMPILING_IN_CPYTHON
    if (likely(__Pyx_TypeCheck(method, &PyMethodDescr_Type)))
    {
        PyMethodDescrObject *descr = (PyMethodDescrObject*) method;
        target->func = descr->d_method->ml_meth;
        target->flag = descr->d_method->ml_flags & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_STACKLESS);
    } else
#endif
#if CYTHON_COMPILING_IN_PYPY
#else
    if (PyCFunction_Check(method))
#endif
    {
        PyObject *self;
        int self_found;
#if CYTHON_COMPILING_IN_LIMITED_API || CYTHON_COMPILING_IN_PYPY
        self = PyObject_GetAttrString(method, "__self__");
        if (!self) {
            PyErr_Clear();
        }
#else
        self = PyCFunction_GET_SELF(method);
#endif
        self_found = (self && self != Py_None);
#if CYTHON_COMPILING_IN_LIMITED_API || CYTHON_COMPILING_IN_PYPY
        Py_XDECREF(self);
#endif
        if (self_found) {
            PyObject *unbound_method = PyCFunction_New(&__Pyx_UnboundCMethod_Def, method);
            if (unlikely(!unbound_method)) return -1;
            Py_DECREF(method);
            result = unbound_method;
        }
    }
#if !CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
    if (unlikely(target->method)) {
        Py_DECREF(result);
    } else
#endif
    target->method = result;
    return 0;
}

/* CallUnboundCMethod2 */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject *__Pyx_CallUnboundCMethod2(__Pyx_CachedCFunction *cfunc, PyObject *self, PyObject *arg1, PyObject *arg2) {
    int was_initialized = __Pyx_CachedCFunction_GetAndSetInitializing(cfunc);
    if (likely(was_initialized == 2 && cfunc->func)) {
        PyObject *args[2] = {arg1, arg2};
        if (cfunc->flag == METH_FASTCALL) {
            return __Pyx_CallCFunctionFast(cfunc, self, args, 2);
        }
        if (cfunc->flag == (METH_FASTCALL | METH_KEYWORDS))
            return __Pyx_CallCFunctionFastWithKeywords(cfunc, self, args, 2, NULL);
    }
#if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
    else if (unlikely(was_initialized == 1)) {
        __Pyx_CachedCFunction tmp_cfunc = {
#ifndef __cplusplus
            0
#endif
        };
        tmp_cfunc.type = cfunc->type;
        tmp_cfunc.method_name = cfunc->method_name;
        return __Pyx__CallUnboundCMethod2(&tmp_cfunc, self, arg1, arg2);
    }
#endif
    PyObject *result = __Pyx__CallUnboundCMethod2(cfunc, self, arg1, arg2);
    __Pyx_CachedCFunction_SetFinishedInitializing(cfunc);
    return result;
}
#endif
static PyObject* __Pyx__CallUnboundCMethod2(__Pyx_CachedCFunction* cfunc, PyObject* self, PyObject* arg1, PyObject* arg2){
    if (unlikely(!cfunc->func && !cfunc->method) && unlikely(__Pyx_TryUnpackUnboundCMethod(cfunc) < 0)) return NULL;
#if CYTHON_COMPILING_IN_CPYTHON
    if (cfunc->func && (cfunc->flag & METH_VARARGS)) {
        PyObject *result = NULL;
        PyObject *args = PyTuple_New(2);
        if (unlikely(!args)) return NULL;
        Py_INCREF(arg1);
        PyTuple_SET_ITEM(args, 0, arg1);
        Py_INCREF(arg2);
        PyTuple_SET_ITEM(args, 1, arg2);
        if (cfunc->flag & METH_KEYWORDS)
            result = __Pyx_CallCFunctionWithKeywords(cfunc, self, args, NULL);
        else
            result = __Pyx_CallCFunction(cfunc, self, args);
        Py_DECREF(args);
        return result;
    }
#endif
    {
        PyObject *args[4] = {NULL, self, arg1, arg2};
        return __Pyx_PyObject_FastCall(cfunc->method, args+1, 3 | __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET);
    }
}

/* ParseKeywords */
static int __Pyx_ValidateDuplicatePosArgs(
    PyObject *kwds,
    PyObject ** const argnames[],
    PyObject ** const *first_kw_arg,
    const char* function_name)
{
    PyObject ** const *name = argnames;
    while (name != first_kw_arg) {
        PyObject *key = **name;
        int found = PyDict_Contains(kwds, key);
        if (unlikely(found)) {
            if (found == 1) __Pyx_RaiseDoubleKeywordsError(function_name, key);
            goto bad;
        }
        name++;
    }
    return 0;
bad:
    return -1;
}
#if CYTHON_USE_UNICODE_INTERNALS
static CYTHON_INLINE int __Pyx_UnicodeKeywordsEqual(PyObject *s1, PyObject *s2) {
    int kind;
    Py_ssize_t len = PyUnicode_GET_LENGTH(s1);
    if (len != PyUnicode_GET_LENGTH(s2)) return 0;
    kind = PyUnicode_KIND(s1);
    if (kind != PyUnicode_KIND(s2)) return 0;
    const void *data1 = PyUnicode_DATA(s1);
    const void *data2 = PyUnicode_DATA(s2);
    return (memcmp(data1, data2, (size_t) len * (size_t) kind) == 0);
}
#endif
static int __Pyx_MatchKeywordArg_str(
    PyObject *key,
    PyObject ** const argnames[],
    PyObject ** const *first_kw_arg,
    size_t *index_found,
    const char *function_name)
{
    PyObject ** const *name;
    #if CYTHON_USE_UNICODE_INTERNALS
    Py_hash_t key_hash = ((PyASCIIObject*)key)->hash;
    if (unlikely(key_hash == -1)) {
        key_hash = PyObject_Hash(key);
        if (unlikely(key_hash == -1))
            goto bad;
    }
    #endif
    name = first_kw_arg;
    while (*name) {
        PyObject *name_str = **name;
        #if CYTHON_USE_UNICODE_INTERNALS
        if (key_hash == ((PyASCIIObject*)name_str)->hash && __Pyx_UnicodeKeywordsEqual(name_str, key)) {
            *index_found = (size_t) (name - argnames);
            return 1;
        }
        #else
        #if CYTHON_ASSUME_SAFE_SIZE
        if (PyUnicode_GET_LENGTH(name_str) == PyUnicode_GET_LENGTH(key))
        #endif
        {
            int cmp = PyUnicode_Compare(name_str, key);
            if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
            if (cmp == 0) {
                *index_found = (size_t) (name - argnames);
                return 1;
            }
        }
        #endif
        name++;
    }
    name = argnames;
    while (name != first_kw_arg) {
        PyObject *name_str = **name;
        #if CYTHON_USE_UNICODE_INTERNALS
        if (unlikely(key_hash == ((PyASCIIObject*)name_str)->hash)) {
            if (__Pyx_UnicodeKeywordsEqual(name_str, key))
                goto arg_passed_twice;
        }
        #else
        #if CYTHON_ASSUME_SAFE_SIZE
        if (PyUnicode_GET_LENGTH(name_str) == PyUnicode_GET_LENGTH(key))
        #endif
        {
            if (unlikely(name_str == key)) goto arg_passed_twice;
            int cmp = PyUnicode_Compare(name_str, key);
            if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
            if (cmp == 0) goto arg_passed_twice;
        }
        #endif
        name++;
    }
    return 0;
arg_passed_twice:
    __Pyx_RaiseDoubleKeywordsError(function_name, key);
    goto bad;
bad:
    return -1;
}
static int __Pyx_MatchKeywordArg_nostr(
    PyObject *key,
    PyObject ** const argnames[],
    PyObject ** const *first_kw_arg,
    size_t *index_found,
    const char *function_name)
{
    PyObject ** const *name;
    if (unlikely(!PyUnicode_Check(key))) goto invalid_keyword_type;
    name = first_kw_arg;
    while (*name) {
        int cmp = PyObject_RichCompareBool(**name, key, Py_EQ);
        if (cmp == 1) {
            *index_found = (size_t) (name - argnames);
            return 1;
        }
        if (unlikely(cmp == -1)) goto bad;
        name++;
    }
    name = argnames;
    while (name != first_kw_arg) {
        int cmp = PyObject_RichCompareBool(**name, key, Py_EQ);
        if (unlikely(cmp != 0)) {
            if (cmp == 1) goto arg_passed_twice;
            else goto bad;
        }
        name++;
    }
    return 0;
arg_passed_twice:
    __Pyx_RaiseDoubleKeywordsError(function_name, key);
    goto bad;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    goto bad;
bad:
    return -1;
}
static CYTHON_INLINE int __Pyx_MatchKeywordArg(
    PyObject *key,
    PyObject ** const argnames[],
    PyObject ** const *first_kw_arg,
    size_t *index_found,
    const char *function_name)
{
    return likely(PyUnicode_CheckExact(key)) ?
        __Pyx_MatchKeywordArg_str(key, argnames, first_kw_arg, index_found, function_name) :
        __Pyx_MatchKeywordArg_nostr(key, argnames, first_kw_arg, index_found, function_name);
}
static void __Pyx_RejectUnknownKeyword(
    PyObject *kwds,
    PyObject ** const argnames[],
    PyObject ** const *first_kw_arg,
    const char *function_name)
{
    Py_ssize_t pos = 0;
    PyObject *key = NULL;
    __Pyx_BEGIN_CRITICAL_SECTION(kwds);
    while (PyDict_Next(kwds, &pos, &key, NULL)) {
        PyObject** const *name = first_kw_arg;
        while (*name && (**name != key)) name++;
        if (!*name) {
            #if CYTHON_AVOID_BORROWED_REFS
            Py_INCREF(key);
            #endif
            size_t index_found = 0;
            int cmp = __Pyx_MatchKeywordArg(key, argnames, first_kw_arg, &index_found, function_name);
            if (cmp != 1) {
                if (cmp == 0) {
                    PyErr_Format(PyExc_TypeError,
                        "%s() got an unexpected keyword argument '%U'",
                        function_name, key);
                }
                #if CYTHON_AVOID_BORROWED_REFS
                Py_DECREF(key);
                #endif
                break;
            }
            #if CYTHON_AVOID_BORROWED_REFS
            Py_DECREF(key);
            #endif
        }
    }
    __Pyx_END_CRITICAL_SECTION();
    assert(PyErr_Occurred());
}
static int __Pyx_ParseKeywordDict(
    PyObject *kwds,
    PyObject ** const argnames[],
    PyObject *values[],
    Py_ssize_t num_pos_args,
    Py_ssize_t num_kwargs,
    const char* function_name,
    int ignore_unknown_kwargs)
{
    PyObject** const *name;
    PyObject** const *first_kw_arg = argnames + num_pos_args;
    Py_ssize_t extracted = 0;
#if !CYTHON_COMPILING_IN_PYPY || defined(PyArg_ValidateKeywordArguments)
    if (unlikely(!PyArg_ValidateKeywordArguments(kwds))) return -1;
#endif
    name = first_kw_arg;
    while (*name && num_kwargs > extracted) {
        PyObject * key = **name;
        PyObject *value;
        int found = 0;
        #if __PYX_LIMITED_VERSION_HEX >= 0x030d0000
        found = PyDict_GetItemRef(kwds, key, &value);
        #else
        value = PyDict_GetItemWithError(kwds, key);
        if (value) {
            Py_INCREF(value);
            found = 1;
        } else {
            if (unlikely(PyErr_Occurred())) goto bad;
        }
        #endif
        if (found) {
            if (unlikely(found < 0)) goto bad;
            values[name-argnames] = value;
            extracted++;
        }
        name++;
    }
    if (num_kwargs > extracted) {
        if (ignore_unknown_kwargs) {
            if (unlikely(__Pyx_ValidateDuplicatePosArgs(kwds, argnames, first_kw_arg, function_name) == -1))
                goto bad;
        } else {
            __Pyx_RejectUnknownKeyword(kwds, argnames, first_kw_arg, function_name);
            goto bad;
        }
    }
    return 0;
bad:
    return -1;
}
static int __Pyx_ParseKeywordDictToDict(
    PyObject *kwds,
    PyObject ** const argnames[],
    PyObject *kwds2,
    PyObject *values[],
    Py_ssize_t num_pos_args,
    const char* function_name)
{
    PyObject** const *name;
    PyObject** const *first_kw_arg = argnames + num_pos_args;
    Py_ssize_t len;
#if !CYTHON_COMPILING_IN_PYPY || defined(PyArg_ValidateKeywordArguments)
    if (unlikely(!PyArg_ValidateKeywordArguments(kwds))) return -1;
#endif
    if (PyDict_Update(kwds2, kwds) < 0) goto bad;
    name = first_kw_arg;
    while (*name) {
        PyObject *key = **name;
        PyObject *value;
#if !CYTHON_COMPILING_IN_LIMITED_API && (PY_VERSION_HEX >= 0x030d00A2 || defined(PyDict_Pop))
        int found = PyDict_Pop(kwds2, key, &value);
        if (found) {
            if (unlikely(found < 0)) goto bad;
            values[name-argnames] = value;
        }
#elif __PYX_LIMITED_VERSION_HEX >= 0x030d0000
        int found = PyDict_GetItemRef(kwds2, key, &value);
        if (found) {
            if (unlikely(found < 0)) goto bad;
            values[name-argnames] = value;
            if (unlikely(PyDict_DelItem(kwds2, key) < 0)) goto bad;
        }
#else
    #if CYTHON_COMPILING_IN_CPYTHON
        value = _PyDict_Pop(kwds2, key, kwds2);
    #else
        value = __Pyx_CallUnboundCMethod2(&__pyx_mstate_global->__pyx_umethod_PyDict_Type_pop, kwds2, key, kwds2);
    #endif
        if (value == kwds2) {
            Py_DECREF(value);
        } else {
            if (unlikely(!value)) goto bad;
            values[name-argnames] = value;
        }
#endif
        name++;
    }
    len = PyDict_Size(kwds2);
    if (len > 0) {
        return __Pyx_ValidateDuplicatePosArgs(kwds, argnames, first_kw_arg, function_name);
    } else if (unlikely(len == -1)) {
        goto bad;
    }
    return 0;
bad:
    return -1;
}
static int __Pyx_ParseKeywordsTuple(
    PyObject *kwds,
    PyObject * const *kwvalues,
    PyObject ** const argnames[],
    PyObject *kwds2,
    PyObject *values[],
    Py_ssize_t num_pos_args,
    Py_ssize_t num_kwargs,
    const char* function_name,
    int ignore_unknown_kwargs)
{
    PyObject *key = NULL;
    PyObject** const * name;
    PyObject** const *first_kw_arg = argnames + num_pos_args;
    for (Py_ssize_t pos = 0; pos < num_kwargs; pos++) {
#if CYTHON_AVOID_BORROWED_REFS
        key = __Pyx_PySequence_ITEM(kwds, pos);
#else
        key = __Pyx_PyTuple_GET_ITEM(kwds, pos);
#endif
#if !CYTHON_ASSUME_SAFE_MACROS
        if (unlikely(!key)) goto bad;
#endif
        name = first_kw_arg;
        while (*name && (**name != key)) name++;
        if (*name) {
            PyObject *value = kwvalues[pos];
            values[name-argnames] = __Pyx_NewRef(value);
        } else {
            size_t index_found = 0;
            int cmp = __Pyx_MatchKeywordArg(key, argnames, first_kw_arg, &index_found, function_name);
            if (cmp == 1) {
                PyObject *value = kwvalues[pos];
                values[index_found] = __Pyx_NewRef(value);
            } else {
                if (unlikely(cmp == -1)) goto bad;
                if (kwds2) {
                    PyObject *value = kwvalues[pos];
                    if (unlikely(PyDict_SetItem(kwds2, key, value))) goto bad;
                } else if (!ignore_unknown_kwargs) {
                    goto invalid_keyword;
                }
            }
        }
        #if CYTHON_AVOID_BORROWED_REFS
        Py_DECREF(key);
        key = NULL;
        #endif
    }
    return 0;
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    goto bad;
bad:
    #if CYTHON_AVOID_BORROWED_REFS
    Py_XDECREF(key);
    #endif
    return -1;
}
static int __Pyx_ParseKeywords(
    PyObject *kwds,
    PyObject * const *kwvalues,
    PyObject ** const argnames[],
    PyObject *kwds2,
    PyObject *values[],
    Py_ssize_t num_pos_args,
    Py_ssize_t num_kwargs,
    const char* function_name,
    int ignore_unknown_kwargs)
{
    if (CYTHON_METH_FASTCALL && likely(PyTuple_Check(kwds)))
        return __Pyx_ParseKeywordsTuple(kwds, kwvalues, argnames, kwds2, values, num_pos_args, num_kwargs, function_name, ignore_unknown_kwargs);
    else if (kwds2)
        return __Pyx_ParseKeywordDictToDict(kwds, argnames, kwds2, values, num_pos_args, function_name);
    else
        return __Pyx_ParseKeywordDict(kwds, argnames, values, num_pos_args, num_kwargs, function_name, ignore_unknown_kwargs);
}

/* RaiseArgTupleInvalid */
static void __Pyx_RaiseArgtupleInvalid(
    const char* func_name,
    int exact,
    Py_ssize_t num_min,
    Py_ssize_t num_max,
    Py_ssize_t num_found)
{
    Py_ssize_t num_expected;
    const char *more_or_less;
    if (num_found < num_min) {
        num_expected = num_min;
        more_or_less = "at least";
    } else {
        num_expected = num_max;
        more_or_less = "at most";
    }
    if (exact) {
        more_or_less = "exactly";
    }
    PyErr_Format(PyExc_TypeError,
                 "%.200s() takes %.8s %" CYTHON_FORMAT_SSIZE_T "d positional argument%.1s (%" CYTHON_FORMAT_SSIZE_T "d given)",
                 func_name, more_or_less, num_expected,
                 (num_expected == 1) ? "" : "s", num_found);
}

/* DictGetItem */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject *__Pyx_PyDict_GetItem(PyObject *d, PyObject* key) {
    PyObject *value;
    if (unlikely(__Pyx_PyDict_GetItemRef(d, key, &value) == 0)) { // no value, no error
        if (unlikely(PyTuple_Check(key))) {
            PyObject* args = PyTuple_Pack(1, key);
            if (likely(args)) {
                PyErr_SetObject(PyExc_KeyError, args);
                Py_DECREF(args);
            }
        } else {
            PyErr_SetObject(PyExc_KeyError, key);
        }
    }
    return value;
}
#endif

/* PyObjectFastCallMethod */
#if !CYTHON_VECTORCALL || PY_VERSION_HEX < 0x03090000
static PyObject *__Pyx_PyObject_FastCallMethod(PyObject *name, PyObject *const *args, size_t nargsf) {
    PyObject *result;
    PyObject *attr = PyObject_GetAttr(args[0], name);
    if (unlikely(!attr))
        return NULL;
    result = __Pyx_PyObject_FastCall(attr, args+1, nargsf - 1);
    Py_DECREF(attr);
    return result;
}
#endif

/* RaiseTooManyValuesToUnpack */
static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected) {
    PyErr_Format(PyExc_ValueError,
                 "too many values to unpack (expected %" CYTHON_FORMAT_SSIZE_T "d)", expected);
}

/* RaiseNeedMoreValuesToUnpack */
static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index) {
    PyErr_Format(PyExc_ValueError,
                 "need more than %" CYTHON_FORMAT_SSIZE_T "d value%.1s to unpack",
                 index, (index == 1) ? "" : "s");
}

/* IterFinish */
static CYTHON_INLINE int __Pyx_IterFinish(void) {
    PyObject* exc_type;
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    exc_type = __Pyx_PyErr_CurrentExceptionType();
    if (unlikely(exc_type)) {
        if (unlikely(!__Pyx_PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration)))
            return -1;
        __Pyx_PyErr_Clear();
        return 0;
    }
    return 0;
}

/* UnpackItemEndCheck */
static int __Pyx_IternextUnpackEndCheck(PyObject *retval, Py_ssize_t expected) {
    if (unlikely(retval)) {
        Py_DECREF(retval);
        __Pyx_RaiseTooManyValuesError(expected);
        return -1;
    }
    return __Pyx_IterFinish();
}

/* RaiseUnexpectedTypeError */
static int
__Pyx_RaiseUnexpectedTypeError(const char *expected, PyObject *obj)
{
    __Pyx_TypeName obj_type_name = __Pyx_PyType_GetFullyQualifiedName(Py_TYPE(obj));
    PyErr_Format(PyExc_TypeError, "Expected %s, got " __Pyx_FMT_TYPENAME,
                 expected, obj_type_name);
    __Pyx_DECREF_TypeName(obj_type_name);
    return 0;
}

/* GetItemInt */
static PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j) {
    PyObject *r;
    if (unlikely(!j)) return NULL;
    r = PyObject_GetItem(o, j);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && CYTHON_ASSUME_SAFE_SIZE && !CYTHON_AVOID_BORROWED_REFS && !CYTHON_AVOID_THREAD_UNSAFE_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyList_GET_SIZE(o);
    }
    if ((!boundscheck) || likely(__Pyx_is_valid_index(wrapped_i, PyList_GET_SIZE(o)))) {
        PyObject *r = PyList_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyLong_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && CYTHON_ASSUME_SAFE_SIZE && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyTuple_GET_SIZE(o);
    }
    if ((!boundscheck) || likely(__Pyx_is_valid_index(wrapped_i, PyTuple_GET_SIZE(o)))) {
        PyObject *r = PyTuple_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyLong_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i, int is_list,
                                                     CYTHON_NCP_UNUSED int wraparound,
                                                     CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && CYTHON_ASSUME_SAFE_SIZE && !CYTHON_AVOID_BORROWED_REFS && CYTHON_USE_TYPE_SLOTS
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyList_GET_SIZE(o);
        if ((!boundscheck) || (likely(__Pyx_is_valid_index(n, PyList_GET_SIZE(o))))) {
            return __Pyx_PyList_GetItemRef(o, n);
        }
    }
    else if (PyTuple_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyTuple_GET_SIZE(o);
        if ((!boundscheck) || likely(__Pyx_is_valid_index(n, PyTuple_GET_SIZE(o)))) {
            PyObject *r = PyTuple_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    } else {
        PyMappingMethods *mm = Py_TYPE(o)->tp_as_mapping;
        PySequenceMethods *sm = Py_TYPE(o)->tp_as_sequence;
        if (mm && mm->mp_subscript) {
            PyObject *r, *key = PyLong_FromSsize_t(i);
            if (unlikely(!key)) return NULL;
            r = mm->mp_subscript(o, key);
            Py_DECREF(key);
            return r;
        }
        if (likely(sm && sm->sq_item)) {
            if (wraparound && unlikely(i < 0) && likely(sm->sq_length)) {
                Py_ssize_t l = sm->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                        return NULL;
                    PyErr_Clear();
                }
            }
            return sm->sq_item(o, i);
        }
    }
#else
    if (is_list || !PyMapping_Check(o)) {
        return PySequence_GetItem(o, i);
    }
#endif
    return __Pyx_GetItemInt_Generic(o, PyLong_FromSsize_t(i));
}

/* SetItemInt */
static int __Pyx_SetItemInt_Generic(PyObject *o, PyObject *j, PyObject *v) {
    int r;
    if (unlikely(!j)) return -1;
    r = PyObject_SetItem(o, j, v);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE int __Pyx_SetItemInt_Fast(PyObject *o, Py_ssize_t i, PyObject *v, int is_list,
                                               CYTHON_NCP_UNUSED int wraparound, CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && CYTHON_ASSUME_SAFE_SIZE && !CYTHON_AVOID_BORROWED_REFS && CYTHON_USE_TYPE_SLOTS
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = (!wraparound) ? i : ((likely(i >= 0)) ? i : i + PyList_GET_SIZE(o));
        if ((!boundscheck) || likely(__Pyx_is_valid_index(n, PyList_GET_SIZE(o)))) {
            Py_INCREF(v);
#if CYTHON_AVOID_THREAD_UNSAFE_BORROWED_REFS
            PyList_SetItem(o, n, v);
#else
            PyObject* old = PyList_GET_ITEM(o, n);
            PyList_SET_ITEM(o, n, v);
            Py_DECREF(old);
#endif
            return 1;
        }
    } else {
        PyMappingMethods *mm = Py_TYPE(o)->tp_as_mapping;
        PySequenceMethods *sm = Py_TYPE(o)->tp_as_sequence;
        if (mm && mm->mp_ass_subscript) {
            int r;
            PyObject *key = PyLong_FromSsize_t(i);
            if (unlikely(!key)) return -1;
            r = mm->mp_ass_subscript(o, key, v);
            Py_DECREF(key);
            return r;
        }
        if (likely(sm && sm->sq_ass_item)) {
            if (wraparound && unlikely(i < 0) && likely(sm->sq_length)) {
                Py_ssize_t l = sm->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                        return -1;
                    PyErr_Clear();
                }
            }
            return sm->sq_ass_item(o, i, v);
        }
    }
#else
    if (is_list || !PyMapping_Check(o))
    {
        return PySequence_SetItem(o, i, v);
    }
#endif
    return __Pyx_SetItemInt_Generic(o, PyLong_FromSsize_t(i), v);
}

/* GetException */
#if CYTHON_FAST_THREAD_STATE
static int __Pyx__GetException(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb)
#else
static int __Pyx_GetException(PyObject **type, PyObject **value, PyObject **tb)
#endif
{
    PyObject *local_type = NULL, *local_value, *local_tb = NULL;
#if CYTHON_FAST_THREAD_STATE
    PyObject *tmp_type, *tmp_value, *tmp_tb;
  #if PY_VERSION_HEX >= 0x030C0000
    local_value = tstate->current_exception;
    tstate->current_exception = 0;
  #else
    local_type = tstate->curexc_type;
    local_value = tstate->curexc_value;
    local_tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
  #endif
#elif __PYX_LIMITED_VERSION_HEX > 0x030C0000
    local_value = PyErr_GetRaisedException();
#else
    PyErr_Fetch(&local_type, &local_value, &local_tb);
#endif
#if __PYX_LIMITED_VERSION_HEX > 0x030C0000
    if (likely(local_value)) {
        local_type = (PyObject*) Py_TYPE(local_value);
        Py_INCREF(local_type);
        local_tb = PyException_GetTraceback(local_value);
    }
#else
    PyErr_NormalizeException(&local_type, &local_value, &local_tb);
#if CYTHON_FAST_THREAD_STATE
    if (unlikely(tstate->curexc_type))
#else
    if (unlikely(PyErr_Occurred()))
#endif
        goto bad;
    if (local_tb) {
        if (unlikely(PyException_SetTraceback(local_value, local_tb) < 0))
            goto bad;
    }
#endif // __PYX_LIMITED_VERSION_HEX > 0x030C0000
    Py_XINCREF(local_tb);
    Py_XINCREF(local_type);
    Py_XINCREF(local_value);
    *type = local_type;
    *value = local_value;
    *tb = local_tb;
#if CYTHON_FAST_THREAD_STATE
    #if CYTHON_USE_EXC_INFO_STACK
    {
        _PyErr_StackItem *exc_info = tstate->exc_info;
      #if PY_VERSION_HEX >= 0x030B00a4
        tmp_value = exc_info->exc_value;
        exc_info->exc_value = local_value;
        tmp_type = NULL;
        tmp_tb = NULL;
        Py_XDECREF(local_type);
        Py_XDECREF(local_tb);
      #else
        tmp_type = exc_info->exc_type;
        tmp_value = exc_info->exc_value;
        tmp_tb = exc_info->exc_traceback;
        exc_info->exc_type = local_type;
        exc_info->exc_value = local_value;
        exc_info->exc_traceback = local_tb;
      #endif
    }
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = local_type;
    tstate->exc_value = local_value;
    tstate->exc_traceback = local_tb;
    #endif
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
#elif __PYX_LIMITED_VERSION_HEX >= 0x030b0000
    PyErr_SetHandledException(local_value);
    Py_XDECREF(local_value);
    Py_XDECREF(local_type);
    Py_XDECREF(local_tb);
#else
    PyErr_SetExcInfo(local_type, local_value, local_tb);
#endif
    return 0;
#if __PYX_LIMITED_VERSION_HEX <= 0x030C0000
bad:
    *type = 0;
    *value = 0;
    *tb = 0;
    Py_XDECREF(local_type);
    Py_XDECREF(local_value);
    Py_XDECREF(local_tb);
    return -1;
#endif
}

/* SwapException */
#if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSwap(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
  #if CYTHON_USE_EXC_INFO_STACK && PY_VERSION_HEX >= 0x030B00a4
    _PyErr_StackItem *exc_info = tstate->exc_info;
    tmp_value = exc_info->exc_value;
    exc_info->exc_value = *value;
    if (tmp_value == NULL || tmp_value == Py_None) {
        Py_XDECREF(tmp_value);
        tmp_value = NULL;
        tmp_type = NULL;
        tmp_tb = NULL;
    } else {
        tmp_type = (PyObject*) Py_TYPE(tmp_value);
        Py_INCREF(tmp_type);
        #if CYTHON_COMPILING_IN_CPYTHON
        tmp_tb = ((PyBaseExceptionObject*) tmp_value)->traceback;
        Py_XINCREF(tmp_tb);
        #else
        tmp_tb = PyException_GetTraceback(tmp_value);
        #endif
    }
  #elif CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = tstate->exc_info;
    tmp_type = exc_info->exc_type;
    tmp_value = exc_info->exc_value;
    tmp_tb = exc_info->exc_traceback;
    exc_info->exc_type = *type;
    exc_info->exc_value = *value;
    exc_info->exc_traceback = *tb;
  #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = *type;
    tstate->exc_value = *value;
    tstate->exc_traceback = *tb;
  #endif
    *type = tmp_type;
    *value = tmp_value;
    *tb = tmp_tb;
}
#else
static CYTHON_INLINE void __Pyx_ExceptionSwap(PyObject **type, PyObject **value, PyObject **tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    PyErr_GetExcInfo(&tmp_type, &tmp_value, &tmp_tb);
    PyErr_SetExcInfo(*type, *value, *tb);
    *type = tmp_type;
    *value = tmp_value;
    *tb = tmp_tb;
}
#endif

/* GetTopmostException */
#if CYTHON_USE_EXC_INFO_STACK && CYTHON_FAST_THREAD_STATE
static _PyErr_StackItem *
__Pyx_PyErr_GetTopmostException(PyThreadState *tstate)
{
    _PyErr_StackItem *exc_info = tstate->exc_info;
    while ((exc_info->exc_value == NULL || exc_info->exc_value == Py_None) &&
           exc_info->previous_item != NULL)
    {
        exc_info = exc_info->previous_item;
    }
    return exc_info;
}
#endif

/* SaveResetException */
#if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx__ExceptionSave(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
  #if CYTHON_USE_EXC_INFO_STACK && PY_VERSION_HEX >= 0x030B00a4
    _PyErr_StackItem *exc_info = __Pyx_PyErr_GetTopmostException(tstate);
    PyObject *exc_value = exc_info->exc_value;
    if (exc_value == NULL || exc_value == Py_None) {
        *value = NULL;
        *type = NULL;
        *tb = NULL;
    } else {
        *value = exc_value;
        Py_INCREF(*value);
        *type = (PyObject*) Py_TYPE(exc_value);
        Py_INCREF(*type);
        *tb = PyException_GetTraceback(exc_value);
    }
  #elif CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = __Pyx_PyErr_GetTopmostException(tstate);
    *type = exc_info->exc_type;
    *value = exc_info->exc_value;
    *tb = exc_info->exc_traceback;
    Py_XINCREF(*type);
    Py_XINCREF(*value);
    Py_XINCREF(*tb);
  #else
    *type = tstate->exc_type;
    *value = tstate->exc_value;
    *tb = tstate->exc_traceback;
    Py_XINCREF(*type);
    Py_XINCREF(*value);
    Py_XINCREF(*tb);
  #endif
}
static CYTHON_INLINE void __Pyx__ExceptionReset(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
  #if CYTHON_USE_EXC_INFO_STACK && PY_VERSION_HEX >= 0x030B00a4
    _PyErr_StackItem *exc_info = tstate->exc_info;
    PyObject *tmp_value = exc_info->exc_value;
    exc_info->exc_value = value;
    Py_XDECREF(tmp_value);
    Py_XDECREF(type);
    Py_XDECREF(tb);
  #else
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    #if CYTHON_USE_EXC_INFO_STACK
    _PyErr_StackItem *exc_info = tstate->exc_info;
    tmp_type = exc_info->exc_type;
    tmp_value = exc_info->exc_value;
    tmp_tb = exc_info->exc_traceback;
    exc_info->exc_type = type;
    exc_info->exc_value = value;
    exc_info->exc_traceback = tb;
    #else
    tmp_type = tstate->exc_type;
    tmp_value = tstate->exc_value;
    tmp_tb = tstate->exc_traceback;
    tstate->exc_type = type;
    tstate->exc_value = value;
    tstate->exc_traceback = tb;
    #endif
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
  #endif
}
#endif

/* WriteUnraisableException */
static void __Pyx_WriteUnraisable(const char *name, int clineno,
                                  int lineno, const char *filename,
                                  int full_traceback, int nogil) {
    PyObject *old_exc, *old_val, *old_tb;
    PyObject *ctx;
    __Pyx_PyThreadState_declare
    PyGILState_STATE state;
    if (nogil)
        state = PyGILState_Ensure();
    else state = (PyGILState_STATE)0;
    CYTHON_UNUSED_VAR(clineno);
    CYTHON_UNUSED_VAR(lineno);
    CYTHON_UNUSED_VAR(filename);
    CYTHON_MAYBE_UNUSED_VAR(nogil);
    __Pyx_PyThreadState_assign
    __Pyx_ErrFetch(&old_exc, &old_val, &old_tb);
    if (full_traceback) {
        Py_XINCREF(old_exc);
        Py_XINCREF(old_val);
        Py_XINCREF(old_tb);
        __Pyx_ErrRestore(old_exc, old_val, old_tb);
        PyErr_PrintEx(0);
    }
    ctx = PyUnicode_FromString(name);
    __Pyx_ErrRestore(old_exc, old_val, old_tb);
    if (!ctx) {
        PyErr_WriteUnraisable(Py_None);
    } else {
        PyErr_WriteUnraisable(ctx);
        Py_DECREF(ctx);
    }
    if (nogil)
        PyGILState_Release(state);
}

/* RejectKeywords */
static void __Pyx_RejectKeywords(const char* function_name, PyObject *kwds) {
    PyObject *key = NULL;
    if (CYTHON_METH_FASTCALL && likely(PyTuple_Check(kwds))) {
        key = __Pyx_PySequence_ITEM(kwds, 0);
    } else {
        Py_ssize_t pos = 0;
#if !CYTHON_COMPILING_IN_PYPY || defined(PyArg_ValidateKeywordArguments)
        if (unlikely(!PyArg_ValidateKeywordArguments(kwds))) return;
#endif
        PyDict_Next(kwds, &pos, &key, NULL);
        Py_INCREF(key);
    }
    if (likely(key)) {
        PyErr_Format(PyExc_TypeError,
            "%s() got an unexpected keyword argument '%U'",
            function_name, key);
        Py_DECREF(key);
    }
}

/* DivInt[int] */
static CYTHON_INLINE int __Pyx_div_int(int a, int b, int b_is_constant) {
    int q = a / b;
    int r = a - q*b;
    int adapt_python = (b_is_constant ?
        ((r != 0) & ((r < 0) ^ (b < 0))) :
        ((r != 0) & ((r ^ b) < 0))
    );
    return q - adapt_python;
}

/* ModInt[int] */
static CYTHON_INLINE int __Pyx_mod_int(int a, int b, int b_is_constant) {
    int r = a % b;
    int adapt_python = (b_is_constant ?
        ((r != 0) & ((r < 0) ^ (b < 0))) :
        ((r != 0) & ((r ^ b) < 0))
    );
    return r + adapt_python * b;
}

/* PyLongBinop */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_Fallback___Pyx_PyLong_AddObjC(PyObject *op1, PyObject *op2, int inplace) {
    return (inplace ? PyNumber_InPlaceAdd : PyNumber_Add)(op1, op2);
}
#if CYTHON_USE_PYLONG_INTERNALS
static PyObject* __Pyx_Unpacked___Pyx_PyLong_AddObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check) {
    CYTHON_MAYBE_UNUSED_VAR(inplace);
    CYTHON_UNUSED_VAR(zerodivision_check);
    const long b = intval;
    long a, x;
#ifdef HAVE_LONG_LONG
    const PY_LONG_LONG llb = intval;
    PY_LONG_LONG lla, llx;
#endif
    if (unlikely(__Pyx_PyLong_IsZero(op1))) {
        return __Pyx_NewRef(op2);
    }
    if (unlikely(!__Pyx_PyLong_CompactAsLong(op1, &a))) {
        const digit* digits = __Pyx_PyLong_Digits(op1);
        const Py_ssize_t size = __Pyx_PyLong_SignedDigitCount(op1);
        switch (size) {
            case -2:
                if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                    a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                    lla = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            case 2:
                if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                    a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                    lla = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            case -3:
                if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                    a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                    lla = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            case 3:
                if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                    a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                    lla = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            case -4:
                if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                    a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                    lla = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            case 4:
                if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                    a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                    lla = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            default: return PyLong_Type.tp_as_number->nb_add(op1, op2);
        }
    }
            x = a + b;
        return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
    long_long:
            llx = lla + llb;
        return PyLong_FromLongLong(llx);
#endif
    return __Pyx_Fallback___Pyx_PyLong_AddObjC(op1, op2, inplace);
    
    
}
#endif
static PyObject* __Pyx_Float___Pyx_PyLong_AddObjC(PyObject *float_val, long intval, int zerodivision_check) {
    CYTHON_UNUSED_VAR(zerodivision_check);
    const long b = intval;
    double a = __Pyx_PyFloat_AS_DOUBLE(float_val);
        double result;
        
        result = ((double)a) + (double)b;
        return PyFloat_FromDouble(result);
}
static CYTHON_INLINE PyObject* __Pyx_PyLong_AddObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check) {
    CYTHON_MAYBE_UNUSED_VAR(intval);
    CYTHON_UNUSED_VAR(zerodivision_check);
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        return __Pyx_Unpacked___Pyx_PyLong_AddObjC(op1, op2, intval, inplace, zerodivision_check);
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        return __Pyx_Float___Pyx_PyLong_AddObjC(op1, intval, zerodivision_check);
    }
    return __Pyx_Fallback___Pyx_PyLong_AddObjC(op1, op2, inplace);
}
#endif

/* ArgTypeTest */
static int __Pyx__ArgTypeTest(PyObject *obj, PyTypeObject *type, const char *name, int exact)
{
    __Pyx_TypeName type_name;
    __Pyx_TypeName obj_type_name;
    PyObject *extra_info = __pyx_mstate_global->__pyx_empty_unicode;
    int from_annotation_subclass = 0;
    if (unlikely(!type)) {
        PyErr_SetString(PyExc_SystemError, "Missing type object");
        return 0;
    }
    else if (!exact) {
        if (likely(__Pyx_TypeCheck(obj, type))) return 1;
    } else if (exact == 2) {
        if (__Pyx_TypeCheck(obj, type)) {
            from_annotation_subclass = 1;
            extra_info = __pyx_mstate_global->__pyx_kp_u_Note_that_Cython_is_deliberately;
        }
    }
    type_name = __Pyx_PyType_GetFullyQualifiedName(type);
    obj_type_name = __Pyx_PyType_GetFullyQualifiedName(Py_TYPE(obj));
    PyErr_Format(PyExc_TypeError,
        "Argument '%.200s' has incorrect type (expected " __Pyx_FMT_TYPENAME
        ", got " __Pyx_FMT_TYPENAME ")"
#if __PYX_LIMITED_VERSION_HEX < 0x030C0000
        "%s%U"
#endif
        , name, type_name, obj_type_name
#if __PYX_LIMITED_VERSION_HEX < 0x030C0000
        , (from_annotation_subclass ? ". " : ""), extra_info
#endif
        );
#if __PYX_LIMITED_VERSION_HEX >= 0x030C0000
    if (exact == 2 && from_annotation_subclass) {
        PyObject *res;
        PyObject *vargs[2];
        vargs[0] = PyErr_GetRaisedException();
        vargs[1] = extra_info;
        res = PyObject_VectorcallMethod(__pyx_mstate_global->__pyx_kp_u_add_note, vargs, 2, NULL);
        Py_XDECREF(res);
        PyErr_SetRaisedException(vargs[0]);
    }
#endif
    __Pyx_DECREF_TypeName(type_name);
    __Pyx_DECREF_TypeName(obj_type_name);
    return 0;
}

/* SliceObject */
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetSlice(PyObject* obj,
        Py_ssize_t cstart, Py_ssize_t cstop,
        PyObject** _py_start, PyObject** _py_stop, PyObject** _py_slice,
        int has_cstart, int has_cstop, CYTHON_UNUSED int wraparound) {
    __Pyx_TypeName obj_type_name;
#if CYTHON_USE_TYPE_SLOTS
    PyMappingMethods* mp = Py_TYPE(obj)->tp_as_mapping;
    if (likely(mp && mp->mp_subscript))
#endif
    {
        PyObject* result;
        PyObject *py_slice, *py_start, *py_stop;
        if (_py_slice) {
            py_slice = *_py_slice;
        } else {
            PyObject* owned_start = NULL;
            PyObject* owned_stop = NULL;
            if (_py_start) {
                py_start = *_py_start;
            } else {
                if (has_cstart) {
                    owned_start = py_start = PyLong_FromSsize_t(cstart);
                    if (unlikely(!py_start)) goto bad;
                } else
                    py_start = Py_None;
            }
            if (_py_stop) {
                py_stop = *_py_stop;
            } else {
                if (has_cstop) {
                    owned_stop = py_stop = PyLong_FromSsize_t(cstop);
                    if (unlikely(!py_stop)) {
                        Py_XDECREF(owned_start);
                        goto bad;
                    }
                } else
                    py_stop = Py_None;
            }
            py_slice = PySlice_New(py_start, py_stop, Py_None);
            Py_XDECREF(owned_start);
            Py_XDECREF(owned_stop);
            if (unlikely(!py_slice)) goto bad;
        }
#if CYTHON_USE_TYPE_SLOTS
        result = mp->mp_subscript(obj, py_slice);
#else
        result = PyObject_GetItem(obj, py_slice);
#endif
        if (!_py_slice) {
            Py_DECREF(py_slice);
        }
        return result;
    }
    obj_type_name = __Pyx_PyType_GetFullyQualifiedName(Py_TYPE(obj));
    PyErr_Format(PyExc_TypeError,
        "'" __Pyx_FMT_TYPENAME "' object is unsliceable", obj_type_name);
    __Pyx_DECREF_TypeName(obj_type_name);
bad:
    return NULL;
}

/* PyObjectCallOneArg */
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *args[2] = {NULL, arg};
    return __Pyx_PyObject_FastCall(func, args+1, 1 | __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET);
}

/* ObjectGetItem */
#if CYTHON_USE_TYPE_SLOTS
static PyObject *__Pyx_PyObject_GetIndex(PyObject *obj, PyObject *index) {
    PyObject *runerr = NULL;
    Py_ssize_t key_value;
    key_value = __Pyx_PyIndex_AsSsize_t(index);
    if (likely(key_value != -1 || !(runerr = PyErr_Occurred()))) {
        return __Pyx_GetItemInt_Fast(obj, key_value, 0, 1, 1);
    }
    if (PyErr_GivenExceptionMatches(runerr, PyExc_OverflowError)) {
        __Pyx_TypeName index_type_name = __Pyx_PyType_GetFullyQualifiedName(Py_TYPE(index));
        PyErr_Clear();
        PyErr_Format(PyExc_IndexError,
            "cannot fit '" __Pyx_FMT_TYPENAME "' into an index-sized integer", index_type_name);
        __Pyx_DECREF_TypeName(index_type_name);
    }
    return NULL;
}
static PyObject *__Pyx_PyObject_GetItem_Slow(PyObject *obj, PyObject *key) {
    __Pyx_TypeName obj_type_name;
    if (likely(PyType_Check(obj))) {
        PyObject *meth = __Pyx_PyObject_GetAttrStrNoError(obj, __pyx_mstate_global->__pyx_n_u_class_getitem);
        if (!meth) {
            PyErr_Clear();
        } else {
            PyObject *result = __Pyx_PyObject_CallOneArg(meth, key);
            Py_DECREF(meth);
            return result;
        }
    }
    obj_type_name = __Pyx_PyType_GetFullyQualifiedName(Py_TYPE(obj));
    PyErr_Format(PyExc_TypeError,
        "'" __Pyx_FMT_TYPENAME "' object is not subscriptable", obj_type_name);
    __Pyx_DECREF_TypeName(obj_type_name);
    return NULL;
}
static PyObject *__Pyx_PyObject_GetItem(PyObject *obj, PyObject *key) {
    PyTypeObject *tp = Py_TYPE(obj);
    PyMappingMethods *mm = tp->tp_as_mapping;
    PySequenceMethods *sm = tp->tp_as_sequence;
    if (likely(mm && mm->mp_subscript)) {
        return mm->mp_subscript(obj, key);
    }
    if (likely(sm && sm->sq_item)) {
        return __Pyx_PyObject_GetIndex(obj, key);
    }
    return __Pyx_PyObject_GetItem_Slow(obj, key);
}
#endif

/* PyLongCompare */
static CYTHON_INLINE int __Pyx_PyLong_BoolNeObjC(PyObject *op1, PyObject *op2, long intval, long inplace) {
    CYTHON_MAYBE_UNUSED_VAR(intval);
    CYTHON_UNUSED_VAR(inplace);
    if (op1 == op2) {
        return 0;
    }
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        int unequal;
        unsigned long uintval;
        Py_ssize_t size = __Pyx_PyLong_DigitCount(op1);
        const digit* digits = __Pyx_PyLong_Digits(op1);
        if (intval == 0) {
            return (__Pyx_PyLong_IsZero(op1) != 1);
        } else if (intval < 0) {
            if (__Pyx_PyLong_IsNonNeg(op1))
                return 1;
            intval = -intval;
        } else {
            if (__Pyx_PyLong_IsNeg(op1))
                return 1;
        }
        uintval = (unsigned long) intval;
#if PyLong_SHIFT * 4 < SIZEOF_LONG*8
        if (uintval >> (PyLong_SHIFT * 4)) {
            unequal = (size != 5) || (digits[0] != (uintval & (unsigned long) PyLong_MASK))
                 | (digits[1] != ((uintval >> (1 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[2] != ((uintval >> (2 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[3] != ((uintval >> (3 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[4] != ((uintval >> (4 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK));
        } else
#endif
#if PyLong_SHIFT * 3 < SIZEOF_LONG*8
        if (uintval >> (PyLong_SHIFT * 3)) {
            unequal = (size != 4) || (digits[0] != (uintval & (unsigned long) PyLong_MASK))
                 | (digits[1] != ((uintval >> (1 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[2] != ((uintval >> (2 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[3] != ((uintval >> (3 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK));
        } else
#endif
#if PyLong_SHIFT * 2 < SIZEOF_LONG*8
        if (uintval >> (PyLong_SHIFT * 2)) {
            unequal = (size != 3) || (digits[0] != (uintval & (unsigned long) PyLong_MASK))
                 | (digits[1] != ((uintval >> (1 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK)) | (digits[2] != ((uintval >> (2 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK));
        } else
#endif
#if PyLong_SHIFT * 1 < SIZEOF_LONG*8
        if (uintval >> (PyLong_SHIFT * 1)) {
            unequal = (size != 2) || (digits[0] != (uintval & (unsigned long) PyLong_MASK))
                 | (digits[1] != ((uintval >> (1 * PyLong_SHIFT)) & (unsigned long) PyLong_MASK));
        } else
#endif
            unequal = (size != 1) || (((unsigned long) digits[0]) != (uintval & (unsigned long) PyLong_MASK));
        return (unequal != 0);
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
        double a = __Pyx_PyFloat_AS_DOUBLE(op1);
        return ((double)a != (double)b);
    }
    return __Pyx_PyObject_IsTrueAndDecref(
        PyObject_RichCompare(op1, op2, Py_NE));
}

/* PyLongBinop */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_Fallback___Pyx_PyLong_SubtractObjC(PyObject *op1, PyObject *op2, int inplace) {
    return (inplace ? PyNumber_InPlaceSubtract : PyNumber_Subtract)(op1, op2);
}
#if CYTHON_USE_PYLONG_INTERNALS
static PyObject* __Pyx_Unpacked___Pyx_PyLong_SubtractObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check) {
    CYTHON_MAYBE_UNUSED_VAR(inplace);
    CYTHON_UNUSED_VAR(zerodivision_check);
    const long b = intval;
    long a, x;
#ifdef HAVE_LONG_LONG
    const PY_LONG_LONG llb = intval;
    PY_LONG_LONG lla, llx;
#endif
    if (unlikely(__Pyx_PyLong_IsZero(op1))) {
        return PyLong_FromLong(-intval);
    }
    if (unlikely(!__Pyx_PyLong_CompactAsLong(op1, &a))) {
        const digit* digits = __Pyx_PyLong_Digits(op1);
        const Py_ssize_t size = __Pyx_PyLong_SignedDigitCount(op1);
        switch (size) {
            case -2:
                if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                    a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                    lla = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            case 2:
                if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                    a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                    lla = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            case -3:
                if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                    a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                    lla = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            case 3:
                if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                    a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                    lla = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            case -4:
                if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                    a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                    lla = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            case 4:
                if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                    a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                    lla = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            default: return PyLong_Type.tp_as_number->nb_subtract(op1, op2);
        }
    }
            x = a - b;
        return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
    long_long:
            llx = lla - llb;
        return PyLong_FromLongLong(llx);
#endif
    return __Pyx_Fallback___Pyx_PyLong_SubtractObjC(op1, op2, inplace);
    
    
}
#endif
static PyObject* __Pyx_Float___Pyx_PyLong_SubtractObjC(PyObject *float_val, long intval, int zerodivision_check) {
    CYTHON_UNUSED_VAR(zerodivision_check);
    const long b = intval;
    double a = __Pyx_PyFloat_AS_DOUBLE(float_val);
        double result;
        
        result = ((double)a) - (double)b;
        return PyFloat_FromDouble(result);
}
static CYTHON_INLINE PyObject* __Pyx_PyLong_SubtractObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check) {
    CYTHON_MAYBE_UNUSED_VAR(intval);
    CYTHON_UNUSED_VAR(zerodivision_check);
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        return __Pyx_Unpacked___Pyx_PyLong_SubtractObjC(op1, op2, intval, inplace, zerodivision_check);
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        return __Pyx_Float___Pyx_PyLong_SubtractObjC(op1, intval, zerodivision_check);
    }
    return __Pyx_Fallback___Pyx_PyLong_SubtractObjC(op1, op2, inplace);
}
#endif

/* PyLongBinop */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_Fallback___Pyx_PyLong_FloorDivideObjC(PyObject *op1, PyObject *op2, int inplace) {
    return (inplace ? PyNumber_InPlaceFloorDivide : PyNumber_FloorDivide)(op1, op2);
}
#if CYTHON_USE_PYLONG_INTERNALS
static PyObject* __Pyx_Unpacked___Pyx_PyLong_FloorDivideObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check) {
    CYTHON_MAYBE_UNUSED_VAR(inplace);
    CYTHON_UNUSED_VAR(zerodivision_check);
    const long b = intval;
    long a, x;
#ifdef HAVE_LONG_LONG
    const PY_LONG_LONG llb = intval;
    PY_LONG_LONG lla, llx;
#endif
    if (unlikely(__Pyx_PyLong_IsZero(op1))) {
        return __Pyx_NewRef(op1);
    }
    if (unlikely(!__Pyx_PyLong_CompactAsLong(op1, &a))) {
        const digit* digits = __Pyx_PyLong_Digits(op1);
        const Py_ssize_t size = __Pyx_PyLong_SignedDigitCount(op1);
        switch (size) {
            case -2:
                if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                    a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                    lla = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            case 2:
                if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                    a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                    lla = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            case -3:
                if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                    a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                    lla = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            case 3:
                if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                    a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                    lla = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            case -4:
                if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                    a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                    lla = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            case 4:
                if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                    a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                    break;
                #ifdef HAVE_LONG_LONG
                } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                    lla = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                    goto long_long;
                #endif
                }
                CYTHON_FALLTHROUGH;
            default: return PyLong_Type.tp_as_number->nb_floor_divide(op1, op2);
        }
    }
            {
                long q, r;
                q = a / b;
                r = a - q*b;
                q -= ((r != 0) & ((r ^ b) < 0));
                x = q;
            }
        return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
    long_long:
            {
                PY_LONG_LONG q, r;
                q = lla / llb;
                r = lla - q*llb;
                q -= ((r != 0) & ((r ^ llb) < 0));
                llx = q;
            }
        return PyLong_FromLongLong(llx);
#endif
    return __Pyx_Fallback___Pyx_PyLong_FloorDivideObjC(op1, op2, inplace);
    
    
}
#endif
static CYTHON_INLINE PyObject* __Pyx_PyLong_FloorDivideObjC(PyObject *op1, PyObject *op2, long intval, int inplace, int zerodivision_check) {
    CYTHON_MAYBE_UNUSED_VAR(intval);
    CYTHON_UNUSED_VAR(zerodivision_check);
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        return __Pyx_Unpacked___Pyx_PyLong_FloorDivideObjC(op1, op2, intval, inplace, zerodivision_check);
    }
    #endif
    return __Pyx_Fallback___Pyx_PyLong_FloorDivideObjC(op1, op2, inplace);
}
#endif

/* GetAttr3 */
#if __PYX_LIMITED_VERSION_HEX < 0x030d0000
static PyObject *__Pyx_GetAttr3Default(PyObject *d) {
    __Pyx_PyThreadState_declare
    __Pyx_PyThreadState_assign
    if (unlikely(!__Pyx_PyErr_ExceptionMatches(PyExc_AttributeError)))
        return NULL;
    __Pyx_PyErr_Clear();
    Py_INCREF(d);
    return d;
}
#endif
static CYTHON_INLINE PyObject *__Pyx_GetAttr3(PyObject *o, PyObject *n, PyObject *d) {
    PyObject *r;
#if __PYX_LIMITED_VERSION_HEX >= 0x030d0000
    int res = PyObject_GetOptionalAttr(o, n, &r);
    return (res != 0) ? r : __Pyx_NewRef(d);
#else
  #if CYTHON_USE_TYPE_SLOTS
    if (likely(PyUnicode_Check(n))) {
        r = __Pyx_PyObject_GetAttrStrNoError(o, n);
        if (unlikely(!r) && likely(!PyErr_Occurred())) {
            r = __Pyx_NewRef(d);
        }
        return r;
    }
  #endif
    r = PyObject_GetAttr(o, n);
    return (likely(r)) ? r : __Pyx_GetAttr3Default(d);
#endif
}

/* RaiseKeywordRequired */
static void __Pyx_RaiseKeywordRequired(const char* func_name, PyObject* kw_name) {
    PyErr_Format(PyExc_TypeError,
        "%s() needs keyword-only argument %U", func_name, kw_name);
}

/* Import */
static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level) {
    PyObject *module = 0;
    PyObject *empty_dict = 0;
    PyObject *empty_list = 0;
    empty_dict = PyDict_New();
    if (unlikely(!empty_dict))
        goto bad;
    if (level == -1) {
        const char* package_sep = strchr(__Pyx_MODULE_NAME, '.');
        if (package_sep != (0)) {
            module = PyImport_ImportModuleLevelObject(
                name, __pyx_mstate_global->__pyx_d, empty_dict, from_list, 1);
            if (unlikely(!module)) {
                if (unlikely(!PyErr_ExceptionMatches(PyExc_ImportError)))
                    goto bad;
                PyErr_Clear();
            }
        }
        level = 0;
    }
    if (!module) {
        module = PyImport_ImportModuleLevelObject(
            name, __pyx_mstate_global->__pyx_d, empty_dict, from_list, level);
    }
bad:
    Py_XDECREF(empty_dict);
    Py_XDECREF(empty_list);
    return module;
}

/* ImportFrom */
static PyObject* __Pyx_ImportFrom(PyObject* module, PyObject* name) {
    PyObject* value = __Pyx_PyObject_GetAttrStr(module, name);
    if (unlikely(!value) && PyErr_ExceptionMatches(PyExc_AttributeError)) {
        const char* module_name_str = 0;
        PyObject* module_name = 0;
        PyObject* module_dot = 0;
        PyObject* full_name = 0;
        PyErr_Clear();
        module_name_str = PyModule_GetName(module);
        if (unlikely(!module_name_str)) { goto modbad; }
        module_name = PyUnicode_FromString(module_name_str);
        if (unlikely(!module_name)) { goto modbad; }
        module_dot = PyUnicode_Concat(module_name, __pyx_mstate_global->__pyx_kp_u_);
        if (unlikely(!module_dot)) { goto modbad; }
        full_name = PyUnicode_Concat(module_dot, name);
        if (unlikely(!full_name)) { goto modbad; }
        #if (CYTHON_COMPILING_IN_PYPY && PYPY_VERSION_NUM  < 0x07030400) ||\
                CYTHON_COMPILING_IN_GRAAL
        {
            PyObject *modules = PyImport_GetModuleDict();
            if (unlikely(!modules))
                goto modbad;
            value = PyObject_GetItem(modules, full_name);
        }
        #else
        value = PyImport_GetModule(full_name);
        #endif
      modbad:
        Py_XDECREF(full_name);
        Py_XDECREF(module_dot);
        Py_XDECREF(module_name);
    }
    if (unlikely(!value)) {
        PyErr_Format(PyExc_ImportError, "cannot import name %S", name);
    }
    return value;
}

/* RaiseUnboundLocalError */
static void __Pyx_RaiseUnboundLocalError(const char *varname) {
    PyErr_Format(PyExc_UnboundLocalError, "local variable '%s' referenced before assignment", varname);
}

/* CallTypeTraverse */
#if !CYTHON_USE_TYPE_SPECS || (!CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x03090000)
#else
static int __Pyx_call_type_traverse(PyObject *o, int always_call, visitproc visit, void *arg) {
    #if CYTHON_COMPILING_IN_LIMITED_API && __PYX_LIMITED_VERSION_HEX < 0x03090000
    if (__Pyx_get_runtime_version() < 0x03090000) return 0;
    #endif
    if (!always_call) {
        PyTypeObject *base = __Pyx_PyObject_GetSlot(o, tp_base, PyTypeObject*);
        unsigned long flags = PyType_GetFlags(base);
        if (flags & Py_TPFLAGS_HEAPTYPE) {
            return 0;
        }
    }
    Py_VISIT((PyObject*)Py_TYPE(o));
    return 0;
}
#endif

/* LimitedApiGetTypeDict */
#if CYTHON_COMPILING_IN_LIMITED_API
static Py_ssize_t __Pyx_GetTypeDictOffset(void) {
    PyObject *tp_dictoffset_o;
    Py_ssize_t tp_dictoffset;
    tp_dictoffset_o = PyObject_GetAttrString((PyObject*)(&PyType_Type), "__dictoffset__");
    if (unlikely(!tp_dictoffset_o)) return -1;
    tp_dictoffset = PyLong_AsSsize_t(tp_dictoffset_o);
    Py_DECREF(tp_dictoffset_o);
    if (unlikely(tp_dictoffset == 0)) {
        PyErr_SetString(
            PyExc_TypeError,
            "'type' doesn't have a dictoffset");
        return -1;
    } else if (unlikely(tp_dictoffset < 0)) {
        PyErr_SetString(
            PyExc_TypeError,
            "'type' has an unexpected negative dictoffset. "
            "Please report this as Cython bug");
        return -1;
    }
    return tp_dictoffset;
}
static PyObject *__Pyx_GetTypeDict(PyTypeObject *tp) {
    static Py_ssize_t tp_dictoffset = 0;
    if (unlikely(tp_dictoffset == 0)) {
        tp_dictoffset = __Pyx_GetTypeDictOffset();
        if (unlikely(tp_dictoffset == -1 && PyErr_Occurred())) {
            tp_dictoffset = 0; // try again next time?
            return NULL;
        }
    }
    return *(PyObject**)((char*)tp + tp_dictoffset);
}
#endif

/* SetItemOnTypeDict */
static int __Pyx__SetItemOnTypeDict(PyTypeObject *tp, PyObject *k, PyObject *v) {
    int result;
    PyObject *tp_dict;
#if CYTHON_COMPILING_IN_LIMITED_API
    tp_dict = __Pyx_GetTypeDict(tp);
    if (unlikely(!tp_dict)) return -1;
#else
    tp_dict = tp->tp_dict;
#endif
    result = PyDict_SetItem(tp_dict, k, v);
    if (likely(!result)) {
        PyType_Modified(tp);
        if (unlikely(PyObject_HasAttr(v, __pyx_mstate_global->__pyx_n_u_set_name))) {
            PyObject *setNameResult = PyObject_CallMethodObjArgs(v, __pyx_mstate_global->__pyx_n_u_set_name,  (PyObject *) tp, k, NULL);
            if (!setNameResult) return -1;
            Py_DECREF(setNameResult);
        }
    }
    return result;
}

/* FixUpExtensionType */
static int __Pyx_fix_up_extension_type_from_spec(PyType_Spec *spec, PyTypeObject *type) {
#if __PYX_LIMITED_VERSION_HEX > 0x030900B1
    CYTHON_UNUSED_VAR(spec);
    CYTHON_UNUSED_VAR(type);
    CYTHON_UNUSED_VAR(__Pyx__SetItemOnTypeDict);
#else
    const PyType_Slot *slot = spec->slots;
    int changed = 0;
#if !CYTHON_COMPILING_IN_LIMITED_API
    while (slot && slot->slot && slot->slot != Py_tp_members)
        slot++;
    if (slot && slot->slot == Py_tp_members) {
#if !CYTHON_COMPILING_IN_CPYTHON
        const
#endif  // !CYTHON_COMPILING_IN_CPYTHON)
            PyMemberDef *memb = (PyMemberDef*) slot->pfunc;
        while (memb && memb->name) {
            if (memb->name[0] == '_' && memb->name[1] == '_') {
                if (strcmp(memb->name, "__weaklistoffset__") == 0) {
                    assert(memb->type == T_PYSSIZET);
                    assert(memb->flags == READONLY);
                    type->tp_weaklistoffset = memb->offset;
                    changed = 1;
                }
                else if (strcmp(memb->name, "__dictoffset__") == 0) {
                    assert(memb->type == T_PYSSIZET);
                    assert(memb->flags == READONLY);
                    type->tp_dictoffset = memb->offset;
                    changed = 1;
                }
#if CYTHON_METH_FASTCALL
                else if (strcmp(memb->name, "__vectorcalloffset__") == 0) {
                    assert(memb->type == T_PYSSIZET);
                    assert(memb->flags == READONLY);
#if PY_VERSION_HEX >= 0x030800b4
                    type->tp_vectorcall_offset = memb->offset;
#else
                    type->tp_print = (printfunc) memb->offset;
#endif
                    changed = 1;
                }
#endif  // CYTHON_METH_FASTCALL
#if !CYTHON_COMPILING_IN_PYPY
                else if (strcmp(memb->name, "__module__") == 0) {
                    PyObject *descr;
                    assert(memb->type == T_OBJECT);
                    assert(memb->flags == 0 || memb->flags == READONLY);
                    descr = PyDescr_NewMember(type, memb);
                    if (unlikely(!descr))
                        return -1;
                    int set_item_result = PyDict_SetItem(type->tp_dict, PyDescr_NAME(descr), descr);
                    Py_DECREF(descr);
                    if (unlikely(set_item_result < 0)) {
                        return -1;
                    }
                    changed = 1;
                }
#endif  // !CYTHON_COMPILING_IN_PYPY
            }
            memb++;
        }
    }
#endif  // !CYTHON_COMPILING_IN_LIMITED_API
#if !CYTHON_COMPILING_IN_PYPY
    slot = spec->slots;
    while (slot && slot->slot && slot->slot != Py_tp_getset)
        slot++;
    if (slot && slot->slot == Py_tp_getset) {
        PyGetSetDef *getset = (PyGetSetDef*) slot->pfunc;
        while (getset && getset->name) {
            if (getset->name[0] == '_' && getset->name[1] == '_' && strcmp(getset->name, "__module__") == 0) {
                PyObject *descr = PyDescr_NewGetSet(type, getset);
                if (unlikely(!descr))
                    return -1;
                #if CYTHON_COMPILING_IN_LIMITED_API
                PyObject *pyname = PyUnicode_FromString(getset->name);
                if (unlikely(!pyname)) {
                    Py_DECREF(descr);
                    return -1;
                }
                int set_item_result = __Pyx_SetItemOnTypeDict(type, pyname, descr);
                Py_DECREF(pyname);
                #else
                CYTHON_UNUSED_VAR(__Pyx__SetItemOnTypeDict);
                int set_item_result = PyDict_SetItem(type->tp_dict, PyDescr_NAME(descr), descr);
                #endif
                Py_DECREF(descr);
                if (unlikely(set_item_result < 0)) {
                    return -1;
                }
                changed = 1;
            }
            ++getset;
        }
    }
#endif  // !CYTHON_COMPILING_IN_PYPY
    if (changed)
        PyType_Modified(type);
#endif  // PY_VERSION_HEX > 0x030900B1
    return 0;
}

/* PyObjectCallNoArg */
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallNoArg(PyObject *func) {
    PyObject *arg[2] = {NULL, NULL};
    return __Pyx_PyObject_FastCall(func, arg + 1, 0 | __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET);
}

/* PyObjectGetMethod */
static int __Pyx_PyObject_GetMethod(PyObject *obj, PyObject *name, PyObject **method) {
    PyObject *attr;
#if CYTHON_UNPACK_METHODS && CYTHON_COMPILING_IN_CPYTHON && CYTHON_USE_PYTYPE_LOOKUP
    __Pyx_TypeName type_name;
    PyTypeObject *tp = Py_TYPE(obj);
    PyObject *descr;
    descrgetfunc f = NULL;
    PyObject **dictptr, *dict;
    int meth_found = 0;
    assert (*method == NULL);
    if (unlikely(tp->tp_getattro != PyObject_GenericGetAttr)) {
        attr = __Pyx_PyObject_GetAttrStr(obj, name);
        goto try_unpack;
    }
    if (unlikely(tp->tp_dict == NULL) && unlikely(PyType_Ready(tp) < 0)) {
        return 0;
    }
    descr = _PyType_Lookup(tp, name);
    if (likely(descr != NULL)) {
        Py_INCREF(descr);
#if defined(Py_TPFLAGS_METHOD_DESCRIPTOR) && Py_TPFLAGS_METHOD_DESCRIPTOR
        if (__Pyx_PyType_HasFeature(Py_TYPE(descr), Py_TPFLAGS_METHOD_DESCRIPTOR))
#else
        #ifdef __Pyx_CyFunction_USED
        if (likely(PyFunction_Check(descr) || __Pyx_IS_TYPE(descr, &PyMethodDescr_Type) || __Pyx_CyFunction_Check(descr)))
        #else
        if (likely(PyFunction_Check(descr) || __Pyx_IS_TYPE(descr, &PyMethodDescr_Type)))
        #endif
#endif
        {
            meth_found = 1;
        } else {
            f = Py_TYPE(descr)->tp_descr_get;
            if (f != NULL && PyDescr_IsData(descr)) {
                attr = f(descr, obj, (PyObject *)Py_TYPE(obj));
                Py_DECREF(descr);
                goto try_unpack;
            }
        }
    }
    dictptr = _PyObject_GetDictPtr(obj);
    if (dictptr != NULL && (dict = *dictptr) != NULL) {
        Py_INCREF(dict);
        attr = __Pyx_PyDict_GetItemStr(dict, name);
        if (attr != NULL) {
            Py_INCREF(attr);
            Py_DECREF(dict);
            Py_XDECREF(descr);
            goto try_unpack;
        }
        Py_DECREF(dict);
    }
    if (meth_found) {
        *method = descr;
        return 1;
    }
    if (f != NULL) {
        attr = f(descr, obj, (PyObject *)Py_TYPE(obj));
        Py_DECREF(descr);
        goto try_unpack;
    }
    if (likely(descr != NULL)) {
        *method = descr;
        return 0;
    }
    type_name = __Pyx_PyType_GetFullyQualifiedName(tp);
    PyErr_Format(PyExc_AttributeError,
                 "'" __Pyx_FMT_TYPENAME "' object has no attribute '%U'",
                 type_name, name);
    __Pyx_DECREF_TypeName(type_name);
    return 0;
#else
    attr = __Pyx_PyObject_GetAttrStr(obj, name);
    goto try_unpack;
#endif
try_unpack:
#if CYTHON_UNPACK_METHODS
    if (likely(attr) && PyMethod_Check(attr) && likely(PyMethod_GET_SELF(attr) == obj)) {
        PyObject *function = PyMethod_GET_FUNCTION(attr);
        Py_INCREF(function);
        Py_DECREF(attr);
        *method = function;
        return 1;
    }
#endif
    *method = attr;
    return 0;
}

/* PyObjectCallMethod0 */
static PyObject* __Pyx_PyObject_CallMethod0(PyObject* obj, PyObject* method_name) {
#if CYTHON_VECTORCALL && (__PYX_LIMITED_VERSION_HEX >= 0x030C0000 || (!CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX >= 0x03090000))
    PyObject *args[1] = {obj};
    (void) __Pyx_PyObject_GetMethod;
    (void) __Pyx_PyObject_CallOneArg;
    (void) __Pyx_PyObject_CallNoArg;
    return PyObject_VectorcallMethod(method_name, args, 1 | PY_VECTORCALL_ARGUMENTS_OFFSET, NULL);
#else
    PyObject *method = NULL, *result = NULL;
    int is_method = __Pyx_PyObject_GetMethod(obj, method_name, &method);
    if (likely(is_method)) {
        result = __Pyx_PyObject_CallOneArg(method, obj);
        Py_DECREF(method);
        return result;
    }
    if (unlikely(!method)) goto bad;
    result = __Pyx_PyObject_CallNoArg(method);
    Py_DECREF(method);
bad:
    return result;
#endif
}

/* ValidateBasesTuple */
#if CYTHON_COMPILING_IN_CPYTHON || CYTHON_COMPILING_IN_LIMITED_API || CYTHON_USE_TYPE_SPECS
static int __Pyx_validate_bases_tuple(const char *type_name, Py_ssize_t dictoffset, PyObject *bases) {
    Py_ssize_t i, n;
#if CYTHON_ASSUME_SAFE_SIZE
    n = PyTuple_GET_SIZE(bases);
#else
    n = PyTuple_Size(bases);
    if (unlikely(n < 0)) return -1;
#endif
    for (i = 1; i < n; i++)
    {
        PyTypeObject *b;
#if CYTHON_AVOID_BORROWED_REFS
        PyObject *b0 = PySequence_GetItem(bases, i);
        if (!b0) return -1;
#elif CYTHON_ASSUME_SAFE_MACROS
        PyObject *b0 = PyTuple_GET_ITEM(bases, i);
#else
        PyObject *b0 = PyTuple_GetItem(bases, i);
        if (!b0) return -1;
#endif
        b = (PyTypeObject*) b0;
        if (!__Pyx_PyType_HasFeature(b, Py_TPFLAGS_HEAPTYPE))
        {
            __Pyx_TypeName b_name = __Pyx_PyType_GetFullyQualifiedName(b);
            PyErr_Format(PyExc_TypeError,
                "base class '" __Pyx_FMT_TYPENAME "' is not a heap type", b_name);
            __Pyx_DECREF_TypeName(b_name);
#if CYTHON_AVOID_BORROWED_REFS
            Py_DECREF(b0);
#endif
            return -1;
        }
        if (dictoffset == 0)
        {
            Py_ssize_t b_dictoffset = 0;
#if CYTHON_USE_TYPE_SLOTS
            b_dictoffset = b->tp_dictoffset;
#else
            PyObject *py_b_dictoffset = PyObject_GetAttrString((PyObject*)b, "__dictoffset__");
            if (!py_b_dictoffset) goto dictoffset_return;
            b_dictoffset = PyLong_AsSsize_t(py_b_dictoffset);
            Py_DECREF(py_b_dictoffset);
            if (b_dictoffset == -1 && PyErr_Occurred()) goto dictoffset_return;
#endif
            if (b_dictoffset) {
                {
                    __Pyx_TypeName b_name = __Pyx_PyType_GetFullyQualifiedName(b);
                    PyErr_Format(PyExc_TypeError,
                        "extension type '%.200s' has no __dict__ slot, "
                        "but base type '" __Pyx_FMT_TYPENAME "' has: "
                        "either add 'cdef dict __dict__' to the extension type "
                        "or add '__slots__ = [...]' to the base type",
                        type_name, b_name);
                    __Pyx_DECREF_TypeName(b_name);
                }
#if !CYTHON_USE_TYPE_SLOTS
              dictoffset_return:
#endif
#if CYTHON_AVOID_BORROWED_REFS
                Py_DECREF(b0);
#endif
                return -1;
            }
        }
#if CYTHON_AVOID_BORROWED_REFS
        Py_DECREF(b0);
#endif
    }
    return 0;
}
#endif

/* PyType_Ready */
CYTHON_UNUSED static int __Pyx_PyType_HasMultipleInheritance(PyTypeObject *t) {
    while (t) {
        PyObject *bases = __Pyx_PyType_GetSlot(t, tp_bases, PyObject*);
        if (bases) {
            return 1;
        }
        t = __Pyx_PyType_GetSlot(t, tp_base, PyTypeObject*);
    }
    return 0;
}
static int __Pyx_PyType_Ready(PyTypeObject *t) {
#if CYTHON_USE_TYPE_SPECS || !CYTHON_COMPILING_IN_CPYTHON || defined(PYSTON_MAJOR_VERSION)
    (void)__Pyx_PyObject_CallMethod0;
#if CYTHON_USE_TYPE_SPECS
    (void)__Pyx_validate_bases_tuple;
#endif
    return PyType_Ready(t);
#else
    int r;
    if (!__Pyx_PyType_HasMultipleInheritance(t)) {
        return PyType_Ready(t);
    }
    PyObject *bases = __Pyx_PyType_GetSlot(t, tp_bases, PyObject*);
    if (bases && unlikely(__Pyx_validate_bases_tuple(t->tp_name, t->tp_dictoffset, bases) == -1))
        return -1;
#if !defined(PYSTON_MAJOR_VERSION)
    {
        int gc_was_enabled;
    #if PY_VERSION_HEX >= 0x030A00b1
        gc_was_enabled = PyGC_Disable();
        (void)__Pyx_PyObject_CallMethod0;
    #else
        PyObject *ret, *py_status;
        PyObject *gc = NULL;
        #if (!CYTHON_COMPILING_IN_PYPY || PYPY_VERSION_NUM+0 >= 0x07030400) &&\
                !CYTHON_COMPILING_IN_GRAAL
        gc = PyImport_GetModule(__pyx_mstate_global->__pyx_kp_u_gc);
        #endif
        if (unlikely(!gc)) gc = PyImport_Import(__pyx_mstate_global->__pyx_kp_u_gc);
        if (unlikely(!gc)) return -1;
        py_status = __Pyx_PyObject_CallMethod0(gc, __pyx_mstate_global->__pyx_kp_u_isenabled);
        if (unlikely(!py_status)) {
            Py_DECREF(gc);
            return -1;
        }
        gc_was_enabled = __Pyx_PyObject_IsTrue(py_status);
        Py_DECREF(py_status);
        if (gc_was_enabled > 0) {
            ret = __Pyx_PyObject_CallMethod0(gc, __pyx_mstate_global->__pyx_kp_u_disable);
            if (unlikely(!ret)) {
                Py_DECREF(gc);
                return -1;
            }
            Py_DECREF(ret);
        } else if (unlikely(gc_was_enabled == -1)) {
            Py_DECREF(gc);
            return -1;
        }
    #endif
        t->tp_flags |= Py_TPFLAGS_HEAPTYPE;
#if PY_VERSION_HEX >= 0x030A0000
        t->tp_flags |= Py_TPFLAGS_IMMUTABLETYPE;
#endif
#else
        (void)__Pyx_PyObject_CallMethod0;
#endif
    r = PyType_Ready(t);
#if !defined(PYSTON_MAJOR_VERSION)
        t->tp_flags &= ~Py_TPFLAGS_HEAPTYPE;
    #if PY_VERSION_HEX >= 0x030A00b1
        if (gc_was_enabled)
            PyGC_Enable();
    #else
        if (gc_was_enabled) {
            PyObject *tp, *v, *tb;
            PyErr_Fetch(&tp, &v, &tb);
            ret = __Pyx_PyObject_CallMethod0(gc, __pyx_mstate_global->__pyx_kp_u_enable);
            if (likely(ret || r == -1)) {
                Py_XDECREF(ret);
                PyErr_Restore(tp, v, tb);
            } else {
                Py_XDECREF(tp);
                Py_XDECREF(v);
                Py_XDECREF(tb);
                r = -1;
            }
        }
        Py_DECREF(gc);
    #endif
    }
#endif
    return r;
#endif
}

/* SetVTable */
static int __Pyx_SetVtable(PyTypeObject *type, void *vtable) {
    PyObject *ob = PyCapsule_New(vtable, 0, 0);
    if (unlikely(!ob))
        goto bad;
#if CYTHON_COMPILING_IN_LIMITED_API
    if (unlikely(PyObject_SetAttr((PyObject *) type, __pyx_mstate_global->__pyx_n_u_pyx_vtable, ob) < 0))
#else
    if (unlikely(PyDict_SetItem(type->tp_dict, __pyx_mstate_global->__pyx_n_u_pyx_vtable, ob) < 0))
#endif
        goto bad;
    Py_DECREF(ob);
    return 0;
bad:
    Py_XDECREF(ob);
    return -1;
}

/* GetVTable */
static void* __Pyx_GetVtable(PyTypeObject *type) {
    void* ptr;
#if CYTHON_COMPILING_IN_LIMITED_API
    PyObject *ob = PyObject_GetAttr((PyObject *)type, __pyx_mstate_global->__pyx_n_u_pyx_vtable);
#else
    PyObject *ob = PyObject_GetItem(type->tp_dict, __pyx_mstate_global->__pyx_n_u_pyx_vtable);
#endif
    if (!ob)
        goto bad;
    ptr = PyCapsule_GetPointer(ob, 0);
    if (!ptr && !PyErr_Occurred())
        PyErr_SetString(PyExc_RuntimeError, "invalid vtable found for imported type");
    Py_DECREF(ob);
    return ptr;
bad:
    Py_XDECREF(ob);
    return NULL;
}

/* MergeVTables */
static int __Pyx_MergeVtables(PyTypeObject *type) {
    int i=0;
    Py_ssize_t size;
    void** base_vtables;
    __Pyx_TypeName tp_base_name = NULL;
    __Pyx_TypeName base_name = NULL;
    void* unknown = (void*)-1;
    PyObject* bases = __Pyx_PyType_GetSlot(type, tp_bases, PyObject*);
    int base_depth = 0;
    {
        PyTypeObject* base = __Pyx_PyType_GetSlot(type, tp_base, PyTypeObject*);
        while (base) {
            base_depth += 1;
            base = __Pyx_PyType_GetSlot(base, tp_base, PyTypeObject*);
        }
    }
    base_vtables = (void**) PyMem_Malloc(sizeof(void*) * (size_t)(base_depth + 1));
    base_vtables[0] = unknown;
#if CYTHON_COMPILING_IN_LIMITED_API
    size = PyTuple_Size(bases);
    if (size < 0) goto other_failure;
#else
    size = PyTuple_GET_SIZE(bases);
#endif
    for (i = 1; i < size; i++) {
        PyObject *basei;
        void* base_vtable;
#if CYTHON_AVOID_BORROWED_REFS
        basei = PySequence_GetItem(bases, i);
        if (unlikely(!basei)) goto other_failure;
#elif !CYTHON_ASSUME_SAFE_MACROS
        basei = PyTuple_GetItem(bases, i);
        if (unlikely(!basei)) goto other_failure;
#else
        basei = PyTuple_GET_ITEM(bases, i);
#endif
        base_vtable = __Pyx_GetVtable((PyTypeObject*)basei);
#if CYTHON_AVOID_BORROWED_REFS
        Py_DECREF(basei);
#endif
        if (base_vtable != NULL) {
            int j;
            PyTypeObject* base = __Pyx_PyType_GetSlot(type, tp_base, PyTypeObject*);
            for (j = 0; j < base_depth; j++) {
                if (base_vtables[j] == unknown) {
                    base_vtables[j] = __Pyx_GetVtable(base);
                    base_vtables[j + 1] = unknown;
                }
                if (base_vtables[j] == base_vtable) {
                    break;
                } else if (base_vtables[j] == NULL) {
                    goto bad;
                }
                base = __Pyx_PyType_GetSlot(base, tp_base, PyTypeObject*);
            }
        }
    }
    PyErr_Clear();
    PyMem_Free(base_vtables);
    return 0;
bad:
    {
        PyTypeObject* basei = NULL;
        PyTypeObject* tp_base = __Pyx_PyType_GetSlot(type, tp_base, PyTypeObject*);
        tp_base_name = __Pyx_PyType_GetFullyQualifiedName(tp_base);
#if CYTHON_AVOID_BORROWED_REFS
        basei = (PyTypeObject*)PySequence_GetItem(bases, i);
        if (unlikely(!basei)) goto really_bad;
#elif !CYTHON_ASSUME_SAFE_MACROS
        basei = (PyTypeObject*)PyTuple_GetItem(bases, i);
        if (unlikely(!basei)) goto really_bad;
#else
        basei = (PyTypeObject*)PyTuple_GET_ITEM(bases, i);
#endif
        base_name = __Pyx_PyType_GetFullyQualifiedName(basei);
#if CYTHON_AVOID_BORROWED_REFS
        Py_DECREF(basei);
#endif
    }
    PyErr_Format(PyExc_TypeError,
        "multiple bases have vtable conflict: '" __Pyx_FMT_TYPENAME "' and '" __Pyx_FMT_TYPENAME "'", tp_base_name, base_name);
#if CYTHON_AVOID_BORROWED_REFS || !CYTHON_ASSUME_SAFE_MACROS
really_bad: // bad has failed!
#endif
    __Pyx_DECREF_TypeName(tp_base_name);
    __Pyx_DECREF_TypeName(base_name);
#if CYTHON_COMPILING_IN_LIMITED_API || CYTHON_AVOID_BORROWED_REFS || !CYTHON_ASSUME_SAFE_MACROS
other_failure:
#endif
    PyMem_Free(base_vtables);
    return -1;
}

/* DelItemOnTypeDict */
static int __Pyx__DelItemOnTypeDict(PyTypeObject *tp, PyObject *k) {
    int result;
    PyObject *tp_dict;
#if CYTHON_COMPILING_IN_LIMITED_API
    tp_dict = __Pyx_GetTypeDict(tp);
    if (unlikely(!tp_dict)) return -1;
#else
    tp_dict = tp->tp_dict;
#endif
    result = PyDict_DelItem(tp_dict, k);
    if (likely(!result)) PyType_Modified(tp);
    return result;
}

/* SetupReduce */
static int __Pyx_setup_reduce_is_named(PyObject* meth, PyObject* name) {
  int ret;
  PyObject *name_attr;
  name_attr = __Pyx_PyObject_GetAttrStrNoError(meth, __pyx_mstate_global->__pyx_n_u_name);
  if (likely(name_attr)) {
      ret = PyObject_RichCompareBool(name_attr, name, Py_EQ);
  } else {
      ret = -1;
  }
  if (unlikely(ret < 0)) {
      PyErr_Clear();
      ret = 0;
  }
  Py_XDECREF(name_attr);
  return ret;
}
static int __Pyx_setup_reduce(PyObject* type_obj) {
    int ret = 0;
    PyObject *object_reduce = NULL;
    PyObject *object_getstate = NULL;
    PyObject *object_reduce_ex = NULL;
    PyObject *reduce = NULL;
    PyObject *reduce_ex = NULL;
    PyObject *reduce_cython = NULL;
    PyObject *setstate = NULL;
    PyObject *setstate_cython = NULL;
    PyObject *getstate = NULL;
#if CYTHON_USE_PYTYPE_LOOKUP
    getstate = _PyType_Lookup((PyTypeObject*)type_obj, __pyx_mstate_global->__pyx_n_u_getstate);
#else
    getstate = __Pyx_PyObject_GetAttrStrNoError(type_obj, __pyx_mstate_global->__pyx_n_u_getstate);
    if (!getstate && PyErr_Occurred()) {
        goto __PYX_BAD;
    }
#endif
    if (getstate) {
#if CYTHON_USE_PYTYPE_LOOKUP
        object_getstate = _PyType_Lookup(&PyBaseObject_Type, __pyx_mstate_global->__pyx_n_u_getstate);
#else
        object_getstate = __Pyx_PyObject_GetAttrStrNoError((PyObject*)&PyBaseObject_Type, __pyx_mstate_global->__pyx_n_u_getstate);
        if (!object_getstate && PyErr_Occurred()) {
            goto __PYX_BAD;
        }
#endif
        if (object_getstate != getstate) {
            goto __PYX_GOOD;
        }
    }
#if CYTHON_USE_PYTYPE_LOOKUP
    object_reduce_ex = _PyType_Lookup(&PyBaseObject_Type, __pyx_mstate_global->__pyx_n_u_reduce_ex); if (!object_reduce_ex) goto __PYX_BAD;
#else
    object_reduce_ex = __Pyx_PyObject_GetAttrStr((PyObject*)&PyBaseObject_Type, __pyx_mstate_global->__pyx_n_u_reduce_ex); if (!object_reduce_ex) goto __PYX_BAD;
#endif
    reduce_ex = __Pyx_PyObject_GetAttrStr(type_obj, __pyx_mstate_global->__pyx_n_u_reduce_ex); if (unlikely(!reduce_ex)) goto __PYX_BAD;
    if (reduce_ex == object_reduce_ex) {
#if CYTHON_USE_PYTYPE_LOOKUP
        object_reduce = _PyType_Lookup(&PyBaseObject_Type, __pyx_mstate_global->__pyx_n_u_reduce); if (!object_reduce) goto __PYX_BAD;
#else
        object_reduce = __Pyx_PyObject_GetAttrStr((PyObject*)&PyBaseObject_Type, __pyx_mstate_global->__pyx_n_u_reduce); if (!object_reduce) goto __PYX_BAD;
#endif
        reduce = __Pyx_PyObject_GetAttrStr(type_obj, __pyx_mstate_global->__pyx_n_u_reduce); if (unlikely(!reduce)) goto __PYX_BAD;
        if (reduce == object_reduce || __Pyx_setup_reduce_is_named(reduce, __pyx_mstate_global->__pyx_n_u_reduce_cython)) {
            reduce_cython = __Pyx_PyObject_GetAttrStrNoError(type_obj, __pyx_mstate_global->__pyx_n_u_reduce_cython);
            if (likely(reduce_cython)) {
                ret = __Pyx_SetItemOnTypeDict((PyTypeObject*)type_obj, __pyx_mstate_global->__pyx_n_u_reduce, reduce_cython); if (unlikely(ret < 0)) goto __PYX_BAD;
                ret = __Pyx_DelItemOnTypeDict((PyTypeObject*)type_obj, __pyx_mstate_global->__pyx_n_u_reduce_cython); if (unlikely(ret < 0)) goto __PYX_BAD;
            } else if (reduce == object_reduce || PyErr_Occurred()) {
                goto __PYX_BAD;
            }
            setstate = __Pyx_PyObject_GetAttrStrNoError(type_obj, __pyx_mstate_global->__pyx_n_u_setstate);
            if (!setstate) PyErr_Clear();
            if (!setstate || __Pyx_setup_reduce_is_named(setstate, __pyx_mstate_global->__pyx_n_u_setstate_cython)) {
                setstate_cython = __Pyx_PyObject_GetAttrStrNoError(type_obj, __pyx_mstate_global->__pyx_n_u_setstate_cython);
                if (likely(setstate_cython)) {
                    ret = __Pyx_SetItemOnTypeDict((PyTypeObject*)type_obj, __pyx_mstate_global->__pyx_n_u_setstate, setstate_cython); if (unlikely(ret < 0)) goto __PYX_BAD;
                    ret = __Pyx_DelItemOnTypeDict((PyTypeObject*)type_obj, __pyx_mstate_global->__pyx_n_u_setstate_cython); if (unlikely(ret < 0)) goto __PYX_BAD;
                } else if (!setstate || PyErr_Occurred()) {
                    goto __PYX_BAD;
                }
            }
            PyType_Modified((PyTypeObject*)type_obj);
        }
    }
    goto __PYX_GOOD;
__PYX_BAD:
    if (!PyErr_Occurred()) {
        __Pyx_TypeName type_obj_name =
            __Pyx_PyType_GetFullyQualifiedName((PyTypeObject*)type_obj);
        PyErr_Format(PyExc_RuntimeError,
            "Unable to initialize pickling for " __Pyx_FMT_TYPENAME, type_obj_name);
        __Pyx_DECREF_TypeName(type_obj_name);
    }
    ret = -1;
__PYX_GOOD:
#if !CYTHON_USE_PYTYPE_LOOKUP
    Py_XDECREF(object_reduce);
    Py_XDECREF(object_reduce_ex);
    Py_XDECREF(object_getstate);
    Py_XDECREF(getstate);
#endif
    Py_XDECREF(reduce);
    Py_XDECREF(reduce_ex);
    Py_XDECREF(reduce_cython);
    Py_XDECREF(setstate);
    Py_XDECREF(setstate_cython);
    return ret;
}

/* TypeImport */
#ifndef __PYX_HAVE_RT_ImportType_3_1_6
#define __PYX_HAVE_RT_ImportType_3_1_6
static PyTypeObject *__Pyx_ImportType_3_1_6(PyObject *module, const char *module_name, const char *class_name,
    size_t size, size_t alignment, enum __Pyx_ImportType_CheckSize_3_1_6 check_size)
{
    PyObject *result = 0;
    Py_ssize_t basicsize;
    Py_ssize_t itemsize;
#if defined(Py_LIMITED_API) || (defined(CYTHON_COMPILING_IN_LIMITED_API) && CYTHON_COMPILING_IN_LIMITED_API)
    PyObject *py_basicsize;
    PyObject *py_itemsize;
#endif
    result = PyObject_GetAttrString(module, class_name);
    if (!result)
        goto bad;
    if (!PyType_Check(result)) {
        PyErr_Format(PyExc_TypeError,
            "%.200s.%.200s is not a type object",
            module_name, class_name);
        goto bad;
    }
#if !( defined(Py_LIMITED_API) || (defined(CYTHON_COMPILING_IN_LIMITED_API) && CYTHON_COMPILING_IN_LIMITED_API) )
    basicsize = ((PyTypeObject *)result)->tp_basicsize;
    itemsize = ((PyTypeObject *)result)->tp_itemsize;
#else
    if (size == 0) {
        return (PyTypeObject *)result;
    }
    py_basicsize = PyObject_GetAttrString(result, "__basicsize__");
    if (!py_basicsize)
        goto bad;
    basicsize = PyLong_AsSsize_t(py_basicsize);
    Py_DECREF(py_basicsize);
    py_basicsize = 0;
    if (basicsize == (Py_ssize_t)-1 && PyErr_Occurred())
        goto bad;
    py_itemsize = PyObject_GetAttrString(result, "__itemsize__");
    if (!py_itemsize)
        goto bad;
    itemsize = PyLong_AsSsize_t(py_itemsize);
    Py_DECREF(py_itemsize);
    py_itemsize = 0;
    if (itemsize == (Py_ssize_t)-1 && PyErr_Occurred())
        goto bad;
#endif
    if (itemsize) {
        if (size % alignment) {
            alignment = size % alignment;
        }
        if (itemsize < (Py_ssize_t)alignment)
            itemsize = (Py_ssize_t)alignment;
    }
    if ((size_t)(basicsize + itemsize) < size) {
        PyErr_Format(PyExc_ValueError,
            "%.200s.%.200s size changed, may indicate binary incompatibility. "
            "Expected %zd from C header, got %zd from PyObject",
            module_name, class_name, size, basicsize+itemsize);
        goto bad;
    }
    if (check_size == __Pyx_ImportType_CheckSize_Error_3_1_6 &&
            ((size_t)basicsize > size || (size_t)(basicsize + itemsize) < size)) {
        PyErr_Format(PyExc_ValueError,
            "%.200s.%.200s size changed, may indicate binary incompatibility. "
            "Expected %zd from C header, got %zd-%zd from PyObject",
            module_name, class_name, size, basicsize, basicsize+itemsize);
        goto bad;
    }
    else if (check_size == __Pyx_ImportType_CheckSize_Warn_3_1_6 && (size_t)basicsize > size) {
        if (PyErr_WarnFormat(NULL, 0,
                "%.200s.%.200s size changed, may indicate binary incompatibility. "
                "Expected %zd from C header, got %zd from PyObject",
                module_name, class_name, size, basicsize) < 0) {
            goto bad;
        }
    }
    return (PyTypeObject *)result;
bad:
    Py_XDECREF(result);
    return NULL;
}
#endif

/* ImportDottedModule */
static PyObject *__Pyx__ImportDottedModule_Error(PyObject *name, PyObject *parts_tuple, Py_ssize_t count) {
    PyObject *partial_name = NULL, *slice = NULL, *sep = NULL;
    Py_ssize_t size;
    if (unlikely(PyErr_Occurred())) {
        PyErr_Clear();
    }
#if CYTHON_ASSUME_SAFE_SIZE
    size = PyTuple_GET_SIZE(parts_tuple);
#else
    size = PyTuple_Size(parts_tuple);
    if (size < 0) goto bad;
#endif
    if (likely(size == count)) {
        partial_name = name;
    } else {
        slice = PySequence_GetSlice(parts_tuple, 0, count);
        if (unlikely(!slice))
            goto bad;
        sep = PyUnicode_FromStringAndSize(".", 1);
        if (unlikely(!sep))
            goto bad;
        partial_name = PyUnicode_Join(sep, slice);
    }
    PyErr_Format(
        PyExc_ModuleNotFoundError,
        "No module named '%U'", partial_name);
bad:
    Py_XDECREF(sep);
    Py_XDECREF(slice);
    Py_XDECREF(partial_name);
    return NULL;
}
static PyObject *__Pyx__ImportDottedModule_Lookup(PyObject *name) {
    PyObject *imported_module;
#if (CYTHON_COMPILING_IN_PYPY && PYPY_VERSION_NUM  < 0x07030400) ||\
        CYTHON_COMPILING_IN_GRAAL
    PyObject *modules = PyImport_GetModuleDict();
    if (unlikely(!modules))
        return NULL;
    imported_module = __Pyx_PyDict_GetItemStr(modules, name);
    Py_XINCREF(imported_module);
#else
    imported_module = PyImport_GetModule(name);
#endif
    return imported_module;
}
static PyObject *__Pyx_ImportDottedModule_WalkParts(PyObject *module, PyObject *name, PyObject *parts_tuple) {
    Py_ssize_t i, nparts;
#if CYTHON_ASSUME_SAFE_SIZE
    nparts = PyTuple_GET_SIZE(parts_tuple);
#else
    nparts = PyTuple_Size(parts_tuple);
    if (nparts < 0) return NULL;
#endif
    for (i=1; i < nparts && module; i++) {
        PyObject *part, *submodule;
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
        part = PyTuple_GET_ITEM(parts_tuple, i);
#else
        part = __Pyx_PySequence_ITEM(parts_tuple, i);
        if (!part) return NULL;
#endif
        submodule = __Pyx_PyObject_GetAttrStrNoError(module, part);
#if !(CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS)
        Py_DECREF(part);
#endif
        Py_DECREF(module);
        module = submodule;
    }
    if (unlikely(!module)) {
        return __Pyx__ImportDottedModule_Error(name, parts_tuple, i);
    }
    return module;
}
static PyObject *__Pyx__ImportDottedModule(PyObject *name, PyObject *parts_tuple) {
    PyObject *imported_module;
    PyObject *module = __Pyx_Import(name, NULL, 0);
    if (!parts_tuple || unlikely(!module))
        return module;
    imported_module = __Pyx__ImportDottedModule_Lookup(name);
    if (likely(imported_module)) {
        Py_DECREF(module);
        return imported_module;
    }
    PyErr_Clear();
    return __Pyx_ImportDottedModule_WalkParts(module, name, parts_tuple);
}
static PyObject *__Pyx_ImportDottedModule(PyObject *name, PyObject *parts_tuple) {
#if CYTHON_COMPILING_IN_CPYTHON
    PyObject *module = __Pyx__ImportDottedModule_Lookup(name);
    if (likely(module)) {
        PyObject *spec = __Pyx_PyObject_GetAttrStrNoError(module, __pyx_mstate_global->__pyx_n_u_spec);
        if (likely(spec)) {
            PyObject *unsafe = __Pyx_PyObject_GetAttrStrNoError(spec, __pyx_mstate_global->__pyx_n_u_initializing);
            if (likely(!unsafe || !__Pyx_PyObject_IsTrue(unsafe))) {
                Py_DECREF(spec);
                spec = NULL;
            }
            Py_XDECREF(unsafe);
        }
        if (likely(!spec)) {
            PyErr_Clear();
            return module;
        }
        Py_DECREF(spec);
        Py_DECREF(module);
    } else if (PyErr_Occurred()) {
        PyErr_Clear();
    }
#endif
    return __Pyx__ImportDottedModule(name, parts_tuple);
}

/* ListPack */
static PyObject *__Pyx_PyList_Pack(Py_ssize_t n, ...) {
    va_list va;
    PyObject *l = PyList_New(n);
    va_start(va, n);
    if (unlikely(!l)) goto end;
    for (Py_ssize_t i=0; i<n; ++i) {
        PyObject *arg = va_arg(va, PyObject*);
        Py_INCREF(arg);
        if (__Pyx_PyList_SET_ITEM(l, i, arg) != (0)) {
            Py_CLEAR(l);
            goto end;
        }
    }
    end:
    va_end(va);
    return l;
}

/* Py3UpdateBases */
static PyObject*
__Pyx_PEP560_update_bases(PyObject *bases)
{
    Py_ssize_t i, j, size_bases;
    PyObject *base = NULL, *meth, *new_base, *result, *new_bases = NULL;
#if CYTHON_ASSUME_SAFE_SIZE
    size_bases = PyTuple_GET_SIZE(bases);
#else
    size_bases = PyTuple_Size(bases);
    if (size_bases < 0) return NULL;
#endif
    for (i = 0; i < size_bases; i++) {
#if CYTHON_AVOID_BORROWED_REFS
        Py_CLEAR(base);
#endif
#if CYTHON_ASSUME_SAFE_MACROS
        base = PyTuple_GET_ITEM(bases, i);
#else
        base = PyTuple_GetItem(bases, i);
        if (!base) goto error;
#endif
#if CYTHON_AVOID_BORROWED_REFS
        Py_INCREF(base);
#endif
        if (PyType_Check(base)) {
            if (new_bases) {
                if (PyList_Append(new_bases, base) < 0) {
                    goto error;
                }
            }
            continue;
        }
        meth = __Pyx_PyObject_GetAttrStrNoError(base, __pyx_mstate_global->__pyx_n_u_mro_entries);
        if (!meth && PyErr_Occurred()) {
            goto error;
        }
        if (!meth) {
            if (new_bases) {
                if (PyList_Append(new_bases, base) < 0) {
                    goto error;
                }
            }
            continue;
        }
        new_base = __Pyx_PyObject_CallOneArg(meth, bases);
        Py_DECREF(meth);
        if (!new_base) {
            goto error;
        }
        if (!PyTuple_Check(new_base)) {
            PyErr_SetString(PyExc_TypeError,
                            "__mro_entries__ must return a tuple");
            Py_DECREF(new_base);
            goto error;
        }
        if (!new_bases) {
            if (!(new_bases = PyList_New(i))) {
                goto error;
            }
            for (j = 0; j < i; j++) {
                PyObject *base_from_list;
#if CYTHON_ASSUME_SAFE_MACROS
                base_from_list = PyTuple_GET_ITEM(bases, j);
                PyList_SET_ITEM(new_bases, j, base_from_list);
                Py_INCREF(base_from_list);
#else
                base_from_list = PyTuple_GetItem(bases, j);
                if (!base_from_list) goto error;
                Py_INCREF(base_from_list);
                if (PyList_SetItem(new_bases, j, base_from_list) < 0) goto error;
#endif
            }
        }
#if CYTHON_ASSUME_SAFE_SIZE
        j = PyList_GET_SIZE(new_bases);
#else
        j = PyList_Size(new_bases);
        if (j < 0) goto error;
#endif
        if (PyList_SetSlice(new_bases, j, j, new_base) < 0) {
            goto error;
        }
        Py_DECREF(new_base);
    }
    if (!new_bases) {
        Py_INCREF(bases);
        return bases;
    }
    result = PyList_AsTuple(new_bases);
    Py_DECREF(new_bases);
#if CYTHON_AVOID_BORROWED_REFS
    Py_XDECREF(base);
#endif
    return result;
error:
    Py_XDECREF(new_bases);
#if CYTHON_AVOID_BORROWED_REFS
    Py_XDECREF(base);
#endif
    return NULL;
}

/* CalculateMetaclass */
static PyObject *__Pyx_CalculateMetaclass(PyTypeObject *metaclass, PyObject *bases) {
    Py_ssize_t i, nbases;
#if CYTHON_ASSUME_SAFE_SIZE
    nbases = PyTuple_GET_SIZE(bases);
#else
    nbases = PyTuple_Size(bases);
    if (nbases < 0) return NULL;
#endif
    for (i=0; i < nbases; i++) {
        PyTypeObject *tmptype;
#if CYTHON_ASSUME_SAFE_MACROS
        PyObject *tmp = PyTuple_GET_ITEM(bases, i);
#else
        PyObject *tmp = PyTuple_GetItem(bases, i);
        if (!tmp) return NULL;
#endif
        tmptype = Py_TYPE(tmp);
        if (!metaclass) {
            metaclass = tmptype;
            continue;
        }
        if (PyType_IsSubtype(metaclass, tmptype))
            continue;
        if (PyType_IsSubtype(tmptype, metaclass)) {
            metaclass = tmptype;
            continue;
        }
        PyErr_SetString(PyExc_TypeError,
                        "metaclass conflict: "
                        "the metaclass of a derived class "
                        "must be a (non-strict) subclass "
                        "of the metaclasses of all its bases");
        return NULL;
    }
    if (!metaclass) {
        metaclass = &PyType_Type;
    }
    Py_INCREF((PyObject*) metaclass);
    return (PyObject*) metaclass;
}

/* FetchSharedCythonModule */
static PyObject *__Pyx_FetchSharedCythonABIModule(void) {
    return __Pyx_PyImport_AddModuleRef(__PYX_ABI_MODULE_NAME);
}

/* dict_setdefault */
static CYTHON_INLINE PyObject *__Pyx_PyDict_SetDefault(PyObject *d, PyObject *key, PyObject *default_value,
                                                       int is_safe_type) {
    PyObject* value;
    CYTHON_MAYBE_UNUSED_VAR(is_safe_type);
#if CYTHON_COMPILING_IN_LIMITED_API
    value = PyObject_CallMethod(d, "setdefault", "OO", key, default_value);
#elif PY_VERSION_HEX >= 0x030d0000
    PyDict_SetDefaultRef(d, key, default_value, &value);
#else
    value = PyDict_SetDefault(d, key, default_value);
    if (unlikely(!value)) return NULL;
    Py_INCREF(value);
#endif
    return value;
}

/* FetchCommonType */
#if __PYX_LIMITED_VERSION_HEX < 0x030C0000
static PyObject* __Pyx_PyType_FromMetaclass(PyTypeObject *metaclass, PyObject *module, PyType_Spec *spec, PyObject *bases) {
    PyObject *result = __Pyx_PyType_FromModuleAndSpec(module, spec, bases);
    if (result && metaclass) {
        PyObject *old_tp = (PyObject*)Py_TYPE(result);
    Py_INCREF((PyObject*)metaclass);
#if __PYX_LIMITED_VERSION_HEX >= 0x03090000
        Py_SET_TYPE(result, metaclass);
#else
        result->ob_type = metaclass;
#endif
        Py_DECREF(old_tp);
    }
    return result;
}
#else
#define __Pyx_PyType_FromMetaclass(me, mo, s, b) PyType_FromMetaclass(me, mo, s, b)
#endif
static int __Pyx_VerifyCachedType(PyObject *cached_type,
                               const char *name,
                               Py_ssize_t expected_basicsize) {
    Py_ssize_t basicsize;
    if (!PyType_Check(cached_type)) {
        PyErr_Format(PyExc_TypeError,
            "Shared Cython type %.200s is not a type object", name);
        return -1;
    }
    if (expected_basicsize == 0) {
        return 0; // size is inherited, nothing useful to check
    }
#if CYTHON_COMPILING_IN_LIMITED_API
    PyObject *py_basicsize;
    py_basicsize = PyObject_GetAttrString(cached_type, "__basicsize__");
    if (unlikely(!py_basicsize)) return -1;
    basicsize = PyLong_AsSsize_t(py_basicsize);
    Py_DECREF(py_basicsize);
    py_basicsize = NULL;
    if (unlikely(basicsize == (Py_ssize_t)-1) && PyErr_Occurred()) return -1;
#else
    basicsize = ((PyTypeObject*) cached_type)->tp_basicsize;
#endif
    if (basicsize != expected_basicsize) {
        PyErr_Format(PyExc_TypeError,
            "Shared Cython type %.200s has the wrong size, try recompiling",
            name);
        return -1;
    }
    return 0;
}
static PyTypeObject *__Pyx_FetchCommonTypeFromSpec(PyTypeObject *metaclass, PyObject *module, PyType_Spec *spec, PyObject *bases) {
    PyObject *abi_module = NULL, *cached_type = NULL, *abi_module_dict, *new_cached_type, *py_object_name;
    int get_item_ref_result;
    const char* object_name = strrchr(spec->name, '.');
    object_name = object_name ? object_name+1 : spec->name;
    py_object_name = PyUnicode_FromString(object_name);
    if (!py_object_name) return NULL;
    abi_module = __Pyx_FetchSharedCythonABIModule();
    if (!abi_module) goto done;
    abi_module_dict = PyModule_GetDict(abi_module);
    if (!abi_module_dict) goto done;
    get_item_ref_result = __Pyx_PyDict_GetItemRef(abi_module_dict, py_object_name, &cached_type);
    if (get_item_ref_result == 1) {
        if (__Pyx_VerifyCachedType(
              cached_type,
              object_name,
              spec->basicsize) < 0) {
            goto bad;
        }
        goto done;
    } else if (unlikely(get_item_ref_result == -1)) {
        goto bad;
    }
    CYTHON_UNUSED_VAR(module);
    cached_type = __Pyx_PyType_FromMetaclass(metaclass, abi_module, spec, bases);
    if (unlikely(!cached_type)) goto bad;
    if (unlikely(__Pyx_fix_up_extension_type_from_spec(spec, (PyTypeObject *) cached_type) < 0)) goto bad;
    new_cached_type = __Pyx_PyDict_SetDefault(abi_module_dict, py_object_name, cached_type, 1);
    if (unlikely(new_cached_type != cached_type)) {
        if (unlikely(!new_cached_type)) goto bad;
        Py_DECREF(cached_type);
        cached_type = new_cached_type;
        if (__Pyx_VerifyCachedType(
                cached_type,
                object_name,
                spec->basicsize) < 0) {
            goto bad;
        }
        goto done;
    } else {
        Py_DECREF(new_cached_type);
    }
done:
    Py_XDECREF(abi_module);
    Py_DECREF(py_object_name);
    assert(cached_type == NULL || PyType_Check(cached_type));
    return (PyTypeObject *) cached_type;
bad:
    Py_XDECREF(cached_type);
    cached_type = NULL;
    goto done;
}

/* CommonTypesMetaclass */
static PyObject* __pyx_CommonTypesMetaclass_get_module(CYTHON_UNUSED PyObject *self, CYTHON_UNUSED void* context) {
    return PyUnicode_FromString(__PYX_ABI_MODULE_NAME);
}
static PyGetSetDef __pyx_CommonTypesMetaclass_getset[] = {
    {"__module__", __pyx_CommonTypesMetaclass_get_module, NULL, NULL, NULL},
    {0, 0, 0, 0, 0}
};
static PyType_Slot __pyx_CommonTypesMetaclass_slots[] = {
    {Py_tp_getset, (void *)__pyx_CommonTypesMetaclass_getset},
    {0, 0}
};
static PyType_Spec __pyx_CommonTypesMetaclass_spec = {
    __PYX_TYPE_MODULE_PREFIX "_common_types_metatype",
    0,
    0,
#if PY_VERSION_HEX >= 0x030A0000
    Py_TPFLAGS_IMMUTABLETYPE |
    Py_TPFLAGS_DISALLOW_INSTANTIATION |
#endif
    Py_TPFLAGS_DEFAULT,
    __pyx_CommonTypesMetaclass_slots
};
static int __pyx_CommonTypesMetaclass_init(PyObject *module) {
    __pyx_mstatetype *mstate = __Pyx_PyModule_GetState(module);
    PyObject *bases = PyTuple_Pack(1, &PyType_Type);
    if (unlikely(!bases)) {
        return -1;
    }
    mstate->__pyx_CommonTypesMetaclassType = __Pyx_FetchCommonTypeFromSpec(NULL, module, &__pyx_CommonTypesMetaclass_spec, bases);
    Py_DECREF(bases);
    if (unlikely(mstate->__pyx_CommonTypesMetaclassType == NULL)) {
        return -1;
    }
    return 0;
}

/* PyMethodNew */
#if CYTHON_COMPILING_IN_LIMITED_API
static PyObject *__Pyx_PyMethod_New(PyObject *func, PyObject *self, PyObject *typ) {
    PyObject *result;
    CYTHON_UNUSED_VAR(typ);
    if (!self)
        return __Pyx_NewRef(func);
    #if __PYX_LIMITED_VERSION_HEX >= 0x030C0000
    {
        PyObject *args[] = {func, self};
        result = PyObject_Vectorcall(__pyx_mstate_global->__Pyx_CachedMethodType, args, 2, NULL);
    }
    #else
    result = PyObject_CallFunctionObjArgs(__pyx_mstate_global->__Pyx_CachedMethodType, func, self, NULL);
    #endif
    return result;
}
#else
static PyObject *__Pyx_PyMethod_New(PyObject *func, PyObject *self, PyObject *typ) {
    CYTHON_UNUSED_VAR(typ);
    if (!self)
        return __Pyx_NewRef(func);
    return PyMethod_New(func, self);
}
#endif

/* PyVectorcallFastCallDict */
#if CYTHON_METH_FASTCALL && (CYTHON_VECTORCALL || CYTHON_BACKPORT_VECTORCALL)
static PyObject *__Pyx_PyVectorcall_FastCallDict_kw(PyObject *func, __pyx_vectorcallfunc vc, PyObject *const *args, size_t nargs, PyObject *kw)
{
    PyObject *res = NULL;
    PyObject *kwnames;
    PyObject **newargs;
    PyObject **kwvalues;
    Py_ssize_t i, pos;
    size_t j;
    PyObject *key, *value;
    unsigned long keys_are_strings;
    #if !CYTHON_ASSUME_SAFE_SIZE
    Py_ssize_t nkw = PyDict_Size(kw);
    if (unlikely(nkw == -1)) return NULL;
    #else
    Py_ssize_t nkw = PyDict_GET_SIZE(kw);
    #endif
    newargs = (PyObject **)PyMem_Malloc((nargs + (size_t)nkw) * sizeof(args[0]));
    if (unlikely(newargs == NULL)) {
        PyErr_NoMemory();
        return NULL;
    }
    for (j = 0; j < nargs; j++) newargs[j] = args[j];
    kwnames = PyTuple_New(nkw);
    if (unlikely(kwnames == NULL)) {
        PyMem_Free(newargs);
        return NULL;
    }
    kwvalues = newargs + nargs;
    pos = i = 0;
    keys_are_strings = Py_TPFLAGS_UNICODE_SUBCLASS;
    while (PyDict_Next(kw, &pos, &key, &value)) {
        keys_are_strings &=
        #if CYTHON_COMPILING_IN_LIMITED_API
            PyType_GetFlags(Py_TYPE(key));
        #else
            Py_TYPE(key)->tp_flags;
        #endif
        Py_INCREF(key);
        Py_INCREF(value);
        #if !CYTHON_ASSUME_SAFE_MACROS
        if (unlikely(PyTuple_SetItem(kwnames, i, key) < 0)) goto cleanup;
        #else
        PyTuple_SET_ITEM(kwnames, i, key);
        #endif
        kwvalues[i] = value;
        i++;
    }
    if (unlikely(!keys_are_strings)) {
        PyErr_SetString(PyExc_TypeError, "keywords must be strings");
        goto cleanup;
    }
    res = vc(func, newargs, nargs, kwnames);
cleanup:
    Py_DECREF(kwnames);
    for (i = 0; i < nkw; i++)
        Py_DECREF(kwvalues[i]);
    PyMem_Free(newargs);
    return res;
}
static CYTHON_INLINE PyObject *__Pyx_PyVectorcall_FastCallDict(PyObject *func, __pyx_vectorcallfunc vc, PyObject *const *args, size_t nargs, PyObject *kw)
{
    Py_ssize_t kw_size =
        likely(kw == NULL) ?
        0 :
#if !CYTHON_ASSUME_SAFE_SIZE
        PyDict_Size(kw);
#else
        PyDict_GET_SIZE(kw);
#endif
    if (kw_size == 0) {
        return vc(func, args, nargs, NULL);
    }
#if !CYTHON_ASSUME_SAFE_SIZE
    else if (unlikely(kw_size == -1)) {
        return NULL;
    }
#endif
    return __Pyx_PyVectorcall_FastCallDict_kw(func, vc, args, nargs, kw);
}
#endif

/* CythonFunctionShared */
#if CYTHON_COMPILING_IN_LIMITED_API
static CYTHON_INLINE int __Pyx__IsSameCyOrCFunctionNoMethod(PyObject *func, void (*cfunc)(void)) {
    if (__Pyx_CyFunction_Check(func)) {
        return PyCFunction_GetFunction(((__pyx_CyFunctionObject*)func)->func) == (PyCFunction) cfunc;
    } else if (PyCFunction_Check(func)) {
        return PyCFunction_GetFunction(func) == (PyCFunction) cfunc;
    }
    return 0;
}
static CYTHON_INLINE int __Pyx__IsSameCyOrCFunction(PyObject *func, void (*cfunc)(void)) {
    if ((PyObject*)Py_TYPE(func) == __pyx_mstate_global->__Pyx_CachedMethodType) {
        int result;
        PyObject *newFunc = PyObject_GetAttr(func, __pyx_mstate_global->__pyx_n_u_func);
        if (unlikely(!newFunc)) {
            PyErr_Clear(); // It's only an optimization, so don't throw an error
            return 0;
        }
        result = __Pyx__IsSameCyOrCFunctionNoMethod(newFunc, cfunc);
        Py_DECREF(newFunc);
        return result;
    }
    return __Pyx__IsSameCyOrCFunctionNoMethod(func, cfunc);
}
#else
static CYTHON_INLINE int __Pyx__IsSameCyOrCFunction(PyObject *func, void (*cfunc)(void)) {
    if (PyMethod_Check(func)) {
        func = PyMethod_GET_FUNCTION(func);
    }
    return __Pyx_CyOrPyCFunction_Check(func) && __Pyx_CyOrPyCFunction_GET_FUNCTION(func) == (PyCFunction) cfunc;
}
#endif
static CYTHON_INLINE void __Pyx__CyFunction_SetClassObj(__pyx_CyFunctionObject* f, PyObject* classobj) {
#if PY_VERSION_HEX < 0x030900B1 || CYTHON_COMPILING_IN_LIMITED_API
    __Pyx_Py_XDECREF_SET(
        __Pyx_CyFunction_GetClassObj(f),
            ((classobj) ? __Pyx_NewRef(classobj) : NULL));
#else
    __Pyx_Py_XDECREF_SET(
        ((PyCMethodObject *) (f))->mm_class,
        (PyTypeObject*)((classobj) ? __Pyx_NewRef(classobj) : NULL));
#endif
}
static PyObject *
__Pyx_CyFunction_get_doc_locked(__pyx_CyFunctionObject *op)
{
    if (unlikely(op->func_doc == NULL)) {
#if CYTHON_COMPILING_IN_LIMITED_API
        op->func_doc = PyObject_GetAttrString(op->func, "__doc__");
        if (unlikely(!op->func_doc)) return NULL;
#else
        if (((PyCFunctionObject*)op)->m_ml->ml_doc) {
            op->func_doc = PyUnicode_FromString(((PyCFunctionObject*)op)->m_ml->ml_doc);
            if (unlikely(op->func_doc == NULL))
                return NULL;
        } else {
            Py_INCREF(Py_None);
            return Py_None;
        }
#endif
    }
    Py_INCREF(op->func_doc);
    return op->func_doc;
}
static PyObject *
__Pyx_CyFunction_get_doc(__pyx_CyFunctionObject *op, void *closure) {
    PyObject *result;
    CYTHON_UNUSED_VAR(closure);
    __Pyx_BEGIN_CRITICAL_SECTION(op);
    result = __Pyx_CyFunction_get_doc_locked(op);
    __Pyx_END_CRITICAL_SECTION();
    return result;
}
static int
__Pyx_CyFunction_set_doc(__pyx_CyFunctionObject *op, PyObject *value, void *context)
{
    CYTHON_UNUSED_VAR(context);
    if (value == NULL) {
        value = Py_None;
    }
    Py_INCREF(value);
    __Pyx_BEGIN_CRITICAL_SECTION(op);
    __Pyx_Py_XDECREF_SET(op->func_doc, value);
    __Pyx_END_CRITICAL_SECTION();
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_name_locked(__pyx_CyFunctionObject *op)
{
    if (unlikely(op->func_name == NULL)) {
#if CYTHON_COMPILING_IN_LIMITED_API
        op->func_name = PyObject_GetAttrString(op->func, "__name__");
#else
        op->func_name = PyUnicode_InternFromString(((PyCFunctionObject*)op)->m_ml->ml_name);
#endif
        if (unlikely(op->func_name == NULL))
            return NULL;
    }
    Py_INCREF(op->func_name);
    return op->func_name;
}
static PyObject *
__Pyx_CyFunction_get_name(__pyx_CyFunctionObject *op, void *context)
{
    PyObject *result = NULL;
    CYTHON_UNUSED_VAR(context);
    __Pyx_BEGIN_CRITICAL_SECTION(op);
    result = __Pyx_CyFunction_get_name_locked(op);
    __Pyx_END_CRITICAL_SECTION();
    return result;
}
static int
__Pyx_CyFunction_set_name(__pyx_CyFunctionObject *op, PyObject *value, void *context)
{
    CYTHON_UNUSED_VAR(context);
    if (unlikely(value == NULL || !PyUnicode_Check(value))) {
        PyErr_SetString(PyExc_TypeError,
                        "__name__ must be set to a string object");
        return -1;
    }
    Py_INCREF(value);
    __Pyx_BEGIN_CRITICAL_SECTION(op);
    __Pyx_Py_XDECREF_SET(op->func_name, value);
    __Pyx_END_CRITICAL_SECTION();
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_qualname(__pyx_CyFunctionObject *op, void *context)
{
    CYTHON_UNUSED_VAR(context);
    PyObject *result;
    __Pyx_BEGIN_CRITICAL_SECTION(op);
    Py_INCREF(op->func_qualname);
    result = op->func_qualname;
    __Pyx_END_CRITICAL_SECTION();
    return result;
}
static int
__Pyx_CyFunction_set_qualname(__pyx_CyFunctionObject *op, PyObject *value, void *context)
{
    CYTHON_UNUSED_VAR(context);
    if (unlikely(value == NULL || !PyUnicode_Check(value))) {
        PyErr_SetString(PyExc_TypeError,
                        "__qualname__ must be set to a string object");
        return -1;
    }
    Py_INCREF(value);
    __Pyx_BEGIN_CRITICAL_SECTION(op);
    __Pyx_Py_XDECREF_SET(op->func_qualname, value);
    __Pyx_END_CRITICAL_SECTION();
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_dict_locked(__pyx_CyFunctionObject *op)
{
    if (unlikely(op->func_dict == NULL)) {
        op->func_dict = PyDict_New();
        if (unlikely(op->func_dict == NULL))
            return NULL;
    }
    Py_INCREF(op->func_dict);
    return op->func_dict;
}
static PyObject *
__Pyx_CyFunction_get_dict(__pyx_CyFunctionObject *op, void *context)
{
    CYTHON_UNUSED_VAR(context);
    PyObject *result;
    __Pyx_BEGIN_CRITICAL_SECTION(op);
    result = __Pyx_CyFunction_get_dict_locked(op);
    __Pyx_END_CRITICAL_SECTION();
    return result;
}
static int
__Pyx_CyFunction_set_dict(__pyx_CyFunctionObject *op, PyObject *value, void *context)
{
    CYTHON_UNUSED_VAR(context);
    if (unlikely(value == NULL)) {
        PyErr_SetString(PyExc_TypeError,
               "function's dictionary may not be deleted");
        return -1;
    }
    if (unlikely(!PyDict_Check(value))) {
        PyErr_SetString(PyExc_TypeError,
               "setting function's dictionary to a non-dict");
        return -1;
    }
    Py_INCREF(value);
    __Pyx_BEGIN_CRITICAL_SECTION(op);
    __Pyx_Py_XDECREF_SET(op->func_dict, value);
    __Pyx_END_CRITICAL_SECTION();
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_globals(__pyx_CyFunctionObject *op, void *context)
{
    CYTHON_UNUSED_VAR(context);
    Py_INCREF(op->func_globals);
    return op->func_globals;
}
static PyObject *
__Pyx_CyFunction_get_closure(__pyx_CyFunctionObject *op, void *context)
{
    CYTHON_UNUSED_VAR(op);
    CYTHON_UNUSED_VAR(context);
    Py_INCREF(Py_None);
    return Py_None;
}
static PyObject *
__Pyx_CyFunction_get_code(__pyx_CyFunctionObject *op, void *context)
{
    PyObject* result = (op->func_code) ? op->func_code : Py_None;
    CYTHON_UNUSED_VAR(context);
    Py_INCREF(result);
    return result;
}
static int
__Pyx_CyFunction_init_defaults(__pyx_CyFunctionObject *op) {
    int result = 0;
    PyObject *res = op->defaults_getter((PyObject *) op);
    if (unlikely(!res))
        return -1;
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    op->defaults_tuple = PyTuple_GET_ITEM(res, 0);
    Py_INCREF(op->defaults_tuple);
    op->defaults_kwdict = PyTuple_GET_ITEM(res, 1);
    Py_INCREF(op->defaults_kwdict);
    #else
    op->defaults_tuple = __Pyx_PySequence_ITEM(res, 0);
    if (unlikely(!op->defaults_tuple)) result = -1;
    else {
        op->defaults_kwdict = __Pyx_PySequence_ITEM(res, 1);
        if (unlikely(!op->defaults_kwdict)) result = -1;
    }
    #endif
    Py_DECREF(res);
    return result;
}
static int
__Pyx_CyFunction_set_defaults(__pyx_CyFunctionObject *op, PyObject* value, void *context) {
    CYTHON_UNUSED_VAR(context);
    if (!value) {
        value = Py_None;
    } else if (unlikely(value != Py_None && !PyTuple_Check(value))) {
        PyErr_SetString(PyExc_TypeError,
                        "__defaults__ must be set to a tuple object");
        return -1;
    }
    PyErr_WarnEx(PyExc_RuntimeWarning, "changes to cyfunction.__defaults__ will not "
                 "currently affect the values used in function calls", 1);
    Py_INCREF(value);
    __Pyx_BEGIN_CRITICAL_SECTION(op);
    __Pyx_Py_XDECREF_SET(op->defaults_tuple, value);
    __Pyx_END_CRITICAL_SECTION();
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_defaults_locked(__pyx_CyFunctionObject *op) {
    PyObject* result = op->defaults_tuple;
    if (unlikely(!result)) {
        if (op->defaults_getter) {
            if (unlikely(__Pyx_CyFunction_init_defaults(op) < 0)) return NULL;
            result = op->defaults_tuple;
        } else {
            result = Py_None;
        }
    }
    Py_INCREF(result);
    return result;
}
static PyObject *
__Pyx_CyFunction_get_defaults(__pyx_CyFunctionObject *op, void *context) {
    PyObject* result = NULL;
    CYTHON_UNUSED_VAR(context);
    __Pyx_BEGIN_CRITICAL_SECTION(op);
    result = __Pyx_CyFunction_get_defaults_locked(op);
    __Pyx_END_CRITICAL_SECTION();
    return result;
}
static int
__Pyx_CyFunction_set_kwdefaults(__pyx_CyFunctionObject *op, PyObject* value, void *context) {
    CYTHON_UNUSED_VAR(context);
    if (!value) {
        value = Py_None;
    } else if (unlikely(value != Py_None && !PyDict_Check(value))) {
        PyErr_SetString(PyExc_TypeError,
                        "__kwdefaults__ must be set to a dict object");
        return -1;
    }
    PyErr_WarnEx(PyExc_RuntimeWarning, "changes to cyfunction.__kwdefaults__ will not "
                 "currently affect the values used in function calls", 1);
    Py_INCREF(value);
    __Pyx_BEGIN_CRITICAL_SECTION(op);
    __Pyx_Py_XDECREF_SET(op->defaults_kwdict, value);
    __Pyx_END_CRITICAL_SECTION();
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_kwdefaults_locked(__pyx_CyFunctionObject *op) {
    PyObject* result = op->defaults_kwdict;
    if (unlikely(!result)) {
        if (op->defaults_getter) {
            if (unlikely(__Pyx_CyFunction_init_defaults(op) < 0)) return NULL;
            result = op->defaults_kwdict;
        } else {
            result = Py_None;
        }
    }
    Py_INCREF(result);
    return result;
}
static PyObject *
__Pyx_CyFunction_get_kwdefaults(__pyx_CyFunctionObject *op, void *context) {
    PyObject* result;
    CYTHON_UNUSED_VAR(context);
    __Pyx_BEGIN_CRITICAL_SECTION(op);
    result = __Pyx_CyFunction_get_kwdefaults_locked(op);
    __Pyx_END_CRITICAL_SECTION();
    return result;
}
static int
__Pyx_CyFunction_set_annotations(__pyx_CyFunctionObject *op, PyObject* value, void *context) {
    CYTHON_UNUSED_VAR(context);
    if (!value || value == Py_None) {
        value = NULL;
    } else if (unlikely(!PyDict_Check(value))) {
        PyErr_SetString(PyExc_TypeError,
                        "__annotations__ must be set to a dict object");
        return -1;
    }
    Py_XINCREF(value);
    __Pyx_BEGIN_CRITICAL_SECTION(op);
    __Pyx_Py_XDECREF_SET(op->func_annotations, value);
    __Pyx_END_CRITICAL_SECTION();
    return 0;
}
static PyObject *
__Pyx_CyFunction_get_annotations_locked(__pyx_CyFunctionObject *op) {
    PyObject* result = op->func_annotations;
    if (unlikely(!result)) {
        result = PyDict_New();
        if (unlikely(!result)) return NULL;
        op->func_annotations = result;
    }
    Py_INCREF(result);
    return result;
}
static PyObject *
__Pyx_CyFunction_get_annotations(__pyx_CyFunctionObject *op, void *context) {
    PyObject *result;
    CYTHON_UNUSED_VAR(context);
    __Pyx_BEGIN_CRITICAL_SECTION(op);
    result = __Pyx_CyFunction_get_annotations_locked(op);
    __Pyx_END_CRITICAL_SECTION();
    return result;
}
static PyObject *
__Pyx_CyFunction_get_is_coroutine_value(__pyx_CyFunctionObject *op) {
    int is_coroutine = op->flags & __Pyx_CYFUNCTION_COROUTINE;
    if (is_coroutine) {
        PyObject *is_coroutine_value, *module, *fromlist, *marker = __pyx_mstate_global->__pyx_n_u_is_coroutine;
        fromlist = PyList_New(1);
        if (unlikely(!fromlist)) return NULL;
        Py_INCREF(marker);
#if CYTHON_ASSUME_SAFE_MACROS
        PyList_SET_ITEM(fromlist, 0, marker);
#else
        if (unlikely(PyList_SetItem(fromlist, 0, marker) < 0)) {
            Py_DECREF(marker);
            Py_DECREF(fromlist);
            return NULL;
        }
#endif
        module = PyImport_ImportModuleLevelObject(__pyx_mstate_global->__pyx_n_u_asyncio_coroutines, NULL, NULL, fromlist, 0);
        Py_DECREF(fromlist);
        if (unlikely(!module)) goto ignore;
        is_coroutine_value = __Pyx_PyObject_GetAttrStr(module, marker);
        Py_DECREF(module);
        if (likely(is_coroutine_value)) {
            return is_coroutine_value;
        }
ignore:
        PyErr_Clear();
    }
    return __Pyx_PyBool_FromLong(is_coroutine);
}
static PyObject *
__Pyx_CyFunction_get_is_coroutine(__pyx_CyFunctionObject *op, void *context) {
    PyObject *result;
    CYTHON_UNUSED_VAR(context);
    if (op->func_is_coroutine) {
        return __Pyx_NewRef(op->func_is_coroutine);
    }
    result = __Pyx_CyFunction_get_is_coroutine_value(op);
    if (unlikely(!result))
        return NULL;
    __Pyx_BEGIN_CRITICAL_SECTION(op);
    if (op->func_is_coroutine) {
        Py_DECREF(result);
        result = __Pyx_NewRef(op->func_is_coroutine);
    } else {
        op->func_is_coroutine = __Pyx_NewRef(result);
    }
    __Pyx_END_CRITICAL_SECTION();
    return result;
}
static void __Pyx_CyFunction_raise_argument_count_error(__pyx_CyFunctionObject *func, const char* message, Py_ssize_t size) {
#if CYTHON_COMPILING_IN_LIMITED_API
    PyObject *py_name = __Pyx_CyFunction_get_name(func, NULL);
    if (!py_name) return;
    PyErr_Format(PyExc_TypeError,
        "%.200S() %s (%" CYTHON_FORMAT_SSIZE_T "d given)",
        py_name, message, size);
    Py_DECREF(py_name);
#else
    const char* name = ((PyCFunctionObject*)func)->m_ml->ml_name;
    PyErr_Format(PyExc_TypeError,
        "%.200s() %s (%" CYTHON_FORMAT_SSIZE_T "d given)",
        name, message, size);
#endif
}
static void __Pyx_CyFunction_raise_type_error(__pyx_CyFunctionObject *func, const char* message) {
#if CYTHON_COMPILING_IN_LIMITED_API
    PyObject *py_name = __Pyx_CyFunction_get_name(func, NULL);
    if (!py_name) return;
    PyErr_Format(PyExc_TypeError,
        "%.200S() %s",
        py_name, message);
    Py_DECREF(py_name);
#else
    const char* name = ((PyCFunctionObject*)func)->m_ml->ml_name;
    PyErr_Format(PyExc_TypeError,
        "%.200s() %s",
        name, message);
#endif
}
#if CYTHON_COMPILING_IN_LIMITED_API
static PyObject *
__Pyx_CyFunction_get_module(__pyx_CyFunctionObject *op, void *context) {
    CYTHON_UNUSED_VAR(context);
    return PyObject_GetAttrString(op->func, "__module__");
}
static int
__Pyx_CyFunction_set_module(__pyx_CyFunctionObject *op, PyObject* value, void *context) {
    CYTHON_UNUSED_VAR(context);
    return PyObject_SetAttrString(op->func, "__module__", value);
}
#endif
static PyGetSetDef __pyx_CyFunction_getsets[] = {
    {"func_doc", (getter)__Pyx_CyFunction_get_doc, (setter)__Pyx_CyFunction_set_doc, 0, 0},
    {"__doc__",  (getter)__Pyx_CyFunction_get_doc, (setter)__Pyx_CyFunction_set_doc, 0, 0},
    {"func_name", (getter)__Pyx_CyFunction_get_name, (setter)__Pyx_CyFunction_set_name, 0, 0},
    {"__name__", (getter)__Pyx_CyFunction_get_name, (setter)__Pyx_CyFunction_set_name, 0, 0},
    {"__qualname__", (getter)__Pyx_CyFunction_get_qualname, (setter)__Pyx_CyFunction_set_qualname, 0, 0},
    {"func_dict", (getter)__Pyx_CyFunction_get_dict, (setter)__Pyx_CyFunction_set_dict, 0, 0},
    {"__dict__", (getter)__Pyx_CyFunction_get_dict, (setter)__Pyx_CyFunction_set_dict, 0, 0},
    {"func_globals", (getter)__Pyx_CyFunction_get_globals, 0, 0, 0},
    {"__globals__", (getter)__Pyx_CyFunction_get_globals, 0, 0, 0},
    {"func_closure", (getter)__Pyx_CyFunction_get_closure, 0, 0, 0},
    {"__closure__", (getter)__Pyx_CyFunction_get_closure, 0, 0, 0},
    {"func_code", (getter)__Pyx_CyFunction_get_code, 0, 0, 0},
    {"__code__", (getter)__Pyx_CyFunction_get_code, 0, 0, 0},
    {"func_defaults", (getter)__Pyx_CyFunction_get_defaults, (setter)__Pyx_CyFunction_set_defaults, 0, 0},
    {"__defaults__", (getter)__Pyx_CyFunction_get_defaults, (setter)__Pyx_CyFunction_set_defaults, 0, 0},
    {"__kwdefaults__", (getter)__Pyx_CyFunction_get_kwdefaults, (setter)__Pyx_CyFunction_set_kwdefaults, 0, 0},
    {"__annotations__", (getter)__Pyx_CyFunction_get_annotations, (setter)__Pyx_CyFunction_set_annotations, 0, 0},
    {"_is_coroutine", (getter)__Pyx_CyFunction_get_is_coroutine, 0, 0, 0},
#if CYTHON_COMPILING_IN_LIMITED_API
    {"__module__", (getter)__Pyx_CyFunction_get_module, (setter)__Pyx_CyFunction_set_module, 0, 0},
#endif
    {0, 0, 0, 0, 0}
};
static PyMemberDef __pyx_CyFunction_members[] = {
#if !CYTHON_COMPILING_IN_LIMITED_API
    {"__module__", T_OBJECT, offsetof(PyCFunctionObject, m_module), 0, 0},
#endif
    {"__dictoffset__", T_PYSSIZET, offsetof(__pyx_CyFunctionObject, func_dict), READONLY, 0},
#if CYTHON_METH_FASTCALL
#if CYTHON_BACKPORT_VECTORCALL || CYTHON_COMPILING_IN_LIMITED_API
    {"__vectorcalloffset__", T_PYSSIZET, offsetof(__pyx_CyFunctionObject, func_vectorcall), READONLY, 0},
#else
    {"__vectorcalloffset__", T_PYSSIZET, offsetof(PyCFunctionObject, vectorcall), READONLY, 0},
#endif
#if CYTHON_COMPILING_IN_LIMITED_API
    {"__weaklistoffset__", T_PYSSIZET, offsetof(__pyx_CyFunctionObject, func_weakreflist), READONLY, 0},
#else
    {"__weaklistoffset__", T_PYSSIZET, offsetof(PyCFunctionObject, m_weakreflist), READONLY, 0},
#endif
#endif
    {0, 0, 0,  0, 0}
};
static PyObject *
__Pyx_CyFunction_reduce(__pyx_CyFunctionObject *m, PyObject *args)
{
    PyObject *result = NULL;
    CYTHON_UNUSED_VAR(args);
    __Pyx_BEGIN_CRITICAL_SECTION(m);
    Py_INCREF(m->func_qualname);
    result = m->func_qualname;
    __Pyx_END_CRITICAL_SECTION();
    return result;
}
static PyMethodDef __pyx_CyFunction_methods[] = {
    {"__reduce__", (PyCFunction)__Pyx_CyFunction_reduce, METH_VARARGS, 0},
    {0, 0, 0, 0}
};
#if CYTHON_COMPILING_IN_LIMITED_API
#define __Pyx_CyFunction_weakreflist(cyfunc) ((cyfunc)->func_weakreflist)
#else
#define __Pyx_CyFunction_weakreflist(cyfunc) (((PyCFunctionObject*)cyfunc)->m_weakreflist)
#endif
static PyObject *__Pyx_CyFunction_Init(__pyx_CyFunctionObject *op, PyMethodDef *ml, int flags, PyObject* qualname,
                                       PyObject *closure, PyObject *module, PyObject* globals, PyObject* code) {
#if !CYTHON_COMPILING_IN_LIMITED_API
    PyCFunctionObject *cf = (PyCFunctionObject*) op;
#endif
    if (unlikely(op == NULL))
        return NULL;
#if CYTHON_COMPILING_IN_LIMITED_API
    op->func = PyCFunction_NewEx(ml, (PyObject*)op, module);
    if (unlikely(!op->func)) return NULL;
#endif
    op->flags = flags;
    __Pyx_CyFunction_weakreflist(op) = NULL;
#if !CYTHON_COMPILING_IN_LIMITED_API
    cf->m_ml = ml;
    cf->m_self = (PyObject *) op;
#endif
    Py_XINCREF(closure);
    op->func_closure = closure;
#if !CYTHON_COMPILING_IN_LIMITED_API
    Py_XINCREF(module);
    cf->m_module = module;
#endif
    op->func_dict = NULL;
    op->func_name = NULL;
    Py_INCREF(qualname);
    op->func_qualname = qualname;
    op->func_doc = NULL;
#if PY_VERSION_HEX < 0x030900B1 || CYTHON_COMPILING_IN_LIMITED_API
    op->func_classobj = NULL;
#else
    ((PyCMethodObject*)op)->mm_class = NULL;
#endif
    op->func_globals = globals;
    Py_INCREF(op->func_globals);
    Py_XINCREF(code);
    op->func_code = code;
    op->defaults = NULL;
    op->defaults_tuple = NULL;
    op->defaults_kwdict = NULL;
    op->defaults_getter = NULL;
    op->func_annotations = NULL;
    op->func_is_coroutine = NULL;
#if CYTHON_METH_FASTCALL
    switch (ml->ml_flags & (METH_VARARGS | METH_FASTCALL | METH_NOARGS | METH_O | METH_KEYWORDS | METH_METHOD)) {
    case METH_NOARGS:
        __Pyx_CyFunction_func_vectorcall(op) = __Pyx_CyFunction_Vectorcall_NOARGS;
        break;
    case METH_O:
        __Pyx_CyFunction_func_vectorcall(op) = __Pyx_CyFunction_Vectorcall_O;
        break;
    case METH_METHOD | METH_FASTCALL | METH_KEYWORDS:
        __Pyx_CyFunction_func_vectorcall(op) = __Pyx_CyFunction_Vectorcall_FASTCALL_KEYWORDS_METHOD;
        break;
    case METH_FASTCALL | METH_KEYWORDS:
        __Pyx_CyFunction_func_vectorcall(op) = __Pyx_CyFunction_Vectorcall_FASTCALL_KEYWORDS;
        break;
    case METH_VARARGS | METH_KEYWORDS:
        __Pyx_CyFunction_func_vectorcall(op) = NULL;
        break;
    default:
        PyErr_SetString(PyExc_SystemError, "Bad call flags for CyFunction");
        Py_DECREF(op);
        return NULL;
    }
#endif
    return (PyObject *) op;
}
static int
__Pyx_CyFunction_clear(__pyx_CyFunctionObject *m)
{
    Py_CLEAR(m->func_closure);
#if CYTHON_COMPILING_IN_LIMITED_API
    Py_CLEAR(m->func);
#else
    Py_CLEAR(((PyCFunctionObject*)m)->m_module);
#endif
    Py_CLEAR(m->func_dict);
    Py_CLEAR(m->func_name);
    Py_CLEAR(m->func_qualname);
    Py_CLEAR(m->func_doc);
    Py_CLEAR(m->func_globals);
    Py_CLEAR(m->func_code);
#if !CYTHON_COMPILING_IN_LIMITED_API
#if PY_VERSION_HEX < 0x030900B1
    Py_CLEAR(__Pyx_CyFunction_GetClassObj(m));
#else
    {
        PyObject *cls = (PyObject*) ((PyCMethodObject *) (m))->mm_class;
        ((PyCMethodObject *) (m))->mm_class = NULL;
        Py_XDECREF(cls);
    }
#endif
#endif
    Py_CLEAR(m->defaults_tuple);
    Py_CLEAR(m->defaults_kwdict);
    Py_CLEAR(m->func_annotations);
    Py_CLEAR(m->func_is_coroutine);
    Py_CLEAR(m->defaults);
    return 0;
}
static void __Pyx__CyFunction_dealloc(__pyx_CyFunctionObject *m)
{
    if (__Pyx_CyFunction_weakreflist(m) != NULL)
        PyObject_ClearWeakRefs((PyObject *) m);
    __Pyx_CyFunction_clear(m);
    __Pyx_PyHeapTypeObject_GC_Del(m);
}
static void __Pyx_CyFunction_dealloc(__pyx_CyFunctionObject *m)
{
    PyObject_GC_UnTrack(m);
    __Pyx__CyFunction_dealloc(m);
}
static int __Pyx_CyFunction_traverse(__pyx_CyFunctionObject *m, visitproc visit, void *arg)
{
    {
        int e = __Pyx_call_type_traverse((PyObject*)m, 1, visit, arg);
        if (e) return e;
    }
    Py_VISIT(m->func_closure);
#if CYTHON_COMPILING_IN_LIMITED_API
    Py_VISIT(m->func);
#else
    Py_VISIT(((PyCFunctionObject*)m)->m_module);
#endif
    Py_VISIT(m->func_dict);
    __Pyx_VISIT_CONST(m->func_name);
    __Pyx_VISIT_CONST(m->func_qualname);
    Py_VISIT(m->func_doc);
    Py_VISIT(m->func_globals);
    __Pyx_VISIT_CONST(m->func_code);
#if !CYTHON_COMPILING_IN_LIMITED_API
    Py_VISIT(__Pyx_CyFunction_GetClassObj(m));
#endif
    Py_VISIT(m->defaults_tuple);
    Py_VISIT(m->defaults_kwdict);
    Py_VISIT(m->func_is_coroutine);
    Py_VISIT(m->defaults);
    return 0;
}
static PyObject*
__Pyx_CyFunction_repr(__pyx_CyFunctionObject *op)
{
    PyObject *repr;
    __Pyx_BEGIN_CRITICAL_SECTION(op);
    repr = PyUnicode_FromFormat("<cyfunction %U at %p>",
                                op->func_qualname, (void *)op);
    __Pyx_END_CRITICAL_SECTION();
    return repr;
}
static PyObject * __Pyx_CyFunction_CallMethod(PyObject *func, PyObject *self, PyObject *arg, PyObject *kw) {
#if CYTHON_COMPILING_IN_LIMITED_API
    PyObject *f = ((__pyx_CyFunctionObject*)func)->func;
    PyCFunction meth;
    int flags;
    meth = PyCFunction_GetFunction(f);
    if (unlikely(!meth)) return NULL;
    flags = PyCFunction_GetFlags(f);
    if (unlikely(flags < 0)) return NULL;
#else
    PyCFunctionObject* f = (PyCFunctionObject*)func;
    PyCFunction meth = f->m_ml->ml_meth;
    int flags = f->m_ml->ml_flags;
#endif
    Py_ssize_t size;
    switch (flags & (METH_VARARGS | METH_KEYWORDS | METH_NOARGS | METH_O)) {
    case METH_VARARGS:
        if (likely(kw == NULL || PyDict_Size(kw) == 0))
            return (*meth)(self, arg);
        break;
    case METH_VARARGS | METH_KEYWORDS:
        return (*(PyCFunctionWithKeywords)(void(*)(void))meth)(self, arg, kw);
    case METH_NOARGS:
        if (likely(kw == NULL || PyDict_Size(kw) == 0)) {
#if CYTHON_ASSUME_SAFE_SIZE
            size = PyTuple_GET_SIZE(arg);
#else
            size = PyTuple_Size(arg);
            if (unlikely(size < 0)) return NULL;
#endif
            if (likely(size == 0))
                return (*meth)(self, NULL);
            __Pyx_CyFunction_raise_argument_count_error(
                (__pyx_CyFunctionObject*)func,
                "takes no arguments", size);
            return NULL;
        }
        break;
    case METH_O:
        if (likely(kw == NULL || PyDict_Size(kw) == 0)) {
#if CYTHON_ASSUME_SAFE_SIZE
            size = PyTuple_GET_SIZE(arg);
#else
            size = PyTuple_Size(arg);
            if (unlikely(size < 0)) return NULL;
#endif
            if (likely(size == 1)) {
                PyObject *result, *arg0;
                #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
                arg0 = PyTuple_GET_ITEM(arg, 0);
                #else
                arg0 = __Pyx_PySequence_ITEM(arg, 0); if (unlikely(!arg0)) return NULL;
                #endif
                result = (*meth)(self, arg0);
                #if !(CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS)
                Py_DECREF(arg0);
                #endif
                return result;
            }
            __Pyx_CyFunction_raise_argument_count_error(
                (__pyx_CyFunctionObject*)func,
                "takes exactly one argument", size);
            return NULL;
        }
        break;
    default:
        PyErr_SetString(PyExc_SystemError, "Bad call flags for CyFunction");
        return NULL;
    }
    __Pyx_CyFunction_raise_type_error(
        (__pyx_CyFunctionObject*)func, "takes no keyword arguments");
    return NULL;
}
static CYTHON_INLINE PyObject *__Pyx_CyFunction_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    PyObject *self, *result;
#if CYTHON_COMPILING_IN_LIMITED_API
    self = PyCFunction_GetSelf(((__pyx_CyFunctionObject*)func)->func);
    if (unlikely(!self) && PyErr_Occurred()) return NULL;
#else
    self = ((PyCFunctionObject*)func)->m_self;
#endif
    result = __Pyx_CyFunction_CallMethod(func, self, arg, kw);
    return result;
}
static PyObject *__Pyx_CyFunction_CallAsMethod(PyObject *func, PyObject *args, PyObject *kw) {
    PyObject *result;
    __pyx_CyFunctionObject *cyfunc = (__pyx_CyFunctionObject *) func;
#if CYTHON_METH_FASTCALL && (CYTHON_VECTORCALL || CYTHON_BACKPORT_VECTORCALL)
     __pyx_vectorcallfunc vc = __Pyx_CyFunction_func_vectorcall(cyfunc);
    if (vc) {
#if CYTHON_ASSUME_SAFE_MACROS && CYTHON_ASSUME_SAFE_SIZE
        return __Pyx_PyVectorcall_FastCallDict(func, vc, &PyTuple_GET_ITEM(args, 0), (size_t)PyTuple_GET_SIZE(args), kw);
#else
        (void) &__Pyx_PyVectorcall_FastCallDict;
        return PyVectorcall_Call(func, args, kw);
#endif
    }
#endif
    if ((cyfunc->flags & __Pyx_CYFUNCTION_CCLASS) && !(cyfunc->flags & __Pyx_CYFUNCTION_STATICMETHOD)) {
        Py_ssize_t argc;
        PyObject *new_args;
        PyObject *self;
#if CYTHON_ASSUME_SAFE_SIZE
        argc = PyTuple_GET_SIZE(args);
#else
        argc = PyTuple_Size(args);
        if (unlikely(argc < 0)) return NULL;
#endif
        new_args = PyTuple_GetSlice(args, 1, argc);
        if (unlikely(!new_args))
            return NULL;
        self = PyTuple_GetItem(args, 0);
        if (unlikely(!self)) {
            Py_DECREF(new_args);
            PyErr_Format(PyExc_TypeError,
                         "unbound method %.200S() needs an argument",
                         cyfunc->func_qualname);
            return NULL;
        }
        result = __Pyx_CyFunction_CallMethod(func, self, new_args, kw);
        Py_DECREF(new_args);
    } else {
        result = __Pyx_CyFunction_Call(func, args, kw);
    }
    return result;
}
#if CYTHON_METH_FASTCALL && (CYTHON_VECTORCALL || CYTHON_BACKPORT_VECTORCALL)
static CYTHON_INLINE int __Pyx_CyFunction_Vectorcall_CheckArgs(__pyx_CyFunctionObject *cyfunc, Py_ssize_t nargs, PyObject *kwnames)
{
    int ret = 0;
    if ((cyfunc->flags & __Pyx_CYFUNCTION_CCLASS) && !(cyfunc->flags & __Pyx_CYFUNCTION_STATICMETHOD)) {
        if (unlikely(nargs < 1)) {
            __Pyx_CyFunction_raise_type_error(
                cyfunc, "needs an argument");
            return -1;
        }
        ret = 1;
    }
    if (unlikely(kwnames) && unlikely(__Pyx_PyTuple_GET_SIZE(kwnames))) {
        __Pyx_CyFunction_raise_type_error(
            cyfunc, "takes no keyword arguments");
        return -1;
    }
    return ret;
}
static PyObject * __Pyx_CyFunction_Vectorcall_NOARGS(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames)
{
    __pyx_CyFunctionObject *cyfunc = (__pyx_CyFunctionObject *)func;
#if CYTHON_BACKPORT_VECTORCALL
    Py_ssize_t nargs = (Py_ssize_t)nargsf;
#else
    Py_ssize_t nargs = PyVectorcall_NARGS(nargsf);
#endif
    PyObject *self;
#if CYTHON_COMPILING_IN_LIMITED_API
    PyCFunction meth = PyCFunction_GetFunction(cyfunc->func);
    if (unlikely(!meth)) return NULL;
#else
    PyCFunction meth = ((PyCFunctionObject*)cyfunc)->m_ml->ml_meth;
#endif
    switch (__Pyx_CyFunction_Vectorcall_CheckArgs(cyfunc, nargs, kwnames)) {
    case 1:
        self = args[0];
        args += 1;
        nargs -= 1;
        break;
    case 0:
#if CYTHON_COMPILING_IN_LIMITED_API
        self = PyCFunction_GetSelf(((__pyx_CyFunctionObject*)cyfunc)->func);
        if (unlikely(!self) && PyErr_Occurred()) return NULL;
#else
        self = ((PyCFunctionObject*)cyfunc)->m_self;
#endif
        break;
    default:
        return NULL;
    }
    if (unlikely(nargs != 0)) {
        __Pyx_CyFunction_raise_argument_count_error(
            cyfunc, "takes no arguments", nargs);
        return NULL;
    }
    return meth(self, NULL);
}
static PyObject * __Pyx_CyFunction_Vectorcall_O(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames)
{
    __pyx_CyFunctionObject *cyfunc = (__pyx_CyFunctionObject *)func;
#if CYTHON_BACKPORT_VECTORCALL
    Py_ssize_t nargs = (Py_ssize_t)nargsf;
#else
    Py_ssize_t nargs = PyVectorcall_NARGS(nargsf);
#endif
    PyObject *self;
#if CYTHON_COMPILING_IN_LIMITED_API
    PyCFunction meth = PyCFunction_GetFunction(cyfunc->func);
    if (unlikely(!meth)) return NULL;
#else
    PyCFunction meth = ((PyCFunctionObject*)cyfunc)->m_ml->ml_meth;
#endif
    switch (__Pyx_CyFunction_Vectorcall_CheckArgs(cyfunc, nargs, kwnames)) {
    case 1:
        self = args[0];
        args += 1;
        nargs -= 1;
        break;
    case 0:
#if CYTHON_COMPILING_IN_LIMITED_API
        self = PyCFunction_GetSelf(((__pyx_CyFunctionObject*)cyfunc)->func);
        if (unlikely(!self) && PyErr_Occurred()) return NULL;
#else
        self = ((PyCFunctionObject*)cyfunc)->m_self;
#endif
        break;
    default:
        return NULL;
    }
    if (unlikely(nargs != 1)) {
        __Pyx_CyFunction_raise_argument_count_error(
            cyfunc, "takes exactly one argument", nargs);
        return NULL;
    }
    return meth(self, args[0]);
}
static PyObject * __Pyx_CyFunction_Vectorcall_FASTCALL_KEYWORDS(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames)
{
    __pyx_CyFunctionObject *cyfunc = (__pyx_CyFunctionObject *)func;
#if CYTHON_BACKPORT_VECTORCALL
    Py_ssize_t nargs = (Py_ssize_t)nargsf;
#else
    Py_ssize_t nargs = PyVectorcall_NARGS(nargsf);
#endif
    PyObject *self;
#if CYTHON_COMPILING_IN_LIMITED_API
    PyCFunction meth = PyCFunction_GetFunction(cyfunc->func);
    if (unlikely(!meth)) return NULL;
#else
    PyCFunction meth = ((PyCFunctionObject*)cyfunc)->m_ml->ml_meth;
#endif
    switch (__Pyx_CyFunction_Vectorcall_CheckArgs(cyfunc, nargs, NULL)) {
    case 1:
        self = args[0];
        args += 1;
        nargs -= 1;
        break;
    case 0:
#if CYTHON_COMPILING_IN_LIMITED_API
        self = PyCFunction_GetSelf(((__pyx_CyFunctionObject*)cyfunc)->func);
        if (unlikely(!self) && PyErr_Occurred()) return NULL;
#else
        self = ((PyCFunctionObject*)cyfunc)->m_self;
#endif
        break;
    default:
        return NULL;
    }
    return ((__Pyx_PyCFunctionFastWithKeywords)(void(*)(void))meth)(self, args, nargs, kwnames);
}
static PyObject * __Pyx_CyFunction_Vectorcall_FASTCALL_KEYWORDS_METHOD(PyObject *func, PyObject *const *args, size_t nargsf, PyObject *kwnames)
{
    __pyx_CyFunctionObject *cyfunc = (__pyx_CyFunctionObject *)func;
    PyTypeObject *cls = (PyTypeObject *) __Pyx_CyFunction_GetClassObj(cyfunc);
#if CYTHON_BACKPORT_VECTORCALL
    Py_ssize_t nargs = (Py_ssize_t)nargsf;
#else
    Py_ssize_t nargs = PyVectorcall_NARGS(nargsf);
#endif
    PyObject *self;
#if CYTHON_COMPILING_IN_LIMITED_API
    PyCFunction meth = PyCFunction_GetFunction(cyfunc->func);
    if (unlikely(!meth)) return NULL;
#else
    PyCFunction meth = ((PyCFunctionObject*)cyfunc)->m_ml->ml_meth;
#endif
    switch (__Pyx_CyFunction_Vectorcall_CheckArgs(cyfunc, nargs, NULL)) {
    case 1:
        self = args[0];
        args += 1;
        nargs -= 1;
        break;
    case 0:
#if CYTHON_COMPILING_IN_LIMITED_API
        self = PyCFunction_GetSelf(((__pyx_CyFunctionObject*)cyfunc)->func);
        if (unlikely(!self) && PyErr_Occurred()) return NULL;
#else
        self = ((PyCFunctionObject*)cyfunc)->m_self;
#endif
        break;
    default:
        return NULL;
    }
    return ((__Pyx_PyCMethod)(void(*)(void))meth)(self, cls, args, (size_t)nargs, kwnames);
}
#endif
static PyType_Slot __pyx_CyFunctionType_slots[] = {
    {Py_tp_dealloc, (void *)__Pyx_CyFunction_dealloc},
    {Py_tp_repr, (void *)__Pyx_CyFunction_repr},
    {Py_tp_call, (void *)__Pyx_CyFunction_CallAsMethod},
    {Py_tp_traverse, (void *)__Pyx_CyFunction_traverse},
    {Py_tp_clear, (void *)__Pyx_CyFunction_clear},
    {Py_tp_methods, (void *)__pyx_CyFunction_methods},
    {Py_tp_members, (void *)__pyx_CyFunction_members},
    {Py_tp_getset, (void *)__pyx_CyFunction_getsets},
    {Py_tp_descr_get, (void *)__Pyx_PyMethod_New},
    {0, 0},
};
static PyType_Spec __pyx_CyFunctionType_spec = {
    __PYX_TYPE_MODULE_PREFIX "cython_function_or_method",
    sizeof(__pyx_CyFunctionObject),
    0,
#ifdef Py_TPFLAGS_METHOD_DESCRIPTOR
    Py_TPFLAGS_METHOD_DESCRIPTOR |
#endif
#if CYTHON_METH_FASTCALL
#if defined(Py_TPFLAGS_HAVE_VECTORCALL)
    Py_TPFLAGS_HAVE_VECTORCALL |
#elif defined(_Py_TPFLAGS_HAVE_VECTORCALL)
    _Py_TPFLAGS_HAVE_VECTORCALL |
#endif
#endif // CYTHON_METH_FASTCALL
#if PY_VERSION_HEX >= 0x030A0000
    Py_TPFLAGS_IMMUTABLETYPE |
#endif
    Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HAVE_GC | Py_TPFLAGS_BASETYPE,
    __pyx_CyFunctionType_slots
};
static int __pyx_CyFunction_init(PyObject *module) {
    __pyx_mstatetype *mstate = __Pyx_PyModule_GetState(module);
    mstate->__pyx_CyFunctionType = __Pyx_FetchCommonTypeFromSpec(
        mstate->__pyx_CommonTypesMetaclassType, module, &__pyx_CyFunctionType_spec, NULL);
    if (unlikely(mstate->__pyx_CyFunctionType == NULL)) {
        return -1;
    }
    return 0;
}
static CYTHON_INLINE PyObject *__Pyx_CyFunction_InitDefaults(PyObject *func, PyTypeObject *defaults_type) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->defaults = PyObject_CallObject((PyObject*)defaults_type, NULL); // _PyObject_New(defaults_type);
    if (unlikely(!m->defaults))
        return NULL;
    return m->defaults;
}
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsTuple(PyObject *func, PyObject *tuple) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->defaults_tuple = tuple;
    Py_INCREF(tuple);
}
static CYTHON_INLINE void __Pyx_CyFunction_SetDefaultsKwDict(PyObject *func, PyObject *dict) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->defaults_kwdict = dict;
    Py_INCREF(dict);
}
static CYTHON_INLINE void __Pyx_CyFunction_SetAnnotationsDict(PyObject *func, PyObject *dict) {
    __pyx_CyFunctionObject *m = (__pyx_CyFunctionObject *) func;
    m->func_annotations = dict;
    Py_INCREF(dict);
}

/* CythonFunction */
static PyObject *__Pyx_CyFunction_New(PyMethodDef *ml, int flags, PyObject* qualname,
                                      PyObject *closure, PyObject *module, PyObject* globals, PyObject* code) {
    PyObject *op = __Pyx_CyFunction_Init(
        PyObject_GC_New(__pyx_CyFunctionObject, __pyx_mstate_global->__pyx_CyFunctionType),
        ml, flags, qualname, closure, module, globals, code
    );
    if (likely(op)) {
        PyObject_GC_Track(op);
    }
    return op;
}

/* PyObjectCall2Args */
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call2Args(PyObject* function, PyObject* arg1, PyObject* arg2) {
    PyObject *args[3] = {NULL, arg1, arg2};
    return __Pyx_PyObject_FastCall(function, args+1, 2 | __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET);
}

/* PyObjectLookupSpecial */
#if CYTHON_USE_PYTYPE_LOOKUP && CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx__PyObject_LookupSpecial(PyObject* obj, PyObject* attr_name, int with_error) {
    PyObject *res;
    PyTypeObject *tp = Py_TYPE(obj);
    res = _PyType_Lookup(tp, attr_name);
    if (likely(res)) {
        descrgetfunc f = Py_TYPE(res)->tp_descr_get;
        if (!f) {
            Py_INCREF(res);
        } else {
            res = f(res, obj, (PyObject *)tp);
        }
    } else if (with_error) {
        PyErr_SetObject(PyExc_AttributeError, attr_name);
    }
    return res;
}
#endif

/* Py3ClassCreate */
static PyObject *__Pyx_Py3MetaclassPrepare(PyObject *metaclass, PyObject *bases, PyObject *name,
                                           PyObject *qualname, PyObject *mkw, PyObject *modname, PyObject *doc) {
    PyObject *ns;
    if (metaclass) {
        PyObject *prep = __Pyx_PyObject_GetAttrStrNoError(metaclass, __pyx_mstate_global->__pyx_n_u_prepare);
        if (prep) {
            PyObject *pargs[3] = {NULL, name, bases};
            ns = __Pyx_PyObject_FastCallDict(prep, pargs+1, 2 | __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET, mkw);
            Py_DECREF(prep);
        } else {
            if (unlikely(PyErr_Occurred()))
                return NULL;
            ns = PyDict_New();
        }
    } else {
        ns = PyDict_New();
    }
    if (unlikely(!ns))
        return NULL;
    if (unlikely(PyObject_SetItem(ns, __pyx_mstate_global->__pyx_n_u_module, modname) < 0)) goto bad;
    if (unlikely(PyObject_SetItem(ns, __pyx_mstate_global->__pyx_n_u_qualname, qualname) < 0)) goto bad;
    if (unlikely(doc && PyObject_SetItem(ns, __pyx_mstate_global->__pyx_n_u_doc, doc) < 0)) goto bad;
    return ns;
bad:
    Py_DECREF(ns);
    return NULL;
}
static PyObject *__Pyx_Py3ClassCreate(PyObject *metaclass, PyObject *name, PyObject *bases,
                                      PyObject *dict, PyObject *mkw,
                                      int calculate_metaclass, int allow_py2_metaclass) {
    PyObject *result;
    PyObject *owned_metaclass = NULL;
    PyObject *margs[4] = {NULL, name, bases, dict};
    if (allow_py2_metaclass) {
        owned_metaclass = PyObject_GetItem(dict, __pyx_mstate_global->__pyx_n_u_metaclass);
        if (owned_metaclass) {
            metaclass = owned_metaclass;
        } else if (likely(PyErr_ExceptionMatches(PyExc_KeyError))) {
            PyErr_Clear();
        } else {
            return NULL;
        }
    }
    if (calculate_metaclass && (!metaclass || PyType_Check(metaclass))) {
        metaclass = __Pyx_CalculateMetaclass((PyTypeObject*) metaclass, bases);
        Py_XDECREF(owned_metaclass);
        if (unlikely(!metaclass))
            return NULL;
        owned_metaclass = metaclass;
    }
    result = __Pyx_PyObject_FastCallDict(metaclass, margs+1, 3 | __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET, mkw);
    Py_XDECREF(owned_metaclass);
    return result;
}

/* CLineInTraceback */
#if CYTHON_CLINE_IN_TRACEBACK && CYTHON_CLINE_IN_TRACEBACK_RUNTIME
static int __Pyx_CLineForTraceback(PyThreadState *tstate, int c_line) {
    PyObject *use_cline;
    PyObject *ptype, *pvalue, *ptraceback;
#if CYTHON_COMPILING_IN_CPYTHON
    PyObject **cython_runtime_dict;
#endif
    CYTHON_MAYBE_UNUSED_VAR(tstate);
    if (unlikely(!__pyx_mstate_global->__pyx_cython_runtime)) {
        return c_line;
    }
    __Pyx_ErrFetchInState(tstate, &ptype, &pvalue, &ptraceback);
#if CYTHON_COMPILING_IN_CPYTHON
    cython_runtime_dict = _PyObject_GetDictPtr(__pyx_mstate_global->__pyx_cython_runtime);
    if (likely(cython_runtime_dict)) {
        __Pyx_BEGIN_CRITICAL_SECTION(*cython_runtime_dict);
        __PYX_PY_DICT_LOOKUP_IF_MODIFIED(
            use_cline, *cython_runtime_dict,
            __Pyx_PyDict_GetItemStr(*cython_runtime_dict, __pyx_mstate_global->__pyx_n_u_cline_in_traceback))
        Py_XINCREF(use_cline);
        __Pyx_END_CRITICAL_SECTION();
    } else
#endif
    {
      PyObject *use_cline_obj = __Pyx_PyObject_GetAttrStrNoError(__pyx_mstate_global->__pyx_cython_runtime, __pyx_mstate_global->__pyx_n_u_cline_in_traceback);
      if (use_cline_obj) {
        use_cline = PyObject_Not(use_cline_obj) ? Py_False : Py_True;
        Py_INCREF(use_cline);
        Py_DECREF(use_cline_obj);
      } else {
        PyErr_Clear();
        use_cline = NULL;
      }
    }
    if (!use_cline) {
        c_line = 0;
        (void) PyObject_SetAttr(__pyx_mstate_global->__pyx_cython_runtime, __pyx_mstate_global->__pyx_n_u_cline_in_traceback, Py_False);
    }
    else if (use_cline == Py_False || (use_cline != Py_True && PyObject_Not(use_cline) != 0)) {
        c_line = 0;
    }
    Py_XDECREF(use_cline);
    __Pyx_ErrRestoreInState(tstate, ptype, pvalue, ptraceback);
    return c_line;
}
#endif

/* CodeObjectCache */
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line) {
    int start = 0, mid = 0, end = count - 1;
    if (end >= 0 && code_line > entries[end].code_line) {
        return count;
    }
    while (start < end) {
        mid = start + (end - start) / 2;
        if (code_line < entries[mid].code_line) {
            end = mid;
        } else if (code_line > entries[mid].code_line) {
             start = mid + 1;
        } else {
            return mid;
        }
    }
    if (code_line <= entries[mid].code_line) {
        return mid;
    } else {
        return mid + 1;
    }
}
static __Pyx_CachedCodeObjectType *__pyx__find_code_object(struct __Pyx_CodeObjectCache *code_cache, int code_line) {
    __Pyx_CachedCodeObjectType* code_object;
    int pos;
    if (unlikely(!code_line) || unlikely(!code_cache->entries)) {
        return NULL;
    }
    pos = __pyx_bisect_code_objects(code_cache->entries, code_cache->count, code_line);
    if (unlikely(pos >= code_cache->count) || unlikely(code_cache->entries[pos].code_line != code_line)) {
        return NULL;
    }
    code_object = code_cache->entries[pos].code_object;
    Py_INCREF(code_object);
    return code_object;
}
static __Pyx_CachedCodeObjectType *__pyx_find_code_object(int code_line) {
#if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING && !CYTHON_ATOMICS
    (void)__pyx__find_code_object;
    return NULL; // Most implementation should have atomics. But otherwise, don't make it thread-safe, just miss.
#else
    struct __Pyx_CodeObjectCache *code_cache = &__pyx_mstate_global->__pyx_code_cache;
#if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
    __pyx_nonatomic_int_type old_count = __pyx_atomic_incr_acq_rel(&code_cache->accessor_count);
    if (old_count < 0) {
        __pyx_atomic_decr_acq_rel(&code_cache->accessor_count);
        return NULL;
    }
#endif
    __Pyx_CachedCodeObjectType *result = __pyx__find_code_object(code_cache, code_line);
#if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
    __pyx_atomic_decr_acq_rel(&code_cache->accessor_count);
#endif
    return result;
#endif
}
static void __pyx__insert_code_object(struct __Pyx_CodeObjectCache *code_cache, int code_line, __Pyx_CachedCodeObjectType* code_object)
{
    int pos, i;
    __Pyx_CodeObjectCacheEntry* entries = code_cache->entries;
    if (unlikely(!code_line)) {
        return;
    }
    if (unlikely(!entries)) {
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Malloc(64*sizeof(__Pyx_CodeObjectCacheEntry));
        if (likely(entries)) {
            code_cache->entries = entries;
            code_cache->max_count = 64;
            code_cache->count = 1;
            entries[0].code_line = code_line;
            entries[0].code_object = code_object;
            Py_INCREF(code_object);
        }
        return;
    }
    pos = __pyx_bisect_code_objects(code_cache->entries, code_cache->count, code_line);
    if ((pos < code_cache->count) && unlikely(code_cache->entries[pos].code_line == code_line)) {
        __Pyx_CachedCodeObjectType* tmp = entries[pos].code_object;
        entries[pos].code_object = code_object;
        Py_INCREF(code_object);
        Py_DECREF(tmp);
        return;
    }
    if (code_cache->count == code_cache->max_count) {
        int new_max = code_cache->max_count + 64;
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Realloc(
            code_cache->entries, ((size_t)new_max) * sizeof(__Pyx_CodeObjectCacheEntry));
        if (unlikely(!entries)) {
            return;
        }
        code_cache->entries = entries;
        code_cache->max_count = new_max;
    }
    for (i=code_cache->count; i>pos; i--) {
        entries[i] = entries[i-1];
    }
    entries[pos].code_line = code_line;
    entries[pos].code_object = code_object;
    code_cache->count++;
    Py_INCREF(code_object);
}
static void __pyx_insert_code_object(int code_line, __Pyx_CachedCodeObjectType* code_object) {
#if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING && !CYTHON_ATOMICS
    (void)__pyx__insert_code_object;
    return; // Most implementation should have atomics. But otherwise, don't make it thread-safe, just fail.
#else
    struct __Pyx_CodeObjectCache *code_cache = &__pyx_mstate_global->__pyx_code_cache;
#if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
    __pyx_nonatomic_int_type expected = 0;
    if (!__pyx_atomic_int_cmp_exchange(&code_cache->accessor_count, &expected, INT_MIN)) {
        return;
    }
#endif
    __pyx__insert_code_object(code_cache, code_line, code_object);
#if CYTHON_COMPILING_IN_CPYTHON_FREETHREADING
    __pyx_atomic_sub(&code_cache->accessor_count, INT_MIN);
#endif
#endif
}

/* AddTraceback */
#include "compile.h"
#include "frameobject.h"
#include "traceback.h"
#if PY_VERSION_HEX >= 0x030b00a6 && !CYTHON_COMPILING_IN_LIMITED_API && !defined(PYPY_VERSION)
  #ifndef Py_BUILD_CORE
    #define Py_BUILD_CORE 1
  #endif
  #include "internal/pycore_frame.h"
#endif
#if CYTHON_COMPILING_IN_LIMITED_API
static PyObject *__Pyx_PyCode_Replace_For_AddTraceback(PyObject *code, PyObject *scratch_dict,
                                                       PyObject *firstlineno, PyObject *name) {
    PyObject *replace = NULL;
    if (unlikely(PyDict_SetItemString(scratch_dict, "co_firstlineno", firstlineno))) return NULL;
    if (unlikely(PyDict_SetItemString(scratch_dict, "co_name", name))) return NULL;
    replace = PyObject_GetAttrString(code, "replace");
    if (likely(replace)) {
        PyObject *result = PyObject_Call(replace, __pyx_mstate_global->__pyx_empty_tuple, scratch_dict);
        Py_DECREF(replace);
        return result;
    }
    PyErr_Clear();
    return NULL;
}
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename) {
    PyObject *code_object = NULL, *py_py_line = NULL, *py_funcname = NULL, *dict = NULL;
    PyObject *replace = NULL, *getframe = NULL, *frame = NULL;
    PyObject *exc_type, *exc_value, *exc_traceback;
    int success = 0;
    if (c_line) {
        (void) __pyx_cfilenm;
        (void) __Pyx_CLineForTraceback(__Pyx_PyThreadState_Current, c_line);
    }
    PyErr_Fetch(&exc_type, &exc_value, &exc_traceback);
    code_object = __pyx_find_code_object(c_line ? -c_line : py_line);
    if (!code_object) {
        code_object = Py_CompileString("_getframe()", filename, Py_eval_input);
        if (unlikely(!code_object)) goto bad;
        py_py_line = PyLong_FromLong(py_line);
        if (unlikely(!py_py_line)) goto bad;
        py_funcname = PyUnicode_FromString(funcname);
        if (unlikely(!py_funcname)) goto bad;
        dict = PyDict_New();
        if (unlikely(!dict)) goto bad;
        {
            PyObject *old_code_object = code_object;
            code_object = __Pyx_PyCode_Replace_For_AddTraceback(code_object, dict, py_py_line, py_funcname);
            Py_DECREF(old_code_object);
        }
        if (unlikely(!code_object)) goto bad;
        __pyx_insert_code_object(c_line ? -c_line : py_line, code_object);
    } else {
        dict = PyDict_New();
    }
    getframe = PySys_GetObject("_getframe");
    if (unlikely(!getframe)) goto bad;
    if (unlikely(PyDict_SetItemString(dict, "_getframe", getframe))) goto bad;
    frame = PyEval_EvalCode(code_object, dict, dict);
    if (unlikely(!frame) || frame == Py_None) goto bad;
    success = 1;
  bad:
    PyErr_Restore(exc_type, exc_value, exc_traceback);
    Py_XDECREF(code_object);
    Py_XDECREF(py_py_line);
    Py_XDECREF(py_funcname);
    Py_XDECREF(dict);
    Py_XDECREF(replace);
    if (success) {
        PyTraceBack_Here(
            (struct _frame*)frame);
    }
    Py_XDECREF(frame);
}
#else
static PyCodeObject* __Pyx_CreateCodeObjectForTraceback(
            const char *funcname, int c_line,
            int py_line, const char *filename) {
    PyCodeObject *py_code = NULL;
    PyObject *py_funcname = NULL;
    if (c_line) {
        py_funcname = PyUnicode_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        if (!py_funcname) goto bad;
        funcname = PyUnicode_AsUTF8(py_funcname);
        if (!funcname) goto bad;
    }
    py_code = PyCode_NewEmpty(filename, funcname, py_line);
    Py_XDECREF(py_funcname);
    return py_code;
bad:
    Py_XDECREF(py_funcname);
    return NULL;
}
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyFrameObject *py_frame = 0;
    PyThreadState *tstate = __Pyx_PyThreadState_Current;
    PyObject *ptype, *pvalue, *ptraceback;
    if (c_line) {
        c_line = __Pyx_CLineForTraceback(tstate, c_line);
    }
    py_code = __pyx_find_code_object(c_line ? -c_line : py_line);
    if (!py_code) {
        __Pyx_ErrFetchInState(tstate, &ptype, &pvalue, &ptraceback);
        py_code = __Pyx_CreateCodeObjectForTraceback(
            funcname, c_line, py_line, filename);
        if (!py_code) {
            /* If the code object creation fails, then we should clear the
               fetched exception references and propagate the new exception */
            Py_XDECREF(ptype);
            Py_XDECREF(pvalue);
            Py_XDECREF(ptraceback);
            goto bad;
        }
        __Pyx_ErrRestoreInState(tstate, ptype, pvalue, ptraceback);
        __pyx_insert_code_object(c_line ? -c_line : py_line, py_code);
    }
    py_frame = PyFrame_New(
        tstate,            /*PyThreadState *tstate,*/
        py_code,           /*PyCodeObject *code,*/
        __pyx_mstate_global->__pyx_d,    /*PyObject *globals,*/
        0                  /*PyObject *locals*/
    );
    if (!py_frame) goto bad;
    __Pyx_PyFrame_SetLineNumber(py_frame, py_line);
    PyTraceBack_Here(py_frame);
bad:
    Py_XDECREF(py_code);
    Py_XDECREF(py_frame);
}
#endif

/* CIntFromPyVerify */
#define __PYX_VERIFY_RETURN_INT(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 0)
#define __PYX_VERIFY_RETURN_INT_EXC(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 1)
#define __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, exc)\
    {\
        func_type value = func_value;\
        if (sizeof(target_type) < sizeof(func_type)) {\
            if (unlikely(value != (func_type) (target_type) value)) {\
                func_type zero = 0;\
                if (exc && unlikely(value == (func_type)-1 && PyErr_Occurred()))\
                    return (target_type) -1;\
                if (is_unsigned && unlikely(value < zero))\
                    goto raise_neg_overflow;\
                else\
                    goto raise_overflow;\
            }\
        }\
        return (target_type) value;\
    }

/* CIntToPy */
static CYTHON_INLINE PyObject* __Pyx_PyLong_From_int(int value) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const int neg_one = (int) -1, const_zero = (int) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(int) < sizeof(long)) {
            return PyLong_FromLong((long) value);
        } else if (sizeof(int) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#if defined(HAVE_LONG_LONG) && !CYTHON_COMPILING_IN_PYPY
        } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(int) <= sizeof(long)) {
            return PyLong_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        unsigned char *bytes = (unsigned char *)&value;
#if !CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX >= 0x030d00A4
        if (is_unsigned) {
            return PyLong_FromUnsignedNativeBytes(bytes, sizeof(value), -1);
        } else {
            return PyLong_FromNativeBytes(bytes, sizeof(value), -1);
        }
#elif !CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x030d0000
        int one = 1; int little = (int)*(unsigned char *)&one;
        return _PyLong_FromByteArray(bytes, sizeof(int),
                                     little, !is_unsigned);
#else
        int one = 1; int little = (int)*(unsigned char *)&one;
        PyObject *from_bytes, *result = NULL, *kwds = NULL;
        PyObject *py_bytes = NULL, *order_str = NULL;
        from_bytes = PyObject_GetAttrString((PyObject*)&PyLong_Type, "from_bytes");
        if (!from_bytes) return NULL;
        py_bytes = PyBytes_FromStringAndSize((char*)bytes, sizeof(int));
        if (!py_bytes) goto limited_bad;
        order_str = PyUnicode_FromString(little ? "little" : "big");
        if (!order_str) goto limited_bad;
        {
            PyObject *args[3+(CYTHON_VECTORCALL ? 1 : 0)] = { NULL, py_bytes, order_str };
            if (!is_unsigned) {
                kwds = __Pyx_MakeVectorcallBuilderKwds(1);
                if (!kwds) goto limited_bad;
                if (__Pyx_VectorcallBuilder_AddArgStr("signed", __Pyx_NewRef(Py_True), kwds, args+3, 0) < 0) goto limited_bad;
            }
            result = __Pyx_Object_Vectorcall_CallFromBuilder(from_bytes, args+1, 2 | __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET, kwds);
        }
        limited_bad:
        Py_XDECREF(kwds);
        Py_XDECREF(order_str);
        Py_XDECREF(py_bytes);
        Py_XDECREF(from_bytes);
        return result;
#endif
    }
}

/* CIntFromPy */
static CYTHON_INLINE int __Pyx_PyLong_As_int(PyObject *x) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const int neg_one = (int) -1, const_zero = (int) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (unlikely(!PyLong_Check(x))) {
        int val;
        PyObject *tmp = __Pyx_PyNumber_Long(x);
        if (!tmp) return (int) -1;
        val = __Pyx_PyLong_As_int(tmp);
        Py_DECREF(tmp);
        return val;
    }
    if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
        if (unlikely(__Pyx_PyLong_IsNeg(x))) {
            goto raise_neg_overflow;
        } else if (__Pyx_PyLong_IsCompact(x)) {
            __PYX_VERIFY_RETURN_INT(int, __Pyx_compact_upylong, __Pyx_PyLong_CompactValueUnsigned(x))
        } else {
            const digit* digits = __Pyx_PyLong_Digits(x);
            assert(__Pyx_PyLong_DigitCount(x) > 1);
            switch (__Pyx_PyLong_DigitCount(x)) {
                case 2:
                    if ((8 * sizeof(int) > 1 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(int) >= 2 * PyLong_SHIFT)) {
                            return (int) (((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if ((8 * sizeof(int) > 2 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(int) >= 3 * PyLong_SHIFT)) {
                            return (int) (((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if ((8 * sizeof(int) > 3 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(int) >= 4 * PyLong_SHIFT)) {
                            return (int) (((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
            }
        }
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030C00A7
        if (unlikely(Py_SIZE(x) < 0)) {
            goto raise_neg_overflow;
        }
#else
        {
            int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
            if (unlikely(result < 0))
                return (int) -1;
            if (unlikely(result == 1))
                goto raise_neg_overflow;
        }
#endif
        if ((sizeof(int) <= sizeof(unsigned long))) {
            __PYX_VERIFY_RETURN_INT_EXC(int, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
        } else if ((sizeof(int) <= sizeof(unsigned PY_LONG_LONG))) {
            __PYX_VERIFY_RETURN_INT_EXC(int, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
        }
    } else {
#if CYTHON_USE_PYLONG_INTERNALS
        if (__Pyx_PyLong_IsCompact(x)) {
            __PYX_VERIFY_RETURN_INT(int, __Pyx_compact_pylong, __Pyx_PyLong_CompactValue(x))
        } else {
            const digit* digits = __Pyx_PyLong_Digits(x);
            assert(__Pyx_PyLong_DigitCount(x) > 1);
            switch (__Pyx_PyLong_SignedDigitCount(x)) {
                case -2:
                    if ((8 * sizeof(int) - 1 > 1 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(int) - 1 > 2 * PyLong_SHIFT)) {
                            return (int) (((int)-1)*(((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if ((8 * sizeof(int) > 1 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(int) - 1 > 2 * PyLong_SHIFT)) {
                            return (int) ((((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if ((8 * sizeof(int) - 1 > 2 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(int) - 1 > 3 * PyLong_SHIFT)) {
                            return (int) (((int)-1)*(((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if ((8 * sizeof(int) > 2 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(int) - 1 > 3 * PyLong_SHIFT)) {
                            return (int) ((((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if ((8 * sizeof(int) - 1 > 3 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(int) - 1 > 4 * PyLong_SHIFT)) {
                            return (int) (((int)-1)*(((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if ((8 * sizeof(int) > 3 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(int) - 1 > 4 * PyLong_SHIFT)) {
                            return (int) ((((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
            }
        }
#endif
        if ((sizeof(int) <= sizeof(long))) {
            __PYX_VERIFY_RETURN_INT_EXC(int, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
        } else if ((sizeof(int) <= sizeof(PY_LONG_LONG))) {
            __PYX_VERIFY_RETURN_INT_EXC(int, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
        }
    }
    {
        int val;
        int ret = -1;
#if PY_VERSION_HEX >= 0x030d00A6 && !CYTHON_COMPILING_IN_LIMITED_API
        Py_ssize_t bytes_copied = PyLong_AsNativeBytes(
            x, &val, sizeof(val), Py_ASNATIVEBYTES_NATIVE_ENDIAN | (is_unsigned ? Py_ASNATIVEBYTES_UNSIGNED_BUFFER | Py_ASNATIVEBYTES_REJECT_NEGATIVE : 0));
        if (unlikely(bytes_copied == -1)) {
        } else if (unlikely(bytes_copied > (Py_ssize_t) sizeof(val))) {
            goto raise_overflow;
        } else {
            ret = 0;
        }
#elif PY_VERSION_HEX < 0x030d0000 && !(CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_LIMITED_API) || defined(_PyLong_AsByteArray)
        int one = 1; int is_little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&val;
        ret = _PyLong_AsByteArray((PyLongObject *)x,
                                    bytes, sizeof(val),
                                    is_little, !is_unsigned);
#else
        PyObject *v;
        PyObject *stepval = NULL, *mask = NULL, *shift = NULL;
        int bits, remaining_bits, is_negative = 0;
        int chunk_size = (sizeof(long) < 8) ? 30 : 62;
        if (likely(PyLong_CheckExact(x))) {
            v = __Pyx_NewRef(x);
        } else {
            v = PyNumber_Long(x);
            if (unlikely(!v)) return (int) -1;
            assert(PyLong_CheckExact(v));
        }
        {
            int result = PyObject_RichCompareBool(v, Py_False, Py_LT);
            if (unlikely(result < 0)) {
                Py_DECREF(v);
                return (int) -1;
            }
            is_negative = result == 1;
        }
        if (is_unsigned && unlikely(is_negative)) {
            Py_DECREF(v);
            goto raise_neg_overflow;
        } else if (is_negative) {
            stepval = PyNumber_Invert(v);
            Py_DECREF(v);
            if (unlikely(!stepval))
                return (int) -1;
        } else {
            stepval = v;
        }
        v = NULL;
        val = (int) 0;
        mask = PyLong_FromLong((1L << chunk_size) - 1); if (unlikely(!mask)) goto done;
        shift = PyLong_FromLong(chunk_size); if (unlikely(!shift)) goto done;
        for (bits = 0; bits < (int) sizeof(int) * 8 - chunk_size; bits += chunk_size) {
            PyObject *tmp, *digit;
            long idigit;
            digit = PyNumber_And(stepval, mask);
            if (unlikely(!digit)) goto done;
            idigit = PyLong_AsLong(digit);
            Py_DECREF(digit);
            if (unlikely(idigit < 0)) goto done;
            val |= ((int) idigit) << bits;
            tmp = PyNumber_Rshift(stepval, shift);
            if (unlikely(!tmp)) goto done;
            Py_DECREF(stepval); stepval = tmp;
        }
        Py_DECREF(shift); shift = NULL;
        Py_DECREF(mask); mask = NULL;
        {
            long idigit = PyLong_AsLong(stepval);
            if (unlikely(idigit < 0)) goto done;
            remaining_bits = ((int) sizeof(int) * 8) - bits - (is_unsigned ? 0 : 1);
            if (unlikely(idigit >= (1L << remaining_bits)))
                goto raise_overflow;
            val |= ((int) idigit) << bits;
        }
        if (!is_unsigned) {
            if (unlikely(val & (((int) 1) << (sizeof(int) * 8 - 1))))
                goto raise_overflow;
            if (is_negative)
                val = ~val;
        }
        ret = 0;
    done:
        Py_XDECREF(shift);
        Py_XDECREF(mask);
        Py_XDECREF(stepval);
#endif
        if (unlikely(ret))
            return (int) -1;
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to int");
    return (int) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to int");
    return (int) -1;
}

/* CIntToPy */
static CYTHON_INLINE PyObject* __Pyx_PyLong_From_cufftType_t(cufftType_t value) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const cufftType_t neg_one = (cufftType_t) -1, const_zero = (cufftType_t) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(cufftType_t) < sizeof(long)) {
            return PyLong_FromLong((long) value);
        } else if (sizeof(cufftType_t) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#if defined(HAVE_LONG_LONG) && !CYTHON_COMPILING_IN_PYPY
        } else if (sizeof(cufftType_t) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(cufftType_t) <= sizeof(long)) {
            return PyLong_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(cufftType_t) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        unsigned char *bytes = (unsigned char *)&value;
#if !CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX >= 0x030d00A4
        if (is_unsigned) {
            return PyLong_FromUnsignedNativeBytes(bytes, sizeof(value), -1);
        } else {
            return PyLong_FromNativeBytes(bytes, sizeof(value), -1);
        }
#elif !CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x030d0000
        int one = 1; int little = (int)*(unsigned char *)&one;
        return _PyLong_FromByteArray(bytes, sizeof(cufftType_t),
                                     little, !is_unsigned);
#else
        int one = 1; int little = (int)*(unsigned char *)&one;
        PyObject *from_bytes, *result = NULL, *kwds = NULL;
        PyObject *py_bytes = NULL, *order_str = NULL;
        from_bytes = PyObject_GetAttrString((PyObject*)&PyLong_Type, "from_bytes");
        if (!from_bytes) return NULL;
        py_bytes = PyBytes_FromStringAndSize((char*)bytes, sizeof(cufftType_t));
        if (!py_bytes) goto limited_bad;
        order_str = PyUnicode_FromString(little ? "little" : "big");
        if (!order_str) goto limited_bad;
        {
            PyObject *args[3+(CYTHON_VECTORCALL ? 1 : 0)] = { NULL, py_bytes, order_str };
            if (!is_unsigned) {
                kwds = __Pyx_MakeVectorcallBuilderKwds(1);
                if (!kwds) goto limited_bad;
                if (__Pyx_VectorcallBuilder_AddArgStr("signed", __Pyx_NewRef(Py_True), kwds, args+3, 0) < 0) goto limited_bad;
            }
            result = __Pyx_Object_Vectorcall_CallFromBuilder(from_bytes, args+1, 2 | __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET, kwds);
        }
        limited_bad:
        Py_XDECREF(kwds);
        Py_XDECREF(order_str);
        Py_XDECREF(py_bytes);
        Py_XDECREF(from_bytes);
        return result;
#endif
    }
}

/* CIntFromPy */
static CYTHON_INLINE cufftType_t __Pyx_PyLong_As_cufftType_t(PyObject *x) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const cufftType_t neg_one = (cufftType_t) -1, const_zero = (cufftType_t) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (unlikely(!PyLong_Check(x))) {
        cufftType_t val;
        PyObject *tmp = __Pyx_PyNumber_Long(x);
        if (!tmp) return (cufftType_t) -1;
        val = __Pyx_PyLong_As_cufftType_t(tmp);
        Py_DECREF(tmp);
        return val;
    }
    if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
        if (unlikely(__Pyx_PyLong_IsNeg(x))) {
            goto raise_neg_overflow;
        } else if (__Pyx_PyLong_IsCompact(x)) {
            __PYX_VERIFY_RETURN_INT(cufftType_t, __Pyx_compact_upylong, __Pyx_PyLong_CompactValueUnsigned(x))
        } else {
            const digit* digits = __Pyx_PyLong_Digits(x);
            assert(__Pyx_PyLong_DigitCount(x) > 1);
            switch (__Pyx_PyLong_DigitCount(x)) {
                case 2:
                    if ((8 * sizeof(cufftType_t) > 1 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(cufftType_t, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(cufftType_t) >= 2 * PyLong_SHIFT)) {
                            return (cufftType_t) (((((cufftType_t)digits[1]) << PyLong_SHIFT) | (cufftType_t)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if ((8 * sizeof(cufftType_t) > 2 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(cufftType_t, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(cufftType_t) >= 3 * PyLong_SHIFT)) {
                            return (cufftType_t) (((((((cufftType_t)digits[2]) << PyLong_SHIFT) | (cufftType_t)digits[1]) << PyLong_SHIFT) | (cufftType_t)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if ((8 * sizeof(cufftType_t) > 3 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(cufftType_t, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(cufftType_t) >= 4 * PyLong_SHIFT)) {
                            return (cufftType_t) (((((((((cufftType_t)digits[3]) << PyLong_SHIFT) | (cufftType_t)digits[2]) << PyLong_SHIFT) | (cufftType_t)digits[1]) << PyLong_SHIFT) | (cufftType_t)digits[0]));
                        }
                    }
                    break;
            }
        }
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030C00A7
        if (unlikely(Py_SIZE(x) < 0)) {
            goto raise_neg_overflow;
        }
#else
        {
            int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
            if (unlikely(result < 0))
                return (cufftType_t) -1;
            if (unlikely(result == 1))
                goto raise_neg_overflow;
        }
#endif
        if ((sizeof(cufftType_t) <= sizeof(unsigned long))) {
            __PYX_VERIFY_RETURN_INT_EXC(cufftType_t, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
        } else if ((sizeof(cufftType_t) <= sizeof(unsigned PY_LONG_LONG))) {
            __PYX_VERIFY_RETURN_INT_EXC(cufftType_t, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
        }
    } else {
#if CYTHON_USE_PYLONG_INTERNALS
        if (__Pyx_PyLong_IsCompact(x)) {
            __PYX_VERIFY_RETURN_INT(cufftType_t, __Pyx_compact_pylong, __Pyx_PyLong_CompactValue(x))
        } else {
            const digit* digits = __Pyx_PyLong_Digits(x);
            assert(__Pyx_PyLong_DigitCount(x) > 1);
            switch (__Pyx_PyLong_SignedDigitCount(x)) {
                case -2:
                    if ((8 * sizeof(cufftType_t) - 1 > 1 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(cufftType_t, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(cufftType_t) - 1 > 2 * PyLong_SHIFT)) {
                            return (cufftType_t) (((cufftType_t)-1)*(((((cufftType_t)digits[1]) << PyLong_SHIFT) | (cufftType_t)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if ((8 * sizeof(cufftType_t) > 1 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(cufftType_t, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(cufftType_t) - 1 > 2 * PyLong_SHIFT)) {
                            return (cufftType_t) ((((((cufftType_t)digits[1]) << PyLong_SHIFT) | (cufftType_t)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if ((8 * sizeof(cufftType_t) - 1 > 2 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(cufftType_t, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(cufftType_t) - 1 > 3 * PyLong_SHIFT)) {
                            return (cufftType_t) (((cufftType_t)-1)*(((((((cufftType_t)digits[2]) << PyLong_SHIFT) | (cufftType_t)digits[1]) << PyLong_SHIFT) | (cufftType_t)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if ((8 * sizeof(cufftType_t) > 2 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(cufftType_t, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(cufftType_t) - 1 > 3 * PyLong_SHIFT)) {
                            return (cufftType_t) ((((((((cufftType_t)digits[2]) << PyLong_SHIFT) | (cufftType_t)digits[1]) << PyLong_SHIFT) | (cufftType_t)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if ((8 * sizeof(cufftType_t) - 1 > 3 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(cufftType_t, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(cufftType_t) - 1 > 4 * PyLong_SHIFT)) {
                            return (cufftType_t) (((cufftType_t)-1)*(((((((((cufftType_t)digits[3]) << PyLong_SHIFT) | (cufftType_t)digits[2]) << PyLong_SHIFT) | (cufftType_t)digits[1]) << PyLong_SHIFT) | (cufftType_t)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if ((8 * sizeof(cufftType_t) > 3 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(cufftType_t, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(cufftType_t) - 1 > 4 * PyLong_SHIFT)) {
                            return (cufftType_t) ((((((((((cufftType_t)digits[3]) << PyLong_SHIFT) | (cufftType_t)digits[2]) << PyLong_SHIFT) | (cufftType_t)digits[1]) << PyLong_SHIFT) | (cufftType_t)digits[0])));
                        }
                    }
                    break;
            }
        }
#endif
        if ((sizeof(cufftType_t) <= sizeof(long))) {
            __PYX_VERIFY_RETURN_INT_EXC(cufftType_t, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
        } else if ((sizeof(cufftType_t) <= sizeof(PY_LONG_LONG))) {
            __PYX_VERIFY_RETURN_INT_EXC(cufftType_t, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
        }
    }
    {
        cufftType_t val;
        int ret = -1;
#if PY_VERSION_HEX >= 0x030d00A6 && !CYTHON_COMPILING_IN_LIMITED_API
        Py_ssize_t bytes_copied = PyLong_AsNativeBytes(
            x, &val, sizeof(val), Py_ASNATIVEBYTES_NATIVE_ENDIAN | (is_unsigned ? Py_ASNATIVEBYTES_UNSIGNED_BUFFER | Py_ASNATIVEBYTES_REJECT_NEGATIVE : 0));
        if (unlikely(bytes_copied == -1)) {
        } else if (unlikely(bytes_copied > (Py_ssize_t) sizeof(val))) {
            goto raise_overflow;
        } else {
            ret = 0;
        }
#elif PY_VERSION_HEX < 0x030d0000 && !(CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_LIMITED_API) || defined(_PyLong_AsByteArray)
        int one = 1; int is_little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&val;
        ret = _PyLong_AsByteArray((PyLongObject *)x,
                                    bytes, sizeof(val),
                                    is_little, !is_unsigned);
#else
        PyErr_SetString(PyExc_RuntimeError,
                        "_PyLong_AsByteArray() or PyLong_AsNativeBytes() not available, cannot convert large enums");
        val = (cufftType_t) -1;
#endif
        if (unlikely(ret))
            return (cufftType_t) -1;
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to cufftType_t");
    return (cufftType_t) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to cufftType_t");
    return (cufftType_t) -1;
}

/* CIntFromPy */
static CYTHON_INLINE PY_LONG_LONG __Pyx_PyLong_As_PY_LONG_LONG(PyObject *x) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const PY_LONG_LONG neg_one = (PY_LONG_LONG) -1, const_zero = (PY_LONG_LONG) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (unlikely(!PyLong_Check(x))) {
        PY_LONG_LONG val;
        PyObject *tmp = __Pyx_PyNumber_Long(x);
        if (!tmp) return (PY_LONG_LONG) -1;
        val = __Pyx_PyLong_As_PY_LONG_LONG(tmp);
        Py_DECREF(tmp);
        return val;
    }
    if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
        if (unlikely(__Pyx_PyLong_IsNeg(x))) {
            goto raise_neg_overflow;
        } else if (__Pyx_PyLong_IsCompact(x)) {
            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, __Pyx_compact_upylong, __Pyx_PyLong_CompactValueUnsigned(x))
        } else {
            const digit* digits = __Pyx_PyLong_Digits(x);
            assert(__Pyx_PyLong_DigitCount(x) > 1);
            switch (__Pyx_PyLong_DigitCount(x)) {
                case 2:
                    if ((8 * sizeof(PY_LONG_LONG) > 1 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(PY_LONG_LONG) >= 2 * PyLong_SHIFT)) {
                            return (PY_LONG_LONG) (((((PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if ((8 * sizeof(PY_LONG_LONG) > 2 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(PY_LONG_LONG) >= 3 * PyLong_SHIFT)) {
                            return (PY_LONG_LONG) (((((((PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if ((8 * sizeof(PY_LONG_LONG) > 3 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(PY_LONG_LONG) >= 4 * PyLong_SHIFT)) {
                            return (PY_LONG_LONG) (((((((((PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0]));
                        }
                    }
                    break;
            }
        }
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030C00A7
        if (unlikely(Py_SIZE(x) < 0)) {
            goto raise_neg_overflow;
        }
#else
        {
            int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
            if (unlikely(result < 0))
                return (PY_LONG_LONG) -1;
            if (unlikely(result == 1))
                goto raise_neg_overflow;
        }
#endif
        if ((sizeof(PY_LONG_LONG) <= sizeof(unsigned long))) {
            __PYX_VERIFY_RETURN_INT_EXC(PY_LONG_LONG, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
        } else if ((sizeof(PY_LONG_LONG) <= sizeof(unsigned PY_LONG_LONG))) {
            __PYX_VERIFY_RETURN_INT_EXC(PY_LONG_LONG, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
        }
    } else {
#if CYTHON_USE_PYLONG_INTERNALS
        if (__Pyx_PyLong_IsCompact(x)) {
            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, __Pyx_compact_pylong, __Pyx_PyLong_CompactValue(x))
        } else {
            const digit* digits = __Pyx_PyLong_Digits(x);
            assert(__Pyx_PyLong_DigitCount(x) > 1);
            switch (__Pyx_PyLong_SignedDigitCount(x)) {
                case -2:
                    if ((8 * sizeof(PY_LONG_LONG) - 1 > 1 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT)) {
                            return (PY_LONG_LONG) (((PY_LONG_LONG)-1)*(((((PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if ((8 * sizeof(PY_LONG_LONG) > 1 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT)) {
                            return (PY_LONG_LONG) ((((((PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if ((8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT)) {
                            return (PY_LONG_LONG) (((PY_LONG_LONG)-1)*(((((((PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if ((8 * sizeof(PY_LONG_LONG) > 2 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT)) {
                            return (PY_LONG_LONG) ((((((((PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if ((8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT)) {
                            return (PY_LONG_LONG) (((PY_LONG_LONG)-1)*(((((((((PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if ((8 * sizeof(PY_LONG_LONG) > 3 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(PY_LONG_LONG, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT)) {
                            return (PY_LONG_LONG) ((((((((((PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (PY_LONG_LONG)digits[0])));
                        }
                    }
                    break;
            }
        }
#endif
        if ((sizeof(PY_LONG_LONG) <= sizeof(long))) {
            __PYX_VERIFY_RETURN_INT_EXC(PY_LONG_LONG, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
        } else if ((sizeof(PY_LONG_LONG) <= sizeof(PY_LONG_LONG))) {
            __PYX_VERIFY_RETURN_INT_EXC(PY_LONG_LONG, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
        }
    }
    {
        PY_LONG_LONG val;
        int ret = -1;
#if PY_VERSION_HEX >= 0x030d00A6 && !CYTHON_COMPILING_IN_LIMITED_API
        Py_ssize_t bytes_copied = PyLong_AsNativeBytes(
            x, &val, sizeof(val), Py_ASNATIVEBYTES_NATIVE_ENDIAN | (is_unsigned ? Py_ASNATIVEBYTES_UNSIGNED_BUFFER | Py_ASNATIVEBYTES_REJECT_NEGATIVE : 0));
        if (unlikely(bytes_copied == -1)) {
        } else if (unlikely(bytes_copied > (Py_ssize_t) sizeof(val))) {
            goto raise_overflow;
        } else {
            ret = 0;
        }
#elif PY_VERSION_HEX < 0x030d0000 && !(CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_LIMITED_API) || defined(_PyLong_AsByteArray)
        int one = 1; int is_little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&val;
        ret = _PyLong_AsByteArray((PyLongObject *)x,
                                    bytes, sizeof(val),
                                    is_little, !is_unsigned);
#else
        PyObject *v;
        PyObject *stepval = NULL, *mask = NULL, *shift = NULL;
        int bits, remaining_bits, is_negative = 0;
        int chunk_size = (sizeof(long) < 8) ? 30 : 62;
        if (likely(PyLong_CheckExact(x))) {
            v = __Pyx_NewRef(x);
        } else {
            v = PyNumber_Long(x);
            if (unlikely(!v)) return (PY_LONG_LONG) -1;
            assert(PyLong_CheckExact(v));
        }
        {
            int result = PyObject_RichCompareBool(v, Py_False, Py_LT);
            if (unlikely(result < 0)) {
                Py_DECREF(v);
                return (PY_LONG_LONG) -1;
            }
            is_negative = result == 1;
        }
        if (is_unsigned && unlikely(is_negative)) {
            Py_DECREF(v);
            goto raise_neg_overflow;
        } else if (is_negative) {
            stepval = PyNumber_Invert(v);
            Py_DECREF(v);
            if (unlikely(!stepval))
                return (PY_LONG_LONG) -1;
        } else {
            stepval = v;
        }
        v = NULL;
        val = (PY_LONG_LONG) 0;
        mask = PyLong_FromLong((1L << chunk_size) - 1); if (unlikely(!mask)) goto done;
        shift = PyLong_FromLong(chunk_size); if (unlikely(!shift)) goto done;
        for (bits = 0; bits < (int) sizeof(PY_LONG_LONG) * 8 - chunk_size; bits += chunk_size) {
            PyObject *tmp, *digit;
            long idigit;
            digit = PyNumber_And(stepval, mask);
            if (unlikely(!digit)) goto done;
            idigit = PyLong_AsLong(digit);
            Py_DECREF(digit);
            if (unlikely(idigit < 0)) goto done;
            val |= ((PY_LONG_LONG) idigit) << bits;
            tmp = PyNumber_Rshift(stepval, shift);
            if (unlikely(!tmp)) goto done;
            Py_DECREF(stepval); stepval = tmp;
        }
        Py_DECREF(shift); shift = NULL;
        Py_DECREF(mask); mask = NULL;
        {
            long idigit = PyLong_AsLong(stepval);
            if (unlikely(idigit < 0)) goto done;
            remaining_bits = ((int) sizeof(PY_LONG_LONG) * 8) - bits - (is_unsigned ? 0 : 1);
            if (unlikely(idigit >= (1L << remaining_bits)))
                goto raise_overflow;
            val |= ((PY_LONG_LONG) idigit) << bits;
        }
        if (!is_unsigned) {
            if (unlikely(val & (((PY_LONG_LONG) 1) << (sizeof(PY_LONG_LONG) * 8 - 1))))
                goto raise_overflow;
            if (is_negative)
                val = ~val;
        }
        ret = 0;
    done:
        Py_XDECREF(shift);
        Py_XDECREF(mask);
        Py_XDECREF(stepval);
#endif
        if (unlikely(ret))
            return (PY_LONG_LONG) -1;
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to PY_LONG_LONG");
    return (PY_LONG_LONG) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to PY_LONG_LONG");
    return (PY_LONG_LONG) -1;
}

/* CIntFromPy */
static CYTHON_INLINE long __Pyx_PyLong_As_long(PyObject *x) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const long neg_one = (long) -1, const_zero = (long) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (unlikely(!PyLong_Check(x))) {
        long val;
        PyObject *tmp = __Pyx_PyNumber_Long(x);
        if (!tmp) return (long) -1;
        val = __Pyx_PyLong_As_long(tmp);
        Py_DECREF(tmp);
        return val;
    }
    if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
        if (unlikely(__Pyx_PyLong_IsNeg(x))) {
            goto raise_neg_overflow;
        } else if (__Pyx_PyLong_IsCompact(x)) {
            __PYX_VERIFY_RETURN_INT(long, __Pyx_compact_upylong, __Pyx_PyLong_CompactValueUnsigned(x))
        } else {
            const digit* digits = __Pyx_PyLong_Digits(x);
            assert(__Pyx_PyLong_DigitCount(x) > 1);
            switch (__Pyx_PyLong_DigitCount(x)) {
                case 2:
                    if ((8 * sizeof(long) > 1 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(long) >= 2 * PyLong_SHIFT)) {
                            return (long) (((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if ((8 * sizeof(long) > 2 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(long) >= 3 * PyLong_SHIFT)) {
                            return (long) (((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if ((8 * sizeof(long) > 3 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(long) >= 4 * PyLong_SHIFT)) {
                            return (long) (((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
            }
        }
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030C00A7
        if (unlikely(Py_SIZE(x) < 0)) {
            goto raise_neg_overflow;
        }
#else
        {
            int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
            if (unlikely(result < 0))
                return (long) -1;
            if (unlikely(result == 1))
                goto raise_neg_overflow;
        }
#endif
        if ((sizeof(long) <= sizeof(unsigned long))) {
            __PYX_VERIFY_RETURN_INT_EXC(long, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
        } else if ((sizeof(long) <= sizeof(unsigned PY_LONG_LONG))) {
            __PYX_VERIFY_RETURN_INT_EXC(long, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
        }
    } else {
#if CYTHON_USE_PYLONG_INTERNALS
        if (__Pyx_PyLong_IsCompact(x)) {
            __PYX_VERIFY_RETURN_INT(long, __Pyx_compact_pylong, __Pyx_PyLong_CompactValue(x))
        } else {
            const digit* digits = __Pyx_PyLong_Digits(x);
            assert(__Pyx_PyLong_DigitCount(x) > 1);
            switch (__Pyx_PyLong_SignedDigitCount(x)) {
                case -2:
                    if ((8 * sizeof(long) - 1 > 1 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(long) - 1 > 2 * PyLong_SHIFT)) {
                            return (long) (((long)-1)*(((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if ((8 * sizeof(long) > 1 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(long) - 1 > 2 * PyLong_SHIFT)) {
                            return (long) ((((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if ((8 * sizeof(long) - 1 > 2 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(long) - 1 > 3 * PyLong_SHIFT)) {
                            return (long) (((long)-1)*(((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if ((8 * sizeof(long) > 2 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(long) - 1 > 3 * PyLong_SHIFT)) {
                            return (long) ((((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if ((8 * sizeof(long) - 1 > 3 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(long) - 1 > 4 * PyLong_SHIFT)) {
                            return (long) (((long)-1)*(((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if ((8 * sizeof(long) > 3 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(long) - 1 > 4 * PyLong_SHIFT)) {
                            return (long) ((((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
            }
        }
#endif
        if ((sizeof(long) <= sizeof(long))) {
            __PYX_VERIFY_RETURN_INT_EXC(long, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
        } else if ((sizeof(long) <= sizeof(PY_LONG_LONG))) {
            __PYX_VERIFY_RETURN_INT_EXC(long, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
        }
    }
    {
        long val;
        int ret = -1;
#if PY_VERSION_HEX >= 0x030d00A6 && !CYTHON_COMPILING_IN_LIMITED_API
        Py_ssize_t bytes_copied = PyLong_AsNativeBytes(
            x, &val, sizeof(val), Py_ASNATIVEBYTES_NATIVE_ENDIAN | (is_unsigned ? Py_ASNATIVEBYTES_UNSIGNED_BUFFER | Py_ASNATIVEBYTES_REJECT_NEGATIVE : 0));
        if (unlikely(bytes_copied == -1)) {
        } else if (unlikely(bytes_copied > (Py_ssize_t) sizeof(val))) {
            goto raise_overflow;
        } else {
            ret = 0;
        }
#elif PY_VERSION_HEX < 0x030d0000 && !(CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_LIMITED_API) || defined(_PyLong_AsByteArray)
        int one = 1; int is_little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&val;
        ret = _PyLong_AsByteArray((PyLongObject *)x,
                                    bytes, sizeof(val),
                                    is_little, !is_unsigned);
#else
        PyObject *v;
        PyObject *stepval = NULL, *mask = NULL, *shift = NULL;
        int bits, remaining_bits, is_negative = 0;
        int chunk_size = (sizeof(long) < 8) ? 30 : 62;
        if (likely(PyLong_CheckExact(x))) {
            v = __Pyx_NewRef(x);
        } else {
            v = PyNumber_Long(x);
            if (unlikely(!v)) return (long) -1;
            assert(PyLong_CheckExact(v));
        }
        {
            int result = PyObject_RichCompareBool(v, Py_False, Py_LT);
            if (unlikely(result < 0)) {
                Py_DECREF(v);
                return (long) -1;
            }
            is_negative = result == 1;
        }
        if (is_unsigned && unlikely(is_negative)) {
            Py_DECREF(v);
            goto raise_neg_overflow;
        } else if (is_negative) {
            stepval = PyNumber_Invert(v);
            Py_DECREF(v);
            if (unlikely(!stepval))
                return (long) -1;
        } else {
            stepval = v;
        }
        v = NULL;
        val = (long) 0;
        mask = PyLong_FromLong((1L << chunk_size) - 1); if (unlikely(!mask)) goto done;
        shift = PyLong_FromLong(chunk_size); if (unlikely(!shift)) goto done;
        for (bits = 0; bits < (int) sizeof(long) * 8 - chunk_size; bits += chunk_size) {
            PyObject *tmp, *digit;
            long idigit;
            digit = PyNumber_And(stepval, mask);
            if (unlikely(!digit)) goto done;
            idigit = PyLong_AsLong(digit);
            Py_DECREF(digit);
            if (unlikely(idigit < 0)) goto done;
            val |= ((long) idigit) << bits;
            tmp = PyNumber_Rshift(stepval, shift);
            if (unlikely(!tmp)) goto done;
            Py_DECREF(stepval); stepval = tmp;
        }
        Py_DECREF(shift); shift = NULL;
        Py_DECREF(mask); mask = NULL;
        {
            long idigit = PyLong_AsLong(stepval);
            if (unlikely(idigit < 0)) goto done;
            remaining_bits = ((int) sizeof(long) * 8) - bits - (is_unsigned ? 0 : 1);
            if (unlikely(idigit >= (1L << remaining_bits)))
                goto raise_overflow;
            val |= ((long) idigit) << bits;
        }
        if (!is_unsigned) {
            if (unlikely(val & (((long) 1) << (sizeof(long) * 8 - 1))))
                goto raise_overflow;
            if (is_negative)
                val = ~val;
        }
        ret = 0;
    done:
        Py_XDECREF(shift);
        Py_XDECREF(mask);
        Py_XDECREF(stepval);
#endif
        if (unlikely(ret))
            return (long) -1;
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to long");
    return (long) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to long");
    return (long) -1;
}

/* CIntFromPy */
static CYTHON_INLINE size_t __Pyx_PyLong_As_size_t(PyObject *x) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const size_t neg_one = (size_t) -1, const_zero = (size_t) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (unlikely(!PyLong_Check(x))) {
        size_t val;
        PyObject *tmp = __Pyx_PyNumber_Long(x);
        if (!tmp) return (size_t) -1;
        val = __Pyx_PyLong_As_size_t(tmp);
        Py_DECREF(tmp);
        return val;
    }
    if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
        if (unlikely(__Pyx_PyLong_IsNeg(x))) {
            goto raise_neg_overflow;
        } else if (__Pyx_PyLong_IsCompact(x)) {
            __PYX_VERIFY_RETURN_INT(size_t, __Pyx_compact_upylong, __Pyx_PyLong_CompactValueUnsigned(x))
        } else {
            const digit* digits = __Pyx_PyLong_Digits(x);
            assert(__Pyx_PyLong_DigitCount(x) > 1);
            switch (__Pyx_PyLong_DigitCount(x)) {
                case 2:
                    if ((8 * sizeof(size_t) > 1 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(size_t) >= 2 * PyLong_SHIFT)) {
                            return (size_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if ((8 * sizeof(size_t) > 2 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(size_t) >= 3 * PyLong_SHIFT)) {
                            return (size_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if ((8 * sizeof(size_t) > 3 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(size_t) >= 4 * PyLong_SHIFT)) {
                            return (size_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                        }
                    }
                    break;
            }
        }
#endif
#if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX < 0x030C00A7
        if (unlikely(Py_SIZE(x) < 0)) {
            goto raise_neg_overflow;
        }
#else
        {
            int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
            if (unlikely(result < 0))
                return (size_t) -1;
            if (unlikely(result == 1))
                goto raise_neg_overflow;
        }
#endif
        if ((sizeof(size_t) <= sizeof(unsigned long))) {
            __PYX_VERIFY_RETURN_INT_EXC(size_t, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
        } else if ((sizeof(size_t) <= sizeof(unsigned PY_LONG_LONG))) {
            __PYX_VERIFY_RETURN_INT_EXC(size_t, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
        }
    } else {
#if CYTHON_USE_PYLONG_INTERNALS
        if (__Pyx_PyLong_IsCompact(x)) {
            __PYX_VERIFY_RETURN_INT(size_t, __Pyx_compact_pylong, __Pyx_PyLong_CompactValue(x))
        } else {
            const digit* digits = __Pyx_PyLong_Digits(x);
            assert(__Pyx_PyLong_DigitCount(x) > 1);
            switch (__Pyx_PyLong_SignedDigitCount(x)) {
                case -2:
                    if ((8 * sizeof(size_t) - 1 > 1 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT)) {
                            return (size_t) (((size_t)-1)*(((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if ((8 * sizeof(size_t) > 1 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 2 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT)) {
                            return (size_t) ((((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if ((8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT)) {
                            return (size_t) (((size_t)-1)*(((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if ((8 * sizeof(size_t) > 2 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 3 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT)) {
                            return (size_t) ((((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if ((8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(size_t) - 1 > 4 * PyLong_SHIFT)) {
                            return (size_t) (((size_t)-1)*(((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if ((8 * sizeof(size_t) > 3 * PyLong_SHIFT)) {
                        if ((8 * sizeof(unsigned long) > 4 * PyLong_SHIFT)) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if ((8 * sizeof(size_t) - 1 > 4 * PyLong_SHIFT)) {
                            return (size_t) ((((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
            }
        }
#endif
        if ((sizeof(size_t) <= sizeof(long))) {
            __PYX_VERIFY_RETURN_INT_EXC(size_t, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
        } else if ((sizeof(size_t) <= sizeof(PY_LONG_LONG))) {
            __PYX_VERIFY_RETURN_INT_EXC(size_t, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
        }
    }
    {
        size_t val;
        int ret = -1;
#if PY_VERSION_HEX >= 0x030d00A6 && !CYTHON_COMPILING_IN_LIMITED_API
        Py_ssize_t bytes_copied = PyLong_AsNativeBytes(
            x, &val, sizeof(val), Py_ASNATIVEBYTES_NATIVE_ENDIAN | (is_unsigned ? Py_ASNATIVEBYTES_UNSIGNED_BUFFER | Py_ASNATIVEBYTES_REJECT_NEGATIVE : 0));
        if (unlikely(bytes_copied == -1)) {
        } else if (unlikely(bytes_copied > (Py_ssize_t) sizeof(val))) {
            goto raise_overflow;
        } else {
            ret = 0;
        }
#elif PY_VERSION_HEX < 0x030d0000 && !(CYTHON_COMPILING_IN_PYPY || CYTHON_COMPILING_IN_LIMITED_API) || defined(_PyLong_AsByteArray)
        int one = 1; int is_little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&val;
        ret = _PyLong_AsByteArray((PyLongObject *)x,
                                    bytes, sizeof(val),
                                    is_little, !is_unsigned);
#else
        PyObject *v;
        PyObject *stepval = NULL, *mask = NULL, *shift = NULL;
        int bits, remaining_bits, is_negative = 0;
        int chunk_size = (sizeof(long) < 8) ? 30 : 62;
        if (likely(PyLong_CheckExact(x))) {
            v = __Pyx_NewRef(x);
        } else {
            v = PyNumber_Long(x);
            if (unlikely(!v)) return (size_t) -1;
            assert(PyLong_CheckExact(v));
        }
        {
            int result = PyObject_RichCompareBool(v, Py_False, Py_LT);
            if (unlikely(result < 0)) {
                Py_DECREF(v);
                return (size_t) -1;
            }
            is_negative = result == 1;
        }
        if (is_unsigned && unlikely(is_negative)) {
            Py_DECREF(v);
            goto raise_neg_overflow;
        } else if (is_negative) {
            stepval = PyNumber_Invert(v);
            Py_DECREF(v);
            if (unlikely(!stepval))
                return (size_t) -1;
        } else {
            stepval = v;
        }
        v = NULL;
        val = (size_t) 0;
        mask = PyLong_FromLong((1L << chunk_size) - 1); if (unlikely(!mask)) goto done;
        shift = PyLong_FromLong(chunk_size); if (unlikely(!shift)) goto done;
        for (bits = 0; bits < (int) sizeof(size_t) * 8 - chunk_size; bits += chunk_size) {
            PyObject *tmp, *digit;
            long idigit;
            digit = PyNumber_And(stepval, mask);
            if (unlikely(!digit)) goto done;
            idigit = PyLong_AsLong(digit);
            Py_DECREF(digit);
            if (unlikely(idigit < 0)) goto done;
            val |= ((size_t) idigit) << bits;
            tmp = PyNumber_Rshift(stepval, shift);
            if (unlikely(!tmp)) goto done;
            Py_DECREF(stepval); stepval = tmp;
        }
        Py_DECREF(shift); shift = NULL;
        Py_DECREF(mask); mask = NULL;
        {
            long idigit = PyLong_AsLong(stepval);
            if (unlikely(idigit < 0)) goto done;
            remaining_bits = ((int) sizeof(size_t) * 8) - bits - (is_unsigned ? 0 : 1);
            if (unlikely(idigit >= (1L << remaining_bits)))
                goto raise_overflow;
            val |= ((size_t) idigit) << bits;
        }
        if (!is_unsigned) {
            if (unlikely(val & (((size_t) 1) << (sizeof(size_t) * 8 - 1))))
                goto raise_overflow;
            if (is_negative)
                val = ~val;
        }
        ret = 0;
    done:
        Py_XDECREF(shift);
        Py_XDECREF(mask);
        Py_XDECREF(stepval);
#endif
        if (unlikely(ret))
            return (size_t) -1;
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to size_t");
    return (size_t) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to size_t");
    return (size_t) -1;
}

/* CIntToPy */
static CYTHON_INLINE PyObject* __Pyx_PyLong_From_long(long value) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const long neg_one = (long) -1, const_zero = (long) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(long) < sizeof(long)) {
            return PyLong_FromLong((long) value);
        } else if (sizeof(long) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#if defined(HAVE_LONG_LONG) && !CYTHON_COMPILING_IN_PYPY
        } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(long) <= sizeof(long)) {
            return PyLong_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        unsigned char *bytes = (unsigned char *)&value;
#if !CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX >= 0x030d00A4
        if (is_unsigned) {
            return PyLong_FromUnsignedNativeBytes(bytes, sizeof(value), -1);
        } else {
            return PyLong_FromNativeBytes(bytes, sizeof(value), -1);
        }
#elif !CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x030d0000
        int one = 1; int little = (int)*(unsigned char *)&one;
        return _PyLong_FromByteArray(bytes, sizeof(long),
                                     little, !is_unsigned);
#else
        int one = 1; int little = (int)*(unsigned char *)&one;
        PyObject *from_bytes, *result = NULL, *kwds = NULL;
        PyObject *py_bytes = NULL, *order_str = NULL;
        from_bytes = PyObject_GetAttrString((PyObject*)&PyLong_Type, "from_bytes");
        if (!from_bytes) return NULL;
        py_bytes = PyBytes_FromStringAndSize((char*)bytes, sizeof(long));
        if (!py_bytes) goto limited_bad;
        order_str = PyUnicode_FromString(little ? "little" : "big");
        if (!order_str) goto limited_bad;
        {
            PyObject *args[3+(CYTHON_VECTORCALL ? 1 : 0)] = { NULL, py_bytes, order_str };
            if (!is_unsigned) {
                kwds = __Pyx_MakeVectorcallBuilderKwds(1);
                if (!kwds) goto limited_bad;
                if (__Pyx_VectorcallBuilder_AddArgStr("signed", __Pyx_NewRef(Py_True), kwds, args+3, 0) < 0) goto limited_bad;
            }
            result = __Pyx_Object_Vectorcall_CallFromBuilder(from_bytes, args+1, 2 | __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET, kwds);
        }
        limited_bad:
        Py_XDECREF(kwds);
        Py_XDECREF(order_str);
        Py_XDECREF(py_bytes);
        Py_XDECREF(from_bytes);
        return result;
#endif
    }
}

/* CIntToPy */
static CYTHON_INLINE PyObject* __Pyx_PyLong_From_PY_LONG_LONG(PY_LONG_LONG value) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const PY_LONG_LONG neg_one = (PY_LONG_LONG) -1, const_zero = (PY_LONG_LONG) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(PY_LONG_LONG) < sizeof(long)) {
            return PyLong_FromLong((long) value);
        } else if (sizeof(PY_LONG_LONG) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#if defined(HAVE_LONG_LONG) && !CYTHON_COMPILING_IN_PYPY
        } else if (sizeof(PY_LONG_LONG) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(PY_LONG_LONG) <= sizeof(long)) {
            return PyLong_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(PY_LONG_LONG) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        unsigned char *bytes = (unsigned char *)&value;
#if !CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX >= 0x030d00A4
        if (is_unsigned) {
            return PyLong_FromUnsignedNativeBytes(bytes, sizeof(value), -1);
        } else {
            return PyLong_FromNativeBytes(bytes, sizeof(value), -1);
        }
#elif !CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x030d0000
        int one = 1; int little = (int)*(unsigned char *)&one;
        return _PyLong_FromByteArray(bytes, sizeof(PY_LONG_LONG),
                                     little, !is_unsigned);
#else
        int one = 1; int little = (int)*(unsigned char *)&one;
        PyObject *from_bytes, *result = NULL, *kwds = NULL;
        PyObject *py_bytes = NULL, *order_str = NULL;
        from_bytes = PyObject_GetAttrString((PyObject*)&PyLong_Type, "from_bytes");
        if (!from_bytes) return NULL;
        py_bytes = PyBytes_FromStringAndSize((char*)bytes, sizeof(PY_LONG_LONG));
        if (!py_bytes) goto limited_bad;
        order_str = PyUnicode_FromString(little ? "little" : "big");
        if (!order_str) goto limited_bad;
        {
            PyObject *args[3+(CYTHON_VECTORCALL ? 1 : 0)] = { NULL, py_bytes, order_str };
            if (!is_unsigned) {
                kwds = __Pyx_MakeVectorcallBuilderKwds(1);
                if (!kwds) goto limited_bad;
                if (__Pyx_VectorcallBuilder_AddArgStr("signed", __Pyx_NewRef(Py_True), kwds, args+3, 0) < 0) goto limited_bad;
            }
            result = __Pyx_Object_Vectorcall_CallFromBuilder(from_bytes, args+1, 2 | __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET, kwds);
        }
        limited_bad:
        Py_XDECREF(kwds);
        Py_XDECREF(order_str);
        Py_XDECREF(py_bytes);
        Py_XDECREF(from_bytes);
        return result;
#endif
    }
}

/* FormatTypeName */
#if CYTHON_COMPILING_IN_LIMITED_API && __PYX_LIMITED_VERSION_HEX < 0x030d0000
static __Pyx_TypeName
__Pyx_PyType_GetFullyQualifiedName(PyTypeObject* tp)
{
    PyObject *module = NULL, *name = NULL, *result = NULL;
    #if __PYX_LIMITED_VERSION_HEX < 0x030b0000
    name = __Pyx_PyObject_GetAttrStr((PyObject *)tp,
                                               __pyx_mstate_global->__pyx_n_u_qualname);
    #else
    name = PyType_GetQualName(tp);
    #endif
    if (unlikely(name == NULL) || unlikely(!PyUnicode_Check(name))) goto bad;
    module = __Pyx_PyObject_GetAttrStr((PyObject *)tp,
                                               __pyx_mstate_global->__pyx_n_u_module);
    if (unlikely(module == NULL) || unlikely(!PyUnicode_Check(module))) goto bad;
    if (PyUnicode_CompareWithASCIIString(module, "builtins") == 0) {
        result = name;
        name = NULL;
        goto done;
    }
    result = PyUnicode_FromFormat("%U.%U", module, name);
    if (unlikely(result == NULL)) goto bad;
  done:
    Py_XDECREF(name);
    Py_XDECREF(module);
    return result;
  bad:
    PyErr_Clear();
    if (name) {
        result = name;
        name = NULL;
    } else {
        result = __Pyx_NewRef(__pyx_mstate_global->__pyx_kp_u__2);
    }
    goto done;
}
#endif

/* FastTypeChecks */
#if CYTHON_COMPILING_IN_CPYTHON
static int __Pyx_InBases(PyTypeObject *a, PyTypeObject *b) {
    while (a) {
        a = __Pyx_PyType_GetSlot(a, tp_base, PyTypeObject*);
        if (a == b)
            return 1;
    }
    return b == &PyBaseObject_Type;
}
static CYTHON_INLINE int __Pyx_IsSubtype(PyTypeObject *a, PyTypeObject *b) {
    PyObject *mro;
    if (a == b) return 1;
    mro = a->tp_mro;
    if (likely(mro)) {
        Py_ssize_t i, n;
        n = PyTuple_GET_SIZE(mro);
        for (i = 0; i < n; i++) {
            if (PyTuple_GET_ITEM(mro, i) == (PyObject *)b)
                return 1;
        }
        return 0;
    }
    return __Pyx_InBases(a, b);
}
static CYTHON_INLINE int __Pyx_IsAnySubtype2(PyTypeObject *cls, PyTypeObject *a, PyTypeObject *b) {
    PyObject *mro;
    if (cls == a || cls == b) return 1;
    mro = cls->tp_mro;
    if (likely(mro)) {
        Py_ssize_t i, n;
        n = PyTuple_GET_SIZE(mro);
        for (i = 0; i < n; i++) {
            PyObject *base = PyTuple_GET_ITEM(mro, i);
            if (base == (PyObject *)a || base == (PyObject *)b)
                return 1;
        }
        return 0;
    }
    return __Pyx_InBases(cls, a) || __Pyx_InBases(cls, b);
}
static CYTHON_INLINE int __Pyx_inner_PyErr_GivenExceptionMatches2(PyObject *err, PyObject* exc_type1, PyObject *exc_type2) {
    if (exc_type1) {
        return __Pyx_IsAnySubtype2((PyTypeObject*)err, (PyTypeObject*)exc_type1, (PyTypeObject*)exc_type2);
    } else {
        return __Pyx_IsSubtype((PyTypeObject*)err, (PyTypeObject*)exc_type2);
    }
}
static int __Pyx_PyErr_GivenExceptionMatchesTuple(PyObject *exc_type, PyObject *tuple) {
    Py_ssize_t i, n;
    assert(PyExceptionClass_Check(exc_type));
    n = PyTuple_GET_SIZE(tuple);
    for (i=0; i<n; i++) {
        if (exc_type == PyTuple_GET_ITEM(tuple, i)) return 1;
    }
    for (i=0; i<n; i++) {
        PyObject *t = PyTuple_GET_ITEM(tuple, i);
        if (likely(PyExceptionClass_Check(t))) {
            if (__Pyx_inner_PyErr_GivenExceptionMatches2(exc_type, NULL, t)) return 1;
        } else {
        }
    }
    return 0;
}
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches(PyObject *err, PyObject* exc_type) {
    if (likely(err == exc_type)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        if (likely(PyExceptionClass_Check(exc_type))) {
            return __Pyx_inner_PyErr_GivenExceptionMatches2(err, NULL, exc_type);
        } else if (likely(PyTuple_Check(exc_type))) {
            return __Pyx_PyErr_GivenExceptionMatchesTuple(err, exc_type);
        } else {
        }
    }
    return PyErr_GivenExceptionMatches(err, exc_type);
}
static CYTHON_INLINE int __Pyx_PyErr_GivenExceptionMatches2(PyObject *err, PyObject *exc_type1, PyObject *exc_type2) {
    assert(PyExceptionClass_Check(exc_type1));
    assert(PyExceptionClass_Check(exc_type2));
    if (likely(err == exc_type1 || err == exc_type2)) return 1;
    if (likely(PyExceptionClass_Check(err))) {
        return __Pyx_inner_PyErr_GivenExceptionMatches2(err, exc_type1, exc_type2);
    }
    return (PyErr_GivenExceptionMatches(err, exc_type1) || PyErr_GivenExceptionMatches(err, exc_type2));
}
#endif

/* GetRuntimeVersion */
static unsigned long __Pyx_get_runtime_version(void) {
#if __PYX_LIMITED_VERSION_HEX >= 0x030b0000
    return Py_Version & ~0xFFUL;
#else
    static unsigned long __Pyx_cached_runtime_version = 0;
    if (__Pyx_cached_runtime_version == 0) {
        const char* rt_version = Py_GetVersion();
        unsigned long version = 0;
        unsigned long factor = 0x01000000UL;
        unsigned int digit = 0;
        int i = 0;
        while (factor) {
            while ('0' <= rt_version[i] && rt_version[i] <= '9') {
                digit = digit * 10 + (unsigned int) (rt_version[i] - '0');
                ++i;
            }
            version += factor * digit;
            if (rt_version[i] != '.')
                break;
            digit = 0;
            factor >>= 8;
            ++i;
        }
        __Pyx_cached_runtime_version = version;
    }
    return __Pyx_cached_runtime_version;
#endif
}

/* CheckBinaryVersion */
static int __Pyx_check_binary_version(unsigned long ct_version, unsigned long rt_version, int allow_newer) {
    const unsigned long MAJOR_MINOR = 0xFFFF0000UL;
    if ((rt_version & MAJOR_MINOR) == (ct_version & MAJOR_MINOR))
        return 0;
    if (likely(allow_newer && (rt_version & MAJOR_MINOR) > (ct_version & MAJOR_MINOR)))
        return 1;
    {
        char message[200];
        PyOS_snprintf(message, sizeof(message),
                      "compile time Python version %d.%d "
                      "of module '%.100s' "
                      "%s "
                      "runtime version %d.%d",
                       (int) (ct_version >> 24), (int) ((ct_version >> 16) & 0xFF),
                       __Pyx_MODULE_NAME,
                       (allow_newer) ? "was newer than" : "does not match",
                       (int) (rt_version >> 24), (int) ((rt_version >> 16) & 0xFF)
       );
        return PyErr_WarnEx(NULL, message, 1);
    }
}

/* FunctionExport */
static int __Pyx_ExportFunction(const char *name, void (*f)(void), const char *sig) {
    PyObject *d = 0;
    PyObject *cobj = 0;
    union {
        void (*fp)(void);
        void *p;
    } tmp;
    d = PyObject_GetAttrString(__pyx_m, "__pyx_capi__");
    if (!d) {
        PyErr_Clear();
        d = PyDict_New();
        if (!d)
            goto bad;
        Py_INCREF(d);
        if (PyModule_AddObject(__pyx_m, "__pyx_capi__", d) < 0)
            goto bad;
    }
    tmp.fp = f;
    cobj = PyCapsule_New(tmp.p, sig, 0);
    if (!cobj)
        goto bad;
    if (PyDict_SetItemString(d, name, cobj) < 0)
        goto bad;
    Py_DECREF(cobj);
    Py_DECREF(d);
    return 0;
bad:
    Py_XDECREF(cobj);
    Py_XDECREF(d);
    return -1;
}

/* CIntToPy */
static CYTHON_INLINE PyObject* __Pyx_PyLong_From___pyx_anon_enum(int value) {
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wconversion"
#endif
    const int neg_one = (int) -1, const_zero = (int) 0;
#ifdef __Pyx_HAS_GCC_DIAGNOSTIC
#pragma GCC diagnostic pop
#endif
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(int) < sizeof(long)) {
            return PyLong_FromLong((long) value);
        } else if (sizeof(int) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#if defined(HAVE_LONG_LONG) && !CYTHON_COMPILING_IN_PYPY
        } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(int) <= sizeof(long)) {
            return PyLong_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        unsigned char *bytes = (unsigned char *)&value;
#if !CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX >= 0x030d00A4
        if (is_unsigned) {
            return PyLong_FromUnsignedNativeBytes(bytes, sizeof(value), -1);
        } else {
            return PyLong_FromNativeBytes(bytes, sizeof(value), -1);
        }
#elif !CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX < 0x030d0000
        int one = 1; int little = (int)*(unsigned char *)&one;
        return _PyLong_FromByteArray(bytes, sizeof(int),
                                     little, !is_unsigned);
#else
        int one = 1; int little = (int)*(unsigned char *)&one;
        PyObject *from_bytes, *result = NULL, *kwds = NULL;
        PyObject *py_bytes = NULL, *order_str = NULL;
        from_bytes = PyObject_GetAttrString((PyObject*)&PyLong_Type, "from_bytes");
        if (!from_bytes) return NULL;
        py_bytes = PyBytes_FromStringAndSize((char*)bytes, sizeof(int));
        if (!py_bytes) goto limited_bad;
        order_str = PyUnicode_FromString(little ? "little" : "big");
        if (!order_str) goto limited_bad;
        {
            PyObject *args[3+(CYTHON_VECTORCALL ? 1 : 0)] = { NULL, py_bytes, order_str };
            if (!is_unsigned) {
                kwds = __Pyx_MakeVectorcallBuilderKwds(1);
                if (!kwds) goto limited_bad;
                if (__Pyx_VectorcallBuilder_AddArgStr("signed", __Pyx_NewRef(Py_True), kwds, args+3, 0) < 0) goto limited_bad;
            }
            result = __Pyx_Object_Vectorcall_CallFromBuilder(from_bytes, args+1, 2 | __Pyx_PY_VECTORCALL_ARGUMENTS_OFFSET, kwds);
        }
        limited_bad:
        Py_XDECREF(kwds);
        Py_XDECREF(order_str);
        Py_XDECREF(py_bytes);
        Py_XDECREF(from_bytes);
        return result;
#endif
    }
}

/* NewCodeObj */
#if CYTHON_COMPILING_IN_LIMITED_API
    static PyObject* __Pyx__PyCode_New(int a, int p, int k, int l, int s, int f,
                                       PyObject *code, PyObject *c, PyObject* n, PyObject *v,
                                       PyObject *fv, PyObject *cell, PyObject* fn,
                                       PyObject *name, int fline, PyObject *lnos) {
        PyObject *exception_table = NULL;
        PyObject *types_module=NULL, *code_type=NULL, *result=NULL;
        #if __PYX_LIMITED_VERSION_HEX < 0x030b0000
        PyObject *version_info;
        PyObject *py_minor_version = NULL;
        #endif
        long minor_version = 0;
        PyObject *type, *value, *traceback;
        PyErr_Fetch(&type, &value, &traceback);
        #if __PYX_LIMITED_VERSION_HEX >= 0x030b0000
        minor_version = 11;
        #else
        if (!(version_info = PySys_GetObject("version_info"))) goto end;
        if (!(py_minor_version = PySequence_GetItem(version_info, 1))) goto end;
        minor_version = PyLong_AsLong(py_minor_version);
        Py_DECREF(py_minor_version);
        if (minor_version == -1 && PyErr_Occurred()) goto end;
        #endif
        if (!(types_module = PyImport_ImportModule("types"))) goto end;
        if (!(code_type = PyObject_GetAttrString(types_module, "CodeType"))) goto end;
        if (minor_version <= 7) {
            (void)p;
            result = PyObject_CallFunction(code_type, "iiiiiOOOOOOiOOO", a, k, l, s, f, code,
                          c, n, v, fn, name, fline, lnos, fv, cell);
        } else if (minor_version <= 10) {
            result = PyObject_CallFunction(code_type, "iiiiiiOOOOOOiOOO", a,p, k, l, s, f, code,
                          c, n, v, fn, name, fline, lnos, fv, cell);
        } else {
            if (!(exception_table = PyBytes_FromStringAndSize(NULL, 0))) goto end;
            result = PyObject_CallFunction(code_type, "iiiiiiOOOOOOOiOOOO", a,p, k, l, s, f, code,
                          c, n, v, fn, name, name, fline, lnos, exception_table, fv, cell);
        }
    end:
        Py_XDECREF(code_type);
        Py_XDECREF(exception_table);
        Py_XDECREF(types_module);
        if (type) {
            PyErr_Restore(type, value, traceback);
        }
        return result;
    }
#elif PY_VERSION_HEX >= 0x030B0000
  static PyCodeObject* __Pyx__PyCode_New(int a, int p, int k, int l, int s, int f,
                                         PyObject *code, PyObject *c, PyObject* n, PyObject *v,
                                         PyObject *fv, PyObject *cell, PyObject* fn,
                                         PyObject *name, int fline, PyObject *lnos) {
    PyCodeObject *result;
    result =
      #if PY_VERSION_HEX >= 0x030C0000
        PyUnstable_Code_NewWithPosOnlyArgs
      #else
        PyCode_NewWithPosOnlyArgs
      #endif
        (a, p, k, l, s, f, code, c, n, v, fv, cell, fn, name, name, fline, lnos, __pyx_mstate_global->__pyx_empty_bytes);
    #if CYTHON_COMPILING_IN_CPYTHON && PY_VERSION_HEX >= 0x030c00A1
    if (likely(result))
        result->_co_firsttraceable = 0;
    #endif
    return result;
  }
#elif PY_VERSION_HEX >= 0x030800B2 && !CYTHON_COMPILING_IN_PYPY
  #define __Pyx__PyCode_New(a, p, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_NewWithPosOnlyArgs(a, p, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
#else
  #define __Pyx__PyCode_New(a, p, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
#endif
static PyObject* __Pyx_PyCode_New(
        const __Pyx_PyCode_New_function_description descr,
        PyObject * const *varnames,
        PyObject *filename,
        PyObject *funcname,
        const char *line_table,
        PyObject *tuple_dedup_map
) {
    PyObject *code_obj = NULL, *varnames_tuple_dedup = NULL, *code_bytes = NULL, *line_table_bytes = NULL;
    Py_ssize_t var_count = (Py_ssize_t) descr.nlocals;
    PyObject *varnames_tuple = PyTuple_New(var_count);
    if (unlikely(!varnames_tuple)) return NULL;
    for (Py_ssize_t i=0; i < var_count; i++) {
        Py_INCREF(varnames[i]);
        if (__Pyx_PyTuple_SET_ITEM(varnames_tuple, i, varnames[i]) != (0)) goto done;
    }
    #if CYTHON_COMPILING_IN_LIMITED_API
    varnames_tuple_dedup = PyDict_GetItem(tuple_dedup_map, varnames_tuple);
    if (!varnames_tuple_dedup) {
        if (unlikely(PyDict_SetItem(tuple_dedup_map, varnames_tuple, varnames_tuple) < 0)) goto done;
        varnames_tuple_dedup = varnames_tuple;
    }
    #else
    varnames_tuple_dedup = PyDict_SetDefault(tuple_dedup_map, varnames_tuple, varnames_tuple);
    if (unlikely(!varnames_tuple_dedup)) goto done;
    #endif
    #if CYTHON_AVOID_BORROWED_REFS
    Py_INCREF(varnames_tuple_dedup);
    #endif
    if (__PYX_LIMITED_VERSION_HEX >= (0x030b0000) && line_table != NULL
        && !CYTHON_COMPILING_IN_GRAAL) {
        line_table_bytes = PyBytes_FromStringAndSize(line_table, descr.line_table_length);
        if (unlikely(!line_table_bytes)) goto done;
        Py_ssize_t code_len = (descr.line_table_length * 2 + 4) & ~3;
        code_bytes = PyBytes_FromStringAndSize(NULL, code_len);
        if (unlikely(!code_bytes)) goto done;
        char* c_code_bytes = PyBytes_AsString(code_bytes);
        if (unlikely(!c_code_bytes)) goto done;
        memset(c_code_bytes, 0, (size_t) code_len);
    }
    code_obj = (PyObject*) __Pyx__PyCode_New(
        (int) descr.argcount,
        (int) descr.num_posonly_args,
        (int) descr.num_kwonly_args,
        (int) descr.nlocals,
        0,
        (int) descr.flags,
        code_bytes ? code_bytes : __pyx_mstate_global->__pyx_empty_bytes,
        __pyx_mstate_global->__pyx_empty_tuple,
        __pyx_mstate_global->__pyx_empty_tuple,
        varnames_tuple_dedup,
        __pyx_mstate_global->__pyx_empty_tuple,
        __pyx_mstate_global->__pyx_empty_tuple,
        filename,
        funcname,
        (int) descr.first_line,
        (__PYX_LIMITED_VERSION_HEX >= (0x030b0000) && line_table_bytes) ? line_table_bytes : __pyx_mstate_global->__pyx_empty_bytes
    );
done:
    Py_XDECREF(code_bytes);
    Py_XDECREF(line_table_bytes);
    #if CYTHON_AVOID_BORROWED_REFS
    Py_XDECREF(varnames_tuple_dedup);
    #endif
    Py_DECREF(varnames_tuple);
    return code_obj;
}

/* InitStrings */
static int __Pyx_InitStrings(__Pyx_StringTabEntry const *t, PyObject **target, const char* const* encoding_names) {
    while (t->s) {
        PyObject *str;
        if (t->is_unicode) {
            if (t->intern) {
                str = PyUnicode_InternFromString(t->s);
            } else if (t->encoding) {
                str = PyUnicode_Decode(t->s, t->n - 1, encoding_names[t->encoding], NULL);
            } else {
                str = PyUnicode_FromStringAndSize(t->s, t->n - 1);
            }
        } else {
            str = PyBytes_FromStringAndSize(t->s, t->n - 1);
        }
        if (!str)
            return -1;
        *target = str;
        if (PyObject_Hash(str) == -1)
            return -1;
        ++t;
        ++target;
    }
    return 0;
}

#include <string.h>
static CYTHON_INLINE Py_ssize_t __Pyx_ssize_strlen(const char *s) {
    size_t len = strlen(s);
    if (unlikely(len > (size_t) PY_SSIZE_T_MAX)) {
        PyErr_SetString(PyExc_OverflowError, "byte string is too long");
        return -1;
    }
    return (Py_ssize_t) len;
}
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char* c_str) {
    Py_ssize_t len = __Pyx_ssize_strlen(c_str);
    if (unlikely(len < 0)) return NULL;
    return __Pyx_PyUnicode_FromStringAndSize(c_str, len);
}
static CYTHON_INLINE PyObject* __Pyx_PyByteArray_FromString(const char* c_str) {
    Py_ssize_t len = __Pyx_ssize_strlen(c_str);
    if (unlikely(len < 0)) return NULL;
    return PyByteArray_FromStringAndSize(c_str, len);
}
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject* o) {
    Py_ssize_t ignore;
    return __Pyx_PyObject_AsStringAndSize(o, &ignore);
}
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_UTF8
static CYTHON_INLINE const char* __Pyx_PyUnicode_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
    if (unlikely(__Pyx_PyUnicode_READY(o) == -1)) return NULL;
#if CYTHON_COMPILING_IN_LIMITED_API
    {
        const char* result;
        Py_ssize_t unicode_length;
        CYTHON_MAYBE_UNUSED_VAR(unicode_length); // only for __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
        #if __PYX_LIMITED_VERSION_HEX < 0x030A0000
        if (unlikely(PyArg_Parse(o, "s#", &result, length) < 0)) return NULL;
        #else
        result = PyUnicode_AsUTF8AndSize(o, length);
        #endif
        #if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
        unicode_length = PyUnicode_GetLength(o);
        if (unlikely(unicode_length < 0)) return NULL;
        if (unlikely(unicode_length != *length)) {
            PyUnicode_AsASCIIString(o);
            return NULL;
        }
        #endif
        return result;
    }
#else
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
    if (likely(PyUnicode_IS_ASCII(o))) {
        *length = PyUnicode_GET_LENGTH(o);
        return PyUnicode_AsUTF8(o);
    } else {
        PyUnicode_AsASCIIString(o);
        return NULL;
    }
#else
    return PyUnicode_AsUTF8AndSize(o, length);
#endif
#endif
}
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_UTF8
    if (PyUnicode_Check(o)) {
        return __Pyx_PyUnicode_AsStringAndSize(o, length);
    } else
#endif
    if (PyByteArray_Check(o)) {
#if (CYTHON_ASSUME_SAFE_SIZE && CYTHON_ASSUME_SAFE_MACROS) || (CYTHON_COMPILING_IN_PYPY && (defined(PyByteArray_AS_STRING) && defined(PyByteArray_GET_SIZE)))
        *length = PyByteArray_GET_SIZE(o);
        return PyByteArray_AS_STRING(o);
#else
        *length = PyByteArray_Size(o);
        if (*length == -1) return NULL;
        return PyByteArray_AsString(o);
#endif
    } else
    {
        char* result;
        int r = PyBytes_AsStringAndSize(o, &result, length);
        if (unlikely(r < 0)) {
            return NULL;
        } else {
            return result;
        }
    }
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject* x) {
   int is_true = x == Py_True;
   if (is_true | (x == Py_False) | (x == Py_None)) return is_true;
   else return PyObject_IsTrue(x);
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrueAndDecref(PyObject* x) {
    int retval;
    if (unlikely(!x)) return -1;
    retval = __Pyx_PyObject_IsTrue(x);
    Py_DECREF(x);
    return retval;
}
static PyObject* __Pyx_PyNumber_LongWrongResultType(PyObject* result) {
    __Pyx_TypeName result_type_name = __Pyx_PyType_GetFullyQualifiedName(Py_TYPE(result));
    if (PyLong_Check(result)) {
        if (PyErr_WarnFormat(PyExc_DeprecationWarning, 1,
                "__int__ returned non-int (type " __Pyx_FMT_TYPENAME ").  "
                "The ability to return an instance of a strict subclass of int is deprecated, "
                "and may be removed in a future version of Python.",
                result_type_name)) {
            __Pyx_DECREF_TypeName(result_type_name);
            Py_DECREF(result);
            return NULL;
        }
        __Pyx_DECREF_TypeName(result_type_name);
        return result;
    }
    PyErr_Format(PyExc_TypeError,
                 "__int__ returned non-int (type " __Pyx_FMT_TYPENAME ")",
                 result_type_name);
    __Pyx_DECREF_TypeName(result_type_name);
    Py_DECREF(result);
    return NULL;
}
static CYTHON_INLINE PyObject* __Pyx_PyNumber_Long(PyObject* x) {
#if CYTHON_USE_TYPE_SLOTS
  PyNumberMethods *m;
#endif
  PyObject *res = NULL;
  if (likely(PyLong_Check(x)))
      return __Pyx_NewRef(x);
#if CYTHON_USE_TYPE_SLOTS
  m = Py_TYPE(x)->tp_as_number;
  if (likely(m && m->nb_int)) {
      res = m->nb_int(x);
  }
#else
  if (!PyBytes_CheckExact(x) && !PyUnicode_CheckExact(x)) {
      res = PyNumber_Long(x);
  }
#endif
  if (likely(res)) {
      if (unlikely(!PyLong_CheckExact(res))) {
          return __Pyx_PyNumber_LongWrongResultType(res);
      }
  }
  else if (!PyErr_Occurred()) {
      PyErr_SetString(PyExc_TypeError,
                      "an integer is required");
  }
  return res;
}
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject* b) {
  Py_ssize_t ival;
  PyObject *x;
  if (likely(PyLong_CheckExact(b))) {
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(__Pyx_PyLong_IsCompact(b))) {
        return __Pyx_PyLong_CompactValue(b);
    } else {
      const digit* digits = __Pyx_PyLong_Digits(b);
      const Py_ssize_t size = __Pyx_PyLong_SignedDigitCount(b);
      switch (size) {
         case 2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
      }
    }
    #endif
    return PyLong_AsSsize_t(b);
  }
  x = PyNumber_Index(b);
  if (!x) return -1;
  ival = PyLong_AsSsize_t(x);
  Py_DECREF(x);
  return ival;
}
static CYTHON_INLINE Py_hash_t __Pyx_PyIndex_AsHash_t(PyObject* o) {
  if (sizeof(Py_hash_t) == sizeof(Py_ssize_t)) {
    return (Py_hash_t) __Pyx_PyIndex_AsSsize_t(o);
  } else {
    Py_ssize_t ival;
    PyObject *x;
    x = PyNumber_Index(o);
    if (!x) return -1;
    ival = PyLong_AsLong(x);
    Py_DECREF(x);
    return ival;
  }
}
static CYTHON_INLINE PyObject *__Pyx_Owned_Py_None(int b) {
    CYTHON_UNUSED_VAR(b);
    return __Pyx_NewRef(Py_None);
}
static CYTHON_INLINE PyObject * __Pyx_PyBool_FromLong(long b) {
  return b ? __Pyx_NewRef(Py_True) : __Pyx_NewRef(Py_False);
}
static CYTHON_INLINE PyObject * __Pyx_PyLong_FromSize_t(size_t ival) {
    return PyLong_FromSize_t(ival);
}
#if CYTHON_USE_PYLONG_INTERNALS
static CYTHON_INLINE int __Pyx_PyLong_CompactAsLong(PyObject *x, long *return_value) {
    if (unlikely(!__Pyx_PyLong_IsCompact(x)))
        return 0;
    Py_ssize_t value = __Pyx_PyLong_CompactValue(x);
    if ((sizeof(long) < sizeof(Py_ssize_t)) && unlikely(value != (long) value))
        return 0;
    *return_value = (long) value;
    return 1;
}
#endif


/* MultiPhaseInitModuleState */
#if CYTHON_PEP489_MULTI_PHASE_INIT && CYTHON_USE_MODULE_STATE
#ifndef CYTHON_MODULE_STATE_LOOKUP_THREAD_SAFE
#if (CYTHON_COMPILING_IN_LIMITED_API || PY_VERSION_HEX >= 0x030C0000)
  #define CYTHON_MODULE_STATE_LOOKUP_THREAD_SAFE 1
#else
  #define CYTHON_MODULE_STATE_LOOKUP_THREAD_SAFE 0
#endif
#endif
#if CYTHON_MODULE_STATE_LOOKUP_THREAD_SAFE && !CYTHON_ATOMICS
#error "Module state with PEP489 requires atomics. Currently that's one of\
 C11, C++11, gcc atomic intrinsics or MSVC atomic intrinsics"
#endif
#if !CYTHON_MODULE_STATE_LOOKUP_THREAD_SAFE
#define __Pyx_ModuleStateLookup_Lock()
#define __Pyx_ModuleStateLookup_Unlock()
#elif !CYTHON_COMPILING_IN_LIMITED_API && PY_VERSION_HEX >= 0x030d0000
static PyMutex __Pyx_ModuleStateLookup_mutex = {0};
#define __Pyx_ModuleStateLookup_Lock() PyMutex_Lock(&__Pyx_ModuleStateLookup_mutex)
#define __Pyx_ModuleStateLookup_Unlock() PyMutex_Unlock(&__Pyx_ModuleStateLookup_mutex)
#elif defined(__cplusplus) && __cplusplus >= 201103L
#include <mutex>
static std::mutex __Pyx_ModuleStateLookup_mutex;
#define __Pyx_ModuleStateLookup_Lock() __Pyx_ModuleStateLookup_mutex.lock()
#define __Pyx_ModuleStateLookup_Unlock() __Pyx_ModuleStateLookup_mutex.unlock()
#elif defined(__STDC_VERSION__) && (__STDC_VERSION__ > 201112L) && !defined(__STDC_NO_THREADS__)
#include <threads.h>
static mtx_t __Pyx_ModuleStateLookup_mutex;
static once_flag __Pyx_ModuleStateLookup_mutex_once_flag = ONCE_FLAG_INIT;
static void __Pyx_ModuleStateLookup_initialize_mutex(void) {
    mtx_init(&__Pyx_ModuleStateLookup_mutex, mtx_plain);
}
#define __Pyx_ModuleStateLookup_Lock()\
  call_once(&__Pyx_ModuleStateLookup_mutex_once_flag, __Pyx_ModuleStateLookup_initialize_mutex);\
  mtx_lock(&__Pyx_ModuleStateLookup_mutex)
#define __Pyx_ModuleStateLookup_Unlock() mtx_unlock(&__Pyx_ModuleStateLookup_mutex)
#elif defined(HAVE_PTHREAD_H)
#include <pthread.h>
static pthread_mutex_t __Pyx_ModuleStateLookup_mutex = PTHREAD_MUTEX_INITIALIZER;
#define __Pyx_ModuleStateLookup_Lock() pthread_mutex_lock(&__Pyx_ModuleStateLookup_mutex)
#define __Pyx_ModuleStateLookup_Unlock() pthread_mutex_unlock(&__Pyx_ModuleStateLookup_mutex)
#elif defined(_WIN32)
#include <Windows.h>  // synchapi.h on its own doesn't work
static SRWLOCK __Pyx_ModuleStateLookup_mutex = SRWLOCK_INIT;
#define __Pyx_ModuleStateLookup_Lock() AcquireSRWLockExclusive(&__Pyx_ModuleStateLookup_mutex)
#define __Pyx_ModuleStateLookup_Unlock() ReleaseSRWLockExclusive(&__Pyx_ModuleStateLookup_mutex)
#else
#error "No suitable lock available for CYTHON_MODULE_STATE_LOOKUP_THREAD_SAFE.\
 Requires C standard >= C11, or C++ standard >= C++11,\
 or pthreads, or the Windows 32 API, or Python >= 3.13."
#endif
typedef struct {
    int64_t id;
    PyObject *module;
} __Pyx_InterpreterIdAndModule;
typedef struct {
    char interpreter_id_as_index;
    Py_ssize_t count;
    Py_ssize_t allocated;
    __Pyx_InterpreterIdAndModule table[1];
} __Pyx_ModuleStateLookupData;
#define __PYX_MODULE_STATE_LOOKUP_SMALL_SIZE 32
#if CYTHON_MODULE_STATE_LOOKUP_THREAD_SAFE
static __pyx_atomic_int_type __Pyx_ModuleStateLookup_read_counter = 0;
#endif
#if CYTHON_MODULE_STATE_LOOKUP_THREAD_SAFE
static __pyx_atomic_ptr_type __Pyx_ModuleStateLookup_data = 0;
#else
static __Pyx_ModuleStateLookupData* __Pyx_ModuleStateLookup_data = NULL;
#endif
static __Pyx_InterpreterIdAndModule* __Pyx_State_FindModuleStateLookupTableLowerBound(
        __Pyx_InterpreterIdAndModule* table,
        Py_ssize_t count,
        int64_t interpreterId) {
    __Pyx_InterpreterIdAndModule* begin = table;
    __Pyx_InterpreterIdAndModule* end = begin + count;
    if (begin->id == interpreterId) {
        return begin;
    }
    while ((end - begin) > __PYX_MODULE_STATE_LOOKUP_SMALL_SIZE) {
        __Pyx_InterpreterIdAndModule* halfway = begin + (end - begin)/2;
        if (halfway->id == interpreterId) {
            return halfway;
        }
        if (halfway->id < interpreterId) {
            begin = halfway;
        } else {
            end = halfway;
        }
    }
    for (; begin < end; ++begin) {
        if (begin->id >= interpreterId) return begin;
    }
    return begin;
}
static PyObject *__Pyx_State_FindModule(CYTHON_UNUSED void* dummy) {
    int64_t interpreter_id = PyInterpreterState_GetID(__Pyx_PyInterpreterState_Get());
    if (interpreter_id == -1) return NULL;
#if CYTHON_MODULE_STATE_LOOKUP_THREAD_SAFE
    __Pyx_ModuleStateLookupData* data = (__Pyx_ModuleStateLookupData*)__pyx_atomic_pointer_load_relaxed(&__Pyx_ModuleStateLookup_data);
    {
        __pyx_atomic_incr_acq_rel(&__Pyx_ModuleStateLookup_read_counter);
        if (likely(data)) {
            __Pyx_ModuleStateLookupData* new_data = (__Pyx_ModuleStateLookupData*)__pyx_atomic_pointer_load_acquire(&__Pyx_ModuleStateLookup_data);
            if (likely(data == new_data)) {
                goto read_finished;
            }
        }
        __pyx_atomic_decr_acq_rel(&__Pyx_ModuleStateLookup_read_counter);
        __Pyx_ModuleStateLookup_Lock();
        __pyx_atomic_incr_relaxed(&__Pyx_ModuleStateLookup_read_counter);
        data = (__Pyx_ModuleStateLookupData*)__pyx_atomic_pointer_load_relaxed(&__Pyx_ModuleStateLookup_data);
        __Pyx_ModuleStateLookup_Unlock();
    }
  read_finished:;
#else
    __Pyx_ModuleStateLookupData* data = __Pyx_ModuleStateLookup_data;
#endif
    __Pyx_InterpreterIdAndModule* found = NULL;
    if (unlikely(!data)) goto end;
    if (data->interpreter_id_as_index) {
        if (interpreter_id < data->count) {
            found = data->table+interpreter_id;
        }
    } else {
        found = __Pyx_State_FindModuleStateLookupTableLowerBound(
            data->table, data->count, interpreter_id);
    }
  end:
    {
        PyObject *result=NULL;
        if (found && found->id == interpreter_id) {
            result = found->module;
        }
#if CYTHON_MODULE_STATE_LOOKUP_THREAD_SAFE
        __pyx_atomic_decr_acq_rel(&__Pyx_ModuleStateLookup_read_counter);
#endif
        return result;
    }
}
#if CYTHON_MODULE_STATE_LOOKUP_THREAD_SAFE
static void __Pyx_ModuleStateLookup_wait_until_no_readers(void) {
    while (__pyx_atomic_load(&__Pyx_ModuleStateLookup_read_counter) != 0);
}
#else
#define __Pyx_ModuleStateLookup_wait_until_no_readers()
#endif
static int __Pyx_State_AddModuleInterpIdAsIndex(__Pyx_ModuleStateLookupData **old_data, PyObject* module, int64_t interpreter_id) {
    Py_ssize_t to_allocate = (*old_data)->allocated;
    while (to_allocate <= interpreter_id) {
        if (to_allocate == 0) to_allocate = 1;
        else to_allocate *= 2;
    }
    __Pyx_ModuleStateLookupData *new_data = *old_data;
    if (to_allocate != (*old_data)->allocated) {
         new_data = (__Pyx_ModuleStateLookupData *)realloc(
            *old_data,
            sizeof(__Pyx_ModuleStateLookupData)+(to_allocate-1)*sizeof(__Pyx_InterpreterIdAndModule));
        if (!new_data) {
            PyErr_NoMemory();
            return -1;
        }
        for (Py_ssize_t i = new_data->allocated; i < to_allocate; ++i) {
            new_data->table[i].id = i;
            new_data->table[i].module = NULL;
        }
        new_data->allocated = to_allocate;
    }
    new_data->table[interpreter_id].module = module;
    if (new_data->count < interpreter_id+1) {
        new_data->count = interpreter_id+1;
    }
    *old_data = new_data;
    return 0;
}
static void __Pyx_State_ConvertFromInterpIdAsIndex(__Pyx_ModuleStateLookupData *data) {
    __Pyx_InterpreterIdAndModule *read = data->table;
    __Pyx_InterpreterIdAndModule *write = data->table;
    __Pyx_InterpreterIdAndModule *end = read + data->count;
    for (; read<end; ++read) {
        if (read->module) {
            write->id = read->id;
            write->module = read->module;
            ++write;
        }
    }
    data->count = write - data->table;
    for (; write<end; ++write) {
        write->id = 0;
        write->module = NULL;
    }
    data->interpreter_id_as_index = 0;
}
static int __Pyx_State_AddModule(PyObject* module, CYTHON_UNUSED void* dummy) {
    int64_t interpreter_id = PyInterpreterState_GetID(__Pyx_PyInterpreterState_Get());
    if (interpreter_id == -1) return -1;
    int result = 0;
    __Pyx_ModuleStateLookup_Lock();
#if CYTHON_MODULE_STATE_LOOKUP_THREAD_SAFE
    __Pyx_ModuleStateLookupData *old_data = (__Pyx_ModuleStateLookupData *)
            __pyx_atomic_pointer_exchange(&__Pyx_ModuleStateLookup_data, 0);
#else
    __Pyx_ModuleStateLookupData *old_data = __Pyx_ModuleStateLookup_data;
#endif
    __Pyx_ModuleStateLookupData *new_data = old_data;
    if (!new_data) {
        new_data = (__Pyx_ModuleStateLookupData *)calloc(1, sizeof(__Pyx_ModuleStateLookupData));
        if (!new_data) {
            result = -1;
            PyErr_NoMemory();
            goto end;
        }
        new_data->allocated = 1;
        new_data->interpreter_id_as_index = 1;
    }
    __Pyx_ModuleStateLookup_wait_until_no_readers();
    if (new_data->interpreter_id_as_index) {
        if (interpreter_id < __PYX_MODULE_STATE_LOOKUP_SMALL_SIZE) {
            result = __Pyx_State_AddModuleInterpIdAsIndex(&new_data, module, interpreter_id);
            goto end;
        }
        __Pyx_State_ConvertFromInterpIdAsIndex(new_data);
    }
    {
        Py_ssize_t insert_at = 0;
        {
            __Pyx_InterpreterIdAndModule* lower_bound = __Pyx_State_FindModuleStateLookupTableLowerBound(
                new_data->table, new_data->count, interpreter_id);
            assert(lower_bound);
            insert_at = lower_bound - new_data->table;
            if (unlikely(insert_at < new_data->count && lower_bound->id == interpreter_id)) {
                lower_bound->module = module;
                goto end;  // already in table, nothing more to do
            }
        }
        if (new_data->count+1 >= new_data->allocated) {
            Py_ssize_t to_allocate = (new_data->count+1)*2;
            new_data =
                (__Pyx_ModuleStateLookupData*)realloc(
                    new_data,
                    sizeof(__Pyx_ModuleStateLookupData) +
                    (to_allocate-1)*sizeof(__Pyx_InterpreterIdAndModule));
            if (!new_data) {
                result = -1;
                new_data = old_data;
                PyErr_NoMemory();
                goto end;
            }
            new_data->allocated = to_allocate;
        }
        ++new_data->count;
        int64_t last_id = interpreter_id;
        PyObject *last_module = module;
        for (Py_ssize_t i=insert_at; i<new_data->count; ++i) {
            int64_t current_id = new_data->table[i].id;
            new_data->table[i].id = last_id;
            last_id = current_id;
            PyObject *current_module = new_data->table[i].module;
            new_data->table[i].module = last_module;
            last_module = current_module;
        }
    }
  end:
#if CYTHON_MODULE_STATE_LOOKUP_THREAD_SAFE
    __pyx_atomic_pointer_exchange(&__Pyx_ModuleStateLookup_data, new_data);
#else
    __Pyx_ModuleStateLookup_data = new_data;
#endif
    __Pyx_ModuleStateLookup_Unlock();
    return result;
}
static int __Pyx_State_RemoveModule(CYTHON_UNUSED void* dummy) {
    int64_t interpreter_id = PyInterpreterState_GetID(__Pyx_PyInterpreterState_Get());
    if (interpreter_id == -1) return -1;
    __Pyx_ModuleStateLookup_Lock();
#if CYTHON_MODULE_STATE_LOOKUP_THREAD_SAFE
    __Pyx_ModuleStateLookupData *data = (__Pyx_ModuleStateLookupData *)
            __pyx_atomic_pointer_exchange(&__Pyx_ModuleStateLookup_data, 0);
#else
    __Pyx_ModuleStateLookupData *data = __Pyx_ModuleStateLookup_data;
#endif
    if (data->interpreter_id_as_index) {
        if (interpreter_id < data->count) {
            data->table[interpreter_id].module = NULL;
        }
        goto done;
    }
    {
        __Pyx_ModuleStateLookup_wait_until_no_readers();
        __Pyx_InterpreterIdAndModule* lower_bound = __Pyx_State_FindModuleStateLookupTableLowerBound(
            data->table, data->count, interpreter_id);
        if (!lower_bound) goto done;
        if (lower_bound->id != interpreter_id) goto done;
        __Pyx_InterpreterIdAndModule *end = data->table+data->count;
        for (;lower_bound<end-1; ++lower_bound) {
            lower_bound->id = (lower_bound+1)->id;
            lower_bound->module = (lower_bound+1)->module;
        }
    }
    --data->count;
    if (data->count == 0) {
        free(data);
        data = NULL;
    }
  done:
#if CYTHON_MODULE_STATE_LOOKUP_THREAD_SAFE
    __pyx_atomic_pointer_exchange(&__Pyx_ModuleStateLookup_data, data);
#else
    __Pyx_ModuleStateLookup_data = data;
#endif
    __Pyx_ModuleStateLookup_Unlock();
    return 0;
}
#endif

/* #### Code section: utility_code_pragmas_end ### */
#ifdef _MSC_VER
#pragma warning( pop )
#endif



/* #### Code section: end ### */
#endif /* Py_PYTHON_H */
